<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [DELM: a Python toolkit for Data Extraction with Language Models](https://arxiv.org/abs/2509.20617)
*Eric Fithian,Kirill Skobelev*

Main category: cs.IR

TL;DR: DELM是一个开源的Python工具包，用于快速迭代基于LLM的数据提取流程，并量化不同方法之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型数据标注工作流大多依赖临时脚本，导致可复现性、鲁棒性和系统性评估困难。

Method: DELM提供模块化框架，包含结构化输出、内置验证、灵活的数据加载和评分策略、高效批处理，以及对LLM API的稳健支持（重试逻辑、结果缓存、成本跟踪等）。

Result: 通过两个案例研究展示了DELM的能力：一个是新的提示优化算法，另一个是量化在决定哪些段落传递给LLM时关键词选择在成本和覆盖率之间的权衡。

Conclusion: DELM解决了LLM数据提取流程中的可复现性和系统性评估问题，为研究人员提供了实用的工具支持。

Abstract: Large Language Models (LLMs) have become powerful tools for annotating
unstructured data. However, most existing workflows rely on ad hoc scripts,
making reproducibility, robustness, and systematic evaluation difficult. To
address these challenges, we introduce DELM (Data Extraction with Language
Models), an open-source Python toolkit designed for rapid experimental
iteration of LLM-based data extraction pipelines and for quantifying the
trade-offs between them. DELM minimizes boilerplate code and offers a modular
framework with structured outputs, built-in validation, flexible data-loading
and scoring strategies, and efficient batch processing. It also includes robust
support for working with LLM APIs, featuring retry logic, result caching,
detailed cost tracking, and comprehensive configuration management. We showcase
DELM's capabilities through two case studies: one featuring a novel prompt
optimization algorithm, and another illustrating how DELM quantifies trade-offs
between cost and coverage when selecting keywords to decide which paragraphs to
pass to an LLM. DELM is available at
\href{https://github.com/Center-for-Applied-AI/delm}{\texttt{github.com/Center-for-Applied-AI/delm}}.

</details>


### [2] [Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems](https://arxiv.org/abs/2509.20769)
*Tuo Zhang,Yuechun Sun,Ruiliang Liu*

Main category: cs.IR

TL;DR: 本文提出了一种基于检索增强生成（RAG）的系统，用于考古文物的来源分析，通过整合多模态检索和大型视觉语言模型（VLM）来支持专家推理。


<details>
  <summary>Details</summary>
Motivation: 旨在减轻学者在分析大量比较语料库时的认知负担，为考古文物分析提供具体的起点。

Method: 系统构建了包含参考文本和图像的双模态知识库，支持原始视觉、边缘增强和语义检索，以识别风格相似的文物。检索到的候选对象由VLM合成，生成结构化的推断，包括年代、地理和文化归属以及解释性理由。

Result: 在英国博物馆的东欧亚青铜时代文物集上进行的专家评估表明，该系统能够产生有意义且可解释的输出。

Conclusion: 该系统为学者提供了有效的分析工具，显著减轻了处理大量比较数据的认知负担，并提供了有价值的分析起点。

Abstract: In this work, we present a retrieval-augmented generation (RAG)-based system
for provenance analysis of archaeological artifacts, designed to support expert
reasoning by integrating multimodal retrieval and large vision-language models
(VLMs). The system constructs a dual-modal knowledge base from reference texts
and images, enabling raw visual, edge-enhanced, and semantic retrieval to
identify stylistically similar objects. Retrieved candidates are synthesized by
the VLM to generate structured inferences, including chronological,
geographical, and cultural attributions, alongside interpretive justifications.
We evaluate the system on a set of Eastern Eurasian Bronze Age artifacts from
the British Museum. Expert evaluation demonstrates that the system produces
meaningful and interpretable outputs, offering scholars concrete starting
points for analysis and significantly alleviating the cognitive burden of
navigating vast comparative corpora.

</details>


### [3] [Performance Consistency of Learning Methods for Information Retrieval Tasks](https://arxiv.org/abs/2509.20804)
*Meng Yuan,Justin Zobel*

Main category: cs.IR

TL;DR: 本文通过分析信息检索方法中基于种子的模型性能变化，发现传统统计模型稳定，而基于Transformer的模型在不同种子下性能波动巨大，质疑了以往研究结果的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估信息检索方法性能测量的准确性和鲁棒性，特别关注依赖种子的机器学习方法（如Transformer模型）的性能稳定性问题。

Method: 使用三种不同的信息检索任务，通过引导测试集和随机种子集来检查性能变化，比较传统统计学习模型和基于Transformer的学习模型。

Result: 统计模型表现稳定，而Transformer模型在不同种子下性能变化巨大：11个案例中有9个F1分数的标准差超过0.075，11个精度值中有7个的标准差超过0.125。

Conclusion: Transformer模型对训练不稳定性高度敏感，以往研究中基于小于0.02差异的方法改进证据可能不可靠，强调了严格评估实践的必要性。

Abstract: A range of approaches have been proposed for estimating the accuracy or
robustness of the measured performance of IR methods. One is to use
bootstrapping of test sets, which, as we confirm, provides an estimate of
variation in performance. For IR methods that rely on a seed, such as those
that involve machine learning, another approach is to use a random set of seeds
to examine performance variation. Using three different IR tasks we have used
such randomness to examine a range of traditional statistical learning models
and transformer-based learning models. While the statistical models are stable,
the transformer models show huge variation as seeds are changed. In 9 of 11
cases the F1-scores (in the range 0.0--1.0) had a standard deviation of over
0.075; while 7 of 11 precision values (also in the range 0.0--1.0) had a
standard deviation of over 0.125. This is in a context where differences of
less than 0.02 have been used as evidence of method improvement. Our findings
highlight the vulnerability of transformer models to training instabilities and
moreover raise questions about the reliability of previous results, thus
underscoring the need for rigorous evaluation practices.

</details>


### [4] [RecIS: Sparse to Dense, A Unified Training Framework for Recommendation Models](https://arxiv.org/abs/2509.20883)
*Hua Zong,Qingtao Zeng,Zhengxiong Zhou,Zhihua Han,Zhensong Yan,Mingjie Liu,Hechen Sun,Jiawei Liu,Yiwen Hu,Qi Wang,YiHan Xian,Wenjie Guo,Houyuan Xiang,Zhiyuan Zeng,Xiangrong Sheng,Bencheng Yan,Nan Hu,Yuheng Huang,Jinqing Lian,Ziru Xu,Yan Zhang,Ju Huang,Siran Yang,Huimin Yi,Jiamang Wang,Pengjie Wang,Han Zhu,Jian Wu,Dan Ou,Jian Xu,Haihong Tang,Yuning Jiang,Bo Zheng,Lin Qu*

Main category: cs.IR

TL;DR: RecIS是一个统一的稀疏-稠密训练框架，基于PyTorch生态系统，旨在满足工业级推荐模型与大模型集成的训练需求，并对稀疏组件进行优化以超越TensorFlow推荐模型的效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决工业级推荐模型与大模型集成时的训练需求，并超越TensorFlow推荐模型的效率，需要一个统一的稀疏-稠密训练框架。

Method: 提出RecIS框架，稀疏组件进行专门优化，稠密组件利用PyTorch生态系统的现有优化技术，基于PyTorch生态系统构建统一的稀疏-稠密训练框架。

Result: RecIS已在阿里巴巴内部用于多个大模型增强的推荐训练任务，一些传统的稀疏模型也开始在该框架中进行训练。

Conclusion: RecIS是一个有效的统一稀疏-稠密训练框架，能够满足工业级推荐模型与大模型集成的训练需求，并在效率上优于TensorFlow推荐模型。

Abstract: In this paper, we propose RecIS, a unified Sparse-Dense training framework
designed to achieve two primary goals: 1. Unified Framework To create a Unified
sparse-dense training framework based on the PyTorch ecosystem that meets the
training needs of industrial-grade recommendation models that integrated with
large models. 2.System Optimization To optimize the sparse component, offering
superior efficiency over the TensorFlow-based recommendation models. The dense
component, meanwhile, leverages existing optimization technologies within the
PyTorch ecosystem. Currently, RecIS is being used in Alibaba for numerous
large-model enhanced recommendation training tasks, and some traditional sparse
models have also begun training in it.

</details>


### [5] [FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets](https://arxiv.org/abs/2509.20904)
*Kairui Fu,Tao Zhang,Shuwen Xiao,Ziyang Wang,Xinming Zhang,Chenchi Zhang,Yuliang Yan,Junjun Zheng,Yu Li,Zhihong Chen,Jian Wu,Xiangheng Kong,Shengyu Zhang,Kun Kuang,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: FORGE是一个用于生成检索中语义标识符构建的综合性基准，解决了当前SID研究面临的三大挑战：缺乏大规模多模态数据集、SID生成优化策略研究有限、工业部署中在线收敛慢的问题。


<details>
  <summary>Details</summary>
Motivation: 当前语义标识符研究面临三个主要挑战：(1)缺乏大规模公开多模态数据集，(2)SID生成优化策略研究有限且依赖昂贵的生成检索训练进行评估，(3)工业部署中在线收敛速度慢。

Method: 提出了FORGE基准，包含从淘宝平台采样的250万商品多模态特征和140亿用户交互数据。探索了多种SID构建优化方法，并提出两个与推荐性能正相关的新型SID评估指标，无需生成检索训练即可评估。同时引入离线预训练模式加速在线收敛。

Result: 离线实验验证了优化方法的有效性，在线分析显示在服务3亿日活用户的平台上交易量提升0.35%。提出的新指标与推荐性能正相关，离线预训练使在线收敛时间减半。

Conclusion: FORGE为语义标识符研究提供了全面的基准和实用解决方案，解决了数据集、评估方法和收敛速度等关键问题，在工业场景中展现出显著的实际价值。

Abstract: Semantic identifiers (SIDs) have gained increasing attention in generative
retrieval (GR) due to their meaningful semantic discriminability. However,
current research on SIDs faces three main challenges: (1) the absence of
large-scale public datasets with multimodal features, (2) limited investigation
into optimization strategies for SID generation, which typically rely on costly
GR training for evaluation, and (3) slow online convergence in industrial
deployment. To address these challenges, we propose FORGE, a comprehensive
benchmark for FOrming semantic identifieR in Generative rEtrieval with
industrial datasets. Specifically, FORGE is equipped with a dataset comprising
14 billion user interactions and multimodal features of 250 million items
sampled from Taobao, one of the biggest e-commerce platforms in China.
Leveraging this dataset, FORGE explores several optimizations to enhance the
SID construction and validates their effectiveness via offline experiments
across different settings and tasks. Further online analysis conducted on our
platform, which serves over 300 million users daily, reveals a 0.35% increase
in transaction count, highlighting the practical impact of our method.
Regarding the expensive SID validation accompanied by the full training of GRs,
we propose two novel metrics of SID that correlate positively with
recommendation performance, enabling convenient evaluations without any GR
training. For real-world applications, FORGE introduces an offline pretraining
schema that reduces online convergence by half. The code and data are available
at https://github.com/selous123/al_sid.

</details>


### [6] [Markup Language Modeling for Web Document Understanding](https://arxiv.org/abs/2509.20940)
*Su Liu,Bin Bi,Jan Bakus,Paritosh Kumar Velalam,Vijay Yella,Vinod Hegde*

Main category: cs.IR

TL;DR: 本文提出MarkupLM++，一种改进的网页信息提取方法，通过扩展DOM树内部节点的预测来构建最新的产品数据库。实验表明，使用更大更多样化的训练集能提高整体提取准确率，最终模型达到F1分数0.805。


<details>
  <summary>Details</summary>
Motivation: 构建最新的产品数据库对于电子商务系统（如客户分析和产品推荐）至关重要，需要从购物评论网站提取详细信息。

Method: 在从不同规模的评论网站收集的产品数据上微调MarkupLM，并开发了MarkupLM++变体，扩展了对DOM树内部节点的预测。

Result: 使用更大更多样化的训练集提高了整体提取准确率；包含内部节点有助于某些产品属性，但导致整体性能略有下降。最终模型精度0.906，召回率0.724，F1分数0.805。

Conclusion: MarkupLM++在网页信息提取任务中表现良好，通过扩展DOM树内部节点的预测和多样化训练集，有效提升了产品信息提取的准确性。

Abstract: Web information extraction (WIE) is an important part of many e-commerce
systems, supporting tasks like customer analysis and product recommendation. In
this work, we look at the problem of building up-to-date product databases by
extracting detailed information from shopping review websites. We fine-tuned
MarkupLM on product data gathered from review sites of different sizes and then
developed a variant we call MarkupLM++, which extends predictions to internal
nodes of the DOM tree. Our experiments show that using larger and more diverse
training sets improves extraction accuracy overall. We also find that including
internal nodes helps with some product attributes, although it leads to a
slight drop in overall performance. The final model reached a precision of
0.906, recall of 0.724, and an F1 score of 0.805.

</details>


### [7] [Rejuvenating Cross-Entropy Loss in Knowledge Distillation for Recommender Systems](https://arxiv.org/abs/2509.20989)
*Zhangchi Zhu,Wei Zhang*

Main category: cs.IR

TL;DR: 本文分析了推荐系统中知识蒸馏的交叉熵损失，揭示了CE损失与NDCG之间的联系，并提出了一种新的RCE-KD方法来改善蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中的知识蒸馏主要关注对最可能被偏好的项目进行排序蒸馏，但只能在项目子集上计算。研究发现当在项目子集上进行知识蒸馏时，最小化CE损失只能在一定条件下最大化NDCG的下界，这与蒸馏教师模型top项目排序的目标存在矛盾。

Method: 提出了Rejuvenated Cross-Entropy for Knowledge Distillation (RCE-KD)方法：将教师模型的top项目根据学生模型是否高度排名分为两个子集，对于不符合条件的子集，使用采样策略通过师生协作来近似闭包假设，并自适应地结合两个子集上的损失。

Result: 广泛的实验证明了该方法的有效性，代码已开源。

Conclusion: RCE-KD方法成功弥补了知识蒸馏目标与理论支持之间的差距，为推荐系统中的知识蒸馏提供了更有效的解决方案。

Abstract: This paper analyzes Cross-Entropy (CE) loss in knowledge distillation (KD)
for recommender systems. KD for recommender systems targets at distilling
rankings, especially among items most likely to be preferred, and can only be
computed on a small subset of items. Considering these features, we reveal the
connection between CE loss and NDCG in the field of KD. We prove that when
performing KD on an item subset, minimizing CE loss maximizes the lower bound
of NDCG, only if an assumption of closure is satisfied. It requires that the
item subset consists of the student's top items. However, this contradicts our
goal of distilling rankings of the teacher's top items. We empirically
demonstrate the vast gap between these two kinds of top items. To bridge the
gap between our goal and theoretical support, we propose Rejuvenated
Cross-Entropy for Knowledge Distillation (RCE-KD). It splits the top items
given by the teacher into two subsets based on whether they are highly ranked
by the student. For the subset that defies the condition, a sampling strategy
is devised to use teacher-student collaboration to approximate our assumption
of closure. We also combine the losses on the two subsets adaptively. Extensive
experiments demonstrate the effectiveness of our method. Our code is available
at https://anonymous.4open.science/r/RCE-KD.

</details>


### [8] [IntSR: An Integrated Generative Framework for Search and Recommendation](https://arxiv.org/abs/2509.21179)
*Huimin Yan,Longfei Xu,Junjie Sun,Ni Ou,Wei Luo,Xing Tan,Ran Cheng,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: IntSR是一个统一的生成式搜索与推荐框架，通过区分查询模态来整合搜索和推荐任务，解决了集成S&R行为带来的计算复杂度增加和动态语料库导致的错误模式学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统主要关注检索和排名的统一，但忽视了搜索和推荐任务的整合。搜索使用显式用户请求，推荐依赖隐式用户兴趣，而检索与排名的区别在于查询是否为目标项本身。

Method: 提出IntSR框架，使用不同的查询模态来整合搜索和推荐任务，同时解决集成S&R行为带来的计算复杂度增加和动态语料库导致的错误模式学习问题。

Result: IntSR已在Amap的多个场景中成功部署，显著提升了数字资产GMV(+3.02%)、POI推荐CTR(+2.76%)和出行方式建议ACC(+5.13%)。

Conclusion: IntSR通过统一的生成式框架有效整合了搜索和推荐任务，在实际应用中取得了显著效果提升。

Abstract: Generative recommendation has emerged as a promising paradigm, demonstrating
remarkable results in both academic benchmarks and industrial applications.
However, existing systems predominantly focus on unifying retrieval and ranking
while neglecting the integration of search and recommendation (S&R) tasks. What
makes search and recommendation different is how queries are formed: search
uses explicit user requests, while recommendation relies on implicit user
interests. As for retrieval versus ranking, the distinction comes down to
whether the queries are the target items themselves. Recognizing the query as
central element, we propose IntSR, an integrated generative framework for S&R.
IntSR integrates these disparate tasks using distinct query modalities. It also
addresses the increased computational complexity associated with integrated S&R
behaviors and the erroneous pattern learning introduced by a dynamically
changing corpus. IntSR has been successfully deployed across various scenarios
in Amap, leading to substantial improvements in digital asset's GMV(+3.02%),
POI recommendation's CTR(+2.76%), and travel mode suggestion's ACC(+5.13%).

</details>


### [9] [Interactive Recommendation Agent with Active User Commands](https://arxiv.org/abs/2509.21317)
*Jiakai Tang,Yujie Luo,Xunke Xi,Fei Sun,Xueyang Feng,Sunhao Dai,Chao Yi,Dian Chen,Zhujin Gao,Yang Li,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: 论文提出了一种名为交互式推荐流（IRF）的新范式，通过自然语言命令让用户在推荐流中主动控制推荐策略，取代传统的被动反馈机制。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖粗粒度的被动反馈（如喜欢/不喜欢），无法捕捉用户细微的行为动机和意图，也无法识别具体影响用户满意度的物品属性，导致偏好建模不准确。

Method: 开发了RecBot双智能体架构：解析器智能体将语言表达转换为结构化偏好，规划器智能体动态编排自适应工具链进行实时策略调整。采用模拟增强的知识蒸馏实现高效部署。

Result: 通过离线和长期在线实验，RecBot在用户满意度和业务成果方面均显示出显著提升。

Conclusion: IRF范式通过自然语言交互有效弥合了用户意图与系统理解之间的差距，显著提升了推荐系统的效果和用户满意度。

Abstract: Traditional recommender systems rely on passive feedback mechanisms that
limit users to simple choices such as like and dislike. However, these
coarse-grained signals fail to capture users' nuanced behavior motivations and
intentions. In turn, current systems cannot also distinguish which specific
item attributes drive user satisfaction or dissatisfaction, resulting in
inaccurate preference modeling. These fundamental limitations create a
persistent gap between user intentions and system interpretations, ultimately
undermining user satisfaction and harming system effectiveness.
  To address these limitations, we introduce the Interactive Recommendation
Feed (IRF), a pioneering paradigm that enables natural language commands within
mainstream recommendation feeds. Unlike traditional systems that confine users
to passive implicit behavioral influence, IRF empowers active explicit control
over recommendation policies through real-time linguistic commands. To support
this paradigm, we develop RecBot, a dual-agent architecture where a Parser
Agent transforms linguistic expressions into structured preferences and a
Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly
policy adjustment. To enable practical deployment, we employ
simulation-augmented knowledge distillation to achieve efficient performance
while maintaining strong reasoning capabilities. Through extensive offline and
long-term online experiments, RecBot shows significant improvements in both
user satisfaction and business outcomes.

</details>
