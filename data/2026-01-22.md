<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Legal Retrieval for Public Defenders](https://arxiv.org/abs/2601.14348)
*Dominik Stammbach,Kylie Zhang,Patty Liu,Nimra Nadeem,Lucia Zheng,Peter Henderson*

Main category: cs.IR

TL;DR: 开发NJ BriefBank检索工具，帮助公设辩护人查找相关上诉状，提升法律研究和写作效率，并创建公设辩护检索数据集。


<details>
  <summary>Details</summary>
Motivation: 公设辩护人面临案件量大、资源有限的挑战，但缺乏AI工具支持日常工作的证据。需要开发实用的AI工具来协助法律检索。

Method: 与纽泽西公设辩护办公室合作开发NJ BriefBank检索工具，通过法律推理查询扩展、领域特定数据和合成示例提升检索质量，并创建分类体系和标注数据集。

Result: 现有法律检索基准在公设辩护检索中效果不佳，但加入领域知识（包括法律推理查询扩展）能显著提升检索质量。提供了实用的检索工具和数据集。

Conclusion: 为公设辩护开发实用可靠的AI检索工具提供了起点，并为更现实的法律检索基准奠定了基础，有助于改善公设辩护人的工作条件。

Abstract: AI tools are increasingly suggested as solutions to assist public agencies with heavy workloads. In public defense, where a constitutional right to counsel meets the complexities of law, overwhelming caseloads and constrained resources, practitioners face especially taxing conditions. Yet, there is little evidence of how AI could meaningfully support defenders' day-to-day work. In partnership with the New Jersey Office of the Public Defender, we develop the NJ BriefBank, a retrieval tool which surfaces relevant appellate briefs to streamline legal research and writing. We show that existing legal retrieval benchmarks fail to transfer to public defense search, however adding domain knowledge improves retrieval quality. This includes query expansion with legal reasoning, domain-specific data and curated synthetic examples. To facilitate further research, we provide a taxonomy of realistic defender search queries and release a manually annotated public defense retrieval dataset. Together, our work offers starting points towards building practical, reliable retrieval AI tools for public defense, and towards more realistic legal retrieval benchmarks.

</details>


### [2] [Trust Me on This: A User Study of Trustworthiness for RAG Responses](https://arxiv.org/abs/2601.14460)
*Weronika Łajewska,Krisztian Balog*

Main category: cs.IR

TL;DR: 研究探讨不同解释类型如何影响用户对检索增强生成系统回答的信任度，发现解释能引导用户选择更高质量回答，但信任还受回答清晰度、可操作性和用户先验知识影响


<details>
  <summary>Details</summary>
Motivation: 生成式AI在信息访问系统中常提供缺乏透明度的合成答案，需要研究如何通过不同类型的解释来增强用户对检索增强生成系统回答的信任

Method: 采用两阶段对照用户研究，参与者从成对回答中选择更可信的回答，一组质量较高，另一组质量较低，分别测试三种解释类型：来源归属、事实依据和信息覆盖度

Result: 解释显著引导用户选择更高质量回答，但信任不仅取决于客观质量，还受回答清晰度、可操作性和用户先验知识的强烈影响

Conclusion: 在设计AI信息访问系统时，需要结合多种解释策略，并考虑用户认知因素，以建立更有效的信任机制

Abstract: The integration of generative AI into information access systems often presents users with synthesized answers that lack transparency. This study investigates how different types of explanations can influence user trust in responses from retrieval-augmented generation systems. We conducted a controlled, two-stage user study where participants chose the more trustworthy response from a pair-one objectively higher quality than the other-both with and without one of three explanation types: (1) source attribution, (2) factual grounding, and (3) information coverage. Our results show that while explanations significantly guide users toward selecting higher quality responses, trust is not dictated by objective quality alone: Users' judgments are also heavily influenced by response clarity, actionability, and their own prior knowledge.

</details>


### [3] [Predicting Retrieval Utility and Answer Quality in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.14546)
*Fangzheng Tian,Debasis Ganguly,Craig Macdonald*

Main category: cs.IR

TL;DR: 本文提出在检索增强生成（RAG）中预测检索性能（RPP）和生成性能（GPP）的方法，通过结合检索器中心特征、阅读器中心特征和文档质量特征，使用线性回归模型获得最准确的RAG性能估计。


<details>
  <summary>Details</summary>
Motivation: RAG中生成答案的质量很大程度上受检索文档上下文信息的影响。关键挑战在于预测检索文档的效用（使用上下文相比无上下文的性能提升）和最终答案的正确性与相关性质量。需要开发系统方法来预测RAG性能。

Method: 定义两个预测任务：检索性能预测（RPP）和生成性能预测（GPP）。假设检索文档的主题相关性与其效用相关，因此可以调整查询性能预测（QPP）方法用于RPP和GPP。此外，引入阅读器中心特征（如LLM在给定查询条件下对检索上下文的困惑度）和查询无关的文档质量与可读性特征。使用线性回归模型结合多类别特征进行预测。

Result: 在Natural Questions（NQ）数据集上的实验表明，结合多个特征类别的预测器能够获得最准确的RAG性能估计。多特征组合方法优于单一特征类别。

Conclusion: 通过结合检索器中心特征、阅读器中心特征和文档质量特征，可以有效地预测RAG中的检索性能和生成性能。多特征集成方法为RAG性能预测提供了有效的解决方案。

Abstract: The quality of answers generated by large language models (LLMs) in retrieval-augmented generation (RAG) is largely influenced by the contextual information contained in the retrieved documents. A key challenge for improving RAG is to predict both the utility of retrieved documents -- quantified as the performance gain from using context over generation without context -- and the quality of the final answers in terms of correctness and relevance. In this paper, we define two prediction tasks within RAG. The first is retrieval performance prediction (RPP), which estimates the utility of retrieved documents. The second is generation performance prediction (GPP), which estimates the final answer quality. We hypothesise that in RAG, the topical relevance of retrieved documents correlates with their utility, suggesting that query performance prediction (QPP) approaches can be adapted for RPP and GPP. Beyond these retriever-centric signals, we argue that reader-centric features, such as the LLM's perplexity of the retrieved context conditioned on the input query, can further enhance prediction accuracy for both RPP and GPP. Finally, we propose that features reflecting query-agnostic document quality and readability can also provide useful signals to the predictions. We train linear regression models with the above categories of predictors for both RPP and GPP. Experiments on the Natural Questions (NQ) dataset show that combining predictors from multiple feature categories yields the most accurate estimates of RAG performance.

</details>


### [4] [When Text-as-Vision Meets Semantic IDs in Generative Recommendation: An Empirical Study](https://arxiv.org/abs/2601.14697)
*Shutong Qiao,Wei Yuan,Tong Chen,Xiangyu Zhao,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.IR

TL;DR: 该论文提出使用OCR视觉方法处理推荐系统中的文本描述，通过将文本渲染为图像并用OCR模型编码，解决了传统文本编码器对符号化、属性中心文本处理不佳的问题，在单模态和多模态生成推荐中都取得了更好效果。


<details>
  <summary>Details</summary>
Motivation: 传统文本编码器主要针对自然语言优化，但推荐系统中的商品描述通常包含数字、单位、缩写等符号化内容，导致语义碎片化。在多模态生成推荐中，文本和图像嵌入的几何结构不匹配问题进一步降低了融合效果。

Method: 将文本作为视觉信号处理，通过将商品描述渲染成图像，然后使用基于视觉的OCR模型进行编码，获得OCR文本表示，用于语义ID学习。

Result: 在四个数据集和两种生成骨干网络上的实验表明，OCR文本表示在单模态和多模态设置中都能匹配或超越标准文本嵌入。即使在极端空间分辨率压缩下，OCR语义ID仍保持鲁棒性。

Conclusion: 将文本作为视觉信号处理，使用OCR方法进行语义ID学习，能有效解决推荐系统中符号化文本的编码问题，提高多模态融合效果，具有实际部署的鲁棒性和效率优势。

Abstract: Semantic ID learning is a key interface in Generative Recommendation (GR) models, mapping items to discrete identifiers grounded in side information, most commonly via a pretrained text encoder. However, these text encoders are primarily optimized for well-formed natural language. In real-world recommendation data, item descriptions are often symbolic and attribute-centric, containing numerals, units, and abbreviations. These text encoders can break these signals into fragmented tokens, weakening semantic coherence and distorting relationships among attributes. Worse still, when moving to multimodal GR, relying on standard text encoders introduces an additional obstacle: text and image embeddings often exhibit mismatched geometric structures, making cross-modal fusion less effective and less stable.
  In this paper, we revisit representation design for Semantic ID learning by treating text as a visual signal. We conduct a systematic empirical study of OCR-based text representations, obtained by rendering item descriptions into images and encoding them with vision-based OCR models. Experiments across four datasets and two generative backbones show that OCR-text consistently matches or surpasses standard text embeddings for Semantic ID learning in both unimodal and multimodal settings. Furthermore, we find that OCR-based Semantic IDs remain robust under extreme spatial-resolution compression, indicating strong robustness and efficiency in practical deployments.

</details>


### [5] [Unified Multimodal and Multilingual Retrieval via Multi-Task Learning with NLU Integration](https://arxiv.org/abs/2601.14714)
*Xinyuan Zhang,Lina Zhang,Lisung Chen,Guangyao Liu,Shuai Nie,Jiaming Xu,Runyu Shi,Ying Huang,Guoquan Zhang*

Main category: cs.IR

TL;DR: 提出多任务学习框架，统一图像、长短文本和意图查询的特征表示，首次联合优化多语言图像检索、文本检索和自然语言理解任务


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在文本检索任务上表现不佳，且额外文本编码器增加存储和推理开销，尤其在多语言环境下检索效率低下

Method: 采用多任务学习框架，集成图像和文本检索，共享文本编码器并通过NLU特征增强意图理解和检索准确性

Result: 这是首个在单一框架内联合优化多语言图像检索、文本检索和自然语言理解任务的工作

Conclusion: 提出的方法解决了现有多模态检索系统的局限性，通过统一特征表示和共享编码器提高了检索效率和准确性

Abstract: Multimodal retrieval systems typically employ Vision Language Models (VLMs) that encode images and text independently into vectors within a shared embedding space. Despite incorporating text encoders, VLMs consistently underperform specialized text models on text-only retrieval tasks. Moreover, introducing additional text encoders increases storage, inference overhead, and exacerbates retrieval inefficiencies, especially in multilingual settings. To address these limitations, we propose a multi-task learning framework that unifies the feature representation across images, long and short texts, and intent-rich queries. To our knowledge, this is the first work to jointly optimize multilingual image retrieval, text retrieval, and natural language understanding (NLU) tasks within a single framework. Our approach integrates image and text retrieval with a shared text encoder that is enhanced by NLU features for intent understanding and retrieval accuracy.

</details>


### [6] [PULSE: Socially-Aware User Representation Modeling Toward Parameter-Efficient Graph Collaborative Filtering](https://arxiv.org/abs/2601.14720)
*Doyun Choi,Cheonwoo Lee,Biniyam Aschalew Tolera,Taewook Ham,Chanyoung Park,Jaemin Yoo*

Main category: cs.IR

TL;DR: PULSE提出了一种参数高效的社交推荐框架，通过从社交信号构建用户表示而非为每个用户学习显式嵌入，将参数规模减少50%，同时在各种交互稀疏度下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的社交推荐方法面临高计算成本和有限可扩展性的挑战，因为它们需要为所有用户和物品分配显式嵌入，导致参数数量庞大。

Method: PULSE框架通过从社交有意义的信号构建用户表示，而不为每个用户创建显式可学习嵌入，实现了参数高效的用户表示学习。

Result: 与最轻量的图协同过滤基线相比，PULSE将参数规模减少高达50%，并在13个基线上实现了最先进的性能，从冷启动用户到高度活跃用户的各种交互稀疏度下都表现优异。

Conclusion: PULSE通过参数高效的设计解决了现有社交推荐方法的可扩展性问题，同时保持了优异的推荐性能，为大规模社交推荐系统提供了实用的解决方案。

Abstract: Graph-based social recommendation (SocialRec) has emerged as a powerful extension of graph collaborative filtering (GCF), which leverages graph neural networks (GNNs) to capture multi-hop collaborative signals from user-item interactions. These methods enrich user representations by incorporating social network information into GCF, thereby integrating additional collaborative signals from social relations. However, existing GCF and graph-based SocialRec approaches face significant challenges: they incur high computational costs and suffer from limited scalability due to the large number of parameters required to assign explicit embeddings to all users and items. In this work, we propose PULSE (Parameter-efficient User representation Learning with Social Knowledge), a framework that addresses this limitation by constructing user representations from socially meaningful signals without creating an explicit learnable embedding for each user. PULSE reduces the parameter size by up to 50% compared to the most lightweight GCF baseline. Beyond parameter efficiency, our method achieves state-of-the-art performance, outperforming 13 GCF and graph-based social recommendation baselines across varying levels of interaction sparsity, from cold-start to highly active users, through a time- and memory-efficient modeling process.

</details>


### [7] [What Should I Cite? A RAG Benchmark for Academic Citation Prediction](https://arxiv.org/abs/2601.14949)
*Leqi Zheng,Jiajun Zhang,Canzhi Chen,Chaokun Wang,Hongwei Li,Yuying Li,Yaoxin Mao,Shannan Yan,Zixin Song,Zhiyuan Feng,Zhaolu Kang,Zirong Chen,Hang Zhang,Qiang Liu,Liang Wang,Ziyang Liu*

Main category: cs.IR

TL;DR: CiteRAG是首个集成检索增强生成（RAG）的学术引用预测基准，包含多级检索策略、专用检索器和生成器，提供全面的评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着网络学术出版物快速增长，每年发表的论文数量激增，学者越来越难以找到相关的前期工作。引用预测旨在自动推荐合适的参考文献，帮助学者在日益扩大的科学文献中导航。

Method: 1) 建立两个不同粒度的引用预测任务实例；2) 构建包含554k论文的三级大规模语料库；3) 提出多级混合RAG方法，通过对比学习微调嵌入模型以捕捉复杂引用关系；4) 使用最先进的语言模型进行广泛实验。

Result: 构建了包含7,267个实例的任务1数据集和8,541个实例的任务2数据集，创建了包含554k论文的语料库，开发了开源工具包，并证明了框架的有效性。

Conclusion: CiteRAG为引用预测提供了首个全面的评估框架，可作为其他科学领域的方法论模板，其开源代码和数据已公开发布。

Abstract: With the rapid growth of Web-based academic publications, more and more papers are being published annually, making it increasingly difficult to find relevant prior work. Citation prediction aims to automatically suggest appropriate references, helping scholars navigate the expanding scientific literature. Here we present \textbf{CiteRAG}, the first comprehensive retrieval-augmented generation (RAG)-integrated benchmark for evaluating large language models on academic citation prediction, featuring a multi-level retrieval strategy, specialized retrievers, and generators. Our benchmark makes four core contributions: (1) We establish two instances of the citation prediction task with different granularity. Task 1 focuses on coarse-grained list-specific citation prediction, while Task 2 targets fine-grained position-specific citation prediction. To enhance these two tasks, we build a dataset containing 7,267 instances for Task 1 and 8,541 instances for Task 2, enabling comprehensive evaluation of both retrieval and generation. (2) We construct a three-level large-scale corpus with 554k papers spanning many major subfields, using an incremental pipeline. (3) We propose a multi-level hybrid RAG approach for citation prediction, fine-tuning embedding models with contrastive learning to capture complex citation relationships, paired with specialized generation models. (4) We conduct extensive experiments across state-of-the-art language models, including closed-source APIs, open-source models, and our fine-tuned generators, demonstrating the effectiveness of our framework. Our open-source toolkit enables reproducible evaluation and focuses on academic literature, providing the first comprehensive evaluation framework for citation prediction and serving as a methodological template for other scientific domains. Our source code and data are released at https://github.com/LQgdwind/CiteRAG.

</details>


### [8] [From Insight to Intervention: Interpretable Neuron Steering for Controlling Popularity Bias in Recommender Systems](https://arxiv.org/abs/2601.15122)
*Parviz Ahmadov,Masoud Mansoury*

Main category: cs.IR

TL;DR: PopSteer：一种利用稀疏自编码器（SAE）解释和缓解推荐系统中流行度偏差的后处理方法，通过识别编码流行度信号的神经元并调整其激活来平衡公平性与准确性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中普遍存在流行度偏差问题，少数热门项目占据大部分曝光，而多数非热门项目被忽视，这降低了推荐质量并导致不公平。现有缓解方法虽然有一定效果，但通常缺乏透明度，难以解释其运作机制。

Method: 提出PopSteer后处理方法：1）使用稀疏自编码器（SAE）复制训练好的推荐模型行为，实现神经元级可解释性；2）创建对热门或非热门项目有强烈偏好的合成用户；3）通过激活模式识别编码流行度信号的神经元；4）调整最具偏差神经元的激活来引导推荐结果。

Result: 在三个公共数据集上使用序列推荐模型进行实验，结果表明PopSteer能显著提升公平性，同时对准确性影响最小，提供了可解释的洞察力，并能对公平性-准确性权衡进行细粒度控制。

Conclusion: PopSteer提供了一种透明、可解释的方法来缓解推荐系统中的流行度偏差，通过神经元级干预实现了公平性与准确性的有效平衡，为推荐系统的公平性研究提供了新思路。

Abstract: Popularity bias is a pervasive challenge in recommender systems, where a few popular items dominate attention while the majority of less popular items remain underexposed. This imbalance can reduce recommendation quality and lead to unfair item exposure. Although existing mitigation methods address this issue to some extent, they often lack transparency in how they operate. In this paper, we propose a post-hoc approach, PopSteer, that leverages a Sparse Autoencoder (SAE) to both interpret and mitigate popularity bias in recommendation models. The SAE is trained to replicate a trained model's behavior while enabling neuron-level interpretability. By introducing synthetic users with strong preferences for either popular or unpopular items, we identify neurons encoding popularity signals through their activation patterns. We then steer recommendations by adjusting the activations of the most biased neurons. Experiments on three public datasets with a sequential recommendation model demonstrate that PopSteer significantly enhances fairness with minimal impact on accuracy, while providing interpretable insights and fine-grained control over the fairness-accuracy trade-off.

</details>


### [9] [Beyond the Geometric Curse: High-Dimensional N-Gram Hashing for Dense Retrieval](https://arxiv.org/abs/2601.15205)
*Sangeet Sharma*

Main category: cs.IR

TL;DR: NUMEN通过确定性字符哈希将文本直接映射到高维向量，无需训练即可超越BM25在检索任务上的表现


<details>
  <summary>Details</summary>
Motivation: 当前强大的7B参数嵌入模型在简单检索任务上表现不如几十年前的BM25方法，理论表明这是由于维度瓶颈问题——将无限的语言细微差别压缩到小的固定长度向量中

Method: NUMEN采用确定性字符哈希方法，完全移除学习过程，直接将语言投影到高维向量，无需训练，支持无限词汇表，几何容量可按需扩展

Result: 在LIMIT基准测试中，NUMEN在32,768维度下达到93.90%的Recall@100，首次正式超越稀疏BM25基线的93.6%

Conclusion: 密集检索的真正问题不在于架构，而在于嵌入层本身；解决方案不是更智能的训练，而是提供更多的表达空间

Abstract: Why do even the most powerful 7B-parameter embedding models struggle with simple retrieval tasks that the decades old BM25 handles with ease? Recent theory suggests that this happens because of a dimensionality bottleneck. This occurs when we force infinite linguistic nuances into small, fixed-length learned vectors. We developed NUMEN to break this bottleneck by removing the learning process entirely. Instead of training heavy layers to map text to a constrained space, NUMEN uses deterministic character hashing to project language directly onto high-dimensional vectors. This approach requires no training, supports an unlimited vocabulary, and allows the geometric capacity scale as needed. On the LIMIT benchmark, NUMEN achieves 93.90 % Recall@100 at 32,768 dimensions. This makes it the first dense retrieval model to officially surpass the sparse BM25 baseline 93.6 %. Our findings show that the real problem in dense retrieval isn't the architecture, but the embedding layer itself. The solution isn't necessarily smarter training, but simply providing more room to breathe.

</details>
