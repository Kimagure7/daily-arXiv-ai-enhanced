<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction](https://arxiv.org/abs/2512.07846)
*Guoyao Li,Ran He,Shusen Jing,Kayhan Behdin,Yubo Wang,Sundara Raman Ramachandran,Chanh Nguyen,Jian Sheng,Xiaojing Ma,Chuanrui Zhu,Sriram Vasudevan,Muchen Wu,Sayan Ghosh,Lin Su,Qingquan Song,Xiaoqing Wang,Zhipeng Wang,Qing Lan,Yanning Chen,Jingwei Wu,Luke Simon,Wenjing Zhang,Qi Guo,Fedor Borisyuk*

Main category: cs.IR

TL;DR: MixLM是一种新型LLM排序框架，通过混合文本和嵌入令牌表示输入，将项目描述从数千文本令牌压缩为几个嵌入令牌，显著提升系统吞吐量10倍，同时保持相关性指标。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语义理解方面表现出色，但在工业级延迟和吞吐要求下计算开销过高。特别是交叉编码器排序系统通常需要处理长上下文预填充工作负载，因为模型需要同时处理用户、查询和项目信息。

Method: 提出MixLM框架，使用混合交互（文本和嵌入令牌的混合）表示输入。将所有目录项目编码为少量嵌入令牌并存储在近线缓存中，在线推理时使用编码后的项目描述，从而将项目长度从数千文本令牌减少到几个嵌入令牌。

Result: 在相同延迟预算下，MixLM将吞吐量提高了10.0倍，同时保持了相关性指标。效率提升使得LLM驱动的搜索能够全流量部署，在线A/B测试中每日活跃用户显著增加0.47%。

Conclusion: MixLM通过创新的混合令牌表示方法，在保持LLM语义优势的同时显著降低了计算开销，为工业级搜索应用中的LLM部署提供了可行的解决方案。

Abstract: Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under industrial latency and throughput requirements. In particular, cross-encoder ranking systems often create long context prefill-heavy workloads, as the model has to be presented with the user, query and item information. To this end, we propose MixLM, a novel LLM-based ranking framework, which significantly improves the system throughput via reducing the input context length, while preserving the semantic strength of cross-encoder rankers. In contrast to a standard ranking system where the context is presented to the model as pure text, we propose to use mix-interaction, a mixture of text and embedding tokens to represent the input. Specifically, MixLM encodes all items in the catalog into a few embedding tokens and stores in a nearline cache. The encoded item descriptions are used during online inference, effectively reducing the item length from a few thousand text tokens to a few embedding tokens. We share insights from deploying our MixLM framework to a real-world search application at LinkedIn, including a detailed discussion of our training pipelines, as well as a thorough analysis of our online serving infrastructure optimization. Comparing with strong baselines, MixLM increased throughput by 10.0x under the same latency budget, while maintaining relevance metrics. The efficiency gains delivered by MixLM enabled full-traffic deployment of LLM-powered search, which resulted in a significant 0.47% increase in Daily Active Users (DAU) in online A/B tests.

</details>


### [2] [Detecting Privileged Documents by Ranking Connected Network Entities](https://arxiv.org/abs/2512.08073)
*Jianping Zhang,Han Qin,Nathaniel Huber-Fliflet*

Main category: cs.IR

TL;DR: 该论文提出了一种基于链接分析的方法，通过从电子邮件头元数据构建人际关系网络来识别特权文档，利用实体与律师的互动频率来量化特权通信的可能性。


<details>
  <summary>Details</summary>
Motivation: 在电子发现（e-discovery）和法律审查过程中，识别特权文档（如律师-客户特权通信）是一项重要但耗时的任务。传统方法主要依赖关键词搜索或手动审查，效率较低且容易遗漏。需要一种更系统的方法来自动识别可能包含特权通信的文档。

Method: 1. 从电子邮件头元数据中提取人类实体并构建网络；2. 基于已知法律专业人士列表将实体分类为律师或非律师；3. 核心假设：与律师频繁互动的个人更可能参与特权通信；4. 开发算法为网络中的每个实体分配分数，量化其参与特权通信的可能性；5. 结合实体分数和连接强度来增强特权文档识别。

Result: 实验结果表明，该算法在特权文档检测中能够有效对法律实体进行排名。通过利用实体间的网络关系和互动模式，该方法提高了识别特权文档的准确性和效率。

Conclusion: 基于链接分析的方法为特权文档识别提供了一种有效的自动化解决方案。通过分析人际关系网络和互动模式，该方法能够量化实体参与特权通信的可能性，从而辅助法律审查过程，减少人工工作量并提高识别准确性。

Abstract: This paper presents a link analysis approach for identifying privileged documents by constructing a network of human entities derived from email header metadata. Entities are classified as either counsel or non-counsel based on a predefined list of known legal professionals. The core assumption is that individuals with frequent interactions with lawyers are more likely to participate in privileged communications. To quantify this likelihood, an algorithm assigns a score to each entity within the network. By utilizing both entity scores and the strength of their connections, the method enhances the identification of privileged documents. Experimental results demonstrate the algorithm's effectiveness in ranking legal entities for privileged document detection.

</details>


### [3] [A Comparative Study of Retrieval Methods in Azure AI Search](https://arxiv.org/abs/2512.08078)
*Qiang Mao,Han Qin,Robert Neary,Charles Wang,Fusheng Wei,Jianping Zhang,Nathaniel Huber-Fliflet*

Main category: cs.IR

TL;DR: 评估Azure AI Search中不同检索方法（关键词、语义、向量、混合、混合语义）在电子取证早期案件评估中的表现，为法律从业者选择RAG配置提供指导。


<details>
  <summary>Details</summary>
Motivation: 律师需要超越传统关键词和语义搜索，利用大语言模型进行自然语言查询以提高文档审查效率。特别是在电子取证的早期案件评估阶段，需要快速理解数据、识别关键事实和风险。

Method: 在微软Azure的RAG框架中，比较Azure AI Search的五种检索方法：关键词检索、语义检索、向量检索、混合检索和混合语义检索，评估每种方法生成AI回答的准确性、相关性和一致性。

Result: 研究提供了不同检索方法在准确性、相关性和一致性方面的性能比较结果，帮助法律从业者了解各种RAG配置的实际效果。

Conclusion: 法律从业者可以利用本研究结果来优化未来RAG配置的选择，提高电子取证早期案件评估的效率和效果。

Abstract: Increasingly, attorneys are interested in moving beyond keyword and semantic search to improve the efficiency of how they find key information during a document review task. Large language models (LLMs) are now seen as tools that attorneys can use to ask natural language questions of their data during document review to receive accurate and concise answers. This study evaluates retrieval strategies within Microsoft Azure's Retrieval-Augmented Generation (RAG) framework to identify effective approaches for Early Case Assessment (ECA) in eDiscovery. During ECA, legal teams analyze data at the outset of a matter to gain a general understanding of the data and attempt to determine key facts and risks before beginning full-scale review. In this paper, we compare the performance of Azure AI Search's keyword, semantic, vector, hybrid, and hybrid-semantic retrieval methods. We then present the accuracy, relevance, and consistency of each method's AI-generated responses. Legal practitioners can use the results of this study to enhance how they select RAG configurations in the future.

</details>


### [4] [Leveraging Machine Learning and Large Language Models for Automated Image Clustering and Description in Legal Discovery](https://arxiv.org/abs/2512.08079)
*Qiang Mao,Fusheng Wei,Robert Neary,Charles Wang,Han Qin,Jianping Zhang,Nathaniel Huber-Fliflet*

Main category: cs.IR

TL;DR: 本文系统研究了自动聚类描述生成方法，通过整合图像聚类、图像描述和LLM，评估了采样策略、提示技术和生成方法，发现20张图像的策略采样效果接近全量但计算成本更低，LLM方法优于传统TF-IDF基线。


<details>
  <summary>Details</summary>
Motivation: 数字图像数量的快速增长给法律发现、数字档案和内容管理带来了巨大挑战。企业和法律团队需要在严格时间压力下组织和分析大规模图像集合，手动审查不切实际且成本高昂，因此需要高效的自动化方法来组织和描述大规模图像数据集。

Method: 采用K-means聚类将图像分为20个视觉连贯的簇，使用Azure AI Vision API生成基础描述。评估三个关键维度：(1)图像采样策略：随机、基于质心、分层、混合和基于密度的采样与使用全部图像对比；(2)提示技术：标准提示与思维链提示对比；(3)描述生成方法：LLM方法与传统的TF-IDF和基于模板的方法对比。使用语义相似性和覆盖度指标评估描述质量。

Result: 结果显示，每个簇使用20张图像的战略采样在显著降低计算成本的同时，性能与使用全部图像相当，只有分层采样显示出适度的性能下降。LLM方法始终优于TF-IDF基线，标准提示在此任务中优于思维链提示。

Conclusion: 这些发现为部署可扩展、准确的聚类描述系统提供了实用指导，支持法律发现和其他需要自动组织大规模图像集合的高容量工作流程。

Abstract: The rapid increase in digital image creation and retention presents substantial challenges during legal discovery, digital archive, and content management. Corporations and legal teams must organize, analyze, and extract meaningful insights from large image collections under strict time pressures, making manual review impractical and costly. These demands have intensified interest in automated methods that can efficiently organize and describe large-scale image datasets. This paper presents a systematic investigation of automated cluster description generation through the integration of image clustering, image captioning, and large language models (LLMs). We apply K-means clustering to group images into 20 visually coherent clusters and generate base captions using the Azure AI Vision API. We then evaluate three critical dimensions of the cluster description process: (1) image sampling strategies, comparing random, centroid-based, stratified, hybrid, and density-based sampling against using all cluster images; (2) prompting techniques, contrasting standard prompting with chain-of-thought prompting; and (3) description generation methods, comparing LLM-based generation with traditional TF-IDF and template-based approaches. We assess description quality using semantic similarity and coverage metrics. Results show that strategic sampling with 20 images per cluster performs comparably to exhaustive inclusion while significantly reducing computational cost, with only stratified sampling showing modest degradation. LLM-based methods consistently outperform TF-IDF baselines, and standard prompts outperform chain-of-thought prompts for this task. These findings provide practical guidance for deploying scalable, accurate cluster description systems that support high-volume workflows in legal discovery and other domains requiring automated organization of large image collections.

</details>


### [5] [Exploiting the Randomness of Large Language Models (LLM) in Text Classification Tasks: Locating Privileged Documents in Legal Matters](https://arxiv.org/abs/2512.08083)
*Keith Huffman,Jianping Zhang,Nathaniel Huber-Fliflet,Fusheng Wei,Peter Gronvall*

Main category: cs.IR

TL;DR: 本文实证研究LLM在法律特权文件检测中的随机性作用，发现LLM能有效识别特权文件，随机性控制参数对性能影响有限，但利用随机性的方法能显著提升准确性并增强合规信心。


<details>
  <summary>Details</summary>
Motivation: 法律文本分类中，LLM已表现出强大性能，但随机性对分类结果的影响尚未充分研究。特别是在特权文件检测等关键法律应用中，理解并控制随机性对提高模型可靠性和合规信心至关重要。

Method: 通过实证研究，从四个维度分析LLM在特权文件检测中的随机性作用：(1) LLM识别特权文件的有效性；(2) 随机性控制参数对分类输出的影响；(3) 随机性对整体分类性能的影响；(4) 开发利用随机性提升准确性的方法。

Result: 实验结果显示：LLM能有效识别特权文件；随机性控制参数对分类性能影响有限；更重要的是，开发的利用随机性方法能显著提升准确性；该方法还能增强企业在制裁合规流程中对LLM输出的信心。

Conclusion: LLM在法律特权文件检测中表现有效，随机性控制参数影响不大，但通过特定方法利用随机性能显著提升准确性。随着组织越来越多地依赖LLM增强合规工作流程，减少输出变异性有助于建立对LLM衍生制裁筛查决策的内部和监管信心。

Abstract: In legal matters, text classification models are most often used to filter through large datasets in search of documents that meet certain pre-selected criteria like relevance to a certain subject matter, such as legally privileged communications and attorney-directed documents. In this context, large language models have demonstrated strong performance. This paper presents an empirical study investigating the role of randomness in LLM-based classification for attorney-client privileged document detection, focusing on four key dimensions: (1) the effectiveness of LLMs in identifying legally privileged documents, (2) the influence of randomness control parameters on classification outputs, (3) their impact on overall classification performance, and (4) a methodology for leveraging randomness to enhance accuracy. Experimental results showed that LLMs can identify privileged documents effectively, randomness control parameters have minimal impact on classification performance, and importantly, our developed methodology for leveraging randomness can have a significant impact on improving accuracy. Notably, this methodology that leverages randomness could also enhance a corporation's confidence in an LLM's output when incorporated into its sanctions-compliance processes. As organizations increasingly rely on LLMs to augment compliance workflows, reducing output variability helps build internal and regulatory confidence in LLM-derived sanctions-screening decisions.

</details>


### [6] [Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring](https://arxiv.org/abs/2512.08398)
*Jiin Park,Hyuna Jeon,Yoonseo Lee,Jisu Hong,Misuk Kim*

Main category: cs.IR

TL;DR: 本文提出了一种基于本体论的知识图谱构建方法，专门针对工业标准文档，通过分层语义结构分析和LLM三元组抽取，有效处理表格、条件规则和数值计算等复杂内容。


<details>
  <summary>Details</summary>
Motivation: 工业标准文档包含大量技术信息和复杂规则，采用表格、应用范围、约束条件、例外情况和数值计算等多种结构化格式，使得知识图谱构建特别具有挑战性。传统方法难以有效表示这些领域特定的语义。

Method: 将文档组织为分层语义结构，将句子和表格分解为基于条件和数值规则的原子命题，通过LLM进行三元组抽取，并将其整合到本体知识图谱中。该方法同时捕获文档的层次结构和逻辑结构。

Result: 构建了规则、表格和多跳问答数据集以及有毒条款检测数据集，实现了本体感知的KG-RAG框架进行对比评估。实验结果显示，该方法在所有问答类型上都比现有KG-RAG方法有显著性能提升。

Conclusion: 研究表明，即使对于条件、约束和范围交织的工业文档，可靠且可扩展的知识表示也是可行的，这有助于未来领域特定的RAG开发和智能文档管理。

Abstract: Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.

</details>


### [7] [VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions for Multimodal Recommendation](https://arxiv.org/abs/2512.08702)
*Jinfeng Xu,Zheyu Chen,Shuo Yang,Jinze Li,Zitong Wan,Hewei Wang,Weijie Liu,Yijie Li,Edith C. H. Ngai*

Main category: cs.IR

TL;DR: VI-MMRec是一个模型无关、无需额外训练成本的框架，通过基于模态特征相似性的虚拟用户-物品交互来缓解多模态推荐中的数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推荐模型受限于数据稀疏问题，用户通常只与少量物品交互，导致模型将未观察到的物品任意视为负样本，限制了推荐效果。

Method: 提出两种策略：Overlay（独立聚合模态特定相似性）和Synergistic（融合跨模态相似性），通过统计感知的权重分配机制自适应分配虚拟交互权重，作为即插即用框架与现有模型集成。

Result: 在六个真实世界数据集上使用七个最先进的多模态推荐模型进行实验，验证了VI-MMRec的有效性。

Conclusion: VI-MMRec是一个灵活、无需额外训练成本的框架，能有效增强现有多模态推荐模型的性能，具有实际部署优势。

Abstract: Although existing multimodal recommendation models have shown promising performance, their effectiveness continues to be limited by the pervasive data sparsity problem. This problem arises because users typically interact with only a small subset of available items, leading existing models to arbitrarily treat unobserved items as negative samples. To this end, we propose VI-MMRec, a model-agnostic and training cost-free framework that enriches sparse user-item interactions via similarity-aware virtual user-item interactions. These virtual interactions are constructed based on modality-specific feature similarities of user-interacted items. Specifically, VI-MMRec introduces two different strategies: (1) Overlay, which independently aggregates modality-specific similarities to preserve modality-specific user preferences, and (2) Synergistic, which holistically fuses cross-modal similarities to capture complementary user preferences. To ensure high-quality augmentation, we design a statistically informed weight allocation mechanism that adaptively assigns weights to virtual user-item interactions based on dataset-specific modality relevance. As a plug-and-play framework, VI-MMRec seamlessly integrates with existing models to enhance their performance without modifying their core architecture. Its flexibility allows it to be easily incorporated into various existing models, maximizing performance with minimal implementation effort. Moreover, VI-MMRec introduces no additional overhead during training, making it significantly advantageous for practical deployment. Comprehensive experiments conducted on six real-world datasets using seven state-of-the-art multimodal recommendation models validate the effectiveness of our VI-MMRec.

</details>
