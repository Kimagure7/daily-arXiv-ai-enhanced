{"id": "2509.18560", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.18560", "abs": "https://arxiv.org/abs/2509.18560", "authors": ["Clarita Hawat", "Wissam Al Jurdi", "Jacques Bou Abdo", "Jacques Demerjian", "Abdallah Makhoul"], "title": "Understand your Users, An Ensemble Learning Framework for Natural Noise Filtering in Recommender Systems", "comment": "32 pages", "summary": "The exponential growth of web content is a major key to the success for\nRecommender Systems. This paper addresses the challenge of defining noise,\nwhich is inherently related to variability in human preferences and behaviors.\nIn classifying changes in user tendencies, we distinguish three kinds of\nphenomena: external factors that directly influence users' sentiment,\nserendipity causing unexpected preference, and incidental interaction perceived\nas noise. To overcome these problems, we present a new framework that\nidentifies noisy ratings. In this context, the proposed framework is modular,\nconsisting of three layers: known natural noise algorithms for item\nclassification, an Ensemble learning model for refined evaluation of the items\nand signature-based noise identification. We further advocate the metrics that\nquantitatively assess serendipity and group validation, offering higher\nrobustness in recommendation accuracy. Our approach aims to provide a cleaner\ntraining dataset that would inherently improve user satisfaction and engagement\nwith Recommender Systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u8bc6\u522b\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u566a\u58f0\u8bc4\u5206\uff0c\u901a\u8fc7\u533a\u5206\u5916\u90e8\u56e0\u7d20\u3001\u610f\u5916\u504f\u597d\u548c\u5076\u7136\u4ea4\u4e92\u4e09\u79cd\u73b0\u8c61\uff0c\u4f7f\u7528\u4e09\u5c42\u6a21\u5757\u5316\u65b9\u6cd5\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u5185\u5bb9\u7684\u6307\u6570\u7ea7\u589e\u957f\uff0c\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u566a\u58f0\u5b9a\u4e49\u7684\u6311\u6218\uff0c\u8fd9\u4e9b\u566a\u58f0\u4e0e\u4eba\u7c7b\u504f\u597d\u548c\u884c\u4e3a\u7684\u53d8\u5f02\u6027\u5bc6\u5207\u76f8\u5173\uff0c\u9700\u8981\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u7684\u53d8\u5316\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5305\u542b\u4e09\u5c42\uff1a\u5df2\u77e5\u81ea\u7136\u566a\u58f0\u7b97\u6cd5\u8fdb\u884c\u9879\u76ee\u5206\u7c7b\u3001\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u9879\u76ee\u7cbe\u70bc\u8bc4\u4f30\u3001\u57fa\u4e8e\u7b7e\u540d\u7684\u566a\u58f0\u8bc6\u522b\u3002\u540c\u65f6\u5021\u5bfc\u4f7f\u7528\u5b9a\u91cf\u8bc4\u4f30\u610f\u5916\u6027\u548c\u7fa4\u4f53\u9a8c\u8bc1\u7684\u6307\u6807\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u6e05\u6d01\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u4ece\u800c\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u51cf\u5c11\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u566a\u58f0\uff0c\u901a\u8fc7\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\u6765\u589e\u5f3a\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2509.18575", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18575", "abs": "https://arxiv.org/abs/2509.18575", "authors": ["Yaoyao Qian", "Yifan Zeng", "Yuchao Jiang", "Chelsi Jain", "Huazheng Wang"], "title": "The Ranking Blind Spot: Decision Hijacking in LLM-based Text Ranking", "comment": "Accepted by EMNLP 2025", "summary": "Large Language Models (LLMs) have demonstrated strong performance in\ninformation retrieval tasks like passage ranking. Our research examines how\ninstruction-following capabilities in LLMs interact with multi-document\ncomparison tasks, identifying what we term the \"Ranking Blind Spot\", a\ncharacteristic of LLM decision processes during comparative evaluation. We\nanalyze how this ranking blind spot affects LLM evaluation systems through two\napproaches: Decision Objective Hijacking, which alters the evaluation goal in\npairwise ranking systems, and Decision Criteria Hijacking, which modifies\nrelevance standards across ranking schemes. These approaches demonstrate how\ncontent providers could potentially influence LLM-based ranking systems to\naffect document positioning. These attacks aim to force the LLM ranker to\nprefer a specific passage and rank it at the top. Malicious content providers\ncan exploit this weakness, which helps them gain additional exposure by\nattacking the ranker. In our experiment, We empirically show that the proposed\nattacks are effective in various LLMs and can be generalized to multiple\nranking schemes. We apply these attack to realistic examples to show their\neffectiveness. We also found stronger LLMs are more vulnerable to these\nattacks. Our code is available at:\nhttps://github.com/blindspotorg/RankingBlindSpot", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLMs\u5728\u591a\u6587\u6863\u6bd4\u8f83\u4efb\u52a1\u4e2d\u7684\"\u6392\u5e8f\u76f2\u70b9\"\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u6076\u610f\u5185\u5bb9\u63d0\u4f9b\u8005\u5982\u4f55\u901a\u8fc7\u51b3\u7b56\u76ee\u6807\u52ab\u6301\u548c\u51b3\u7b56\u6807\u51c6\u52ab\u6301\u6765\u64cd\u7eb5LLM\u6392\u5e8f\u7cfb\u7edf\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u5982\u4f55\u4e0e\u591a\u6587\u6863\u6bd4\u8f83\u4efb\u52a1\u4ea4\u4e92\uff0c\u8bc6\u522bLLM\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u6392\u5e8f\u76f2\u70b9\u7279\u6027\u3002", "method": "\u901a\u8fc7\u4e24\u79cd\u653b\u51fb\u65b9\u6cd5\uff1a\u51b3\u7b56\u76ee\u6807\u52ab\u6301\uff08\u6539\u53d8\u6210\u5bf9\u6392\u5e8f\u7cfb\u7edf\u7684\u8bc4\u4f30\u76ee\u6807\uff09\u548c\u51b3\u7b56\u6807\u51c6\u52ab\u6301\uff08\u4fee\u6539\u4e0d\u540c\u6392\u5e8f\u65b9\u6848\u7684\u76f8\u5173\u6027\u6807\u51c6\uff09\uff0c\u5206\u6790\u6392\u5e8f\u76f2\u70b9\u5bf9LLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e9b\u653b\u51fb\u5728\u591a\u79cdLLMs\u4e2d\u6709\u6548\uff0c\u53ef\u63a8\u5e7f\u5230\u591a\u79cd\u6392\u5e8f\u65b9\u6848\uff0c\u4e14\u66f4\u5f3a\u7684LLMs\u66f4\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002", "conclusion": "LLMs\u5b58\u5728\u6392\u5e8f\u76f2\u70b9\u6f0f\u6d1e\uff0c\u6076\u610f\u5185\u5bb9\u63d0\u4f9b\u8005\u53ef\u5229\u7528\u6b64\u5f31\u70b9\u64cd\u7eb5\u6392\u5e8f\u7ed3\u679c\u83b7\u5f97\u989d\u5916\u66dd\u5149\uff0c\u9700\u8981\u52a0\u5f3aLLM\u6392\u5e8f\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.18661", "categories": ["cs.IR", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.18661", "abs": "https://arxiv.org/abs/2509.18661", "authors": ["Yixin Liu", "Yonghui Wu", "Denghui Zhang", "Lichao Sun"], "title": "Agentic AutoSurvey: Let LLMs Survey LLMs", "comment": "29 pages, 7 figures", "summary": "The exponential growth of scientific literature poses unprecedented\nchallenges for researchers attempting to synthesize knowledge across rapidly\nevolving fields. We present \\textbf{Agentic AutoSurvey}, a multi-agent\nframework for automated survey generation that addresses fundamental\nlimitations in existing approaches. Our system employs four specialized agents\n(Paper Search Specialist, Topic Mining \\& Clustering, Academic Survey Writer,\nand Quality Evaluator) working in concert to generate comprehensive literature\nsurveys with superior synthesis quality. Through experiments on six\nrepresentative LLM research topics from COLM 2024 categories, we demonstrate\nthat our multi-agent approach achieves significant improvements over existing\nbaselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent\narchitecture processes 75--443 papers per topic (847 total across six topics)\nwhile targeting high citation coverage (often $\\geq$80\\% on 75--100-paper sets;\nlower on very large sets such as RLHF) through specialized agent orchestration.\nOur 12-dimension evaluation captures organization, synthesis integration, and\ncritical analysis beyond basic metrics. These findings demonstrate that\nmulti-agent architectures represent a meaningful advancement for automated\nliterature survey generation in rapidly evolving scientific domains.", "AI": {"tldr": "Agentic AutoSurvey\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u6587\u732e\u7efc\u8ff0\uff0c\u901a\u8fc7\u56db\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u5728\u5feb\u901f\u53d1\u5c55\u7684\u79d1\u5b66\u9886\u57df\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u7efc\u8ff0\u8d28\u91cf\u3002", "motivation": "\u79d1\u5b66\u6587\u732e\u7684\u6307\u6570\u7ea7\u589e\u957f\u7ed9\u7814\u7a76\u4eba\u5458\u5728\u5feb\u901f\u53d1\u5c55\u7684\u9886\u57df\u4e2d\u8fdb\u884c\u77e5\u8bc6\u7efc\u5408\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u56db\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\uff08\u8bba\u6587\u641c\u7d22\u4e13\u5bb6\u3001\u4e3b\u9898\u6316\u6398\u4e0e\u805a\u7c7b\u3001\u5b66\u672f\u7efc\u8ff0\u64b0\u5199\u8005\u3001\u8d28\u91cf\u8bc4\u4f30\u8005\uff09\u534f\u540c\u5de5\u4f5c\uff0c\u5904\u7406\u6bcf\u4e2a\u4e3b\u989875-443\u7bc7\u8bba\u6587\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u667a\u80fd\u4f53\u7f16\u6392\u5b9e\u73b0\u9ad8\u5f15\u7528\u8986\u76d6\u7387\u3002", "result": "\u5728\u516d\u4e2a\u4ee3\u8868\u6027LLM\u7814\u7a76\u4e3b\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\uff0c\u8bc4\u5206\u8fbe\u52308.18/10\uff08AutoSurvey\u4e3a4.77/10\uff09\uff0c\u5904\u7406\u4e86847\u7bc7\u8bba\u6587\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4ee3\u8868\u4e86\u5728\u5feb\u901f\u53d1\u5c55\u7684\u79d1\u5b66\u9886\u57df\u4e2d\u81ea\u52a8\u6587\u732e\u7efc\u8ff0\u751f\u6210\u7684\u6709\u610f\u4e49\u8fdb\u5c55\uff0c12\u7ef4\u8bc4\u4f30\u6355\u83b7\u4e86\u7ec4\u7ec7\u3001\u7efc\u5408\u6574\u5408\u548c\u6279\u5224\u6027\u5206\u6790\u7b49\u8d85\u8d8a\u57fa\u672c\u6307\u6807\u7684\u7ef4\u5ea6\u3002"}}
{"id": "2509.18736", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.18736", "abs": "https://arxiv.org/abs/2509.18736", "authors": ["Wenyu Mao", "Shuchang Liu", "Hailan Yang", "Xiaobei Wang", "Xiaoyu Yang", "Xu Gao", "Xiang Li", "Lantao Hu", "Han Li", "Kun Gai", "An Zhang", "Xiang Wang"], "title": "Robust Denoising Neural Reranker for Recommender Systems", "comment": null, "summary": "For multi-stage recommenders in industry, a user request would first trigger\na simple and efficient retriever module that selects and ranks a list of\nrelevant items, then calls a slower but more sophisticated deep reranking model\nthat refines the item arrangement before exposure to the user. The latter model\ntypically reranks the item list conditioned on the user's history content and\nthe initial ranking from retrievers. Although this two-stage retrieval-ranking\nframework demonstrates practical effectiveness, the significance of retriever\nscores from the previous stage has been limitedly explored, which is\ninformative. In this work, we first theoretically analyze the limitations of\nusing retriever scores as the rerankers' input directly and argue that the\nreranking task is essentially a noise reduction problem from the retriever\nscores. Following this notion, we derive an adversarial framework, DNR, that\nassociates the denoising reranker with a carefully designed noise generation\nmodule. We extend the conventional score error minimization term with three\naugmented objectives, including: 1) a denoising objective that aims to denoise\nthe noisy retriever scores to align with the user feedback; 2) an adversarial\nretriever score generation objective that improves the exploration in the\nretriever score space; and 3) a distribution regularization term that aims to\nalign the distribution of generated noisy retriever scores with the real ones.\nExtensive experiments are conducted on three public datasets, together with\nanalytical support, validating the effectiveness of the proposed DNR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDNR\u6846\u67b6\uff0c\u5c06\u591a\u9636\u6bb5\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u91cd\u6392\u5e8f\u4efb\u52a1\u5efa\u6a21\u4e3a\u68c0\u7d22\u5668\u5206\u6570\u7684\u53bb\u566a\u95ee\u9898\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u8bad\u7ec3\u548c\u4e09\u4e2a\u589e\u5f3a\u76ee\u6807\u6765\u63d0\u5347\u91cd\u6392\u5e8f\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e24\u9636\u6bb5\u68c0\u7d22-\u91cd\u6392\u5e8f\u6846\u67b6\u4e2d\uff0c\u68c0\u7d22\u5668\u5206\u6570\u7684\u91cd\u8981\u6027\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u800c\u91cd\u6392\u5e8f\u672c\u8d28\u4e0a\u662f\u4ece\u68c0\u7d22\u5668\u5206\u6570\u4e2d\u53bb\u9664\u566a\u58f0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDNR\u5bf9\u6297\u6846\u67b6\uff0c\u5305\u542b\u53bb\u566a\u91cd\u6392\u5e8f\u5668\u548c\u566a\u58f0\u751f\u6210\u6a21\u5757\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u7684\u5206\u6570\u8bef\u5dee\u6700\u5c0f\u5316\u76ee\u6807\uff0c\u589e\u52a0\u4e86\u53bb\u566a\u76ee\u6807\u3001\u5bf9\u6297\u6027\u68c0\u7d22\u5668\u5206\u6570\u751f\u6210\u76ee\u6807\u548c\u5206\u5e03\u6b63\u5219\u5316\u9879\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DNR\u7684\u6709\u6548\u6027\u3002", "conclusion": "DNR\u6846\u67b6\u901a\u8fc7\u5c06\u91cd\u6392\u5e8f\u5efa\u6a21\u4e3a\u53bb\u566a\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u9636\u6bb5\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2509.18807", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.18807", "abs": "https://arxiv.org/abs/2509.18807", "authors": ["Christian Ganh\u00f6r", "Marta Moscati", "Anna Hausberger", "Shah Nawaz", "Markus Schedl"], "title": "Single-Branch Network Architectures to Close the Modality Gap in Multimodal Recommendation", "comment": "Accepted by ACM Transactions on Recommender Systems (TORS)", "summary": "Traditional recommender systems rely on collaborative filtering, using past\nuser-item interactions to help users discover new items in a vast collection.\nIn cold start, i.e., when interaction histories of users or items are not\navailable, content-based recommender systems use side information instead.\nHybrid recommender systems (HRSs) often employ multimodal learning to combine\ncollaborative and side information, which we jointly refer to as modalities.\nThough HRSs can provide recommendations when some modalities are missing, their\nquality degrades. In this work, we utilize single-branch neural networks\nequipped with weight sharing, modality sampling, and contrastive loss to\nprovide accurate recommendations even in missing modality scenarios by\nnarrowing the modality gap. We compare these networks with multi-branch\nalternatives and conduct extensive experiments on three datasets. Six\naccuracy-based and four beyond-accuracy-based metrics help assess the\nrecommendation quality for the different training paradigms and their\nhyperparameters in warm-start and missing modality scenarios. We quantitatively\nand qualitatively study the effects of these different aspects on bridging the\nmodality gap. Our results show that single-branch networks achieve competitive\nperformance in warm-start scenarios and are significantly better in missing\nmodality settings. Moreover, our approach leads to closer proximity of an\nitem's modalities in the embedding space. Our full experimental setup is\navailable at https://github.com/hcai-mms/single-branch-networks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5355\u5206\u652f\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u6743\u91cd\u5171\u4eab\u3001\u6a21\u6001\u91c7\u6837\u548c\u5bf9\u6bd4\u635f\u5931\u7684\u65b9\u6cd5\uff0c\u5728\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\u63d0\u4f9b\u51c6\u786e\u7684\u63a8\u8350\uff0c\u901a\u8fc7\u7f29\u5c0f\u6a21\u6001\u5dee\u8ddd\u6765\u6539\u8fdb\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\uff0c\u5f53\u67d0\u4e9b\u6a21\u6001\u7f3a\u5931\u65f6\u63a8\u8350\u8d28\u91cf\u4f1a\u4e0b\u964d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6a21\u6001\u7f3a\u5931\u573a\u666f\u4e0b\u7684\u63a8\u8350\u6027\u80fd\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5355\u5206\u652f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u6743\u91cd\u5171\u4eab\u3001\u6a21\u6001\u91c7\u6837\u548c\u5bf9\u6bd4\u635f\u5931\u6280\u672f\uff0c\u4e0e\u591a\u5206\u652f\u7f51\u7edc\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u4f7f\u75286\u4e2a\u51c6\u786e\u6027\u6307\u6807\u548c4\u4e2a\u8d85\u51c6\u786e\u6027\u6307\u6807\u8bc4\u4f30\u4e0d\u540c\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u5355\u5206\u652f\u7f51\u7edc\u5728\u70ed\u542f\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u7ade\u4e89\u529b\uff0c\u5728\u6a21\u6001\u7f3a\u5931\u8bbe\u7f6e\u4e2d\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u4e14\u80fd\u5b9e\u73b0\u5d4c\u5165\u7a7a\u95f4\u4e2d\u9879\u76ee\u6a21\u6001\u7684\u66f4\u7d27\u5bc6\u63a5\u8fd1\u3002", "conclusion": "\u5355\u5206\u652f\u7f51\u7edc\u65b9\u6cd5\u80fd\u6709\u6548\u7f29\u5c0f\u6a21\u6001\u5dee\u8ddd\uff0c\u5728\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u63a8\u8350\uff0c\u4e14\u80fd\u5b9e\u73b0\u66f4\u597d\u7684\u6a21\u6001\u5d4c\u5165\u7a7a\u95f4\u8868\u793a\u3002"}}
{"id": "2509.19057", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.19057", "abs": "https://arxiv.org/abs/2509.19057", "authors": ["Olawumi Olasunkanmi", "Mathew Satursky", "Hong Yi", "Chris Bizon", "Harlin Lee", "Stanley Ahalt"], "title": "RELATE: Relation Extraction in Biomedical Abstracts with LLMs and Ontology Constraints", "comment": null, "summary": "Biomedical knowledge graphs (KGs) are vital for drug discovery and clinical\ndecision support but remain incomplete. Large language models (LLMs) excel at\nextracting biomedical relations, yet their outputs lack standardization and\nalignment with ontologies, limiting KG integration. We introduce RELATE, a\nthree-stage pipeline that maps LLM-extracted relations to standardized ontology\npredicates using ChemProt and the Biolink Model. The pipeline includes: (1)\nontology preprocessing with predicate embeddings, (2) similarity-based\nretrieval enhanced with SapBERT, and (3) LLM-based reranking with explicit\nnegation handling. This approach transforms relation extraction from free-text\noutputs to structured, ontology-constrained representations. On the ChemProt\nbenchmark, RELATE achieves 52% exact match and 94% accuracy@10, and in 2,400\nHEAL Project abstracts, it effectively rejects irrelevant associations (0.4%)\nand identifies negated assertions. RELATE captures nuanced biomedical\nrelationships while ensuring quality for KG augmentation. By combining vector\nsearch with contextual LLM reasoning, RELATE provides a scalable, semantically\naccurate framework for converting unstructured biomedical literature into\nstandardized KGs.", "AI": {"tldr": "RELATE\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5c06LLM\u63d0\u53d6\u7684\u751f\u7269\u533b\u5b66\u5173\u7cfb\u6620\u5c04\u5230\u6807\u51c6\u5316\u672c\u4f53\u8c13\u8bcd\uff0c\u89e3\u51b3LLM\u8f93\u51fa\u7f3a\u4e4f\u6807\u51c6\u5316\u548c\u672c\u4f53\u5bf9\u9f50\u7684\u95ee\u9898\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u5bf9\u836f\u7269\u53d1\u73b0\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f80\u5f80\u4e0d\u5b8c\u6574\u3002LLM\u64c5\u957f\u63d0\u53d6\u751f\u7269\u533b\u5b66\u5173\u7cfb\uff0c\u4f46\u5176\u8f93\u51fa\u7f3a\u4e4f\u6807\u51c6\u5316\u548c\u672c\u4f53\u5bf9\u9f50\uff0c\u9650\u5236\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u96c6\u6210\u3002", "method": "\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a1\uff09\u672c\u4f53\u9884\u5904\u7406\u548c\u8c13\u8bcd\u5d4c\u5165\uff1b2\uff09\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\uff08\u4f7f\u7528SapBERT\u589e\u5f3a\uff09\uff1b3\uff09\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\uff08\u5305\u542b\u663e\u5f0f\u5426\u5b9a\u5904\u7406\uff09\u3002", "result": "\u5728ChemProt\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRELATE\u8fbe\u523052%\u7684\u7cbe\u786e\u5339\u914d\u548c94%\u7684\u51c6\u786e\u7387@10\uff1b\u57282400\u7bc7HEAL\u9879\u76ee\u6458\u8981\u4e2d\uff0c\u6709\u6548\u62d2\u7edd\u65e0\u5173\u5173\u8054\uff080.4%\uff09\u5e76\u8bc6\u522b\u5426\u5b9a\u65ad\u8a00\u3002", "conclusion": "RELATE\u901a\u8fc7\u7ed3\u5408\u5411\u91cf\u641c\u7d22\u548c\u4e0a\u4e0b\u6587LLM\u63a8\u7406\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u8bed\u4e49\u51c6\u786e\u7684\u6846\u67b6\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u751f\u7269\u533b\u5b66\u6587\u732e\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u77e5\u8bc6\u56fe\u8c31\u3002"}}
{"id": "2509.19209", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.19209", "abs": "https://arxiv.org/abs/2509.19209", "authors": ["Olalekan K. Akindele", "Bhupesh Kumar Mishra", "Kenneth Y. Wertheim"], "title": "A Knowledge Graph and a Tripartite Evaluation Framework Make Retrieval-Augmented Generation Scalable and Transparent", "comment": "25 Pages", "summary": "Large Language Models (LLMs) have significantly enhanced conversational\nArtificial Intelligence(AI) chatbots; however, domain-specific accuracy and the\navoidance of factual inconsistencies remain pressing challenges, particularly\nfor large datasets. Designing an effective chatbot with appropriate methods and\nevaluating its effectiveness is among the challenges in this domain. This study\npresents a Retrieval Augmented Generation (RAG) chatbot that harnesses a\nknowledge graph and vector search retrieval to deliver precise, context-rich\nresponses in an exemplary use case from over high-volume engineering\nproject-related emails, thereby minimising the need for document chunking. A\ncentral innovation of this work is the introduction of RAG Evaluation\n(RAG-Eval), a novel chain-of-thought LLM-based tripartite evaluation framework\nspecifically developed to assess RAG applications. This framework operates in\nparallel with the chatbot, jointly assessing the user's query, the retrieved\ndocument, and the generated response, enabling a holistic evaluation across\nmultiple quality metrics like query relevance, factual accuracy, coverage,\ncoherence and fluency. The resulting scoring system is provided directly to\nusers as a confidence score (1 to 100%), enabling quick identification of\npossible misaligned or incomplete answers. This proposed approach promotes\ntransparency and rapid verification by incorporating metadata email IDs,\ntimestamps into responses. Experimental comparisons against BERTScore and\nG-EVAL for summarisation evaluation tasks confirm its effectiveness, and\nempirical analysis also shows RAG-Eval reliably detects factual gaps and query\nmismatches, thereby fostering trust in high demand, data centric environments.\nThese findings highlight a scalable path for developing accurate,\nuser-verifiable chatbots that bridge the gap between high-level conversational\nfluency and factual accuracy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u5411\u91cf\u641c\u7d22\u7684RAG\u804a\u5929\u673a\u5668\u4eba\uff0c\u5e76\u5f00\u53d1\u4e86RAG-Eval\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30RAG\u5e94\u7528\u7684\u8d28\u91cf\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u9886\u57df\u7279\u5b9a\u5e94\u7528\u4e2d\u5b58\u5728\u7684\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u5de5\u7a0b\u90ae\u4ef6\u6570\u636e\u65f6\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u804a\u5929\u673a\u5668\u4eba\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\uff0c\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u5411\u91cf\u641c\u7d22\u68c0\u7d22\u6280\u672f\uff0c\u5f00\u53d1\u4e86RAG-Eval\u8bc4\u4f30\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u94fe\u5f0f\u601d\u7ef4LLM\uff0c\u4ece\u67e5\u8be2\u76f8\u5173\u6027\u3001\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u8986\u76d6\u5ea6\u3001\u8fde\u8d2f\u6027\u548c\u6d41\u7545\u6027\u7b49\u591a\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRAG-Eval\u5728\u6458\u8981\u8bc4\u4f30\u4efb\u52a1\u4e2d\u4f18\u4e8eBERTScore\u548cG-EVAL\uff0c\u80fd\u591f\u53ef\u9760\u5730\u68c0\u6d4b\u4e8b\u5b9e\u5dee\u8ddd\u548c\u67e5\u8be2\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b1-100%\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f00\u53d1\u51c6\u786e\u3001\u7528\u6237\u53ef\u9a8c\u8bc1\u7684\u804a\u5929\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u5f25\u5408\u4e86\u9ad8\u6c34\u5e73\u5bf9\u8bdd\u6d41\u7545\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
