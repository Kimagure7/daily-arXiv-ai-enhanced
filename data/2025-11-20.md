<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 14]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm](https://arxiv.org/abs/2511.14763)
*Li Cuihong,Huang Xiaowen,Yin Chuanhuan,Sang Jitao*

Main category: cs.IR

TL;DR: 提出了一种基于知识蒸馏的成员推理攻击范式，用于提升对基于大语言模型的推荐系统的攻击性能。


<details>
  <summary>Details</summary>
Motivation: 传统MIA通过影子模型获取目标模型特征，但LLM推荐系统的训练数据规模和复杂性使得影子模型难以构建。知识蒸馏有助于构建更强的参考模型。

Method: 引入知识蒸馏获取参考模型，在蒸馏过程中分别对成员和非成员数据进行蒸馏，增强模型对两者的区分能力。从参考模型获取个体特征，并使用融合特征训练攻击模型。

Result: 相比基于影子模型的攻击，该范式提高了MIA的攻击性能。

Conclusion: 知识蒸馏能够有效提升对LLM推荐系统的成员推理攻击效果。

Abstract: Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.

</details>


### [2] [Image-Seeking Intent Prediction for Cross-Device Product Search](https://arxiv.org/abs/2511.14764)
*Mariya Hendriksen,Svitlana Vakulenko,Jordan Massiah,Gabriella Kazai,Emine Yilmaz*

Main category: cs.IR

TL;DR: 本文提出图像寻求意图预测任务，使用LLM驱动的电子商务助手预测何时语音产品查询需要主动触发屏幕设备的视觉增强，通过结合查询语义和产品数据提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着用户在多种设备上购物，主动建议切换到具有视觉功能的设备可以显著改善用户体验，但需要高精度以避免不必要的干扰。

Method: 训练IRP模型，利用用户输入查询和检索到的产品元数据来预测视觉意图，结合查询语义和产品数据，并通过轻量级摘要改进，使用面向精度的可微分损失函数减少误报。

Result: 实验表明，结合查询语义和产品数据能持续提高预测准确性，特别是通过轻量级摘要改进后，使用精度导向损失进一步减少假阳性。

Conclusion: LLM有潜力驱动智能跨设备购物助手，预测并适应用户需求，实现更无缝和个性化的电子商务体验。

Abstract: Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.

</details>


### [3] [Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information](https://arxiv.org/abs/2511.14765)
*Mohammad Usman Altam,Md Imtiaz Habib,Tuan Hoang*

Main category: cs.IR

TL;DR: 本研究开发了一个针对Mycophyto的检索增强生成(RAG)系统，专注于丛枝菌根真菌(AMF)的农业应用，通过结合语义检索和结构化数据提取，提高农业知识发现和决策支持的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型受限于静态训练语料，无法动态整合领域特定知识。RAG系统能够克服时间和学科限制，为可持续农业中的AMF应用提供准确可靠的知识支持。

Method: 采用双层策略：(1)使用向量嵌入从农学和生物技术语料库中进行语义检索和增强；(2)结构化数据提取，捕获预定义的实验元数据如接种方法、孢子密度、土壤参数和产量结果。嵌入存储在高效向量数据库中，支持近实时检索。

Result: 实证评估表明，该管道能够检索和合成关于AMF与作物系统(如番茄)相互作用的高度相关信息，证明了其在农业知识发现中的有效性。

Conclusion: 该框架强调了AI驱动知识发现在加速农业生态创新和增强可持续农业系统决策方面的潜力，为农业领域提供了可扩展的知识增强解决方案。

Abstract: Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.

</details>


### [4] [OTCR: Optimal Transmission, Compression and Representation for Multimodal Information Extraction](https://arxiv.org/abs/2511.14766)
*Yang Li,Yajiao Wang,Wenhao Hu,Zhixiong Zhang,Mengting Zhang*

Main category: cs.IR

TL;DR: OTCR是一个两阶段的多模态信息提取框架，通过跨模态最优传输和变分信息瓶颈实现文本主导、视觉选择性支持的融合策略，在文档AI中取得了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常隐含假设模态等价或采用统一融合方式，导致多模态信号的无差别融合和任务无关冗余，限制了泛化能力。需要从任务中心视角重新审视多模态信息提取。

Method: 两阶段框架：1) 跨模态最优传输生成文本token和视觉patch的稀疏概率对齐，通过上下文感知门控制视觉注入；2) 变分信息瓶颈压缩融合特征，过滤任务无关噪声。

Result: 在FUNSD上达到91.95% SER和91.13% RE，在XFUND(ZH)上达到91.09% SER和94.20% RE，表现出跨数据集的竞争性性能。特征分析确认减少了模态冗余并增强了任务信号。

Conclusion: 这项工作为文档AI中的可控多模态融合提供了一个可解释的、基于信息论的范式，强调文本主导、视觉选择性支持的原则。

Abstract: Multimodal Information Extraction (MIE) requires fusing text and visual cues from visually rich documents. While recent methods have advanced multimodal representation learning, most implicitly assume modality equivalence or treat modalities in a largely uniform manner, still relying on generic fusion paradigms. This often results in indiscriminate incorporation of multimodal signals and insufficient control over task-irrelevant redundancy, which may in turn limit generalization. We revisit MIE from a task-centric view: text should dominate, vision should selectively support. We present OTCR, a two-stage framework. First, Cross-modal Optimal Transport (OT) yields sparse, probabilistic alignments between text tokens and visual patches, with a context-aware gate controlling visual injection. Second, a Variational Information Bottleneck (VIB) compresses fused features, filtering task-irrelevant noise to produce compact, task-adaptive representations. On FUNSD, OTCR achieves 91.95% SER and 91.13% RE, while on XFUND (ZH), it reaches 91.09% SER and 94.20% RE, demonstrating competitive performance across datasets. Feature-level analyses further confirm reduced modality redundancy and strengthened task signals. This work offers an interpretable, information-theoretic paradigm for controllable multimodal fusion in document AI.

</details>


### [5] [An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market](https://arxiv.org/abs/2511.14767)
*Minh-Thuan Nguyen,Thien Vo-Thanh,Thai-Duy Dinh,Xuan-Quang Phan,Tan-Ha Mai,Lam-Son Lê*

Main category: cs.IR

TL;DR: 开发了一个AI职业市场顾问系统，通过自动化爬取和LLM处理越南IT职位数据，基于ReAct框架的智能代理提供实时数据驱动的职业指导。


<details>
  <summary>Details</summary>
Motivation: 越南IT就业市场缺乏可靠的实时职业指导，现有市场报告过时，手动分析大量职位信息不切实际。

Method: 构建自动化数据采集管道（使用Playwright爬取职位门户网站），利用LLM结构化非结构化数据，基于ReAct框架开发工具增强的AI代理，支持SQL查询、语义搜索和数据可视化。

Result: 成功采集分析3,745个职位信息，系统能够回答复杂多步骤查询、生成实时可视化图表，并提供基于真实数据的个性化职业建议。

Conclusion: 这项工作引入了劳动力市场分析的新范式，展示了专业化AI代理系统如何为新一代专业人士提供及时可信的职业智能服务。

Abstract: Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.

</details>


### [6] [Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation](https://arxiv.org/abs/2511.14768)
*Bhavika Jain,Robert Pitsko,Ananya Drishti,Mahfuza Farooque*

Main category: cs.IR

TL;DR: 提出ESMR框架，通过Transformer预测用户情绪轨迹，结合LightGBM和强化学习实现情感感知的社交媒体推荐，在保持参与度的同时改善用户情绪健康。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体推荐系统仅优化参与度指标，不考虑用户情绪状态，长期接触情绪化内容会损害用户情绪健康。

Method: ESMR框架整合Transformer情绪预测器和混合推荐策略：稳定期使用LightGBM模型，持续负面情绪时使用因果奖励的强化学习代理。

Result: 30天交互轨迹评估显示ESMR改善了情绪恢复、降低了情绪波动，同时保持了良好的参与度。

Conclusion: ESMR提供了在不影响参与度性能的前提下实现情感感知推荐的路径。

Abstract: Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.

</details>


### [7] [Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications](https://arxiv.org/abs/2511.14769)
*Yifan Xu,Vipul Gupta,Rohit Aggarwal,Varsha Mahadevan,Bhaskar Krishnamachari*

Main category: cs.IR

TL;DR: CAR算法通过分析查询-文档相似度距离的聚类模式，动态确定检索文档数量，解决了静态top-k检索无法适应不同查询特性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态top-k检索方法无法适应不同查询特性：窄范围查询需要少量高相关文档，而宽泛查询需要更多支持信息。静态方法会导致上下文不足或信息冗余。

Method: CAR算法通过分析查询-文档相似度距离的聚类模式，检测高相关文档向低相关文档的过渡点，建立自适应截断机制。

Result: 在Coinbase CDP语料库和MultiHop-RAG基准测试中，CAR始终选择最优检索深度，获得最高TES分数。在下游RAG评估中，CAR将LLM token使用减少60%，端到端延迟降低22%，幻觉减少10%，同时完全保持答案相关性。

Conclusion: CAR算法显著提升了RAG系统的效率和效果，在Coinbase虚拟助手中的集成使用户参与度提升了200%。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.

</details>


### [8] [ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models](https://arxiv.org/abs/2511.14770)
*Bo Ma,LuYao Liu,ZeHua Hu,Simon Lau*

Main category: cs.IR

TL;DR: ExplainRec是一个基于大语言模型的推荐框架，通过偏好归因、多模态融合和零样本迁移学习提升推荐系统的可解释性和冷启动处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法如TALLRec在可解释性和冷启动场景方面存在挑战，需要开发能够生成可解释推荐并有效处理冷启动问题的框架。

Method: 采用偏好归因调优实现可解释推荐，零样本偏好迁移处理冷启动用户和物品，多模态增强利用视觉和文本内容，多任务协同优化。

Result: 在MovieLens-25M和Amazon数据集上的实验表明，ExplainRec在电影推荐任务上AUC提升0.7%，跨域任务上提升0.9%，同时能生成可解释的推荐理由并有效处理冷启动场景。

Conclusion: ExplainRec框架通过结合偏好归因、多模态融合和零样本迁移学习，显著提升了LLM推荐系统的性能、可解释性和冷启动处理能力。

Abstract: Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\% on movie recommendation and 0.9\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.

</details>


### [9] [SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs](https://arxiv.org/abs/2511.14881)
*Bi Xue,Hong Wu,Lei Chen,Chao Yang,Yiming Ma,Fei Ding,Zhen Wang,Liang Wang,Xiaoheng Mao,Ke Huang,Xialu Li,Peng Xia,Rui Jian,Yanli Zhao,Yanzun Huang,Yijie Deng,Harry Tran,Ryan Chang,Min Yu,Eric Dong,Jiazhou Wang,Qianqian Zhang,Keke Zhai,Hongzhang Yin,Pawel Garbacki,Zheng Fang,Yiyi Pan,Min Ni,Yang Liu*

Main category: cs.IR

TL;DR: SilverTorch是一个在GPU上服务推荐模型的系统，通过统一模型服务、GPU上的Bloom索引算法和Int8 ANN内核，显著降低了延迟并提高了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有基于CPU的ANN索引和过滤服务存在显著成本问题，且无法支持更复杂的模型架构，如学习相似性和多任务检索。

Method: 提出SilverTorch系统，用模型层替换独立的索引和过滤服务，包括GPU上的Bloom索引算法、融合Int8 ANN内核，以及共同设计ANN搜索索引和过滤索引。

Result: 在行业规模数据集上，SilverTorch实现了比最先进方法低5.6倍的延迟和高23.7倍的吞吐量，成本效率比基于CPU的解决方案高13.35倍。

Conclusion: SilverTorch通过其服务范式提高了检索准确性，并为服务更复杂模型提供了可能性，已在主要产品中服务数百个模型，为数十亿日活跃用户推荐内容。

Abstract: Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval.
  In this paper, we propose SilverTorch, a model-based system for serving recommendation models on GPUs. SilverTorch unifies model serving by replacing standalone indexing and filtering services with layers of served models. We propose a Bloom index algorithm on GPUs for feature filtering and a tensor-native fused Int8 ANN kernel on GPUs for nearest neighbor search. We further co-design the ANN search index and filtering index to reduce GPU memory utilization and eliminate unnecessary computation. Benefit from SilverTorch's serving paradigm, we introduce a OverArch scoring layer and a Value Model to aggregate results across multi-tasks. These advancements improve the accuracy for retrieval and enable future studies for serving more complex models. For ranking, SilverTorch's design accelerates item embedding calculation by caching the pre-calculated embeddings inside the serving model.
  Our evaluation on the industry-scale datasets show that SilverTorch achieves up to 5.6x lower latency and 23.7x higher throughput compared to the state-of-the-art approaches. We also demonstrate that SilverTorch's solution is 13.35x more cost-efficient than CPU-based solution while improving accuracy via serving more complex models. SilverTorch serves over hundreds of models online across major products and recommends contents for billions of daily active users.

</details>


### [10] [Multi-Aspect Cross-modal Quantization for Generative Recommendation](https://arxiv.org/abs/2511.15122)
*Fuwei Zhang,Xiaoyu Liu,Dongbo Xi,Jishen Yin,Huan Chen,Peng Yan,Fuzhen Zhuang,Zhao Zhang*

Main category: cs.IR

TL;DR: 提出了MACRec方法，通过跨模态量化和多角度对齐来改进生成式推荐系统，解决语义ID构建和生成模型训练中的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐方法在利用多模态信息和捕捉深度跨模态交互方面存在局限，这影响了高质量语义ID的构建和生成模型的有效训练。

Method: 引入跨模态量化来减少冲突率，并结合隐式和显式的多角度跨模态对齐来增强生成能力。

Result: 在三个知名推荐数据集上的实验证明了该方法的有效性。

Conclusion: MACRec通过整合多模态信息从不同角度改进语义ID学习和生成模型训练，提升了生成式推荐的性能。

Abstract: Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.

</details>


### [11] [ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation](https://arxiv.org/abs/2511.15141)
*Sunwoo Kim,Geon Lee,Kyungho Kim,Jaemin Yoo,Kijung Shin*

Main category: cs.IR

TL;DR: 提出ItemRAG方法，基于物品的检索增强生成技术，通过检索物品间的共购历史来改进LLM推荐系统，在冷启动物品推荐和标准推荐场景下均优于用户基RAG方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法多为用户基，检索相似用户的购买模式。本文提出物品基RAG方法，通过检索物品间的共购模式来更好地适应LLM推荐系统，特别是处理冷启动物品。

Method: ItemRAG方法从物品-物品共购历史中检索相关物品，结合语义相似物品处理冷启动物品，利用共购频率提高检索相关性。

Result: 实验显示ItemRAG将零样本LLM推荐器的Hit-Ratio-1提升高达43%，在标准和冷启动物品推荐场景下均优于用户基RAG基线方法。

Conclusion: ItemRAG通过物品基检索增强生成有效捕捉物品间共购模式，显著提升LLM推荐性能，特别是在冷启动物品推荐方面表现优异。

Abstract: Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.

</details>


### [12] [Selective Mixup for Debiasing Question Selection in Computerized Adaptive Testing](https://arxiv.org/abs/2511.15241)
*Mi Tian,Kun Zhang,Fei Liu,Jinglong Li,Yuxin Liao,Chenxi Bai,Zhengtao Tan,Le Wu,Richang Hong*

Main category: cs.IR

TL;DR: 本文提出了一个用于计算机自适应测试(CAT)的去偏框架，通过交叉属性考生检索和选择性Mixup正则化来解决自适应过程中的选择偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的CAT方法主要关注诊断准确性，但忽视了自适应过程中固有的选择偏差问题。这种偏差源于问题选择强烈依赖于估计的能力水平，导致偏差在迭代更新中被放大，造成预测偏差和对齐问题。

Method: 提出包含两个关键模块的去偏框架：1) 交叉属性考生检索 - 检索具有相对均匀正确和错误回答分布的平衡考生作为偏置考生的中性参考；2) 选择性Mixup正则化 - 在标签一致条件下，对每个偏置考生与其匹配的平衡对应项应用mixup，丰富偏差冲突样本的多样性并平滑选择边界。

Result: 在两个基准数据集上的广泛实验表明，该方法显著提高了CAT中问题选择的泛化能力和公平性。

Conclusion: 所提出的去偏框架有效解决了CAT中的选择偏差问题，提高了诊断模型的泛化性能和公平性。

Abstract: Computerized Adaptive Testing (CAT) is a widely used technology for evaluating learners' proficiency in online education platforms. By leveraging prior estimates of proficiency to select questions and updating the estimates iteratively based on responses, CAT enables personalized learner modeling and has attracted substantial attention. Despite this progress, most existing works focus primarily on improving diagnostic accuracy, while overlooking the selection bias inherent in the adaptive process. Selection Bias arises because the question selection is strongly influenced by the estimated proficiency, such as assigning easier questions to learners with lower proficiency and harder ones to learners with higher proficiency. Since the selection depends on prior estimation, this bias propagates into the diagnosis model, which is further amplified during iterative updates, leading to misalignment and biased predictions. Moreover, the imbalanced nature of learners' historical interactions often exacerbates the bias in diagnosis models. To address this issue, we propose a debiasing framework consisting of two key modules: Cross-Attribute Examinee Retrieval and Selective Mixup-based Regularization. First, we retrieve balanced examinees with relatively even distributions of correct and incorrect responses and use them as neutral references for biased examinees. Then, mixup is applied between each biased examinee and its matched balanced counterpart under label consistency. This augmentation enriches the diversity of bias-conflicting samples and smooths selection boundaries. Finally, extensive experiments on two benchmark datasets with multiple advanced diagnosis models demonstrate that our method substantially improves both the generalization ability and fairness of question selection in CAT.

</details>


### [13] [Unveiling Inference Scaling for Difference-Aware User Modeling in LLM Personalization](https://arxiv.org/abs/2511.15389)
*Suyu Chen,Yimeng Bai,Yulong Huang,Xiaoyan Zhao,Yang Zhang*

Main category: cs.IR

TL;DR: 提出了DRP框架，通过推理扩展重构差异提取机制，利用系统2思维进行用户差异推理，在个性化评论生成任务中优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖用户自身历史，忽略了用户间差异，且特征提取过程依赖固定维度和快速直觉推理，限制了用户差异的覆盖范围和粒度

Method: DRP框架自主识别相关差异特征维度，生成结构化定义和描述，利用系统2思维进行慢速、审慎的用户差异推理

Result: 在个性化评论生成实验中，DRP在多个指标上持续优于基线方法

Conclusion: DRP通过重构差异提取机制，利用推理扩展增强LLM个性化能力，证明了系统2思维在用户差异建模中的有效性

Abstract: Large Language Models (LLMs) are increasingly integrated into users' daily lives, driving a growing demand for personalized outputs. Prior work has primarily leveraged a user's own history, often overlooking inter-user differences that are critical for effective personalization. While recent methods have attempted to model such differences, their feature extraction processes typically rely on fixed dimensions and quick, intuitive inference (System-1 thinking), limiting both the coverage and granularity of captured user differences. To address these limitations, we propose Difference-aware Reasoning Personalization (DRP), a framework that reconstructs the difference extraction mechanism by leveraging inference scaling to enhance LLM personalization. DRP autonomously identifies relevant difference feature dimensions and generates structured definitions and descriptions, enabling slow, deliberate reasoning (System-2 thinking) over user differences. Experiments on personalized review generation demonstrate that DRP consistently outperforms baseline methods across multiple metrics.

</details>


### [14] [CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search](https://arxiv.org/abs/2511.15443)
*Ao Xie,Jiahui Chen,Quanzhi Zhu,Xiaoze Jiang,Zhiheng Qin,Enyun Yu,Han Li*

Main category: cs.IR

TL;DR: CroPS是一个新颖的检索数据引擎，通过从查询级、系统级和知识级三个视角引入多样化的正样本来缓解稠密检索中的过滤气泡效应，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 工业检索系统依赖历史用户交互数据进行训练，导致过滤气泡效应，排除了潜在相关但未被曝光的内容，使模型偏向保守检索。

Method: 提出CroPS框架，从三个视角获取正样本：用户查询重构行为（查询级）、推荐流中的互动数据（系统级）、LLM合成的世界知识（知识级），并采用分层标签分配策略和H-InfoNCE损失函数。

Result: 在快手搜索平台上的实验表明，CroPS显著优于基线方法，在离线评估和在线A/B测试中都表现出优越的检索性能，降低了查询重构率。

Conclusion: CroPS成功缓解了过滤气泡问题，已在快手搜索中全面部署，为数亿用户提供日常服务。

Abstract: Dense retrieval has become a foundational paradigm in modern search systems, especially on short-video platforms. However, most industrial systems adopt a self-reinforcing training pipeline that relies on historically exposed user interactions for supervision. This paradigm inevitably leads to a filter bubble effect, where potentially relevant but previously unseen content is excluded from the training signal, biasing the model toward narrow and conservative retrieval. In this paper, we present CroPS (Cross-Perspective Positive Samples), a novel retrieval data engine designed to alleviate this problem by introducing diverse and semantically meaningful positive examples from multiple perspectives. CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level). To effectively utilize these heterogeneous signals, we introduce a Hierarchical Label Assignment (HLA) strategy and a corresponding H-InfoNCE loss that together enable fine-grained, relevance-aware optimization. Extensive experiments conducted on Kuaishou Search, a large-scale commercial short-video search platform, demonstrate that CroPS significantly outperforms strong baselines both offline and in live A/B tests, achieving superior retrieval performance and reducing query reformulation rates. CroPS is now fully deployed in Kuaishou Search, serving hundreds of millions of users daily.

</details>
