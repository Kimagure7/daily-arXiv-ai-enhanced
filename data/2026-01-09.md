<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 11]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Correct and Weight: A Simple Yet Effective Loss for Implicit Feedback Recommendation](https://arxiv.org/abs/2601.04291)
*Minglei Yin,Chuanbo Hu,Bin Liu,Neil Zhenqiang Gong,Yanfang,Ye,Xin Li*

Main category: cs.IR

TL;DR: 提出一种名为CW的损失函数，通过修正假阴性样本的影响来改进隐式反馈推荐系统。


<details>
  <summary>Details</summary>
Motivation: 隐式反馈推荐系统中存在假阴性问题，即未观察到的用户-物品交互不一定表示负面偏好，这会影响模型训练效果。

Method: 提出CW损失函数，包含两个关键技术：1) 基于正-未标记学习理论，通过可观测数据分布和正交互分布来近似真实负分布，修正负采样偏差；2) 引入动态重加权机制，根据模型当前预测调整每个负样本的重要性。

Result: 在四个大规模稀疏基准数据集上的实验表明，该方法在多个排序指标上持续且显著优于现有最先进的损失函数。

Conclusion: CW损失函数优雅高效，无需复杂的数据采样修改或显著计算开销，可广泛应用于现有推荐模型，有效解决了隐式反馈中的假阴性问题。

Abstract: Learning from implicit feedback has become the standard paradigm for modern recommender systems. However, this setting is fraught with the persistent challenge of false negatives, where unobserved user-item interactions are not necessarily indicative of negative preference. To address this issue, this paper introduces a novel and principled loss function, named Corrected and Weighted (CW) loss, that systematically corrects for the impact of false negatives within the training objective. Our approach integrates two key techniques. First, inspired by Positive-Unlabeled learning, we debias the negative sampling process by re-calibrating the assumed negative distribution. By theoretically approximating the true negative distribution (p-) using the observable general data distribution (p) and the positive interaction distribution (p^+), our method provides a more accurate estimate of the likelihood that a sampled unlabeled item is truly negative. Second, we introduce a dynamic re-weighting mechanism that modulates the importance of each negative instance based on the model's current prediction. This scheme encourages the model to enforce a larger ranking margin between positive items and confidently predicted (i.e., easy) negative items, while simultaneously down-weighting the penalty on uncertain negatives that have a higher probability of being false negatives. A key advantage of our approach is its elegance and efficiency; it requires no complex modifications to the data sampling process or significant computational overhead, making it readily applicable to a wide array of existing recommendation models. Extensive experiments conducted on four large-scale, sparse benchmark datasets demonstrate the superiority of our proposed loss. The results show that our method consistently and significantly outperforms a suite of state-of-the-art loss functions across multiple ranking-oriented metrics.

</details>


### [2] [The Overlooked Role of Graded Relevance Thresholds in Multilingual Dense Retrieval](https://arxiv.org/abs/2601.04395)
*Tomer Wullach,Ori Shapira,Amir DN Cohen*

Main category: cs.IR

TL;DR: 论文分析了在密集检索模型微调中，使用分级相关性评分而非二元标签的重要性，发现不同语言和任务的最佳阈值存在系统性差异，合理选择阈值能提升效果、减少训练数据需求并缓解标注噪声。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型通常使用对比学习目标进行微调，这需要二元相关性判断，但相关性本质上是分级的。当前方法忽略了分级相关性评分这一有价值信号，且不同语言和任务中阈值选择的影响未被系统研究。

Method: 使用LLM标注的分级相关性评分多语言数据集，分析分级相关性评分及其转换为二元标签的阈值如何影响多语言密集检索。研究单语言、多语言混合和跨语言检索场景，系统考察阈值选择对性能的影响。

Result: 研究发现：1）最佳阈值在不同语言和任务间存在系统性差异，通常反映资源水平差异；2）合理选择阈值能提升检索效果、减少微调数据需求并缓解标注噪声；3）不当的阈值选择会降低性能。

Conclusion: 分级相关性是密集检索中宝贵但未充分利用的信号，阈值校准应作为微调流程的原则性组成部分。需要根据具体语言和任务特性进行系统化的阈值选择。

Abstract: Dense retrieval models are typically fine-tuned with contrastive learning objectives that require binary relevance judgments, even though relevance is inherently graded. We analyze how graded relevance scores and the threshold used to convert them into binary labels affect multilingual dense retrieval. Using a multilingual dataset with LLM-annotated relevance scores, we examine monolingual, multilingual mixture, and cross-lingual retrieval scenarios. Our findings show that the optimal threshold varies systematically across languages and tasks, often reflecting differences in resource level. A well-chosen threshold can improve effectiveness, reduce the amount of fine-tuning data required, and mitigate annotation noise, whereas a poorly chosen one can degrade performance. We argue that graded relevance is a valuable but underutilized signal for dense retrieval, and that threshold calibration should be treated as a principled component of the fine-tuning pipeline.

</details>


### [3] [Re-Rankers as Relevance Judges](https://arxiv.org/abs/2601.04455)
*Chuan Meng,Jiqun Liu,Mohammad Aliannejadi,Fengran Mo,Jeff Dalton,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该研究探索将重排序器作为相关性判断工具，通过两种适配策略（二进制标记输出和分数阈值化），在TREC-DL数据集上验证其性能优于现有LLM基准，并揭示了重排序器存在的自我偏好和跨家族偏见。


<details>
  <summary>Details</summary>
Motivation: 当前使用大语言模型预测相关性判断的研究大多将其视为独立任务，专注于提示设计等。然而，预测相关性判断本质上是相关性预测问题，这与重排序任务有高度重叠。现有研究很少探索重用或适配成熟的重排序方法来预测相关性判断，导致资源浪费和重复开发。本文旨在填补这一空白。

Method: 提出"重排序器作为相关性判断器"的框架，设计两种适配策略：1）使用重排序器生成的二进制标记（如"true"/"false"）作为直接判断；2）通过阈值化将连续的重排序分数转换为二进制标签。在TREC-DL 2019-2023数据集上，对来自3个家族的8个重排序器（规模从2.2亿到320亿参数）进行广泛实验，并分析基于重排序器的判断器所表现出的评估偏见。

Result: 实验结果表明：1）基于重排序器的相关性判断器在两种策略下，约40%-50%的情况下能超越当前最先进的LLM基准UMBRELA；2）这些判断器表现出强烈的自我偏好，偏向于自身和同家族的重排序器；3）存在明显的跨家族偏见。

Conclusion: 重排序器可以作为有效的相关性判断工具，其性能在某些情况下优于专门的LLM方法。研究揭示了重排序器在评估中存在的偏见问题，为未来相关性判断系统的开发提供了重要启示，并证明了重用现有重排序方法的可行性。

Abstract: Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., "true" and "false") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.

</details>


### [4] [Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering](https://arxiv.org/abs/2601.04531)
*Jessica Ryan,Alexander I. Gumilang,Robert Wiliam,Derwin Suhartono*

Main category: cs.IR

TL;DR: Self-MedRAG：结合混合检索与自反思循环的临床推理框架，显著提升医学问答准确性和可靠性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学问答中存在幻觉和缺乏依据的问题，传统单次检索无法处理需要多步推理的复杂生物医学查询，限制了其在高风险临床场景中的可靠性。

Method: 提出Self-MedRAG自反思混合框架，包含：1）混合检索策略（BM25稀疏检索+Contriever密集检索+RRF融合）；2）生成器产生答案和推理依据；3）轻量级自反思模块（NLI或LLM验证）；4）若证据不足则自主重写查询并迭代优化。

Result: 在MedQA和PubMedQA基准测试中，混合检索显著优于单检索器基线，自反思循环带来显著提升：MedQA准确率从80.00%提升至83.33%，PubMedQA从69.10%提升至79.82%。

Conclusion: 混合检索与迭代、基于证据的自反思相结合，能有效减少无依据的断言，增强基于LLM系统的临床可靠性，为复杂医学推理提供了有效解决方案。

Abstract: Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.

</details>


### [5] [Exploring Recommender System Evaluation: A Multi-Modal User Agent Framework for A/B Testing](https://arxiv.org/abs/2601.04554)
*Wenlin Zhang,Xiangyang Li,Qiyuan Ge,Kuicai Dong,Pengyue Jia,Xiaopeng Li,Zijian Zhang,Maolin Wang,Yichao Wang,Huifeng Guo,Ruiming Tang,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 提出A/B Agent多模态用户代理，通过构建推荐沙箱环境模拟真实用户行为，替代传统在线A/B测试


<details>
  <summary>Details</summary>
Motivation: 传统在线A/B测试存在经济成本高、用户体验下降、时间需求大等问题，而现有代理缺乏真实环境和视觉感知能力，无法模拟用户感知过程和交互模式

Method: 构建推荐沙箱环境支持多模态多页面交互，设计代理具备多模态信息感知、细粒度用户偏好，集成用户画像、行动记忆检索和疲劳系统来模拟复杂人类决策

Result: 从模型、数据和特征三个角度验证了代理替代传统A/B测试的潜力，发现A/B Agent生成的数据能有效提升推荐模型能力

Conclusion: A/B Agent为替代传统在线A/B测试提供了可行方案，其生成的数据对推荐模型有增强作用，代码已开源

Abstract: In recommender systems, online A/B testing is a crucial method for evaluating the performance of different models. However, conducting online A/B testing often presents significant challenges, including substantial economic costs, user experience degradation, and considerable time requirements. With the Large Language Models' powerful capacity, LLM-based agent shows great potential to replace traditional online A/B testing. Nonetheless, current agents fail to simulate the perception process and interaction patterns, due to the lack of real environments and visual perception capability. To address these challenges, we introduce a multi-modal user agent for A/B testing (A/B Agent). Specifically, we construct a recommendation sandbox environment for A/B testing, enabling multimodal and multi-page interactions that align with real user behavior on online platforms. The designed agent leverages multimodal information perception, fine-grained user preferences, and integrates profiles, action memory retrieval, and a fatigue system to simulate complex human decision-making. We validated the potential of the agent as an alternative to traditional A/B testing from three perspectives: model, data, and features. Furthermore, we found that the data generated by A/B Agent can effectively enhance the capabilities of recommendation models. Our code is publicly available at https://github.com/Applied-Machine-Learning-Lab/ABAgent.

</details>


### [6] [Adaptive Retrieval for Reasoning-Intensive Retrieval](https://arxiv.org/abs/2601.04618)
*Jongho Kim,Jaeyoung Kim,Seung-won Hwang,Jihyuk Kim,Yu Jin Kim,Moontae Lee*

Main category: cs.IR

TL;DR: REPAIR框架利用推理计划作为密集反馈信号进行自适应检索，解决推理密集型检索中"桥梁文档"召回不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于推理的重排序管道在检索"桥梁文档"（对推理过程有贡献但不直接相关初始查询的文档）时存在召回率受限的问题，而将自适应检索简单引入这些管道会导致规划错误传播

Method: 提出REPAIR框架，将推理计划重新用作自适应检索的密集反馈信号，通过选择性自适应检索实现中途修正，检索支持关键计划的文档

Result: 在推理密集型检索和复杂QA任务上的实验结果表明，该方法比现有基线性能提升5.6个百分点

Conclusion: REPAIR通过将推理计划作为反馈信号，有效解决了推理密集型检索中桥梁文档召回不足的问题，实现了更好的检索性能

Abstract: We study leveraging adaptive retrieval to ensure sufficient "bridge" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.

</details>


### [7] [Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search](https://arxiv.org/abs/2601.04646)
*Prateek Jain,Shabari S Nair,Ritesh Goru,Prakhar Agarwal,Ajay Yadav,Yoga Sri Varshan Varadharajan,Constantine Caramanis*

Main category: cs.IR

TL;DR: 提出DevRev Search基准和索引保持适应策略，通过仅微调查询编码器来避免文档重新索引，解决多租户检索系统中的"暗数据"问题。


<details>
  <summary>Details</summary>
Motivation: 大规模多租户检索系统积累了海量用户查询日志，但缺乏用于有效领域适应的标注数据（"暗数据"问题）。同时，联合微查询和文档编码器需要重新索引整个语料库，这在多租户环境中成本过高。

Method: 1) 构建DevRev Search基准：通过融合多种稀疏和密集检索器的候选生成策略，使用LLM作为评判者进行一致性过滤和相关性标注；2) 提出索引保持适应策略：仅通过LoRA微调查询编码器的特定transformer层，保持文档索引不变。

Result: 在DevRev Search和SciFact数据集上的实验表明，针对查询编码器的特定transformer层进行微调，可以在保持文档索引不变的情况下获得竞争力的性能提升，实现质量与效率的最佳权衡。

Conclusion: 提出的方法为个性化企业搜索提供了可扩展的路径，通过仅微调查询编码器来避免昂贵的文档重新索引，同时利用自动构建的基准数据集解决标注数据缺乏的问题。

Abstract: Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This "dark data" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \textbf{consistency filtering} and relevance assignment. We further propose a practical \textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.

</details>


### [8] [PROMISE: Process Reward Models Unlock Test-Time Scaling Laws in Generative Recommendations](https://arxiv.org/abs/2601.04674)
*Chengcheng Guo,Kuo Cai,Yu Zhou,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: Promise框架通过过程奖励模型和引导波束搜索解决生成式推荐中的语义漂移问题，实现推理时计算扩展，让小模型达到或超越大模型性能


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法存在语义漂移问题，早期高层级token的错误会不可逆转地将生成轨迹导向不相关的语义子空间，严重影响推荐准确性

Method: 提出Promise框架：1）轻量级过程奖励模型评估中间推理步骤质量；2）PRM引导的波束搜索策略，利用密集反馈动态修剪错误分支；3）实现推荐系统的测试时扩展定律

Result: 离线实验和在线A/B测试表明，Promise有效缓解语义漂移，显著提高推荐准确性，同时实现高效部署，小模型通过增加推理计算可匹配或超越大模型

Conclusion: Promise框架成功解决生成式推荐中的语义漂移问题，通过过程奖励模型和测试时扩展定律，在保持高效部署的同时显著提升推荐性能

Abstract: Generative Recommendation has emerged as a promising paradigm, reformulating recommendation as a sequence-to-sequence generation task over hierarchical Semantic IDs. However, existing methods suffer from a critical issue we term Semantic Drift, where errors in early, high-level tokens irreversibly divert the generation trajectory into irrelevant semantic subspaces. Inspired by Process Reward Models (PRMs) that enhance reasoning in Large Language Models, we propose Promise, a novel framework that integrates dense, step-by-step verification into generative models. Promise features a lightweight PRM to assess the quality of intermediate inference steps, coupled with a PRM-guided Beam Search strategy that leverages dense feedback to dynamically prune erroneous branches. Crucially, our approach unlocks Test-Time Scaling Laws for recommender systems: by increasing inference compute, smaller models can match or surpass larger models. Extensive offline experiments and online A/B tests on a large-scale platform demonstrate that Promise effectively mitigates Semantic Drift, significantly improving recommendation accuracy while enabling efficient deployment.

</details>


### [9] [Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective](https://arxiv.org/abs/2601.04918)
*Ziwen Wang,Shangshang Yang,Xiaoshan Yu,Haiping Ma,Xingyi Zhang*

Main category: cs.IR

TL;DR: OSCD：一种用于认知诊断的进化多目标一次性神经架构搜索方法，旨在高效、鲁棒地提升模型评估学习者能力，同时处理观测数据中的噪声污染问题。


<details>
  <summary>Details</summary>
Motivation: 现有认知诊断研究过于关注模型性能提升，忽视了观测响应数据中普遍存在的噪声污染问题，这严重阻碍了实际部署。同时，现有CDMs过度依赖研究者的领域专业知识进行结构设计，未能充分探索架构可能性，限制了模型潜力的发挥。

Method: 提出OSCD方法，包含训练和搜索两个阶段：1）训练阶段：构建包含多样化架构组合的搜索空间，训练基于完全二叉树拓扑表示的权重共享超网络；2）搜索阶段：将异构噪声场景下的最优架构搜索建模为多目标优化问题，开发集成帕累托最优解搜索策略和跨场景性能评估的优化框架。

Result: 在真实世界教育数据集上的大量实验验证了OSCD模型发现的认知诊断任务最优架构的有效性和鲁棒性。

Conclusion: OSCD方法能够高效、鲁棒地提升认知诊断模型评估学习者能力，解决了现有研究中忽视噪声污染和架构探索不足的问题，为智能辅导系统中的个性化学习服务提供了更可靠的解决方案。

Abstract: With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.

</details>


### [10] [Dynamics in Search Engine Query Suggestions for European Politicians](https://arxiv.org/abs/2601.05081)
*Franziska Pradel,Fabian Haak,Sven-Oliver Proksch,Philipp Schaer*

Main category: cs.IR

TL;DR: 该研究分析了谷歌搜索建议在不同国家和时间维度上对欧洲政治家的变化模式，发现搜索建议的稳定性受政治家国籍、职务类型和性别影响。


<details>
  <summary>Details</summary>
Motivation: 搜索引擎是政治信息获取的重要渠道，但人们对搜索建议如何反映用户潜在兴趣在不同国家和时间上的变化缺乏了解。研究旨在填补这一空白，特别关注欧洲政治家的搜索建议模式。

Method: 研究使用原创数据集，收集了十个国家中欧洲政治家的谷歌搜索建议。通过系统分析这些数据，考察搜索建议在不同国家间的相似性和时间上的稳定性。

Result: 研究发现：1）在政治家本国，搜索建议随时间变化更不稳定；2）担任超国家职务的政治家搜索建议更不稳定；3）女性政治家的搜索建议更不稳定；4）政治领导人和男性政治家的搜索建议在不同国家间更相似。

Conclusion: 研究揭示了搜索建议模式的重要差异，为理解在线政治信息搜索提供了新视角。未来研究可进一步探索欧洲政治家在线搜索信息的行为模式。

Abstract: Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.

</details>


### [11] [Multivector Reranking in the Era of Strong First-Stage Retrievers](https://arxiv.org/abs/2601.05200)
*Silvio Martinico,Franco Maria Nardini,Cosimo Rulli,Rossano Venturini*

Main category: cs.IR

TL;DR: 用双阶段检索架构（稀疏检索+多向量重排）替代传统多向量检索的token级收集阶段，实现24倍加速且保持检索质量


<details>
  <summary>Details</summary>
Motivation: 现代多向量检索系统虽然效果好，但token级检索成本高，现有收集-精炼策略需要搜索大型token级索引且容易漏掉最优文档

Method: 1) 用学习型稀疏检索器替代token级收集阶段；2) 集成免推理LSR方法减少查询编码时间；3) 引入两种优化技术早期剪枝低质量候选

Result: 检索效率提升1.8倍无质量损失，整体比最先进多向量检索系统快24倍以上，同时保持相当或更优的检索质量

Conclusion: 双阶段检索架构能显著提升多向量检索效率，通过稀疏检索收集候选、多向量重排精炼，结合优化技术实现高效高质量检索

Abstract: Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.

</details>
