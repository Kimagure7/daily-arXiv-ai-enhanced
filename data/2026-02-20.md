<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [RankEvolve: Automating the Discovery of Retrieval Algorithms via LLM-Driven Evolution](https://arxiv.org/abs/2602.16932)
*Jinming Nian,Fangchen Li,Dae Hoon Park,Yi Fang*

Main category: cs.IR

TL;DR: 本文提出RankEvolve，利用大语言模型通过进化搜索自动发现改进的词法检索算法，从BM25和查询似然等基础算法出发，在多个IR数据集上进化出新颖有效的检索算法。


<details>
  <summary>Details</summary>
Motivation: 尽管BM25和带狄利克雷平滑的查询似然等传统检索算法仍然是强大高效的第一阶段排序器，但改进主要依赖参数调整和人类直觉。研究探索是否可以利用大语言模型，在评估器引导下通过进化搜索自动发现改进的词法检索算法。

Method: 提出RankEvolve方法，基于AlphaEvolve的程序进化框架。候选排序算法表示为可执行代码，通过变异、重组和选择迭代进化。使用评估器根据在BEIR和BRIGHT的12个IR数据集上的检索性能进行选择。从两个种子程序（BM25和带狄利克雷平滑的查询似然）开始进化。

Result: 进化出的算法具有新颖性且有效，在完整的BEIR和BRIGHT基准测试以及TREC DL 19和20上显示出良好的迁移能力。结果表明评估器引导的LLM程序进化是自动发现新颖排序算法的实用途径。

Conclusion: 评估器引导的大语言模型程序进化是自动发现新颖排序算法的可行方法，能够从基础算法出发进化出具有良好性能和迁移能力的新算法。

Abstract: Retrieval algorithms like BM25 and query likelihood with Dirichlet smoothing remain strong and efficient first-stage rankers, yet improvements have mostly relied on parameter tuning and human intuition. We investigate whether a large language model, guided by an evaluator and evolutionary search, can automatically discover improved lexical retrieval algorithms. We introduce RankEvolve, a program evolution setup based on AlphaEvolve, in which candidate ranking algorithms are represented as executable code and iteratively mutated, recombined, and selected based on retrieval performance across 12 IR datasets from BEIR and BRIGHT. RankEvolve starts from two seed programs: BM25 and query likelihood with Dirichlet smoothing. The evolved algorithms are novel, effective, and show promising transfer to the full BEIR and BRIGHT benchmarks as well as TREC DL 19 and 20. Our results suggest that evaluator-guided LLM program evolution is a practical path towards automatic discovery of novel ranking algorithms.

</details>


### [2] [SAGE: Structure Aware Graph Expansion for Retrieval of Heterogeneous Data](https://arxiv.org/abs/2602.16964)
*Prasham Titiya,Rohit Khoja,Tomer Wolfson,Vivek Gupta,Dan Roth*

Main category: cs.IR

TL;DR: SAGE框架通过构建块级图并进行在线图扩展检索，提升异构语料问答中的多跳证据检索能力


<details>
  <summary>Details</summary>
Motivation: 异构语料（文本、表格、图节点）的问答需要跨模态的多跳证据链。传统知识图谱构建维护成本高且查询效率低，而标准检索器-阅读器流水线使用扁平相似度搜索，无法捕捉跨模态的多跳证据链。

Method: 提出SAGE框架：1）离线构建块级图，使用元数据驱动的相似度和百分位剪枝；2）在线检索时，先运行基线检索器获取k个种子块，扩展一跳邻居，然后使用密集+稀疏检索过滤邻居，选择k'个额外块。针对隐式跨模态语料使用混合密集+稀疏检索，针对显式模式图使用SPARK代理检索器。

Result: 在OTT-QA和STaRK数据集上，SAGE相比基线分别提升了5.7和8.5个点的检索召回率。

Conclusion: SAGE框架通过结构感知的图扩展方法，有效解决了异构语料问答中的多跳证据检索问题，相比传统方法有显著提升。

Abstract: Retrieval-augmented question answering over heterogeneous corpora requires connected evidence across text, tables, and graph nodes. While entity-level knowledge graphs support structured access, they are costly to construct and maintain, and inefficient to traverse at query time. In contrast, standard retriever-reader pipelines use flat similarity search over independently chunked text, missing multi-hop evidence chains across modalities. We propose SAGE (Structure Aware Graph Expansion) framework that (i) constructs a chunk-level graph offline using metadata-driven similarities with percentile-based pruning, and (ii) performs online retrieval by running an initial baseline retriever to obtain k seed chunks, expanding first-hop neighbors, and then filtering the neighbors using dense+sparse retrieval, selecting k' additional chunks. We instantiate the initial retriever using hybrid dense+sparse retrieval for implicit cross-modal corpora and SPARK (Structure Aware Planning Agent for Retrieval over Knowledge Graphs) an agentic retriever for explicit schema graphs. On OTT-QA and STaRK, SAGE improves retrieval recall by 5.7 and 8.5 points over baselines.

</details>


### [3] [Beyond Chunk-Then-Embed: A Comprehensive Taxonomy and Evaluation of Document Chunking Strategies for Information Retrieval](https://arxiv.org/abs/2602.16974)
*Yongjie Zhou,Shuai Wang,Bevan Koopman,Guido Zuccon*

Main category: cs.IR

TL;DR: 本文系统评估了文档分块策略，发现最优分块方法取决于任务类型：简单结构方法在跨文档检索中表现最佳，而LLM引导方法在文档内检索中效果最好。


<details>
  <summary>Details</summary>
Motivation: 文档分块是密集检索系统的关键预处理步骤，但现有分块策略研究分散且缺乏统一评估框架，难以进行直接比较。

Method: 提出统一框架，从两个维度系统评估分块策略：(1) 分割方法（结构基、语义基、LLM引导）和(2) 嵌入范式（预嵌入分块 vs. 上下文分块），并在两种检索设置下进行复现评估。

Result: 最优分块策略具有任务依赖性：简单结构方法在跨文档检索中优于LLM引导方法，而LumberChunker在文档内检索中表现最佳；上下文分块提升跨文档效果但降低文档内检索性能。

Conclusion: 分块策略选择应基于具体任务需求，而非盲目采用复杂方法；提供了统一评估框架和公开代码基准，促进该领域研究。

Abstract: Document chunking is a critical preprocessing step in dense retrieval systems, yet the design space of chunking strategies remains poorly understood. Recent research has proposed several concurrent approaches, including LLM-guided methods (e.g., DenseX and LumberChunker) and contextualized strategies(e.g., Late Chunking), which generate embeddings before segmentation to preserve contextual information. However, these methods emerged independently and were evaluated on benchmarks with minimal overlap, making direct comparisons difficult.
  This paper reproduces prior studies in document chunking and presents a systematic framework that unifies existing strategies along two key dimensions: (1) segmentation methods, including structure-based methods (fixed-size, sentence-based, and paragraph-based) as well as semantically-informed and LLM-guided methods; and (2) embedding paradigms, which determine the timing of chunking relative to embedding (pre-embedding chunking vs. contextualized chunking). Our reproduction evaluates these approaches in two distinct retrieval settings established in previous work: in-document retrieval (needle-in-a-haystack) and in-corpus retrieval (the standard information retrieval task).
  Our comprehensive evaluation reveals that optimal chunking strategies are task-dependent: simple structure-based methods outperform LLM-guided alternatives for in-corpus retrieval, while LumberChunker performs best for in-document retrieval. Contextualized chunking improves in-corpus effectiveness but degrades in-document retrieval. We also find that chunk size correlates moderately with in-document but weakly with in-corpus effectiveness, suggesting segmentation method differences are not purely driven by chunk size. Our code and evaluation benchmarks are publicly available at (Anonymoused).

</details>


### [4] [Bending the Scaling Law Curve in Large-Scale Recommendation Systems](https://arxiv.org/abs/2602.16986)
*Qin Ding,Kevin Course,Linjian Ma,Jianhui Sun,Rouchen Liu,Zhao Zhu,Chunxing Yin,Wei Li,Dai Li,Yu Shi,Xuan Cao,Ze Yang,Han Li,Xing Liu,Bi Xue,Hongwei Li,Rui Jian,Daisy Shi He,Jing Qian,Matt Ma,Qunshu Zhang,Rui Li*

Main category: cs.IR

TL;DR: ULTRA-HSTU是一种通过模型与系统协同设计的新型序列推荐模型，在输入序列设计、稀疏注意力机制和模型拓扑方面创新，实现了模型质量和效率的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐模型过度依赖交叉注意力机制来解决二次计算瓶颈，这限制了自注意力的表示能力。需要一种既能保持高质量推荐又能高效扩展的解决方案。

Method: 通过端到端的模型与系统协同设计，创新性地设计输入序列、稀疏注意力机制和模型拓扑结构，解决传统序列建模中的计算瓶颈问题。

Result: ULTRA-HSTU实现了显著的扩展效率提升——相比传统模型训练速度提升5倍以上，推理速度提升21倍，同时提供更优的推荐质量。在实际生产环境中，为数十亿用户提供服务，带来4%到8%的消费和参与度提升。

Conclusion: ULTRA-HSTU通过创新的模型架构和系统设计，成功解决了序列推荐中的计算效率瓶颈，在保持高质量推荐的同时实现了显著的性能提升，已在真实生产环境中验证了其有效性。

Abstract: Learning from user interaction history through sequential models has become a cornerstone of large-scale recommender systems. Recent advances in large language models have revealed promising scaling laws, sparking a surge of research into long-sequence modeling and deeper architectures for recommendation tasks. However, many recent approaches rely heavily on cross-attention mechanisms to address the quadratic computational bottleneck in sequential modeling, which can limit the representational power gained from self-attention. We present ULTRA-HSTU, a novel sequential recommendation model developed through end-to-end model and system co-design. By innovating in the design of input sequences, sparse attention mechanisms, and model topology, ULTRA-HSTU achieves substantial improvements in both model quality and efficiency. Comprehensive benchmarking demonstrates that ULTRA-HSTU achieves remarkable scaling efficiency gains -- over 5x faster training scaling and 21x faster inference scaling compared to conventional models -- while delivering superior recommendation quality. Our solution is fully deployed at scale, serving billions of users daily and driving significant 4% to 8% consumption and engagement improvements in real-world production environments.

</details>


### [5] [WSDM Cup 2026 Multilingual Retrieval: A Low-Cost Multi-Stage Retrieval Pipeline](https://arxiv.org/abs/2602.16989)
*Chentong Hao,Minmao Wang*

Main category: cs.IR

TL;DR: 提出一个低成本的多语言检索系统，结合查询扩展、BM25检索、稠密排序和重排序，在WSDM Cup 2026任务中取得良好效果


<details>
  <summary>Details</summary>
Motivation: 解决WSDM Cup 2026多语言检索任务的需求：使用英文查询检索中文、波斯语和俄语新闻文档，需要在有限计算预算下实现高效检索

Method: 采用四阶段流水线：1) LLM-based GRF式查询扩展；2) BM25候选检索；3) 使用jina-embeddings-v4的长文本表示进行稠密排序；4) 使用Qwen3-Reranker-4B对前20个候选进行点式重排序，其余保持稠密排序顺序

Result: 在官方评估中，系统达到nDCG@20为0.403，Judged@20为0.95。通过消融实验量化了各阶段的贡献，分析了查询扩展、稠密排序和重排序在有限计算预算下的有效性

Conclusion: 提出的低成本多阶段检索系统在多语言检索任务中表现良好，通过合理的组件组合在有限计算资源下实现了有效的检索性能

Abstract: We present a low-cost retrieval system for the WSDM Cup 2026 multilingual retrieval task, where English queries are used to retrieve relevant documents from a collection of approximately ten million news articles in Chinese, Persian, and Russian, and to output the top-1000 ranked results for each query. We follow a four-stage pipeline that combines LLM-based GRF-style query expansion with BM25 candidate retrieval, dense ranking using long-text representations from jina-embeddings-v4, and pointwise re-ranking of the top-20 candidates using Qwen3-Reranker-4B while preserving the dense order for the remaining results. On the official evaluation, the system achieves nDCG@20 of 0.403 and Judged@20 of 0.95. We further conduct extensive ablation experiments to quantify the contribution of each stage and to analyze the effectiveness of query expansion, dense ranking, and top-$k$ reranking under limited compute budgets.

</details>


### [6] [LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation](https://arxiv.org/abs/2602.17036)
*Rong Fu,Zijian Zhang,Haiyun Wei,Jiekai Wu,Kun Liu,Xianda Li,Haoyu Zhao,Yang Li,Yongtai Liu,Ziming Wang,Rui Lu,Simon Fong*

Main category: cs.IR

TL;DR: LiveGraph是一个基于图神经网络的主动结构神经重排序框架，用于解决教育推荐系统中长尾分布和学生个性化学习轨迹问题，通过图表示增强和动态重排序机制提升推荐精度和内容多样性。


<details>
  <summary>Details</summary>
Motivation: 数字学习环境的快速发展需要能够提供个性化教育内容的智能系统。当前练习推荐框架面临两个主要挑战：学生参与度的长尾分布问题，以及无法适应个性化学习轨迹的局限性。

Method: 提出LiveGraph框架，采用基于图的表示增强策略来弥合活跃学生与非活跃学生之间的信息差距，同时集成动态重排序机制以促进内容多样性。该模型通过学习历史中的结构关系来平衡推荐精度和教学多样性。

Result: 在多个真实世界数据集上的综合实验评估表明，LiveGraph在预测准确性和练习多样性广度方面均优于当代基线方法。

Conclusion: LiveGraph通过图表示增强和动态重排序机制，有效解决了教育推荐系统中的长尾分布和个性化适应问题，在推荐精度和内容多样性方面取得了显著改进。

Abstract: The continuous expansion of digital learning environments has catalyzed the demand for intelligent systems capable of providing personalized educational content. While current exercise recommendation frameworks have made significant strides, they frequently encounter obstacles regarding the long-tailed distribution of student engagement and the failure to adapt to idiosyncratic learning trajectories. We present LiveGraph, a novel active-structure neural re-ranking framework designed to overcome these limitations. Our approach utilizes a graph-based representation enhancement strategy to bridge the information gap between active and inactive students while integrating a dynamic re-ranking mechanism to foster content diversity. By prioritizing the structural relationships within learning histories, the proposed model effectively balances recommendation precision with pedagogical variety. Comprehensive experimental evaluations conducted on multiple real-world datasets demonstrate that LiveGraph surpasses contemporary baselines in both predictive accuracy and the breadth of exercise diversity.

</details>


### [7] [A Long-term Value Prediction Framework In Video Ranking](https://arxiv.org/abs/2602.17058)
*Huabin Chen,Xinao Wang,Huiping Chu,Keqin Xu,Chenhao Zhai,Chenyi Wang,Kai Meng,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出一个实用的排序阶段长期价值(LTV)框架，解决位置偏差、归因模糊性和时间限制三大挑战，已在淘宝生产系统中亿级规模部署。


<details>
  <summary>Details</summary>
Motivation: 在短视频推荐的排序阶段准确建模长期价值(LTV)仍然具有挑战性。虽然延迟反馈和扩展参与度已被探索，但在亿级规模下的细粒度归因和鲁棒的位置归一化仍然不足。

Method: 提出三模块框架：1) 位置感知去偏分位数(PDQ)模块，通过基于分位数的分布归一化参与度；2) 多维归因模块，学习跨上下文、行为和内容信号的连续归因强度；3) 跨时间作者建模模块，构建审查感知的日级LTV目标。

Result: 离线和在线A/B测试显示LTV指标显著改善，与短期目标保持稳定权衡。框架已在淘宝生产系统亿级规模部署，带来持续的参与度提升。

Conclusion: 该框架成功解决了排序阶段LTV建模的关键挑战，实现了位置鲁棒的LTV估计、细粒度归因和长期创作者驱动的再参与建模，同时保持工业约束的兼容性。

Abstract: Accurately modeling long-term value (LTV) at the ranking stage of short-video recommendation remains challenging. While delayed feedback and extended engagement have been explored, fine-grained attribution and robust position normalization at billion-scale are still underdeveloped. We propose a practical ranking-stage LTV framework addressing three challenges: position bias, attribution ambiguity, and temporal limitations.
  (1) Position bias: We introduce a Position-aware Debias Quantile (PDQ) module that normalizes engagement via quantile-based distributions, enabling position-robust LTV estimation without architectural changes. (2) Attribution ambiguity: We propose a multi-dimensional attribution module that learns continuous attribution strengths across contextual, behavioral, and content signals, replacing static rules to capture nuanced inter-video influence. A customized hybrid loss with explicit noise filtering improves causal clarity. (3) Temporal limitations: We present a cross-temporal author modeling module that builds censoring-aware, day-level LTV targets to capture creator-driven re-engagement over longer horizons; the design is extensible to other dimensions (e.g., topics, styles).
  Offline studies and online A/B tests show significant improvements in LTV metrics and stable trade-offs with short-term objectives. Implemented as task augmentation within an existing ranking model, the framework supports efficient training and serving, and has been deployed at billion-scale in Taobao's production system, delivering sustained engagement gains while remaining compatible with industrial constraints.

</details>


### [8] [When LLM Judges Inflate Scores: Exploring Overrating in Relevance Assessment](https://arxiv.org/abs/2602.17170)
*Chuting Yu,Hang Li,Joel Mackenzie,Teerapong Leelanupab*

Main category: cs.IR

TL;DR: LLM作为相关性评估代理存在系统性高估偏差，对非相关段落过度自信评分，且对文本长度和表面词汇线索敏感，需谨慎使用


<details>
  <summary>Details</summary>
Motivation: 人工相关性评估耗时且认知强度大，限制了信息检索评估的可扩展性，因此研究者探索使用LLM作为人类评估者的替代方案，但LLM评估的可靠性、稳定性和严谨性仍存疑问

Method: 系统研究LLM相关性评估中的高估行为，涵盖不同模型架构、评估范式（点式和配对式）以及段落修改策略，通过控制实验分析LLM对文本长度和表面词汇线索的敏感性

Result: LLM一致性地为不真正满足信息需求的段落分配过高的相关性分数（通常带有高置信度），显示出系统性偏差而非随机波动；LLM相关性评估对段落长度和表面词汇线索高度敏感

Conclusion: LLM不能直接替代人类相关性评估者，使用LLM进行相关性评估时需要建立仔细的诊断评估框架，以确保评估的可靠性和严谨性

Abstract: Human relevance assessment is time-consuming and cognitively intensive, limiting the scalability of Information Retrieval evaluation. This has led to growing interest in using large language models (LLMs) as proxies for human judges. However, it remains an open question whether LLM-based relevance judgments are reliable, stable, and rigorous enough to match humans for relevance assessment. In this work, we conduct a systematic study of overrating behavior in LLM-based relevance judgments across model backbones, evaluation paradigms (pointwise and pairwise), and passage modification strategies. We show that models consistently assign inflated relevance scores -- often with high confidence -- to passages that do not genuinely satisfy the underlying information need, revealing a system-wide bias rather than random fluctuations in judgment. Furthermore, controlled experiments show that LLM-based relevance judgments can be highly sensitive to passage length and surface-level lexical cues. These results raise concerns about the usage of LLMs as drop-in replacements for human relevance assessors, and highlight the urgent need for careful diagnostic evaluation frameworks when applying LLMs for relevance assessments. Our code and results are publicly available.

</details>


### [9] [On the Reliability of User-Centric Evaluation of Conversational Recommender Systems](https://arxiv.org/abs/2602.17264)
*Michael Müller,Amir Reza Mohammadi,Andreas Peintner,Beatriz Barroso Gstrein,Günther Specht,Eva Zangerle*

Main category: cs.IR

TL;DR: 该研究通过大规模实证分析发现，基于静态对话日志的第三方标注在对话推荐系统评估中存在可靠性问题，特别是社交维度可靠性低，且存在强烈的光环效应。


<details>
  <summary>Details</summary>
Motivation: 当前对话推荐系统评估越来越多地依赖第三方标注静态对话日志，但这种做法的可靠性尚未得到充分验证。研究者希望通过实证研究来检验这种评估方法的可靠性和结构。

Method: 采用大规模实证研究方法，收集了124名众包工作者对200个ReDial对话的1,053个标注，使用18维CRS-Que框架。通过随机效应可靠性模型和相关性分析，量化各维度的稳定性及其相互依赖性。

Result: 结果显示：功利性和结果导向的维度（如准确性、有用性、满意度）在聚合后达到中等可靠性，而社交基础维度（如人性化、融洽度）可靠性显著较低。许多维度会坍缩为单一的全局质量信号，显示出强烈的光环效应。

Conclusion: 这些发现挑战了单标注者和基于LLM的评估协议的有效性，强调了在离线CRS评估中需要多标注者聚合和维度简化的必要性。

Abstract: User-centric evaluation has become a key paradigm for assessing Conversational Recommender Systems (CRS), aiming to capture subjective qualities such as satisfaction, trust, and rapport. To enable scalable evaluation, recent work increasingly relies on third-party annotations of static dialogue logs by crowd workers or large language models. However, the reliability of this practice remains largely unexamined. In this paper, we present a large-scale empirical study investigating the reliability and structure of user-centric CRS evaluation on static dialogue transcripts. We collected 1,053 annotations from 124 crowd workers on 200 ReDial dialogues using the 18-dimensional CRS-Que framework. Using random-effects reliability models and correlation analysis, we quantify the stability of individual dimensions and their interdependencies. Our results show that utilitarian and outcome-oriented dimensions such as accuracy, usefulness, and satisfaction achieve moderate reliability under aggregation, whereas socially grounded constructs such as humanness and rapport are substantially less reliable. Furthermore, many dimensions collapse into a single global quality signal, revealing a strong halo effect in third-party judgments. These findings challenge the validity of single-annotator and LLM-based evaluation protocols and motivate the need for multi-rater aggregation and dimension reduction in offline CRS evaluation.

</details>


### [10] [WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval](https://arxiv.org/abs/2602.17327)
*Michael Dinzinger,Laura Caspari,Ali Salman,Irvin Topi,Jelena Mitrović,Michael Granitzer*

Main category: cs.IR

TL;DR: WebFAQ 2.0是一个包含1.98亿FAQ问答对的多语言数据集，覆盖108种语言，提供14.3M双语对齐QA对，是目前最大的FAQ资源，并包含用于密集检索器训练的困难负样本数据集。


<details>
  <summary>Details</summary>
Motivation: 构建一个更大规模、更多样化、更丰富的多语言FAQ数据集，以支持多语言和跨语言信息检索研究，同时响应社区对困难负样本数据的需求。

Method: 采用新颖的数据收集策略：直接爬取和提取相关网页内容；使用两阶段检索管道挖掘困难负样本；提供两种主要的密集检索器微调策略：基于MultipleNegativesRanking损失的对比学习和基于MarginMSE损失的知识蒸馏。

Result: 创建了包含1.98亿FAQ问答对的数据集，覆盖108种语言，提供14.3M双语对齐QA对，以及包含1.25M查询的困难负样本数据集（20种语言，每个查询200个负样本）。

Conclusion: WebFAQ 2.0是目前最大的FAQ资源，通过Open Web Index定期发布结构化FAQ，支持持续扩展和优化，为多语言和跨语言IR研究提供了重要资源。

Abstract: We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.

</details>


### [11] [Training-free Graph-based Imputation of Missing Modalities in Multimodal Recommendation](https://arxiv.org/abs/2602.17354)
*Daniele Malitesta,Emanuele Rossi,Claudio Pomo,Tommaso Di Noia,Fragkiskos D. Malliaros*

Main category: cs.IR

TL;DR: 该论文针对多模态推荐系统中模态缺失问题，提出基于图结构的特征插补方法，通过项目-项目共购图传播可用模态特征来填补缺失信息。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统依赖物品的多模态数据（如图像、描述），但现实中这些数据可能存在噪声甚至缺失。目前处理方式通常是丢弃缺失模态的物品，导致数据损失。多模态推荐中的模态缺失问题尚未得到充分研究，缺乏像传统机器学习中缺失信息处理那样的形式化定义。

Method: 1. 首先形式化定义多模态推荐中的模态缺失问题；2. 利用用户-物品图结构，将多模态信息缺失问题重新定义为项目-项目共购图上的图特征插补问题；3. 提出四种无需训练的图基方法，通过项目-项目图传播可用模态特征来填补缺失特征。

Result: 在流行的多模态推荐数据集上的广泛实验表明：1. 提出的方法可以无缝集成到任何现有的多模态推荐系统和基准框架中；2. 能够保持甚至扩大多模态推荐与传统推荐系统之间的性能差距；3. 在不同模态缺失设置下，图基方法优于传统机器学习插补技术；4. 首次分析了项目-项目图上的特征同质性对图基插补的影响。

Conclusion: 该研究为多模态推荐中的模态缺失问题提供了形式化定义，并提出有效的图基插补解决方案。这些方法不仅实用且性能优越，为处理现实世界中不完整多模态数据提供了新思路，同时揭示了图结构特征同质性对插补效果的重要影响。

Abstract: Multimodal recommender systems (RSs) represent items in the catalog through multimodal data (e.g., product images and descriptions) that, in some cases, might be noisy or (even worse) missing. In those scenarios, the common practice is to drop items with missing modalities and train the multimodal RSs on a subsample of the original dataset. To date, the problem of missing modalities in multimodal recommendation has still received limited attention in the literature, lacking a precise formalisation as done with missing information in traditional machine learning. In this work, we first provide a problem formalisation for missing modalities in multimodal recommendation. Second, by leveraging the user-item graph structure, we re-cast the problem of missing multimodal information as a problem of graph features interpolation on the item-item co-purchase graph. On this basis, we propose four training-free approaches that propagate the available multimodal features throughout the item-item graph to impute the missing features. Extensive experiments on popular multimodal recommendation datasets demonstrate that our solutions can be seamlessly plugged into any existing multimodal RS and benchmarking framework while still preserving (or even widen) the performance gap between multimodal and traditional RSs. Moreover, we show that our graph-based techniques can perform better than traditional imputations in machine learning under different missing modalities settings. Finally, we analyse (for the first time in multimodal RSs) how feature homophily calculated on the item-item graph can influence our graph-based imputations.

</details>


### [12] [Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers](https://arxiv.org/abs/2602.17410)
*Bingqian Li,Bowen Zheng,Xiaolei Wang,Long Zhang,Jinpeng Wang,Sheng Chen,Wayne Xin Zhao,Ji-rong Wen*

Main category: cs.IR

TL;DR: ILRec提出了一种用于LLM推荐系统的偏好微调框架，通过从中间层提取自硬负样本信号来改进偏好学习，包含跨层偏好优化和跨层偏好蒸馏两阶段设计。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法依赖序列级、离线生成的负样本，在大型负项目空间中缺乏区分性和信息性，需要更有效的负样本监督机制来提升推荐性能。

Method: ILRec框架：1) 从中间层识别自硬负样本token作为细粒度负监督；2) 两阶段训练：跨层偏好优化和跨层偏好蒸馏；3) 引入轻量级协同过滤模型为负信号分配token级奖励，减少误判风险。

Result: 在三个数据集上的实验表明，ILRec能有效提升基于LLM的推荐系统性能，证明了自硬负样本信号和两阶段训练框架的有效性。

Conclusion: ILRec通过利用中间层自硬负样本信号，提供了一种更有效的偏好微调方法，解决了传统方法在大型负项目空间中的局限性，为LLM推荐系统提供了新的训练范式。

Abstract: Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.

</details>


### [13] [Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research](https://arxiv.org/abs/2602.17450)
*Amirereza Abbasi,Mohsen Hooshmand*

Main category: cs.IR

TL;DR: 这篇综述论文探讨了大语言模型（LLMs）特别是检索增强生成（RAG）对网络研究和产业的革命性影响，分析了关键进展、开放挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，网络研究和实践正在经历深刻变革。LLMs已经渗透到科技各个领域，正在重塑网络研发，将传统流程转变为生成式解决方案。需要系统性地探索LLMs特别是RAG技术对网络研究和产业的影响。

Method: 采用文献综述方法，系统性地调查和分析LLMs在网络领域的应用进展，特别关注检索增强生成（RAG）技术的应用。论文讨论了LLMs如何改变信息检索、问答系统、推荐系统和网络分析等传统任务。

Result: LLMs正在深刻改变网络研究和开发，将传统流程转变为生成式解决方案。RAG技术特别有效地增强了LLMs在网络任务中的应用，如信息检索、问答、推荐系统和网络分析。同时催生了新的应用，如网络摘要和教育工具。

Conclusion: LLMs特别是RAG技术正在重塑网络研究和产业，但面临开放挑战。未来需要进一步探索如何增强LLMs在网络解决方案中的应用，推动网络技术向更智能、更个性化的方向发展。

Abstract: Web research and practices have evolved significantly over time, offering users diverse and accessible solutions across a wide range of tasks. While advanced concepts such as Web 4.0 have emerged from mature technologies, the introduction of large language models (LLMs) has profoundly influenced both the field and its applications. This wave of LLMs has permeated science and technology so deeply that no area remains untouched. Consequently, LLMs are reshaping web research and development, transforming traditional pipelines into generative solutions for tasks like information retrieval, question answering, recommendation systems, and web analytics. They have also enabled new applications such as web-based summarization and educational tools. This survey explores recent advances in the impact of LLMs-particularly through the use of retrieval-augmented generation (RAG)-on web research and industry. It discusses key developments, open challenges, and future directions for enhancing web solutions with LLMs.

</details>


### [14] [A Picture of Agentic Search](https://arxiv.org/abs/2602.17518)
*Francesca Pezzuti,Ophir Frieder,Fabrizio Silvestri,Sean MacAvaney,Nicola Tonellotto*

Main category: cs.IR

TL;DR: 论文提出Agentic Search Queryset (ASQ)数据集，用于研究自动化代理搜索行为，解决传统信息检索系统与新兴AI代理搜索需求不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 随着自动化系统越来越多地与人类并行发出搜索查询，信息检索面临重大转变。传统IR系统围绕人类查询和行为设计，但现实中工作负载、可预测性和查询行为都已改变，导致系统性能下降和优化失效。缺乏捕捉代理搜索行为的数据集是当前研究的关键缺口。

Method: 开发了一种收集代理检索增强系统在回答查询时产生和消费的所有数据的方法论。发布了ASQ数据集，包含HotpotQA、Researchy Questions和MS MARCO中的推理诱导查询、检索文档和思考过程，涵盖3种不同代理和2种检索流程。配套工具包支持扩展到新代理、检索器和数据集。

Result: 创建了Agentic Search Queryset (ASQ)数据集，这是首个专门捕捉代理搜索行为的数据集，包含丰富的查询-文档-思考三元组数据，为研究自动化代理搜索行为提供了基础资源。

Conclusion: 信息检索需要适应自动化代理的兴起，ASQ数据集填补了代理搜索行为数据缺失的关键空白，为开发同时满足人类和代理需求的检索系统提供了必要的数据基础和研究工具。

Abstract: With automated systems increasingly issuing search queries alongside humans, Information Retrieval (IR) faces a major shift. Yet IR remains human-centred, with systems, evaluation metrics, user models, and datasets designed around human queries and behaviours. Consequently, IR operates under assumptions that no longer hold in practice, with changes to workload volumes, predictability, and querying behaviours. This misalignment affects system performance and optimisation: caching may lose effectiveness, query pre-processing may add overhead without improving results, and standard metrics may mismeasure satisfaction. Without adaptation, retrieval models risk satisfying neither humans, nor the emerging user segment of agents. However, datasets capturing agent search behaviour are lacking, which is a critical gap given IR's historical reliance on data-driven evaluation and optimisation. We develop a methodology for collecting all the data produced and consumed by agentic retrieval-augmented systems when answering queries, and we release the Agentic Search Queryset (ASQ) dataset. ASQ contains reasoning-induced queries, retrieved documents, and thoughts for queries in HotpotQA, Researchy Questions, and MS MARCO, for 3 diverse agents and 2 retrieval pipelines. The accompanying toolkit enables ASQ to be extended to new agents, retrievers, and datasets.

</details>


### [15] [Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval](https://arxiv.org/abs/2602.17654)
*Jiaqi Xi,Raghav Saboo,Luming Chen,Martin Wang,Sudeep Das*

Main category: cs.IR

TL;DR: 提出两阶段"挖掘与精炼"对比训练框架，用于电商搜索的语义文本嵌入，通过策略一致的监督和多级相似度边界优化提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 大规模电商搜索需要能够泛化到长尾、噪声查询的嵌入表示，同时需要符合产品和策略约束的可扩展监督。实际挑战在于相关性通常是分级的：用户接受替代品或互补品而非精确匹配，生产系统需要清晰的相似度分数分层以实现稳定的混合融合和阈值处理。

Method: 1. 使用轻量级LLM在人工标注的三级相关性准则下微调，并通过参与度驱动的审计减少残留噪声。2. 第一阶段：使用标签感知的监督对比目标训练多语言Siamese双塔检索器，构建鲁棒的全局语义空间。3. 第二阶段：通过ANN挖掘困难样本并用策略对齐的LLM重新标注，引入多类扩展的circle loss显式锐化相关性级别间的相似度边界，进一步精炼和丰富嵌入空间。4. 通过拼写增强和合成查询生成提高鲁棒性。

Result: 广泛的离线评估和生产A/B测试表明，该框架提高了检索相关性，并在用户参与度和业务影响方面带来了统计显著的提升。

Conclusion: 提出的两阶段"挖掘与精炼"对比训练框架有效解决了电商搜索中的多级相关性建模问题，通过策略一致的监督和边界优化显著提升了检索性能。

Abstract: We propose a two-stage "Mine and Refine" contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.

</details>
