<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Atomic Information Flow: A Network Flow Model for Tool Attributions in RAG Systems](https://arxiv.org/abs/2602.04912)
*James Gao,Josh Zhou,Qi Sun,Ryan Huang,Steven Yoo*

Main category: cs.IR

TL;DR: 提出Atomic Information Flow (AIF)框架，将工具输出和LLM调用分解为原子信息单元，通过图网络流模型实现细粒度溯源，并训练轻量级Gemma3模型进行上下文压缩。


<details>
  <summary>Details</summary>
Motivation: 当前基于工具的RAG系统缺乏将最终响应追溯到特定工具组件的精确机制，这在系统扩展到复杂多智能体架构时成为关键缺陷。

Method: 提出AIF图网络流模型，将工具输出和LLM调用分解为原子信息单元；基于最大流最小割定理，训练轻量级Gemma3(4B)模型作为上下文压缩器，利用离线计算的AIF流信号近似最小割。

Result: 基础Gemma3-4B模型在HotpotQA上识别关键信息准确率仅54.7%，略优于词法基线；使用AIF信号微调后准确率提升至82.71%(+28.01点)，同时实现87.52%的上下文token压缩，性能接近7倍大的Gemma3-27B变体。

Conclusion: AIF框架为工具型RAG系统提供了细粒度溯源能力，通过流信号训练的轻量模型能有效识别关键信息并压缩上下文，在保持性能的同时大幅降低计算成本。

Abstract: Many tool-based Retrieval Augmented Generation (RAG) systems lack precise mechanisms for tracing final responses back to specific tool components -- a critical gap as systems scale to complex multi-agent architectures. We present \textbf{Atomic Information Flow (AIF)}, a graph-based network flow model that decomposes tool outputs and LLM calls into atoms: indivisible, self-contained units of information. By modeling LLM orchestration as a directed flow of atoms from tool and LLM nodes to a response super-sink, AIF enables granular attribution metrics for AI explainability.
  Motivated by the max-flow min-cut theorem in network flow theory, we train a lightweight Gemma3 (4B parameter) language model as a context compressor to approximate the minimum cut of tool atoms using flow signals computed offline by AIF. We note that the base Gemma3-4B model struggles to identify critical information with \textbf{54.7\%} accuracy on HotpotQA, barely outperforming lexical baselines (BM25). However, post-training on AIF signals boosts accuracy to \textbf{82.71\%} (+28.01 points) while achieving \textbf{87.52\%} (+1.85\%) context token compression -- bridging the gap with the Gemma3-27B variant, a model nearly $7\times$ larger.

</details>


### [2] [Scaling Laws for Embedding Dimension in Information Retrieval](https://arxiv.org/abs/2602.05062)
*Julian Killingback,Mahta Rafiee,Madine Manas,Hamed Zamani*

Main category: cs.IR

TL;DR: 本文系统分析了稠密检索中嵌入维度与检索性能的关系，发现性能随维度增加呈幂律增长但收益递减，并建立了嵌入维度和模型规模的联合缩放定律。


<details>
  <summary>Details</summary>
Motivation: 随着稠密检索任务复杂度增加，基于单向量和内积的底层数据结构局限性日益明显。嵌入维度对检索能力至关重要，理解其缩放行为对构建下一代平衡效果与效率的检索模型至关重要。

Method: 使用两个模型家族和一系列不同规模的模型进行综合实验，构建详细的嵌入缩放行为图景，分析嵌入维度与检索性能的关系。

Result: 发现缩放行为符合幂律，可以仅根据嵌入维度推导性能缩放定律，以及嵌入维度和模型规模的联合定律。对于与训练任务对齐的评估任务，性能随嵌入维度增加而持续改善但收益递减；对于与训练任务对齐度较低的评估数据，性能更不可预测，某些任务中较大嵌入维度会导致性能下降。

Conclusion: 本文工作为理解嵌入的局限性及其行为提供了额外见解，并为选择模型和嵌入维度以实现最佳性能同时降低存储和计算成本提供了实用指南。

Abstract: Dense retrieval, which encodes queries and documents into a single dense vector, has become the dominant neural retrieval approach due to its simplicity and compatibility with fast approximate nearest neighbor algorithms. As the tasks dense retrieval performs grow in complexity, the fundamental limitations of the underlying data structure and similarity metric -- namely vectors and inner-products -- become more apparent. Prior recent work has shown theoretical limitations inherent to single vectors and inner-products that are generally tied to the embedding dimension. Given the importance of embedding dimension for retrieval capacity, understanding how dense retrieval performance changes as embedding dimension is scaled is fundamental to building next generation retrieval models that balance effectiveness and efficiency. In this work, we conduct a comprehensive analysis of the relationship between embedding dimension and retrieval performance. Our experiments include two model families and a range of model sizes from each to construct a detailed picture of embedding scaling behavior. We find that the scaling behavior fits a power law, allowing us to derive scaling laws for performance given only embedding dimension, as well as a joint law accounting for embedding dimension and model size. Our analysis shows that for evaluation tasks aligned with the training task, performance continues to improve as embedding size increases, though with diminishing returns. For evaluation data that is less aligned with the training task, we find that performance is less predictable, with performance degrading with larger embedding dimensions for certain tasks. We hope our work provides additional insight into the limitations of embeddings and their behavior as well as offers a practical guide for selecting model and embedding dimension to achieve optimal performance with reduced storage and compute costs.

</details>


### [3] [RAG without Forgetting: Continual Query-Infused Key Memory](https://arxiv.org/abs/2602.05152)
*Yuntong Hu,Sha Li,Naren Ramakrishnan,Liang Zhao*

Main category: cs.IR

TL;DR: ERM是一个无需训练、基于反馈的检索记忆演化框架，将查询时的临时增益转化为持久的检索改进，实现零推理开销的持续学习。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统存在两个问题：1) 查询时适应方法（如查询扩展）是临时性的，每次查询都要重新计算，无法累积学习；2) 索引端方法（如键扩展）依赖离线预处理或启发式更新，与下游任务效用对齐不佳，导致语义漂移和噪声积累。

Method: 提出ERM框架：1) 通过正确性门控反馈更新检索索引；2) 将有增益的原子扩展信号选择性地归因到受益的文档键；3) 通过稳定、范数有界的更新逐步演化键。理论证明查询扩展和键扩展在标准相似度函数下是等价的。

Result: 在BEIR和BRIGHT的13个领域实验中，ERM在检索和生成任务上均取得一致提升，特别是在推理密集型任务上，同时保持原生检索速度。

Conclusion: ERM成功将最优查询扩展摊销到稳定的索引中，实现了零推理时间开销的持续检索改进，解决了现有RAG系统无法累积学习和语义漂移的问题。

Abstract: Retrieval-augmented generation (RAG) systems commonly improve robustness via query-time adaptations such as query expansion and iterative retrieval. While effective, these approaches are inherently stateless: adaptations are recomputed for each query and discarded thereafter, precluding cumulative learning and repeatedly incurring inference-time cost. Index-side approaches like key expansion introduce persistence but rely on offline preprocessing or heuristic updates that are weakly aligned with downstream task utility, leading to semantic drift and noise accumulation. We propose Evolving Retrieval Memory (ERM), a training-free framework that transforms transient query-time gains into persistent retrieval improvements. ERM updates the retrieval index through correctness-gated feedback, selectively attributes atomic expansion signals to the document keys they benefit, and progressively evolves keys via stable, norm-bounded updates. We show that query and key expansion are theoretically equivalent under standard similarity functions and prove convergence of ERM's selective updates, amortizing optimal query expansion into a stable index with zero inference-time overhead. Experiments on BEIR and BRIGHT across 13 domains demonstrate consistent gains in retrieval and generation, particularly on reasoning-intensive tasks, at native retrieval speed.

</details>


### [4] [Semantic Search over 9 Million Mathematical Theorems](https://arxiv.org/abs/2602.05216)
*Luke Alexander,Eric Leonen,Sophie Szeto,Artemii Remizov,Ignacio Tejeda,Giovanni Inchiostro,Vasily Ilin*

Main category: cs.IR

TL;DR: 该论文提出了一个大规模语义定理检索系统，通过从arXiv等来源提取920万条定理陈述，使用自然语言描述作为检索表示，显著提升了数学定理检索的效果。


<details>
  <summary>Details</summary>
Motivation: 当前数学检索工具主要返回整篇论文，而数学家和定理证明代理通常需要查找特定的定理、引理或命题。语义搜索在大型、高度技术性的数学定理语料库上的表现仍不清楚。

Method: 从arXiv和其他七个来源提取920万条定理陈述，构建最大的公开数学定理语料库。使用简短的自然语言描述作为检索表示，系统分析表示上下文、语言模型选择、嵌入模型和提示策略对检索质量的影响。

Result: 在专业数学家编写的定理搜索查询评估集上，该方法在定理级别和论文级别检索方面都显著优于现有基线，证明语义定理搜索在Web规模上是可行且有效的。

Conclusion: 语义定理搜索在大规模数学语料库上是可行的，提出的方法显著提升了检索质量，为数学家和定理证明代理提供了有效的工具。

Abstract: Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.

</details>


### [5] [NeuCLIRTech: Chinese Monolingual and Cross-Language Information Retrieval Evaluation in a Challenging Domain](https://arxiv.org/abs/2602.05334)
*Dawn Lawrie,James Mayfield,Eugene Yang,Andrew Yates,Sean MacAvaney,Ronak Pradeep,Scott Miller,Paul McNamee,Luca Soldaini*

Main category: cs.IR

TL;DR: NeuCLIRTech是一个用于技术信息跨语言检索的评估数据集，包含中文技术文档及其英文机器翻译版本，支持中文单语检索和英文查询的跨语言检索场景。


<details>
  <summary>Details</summary>
Motivation: 为了准确衡量检索系统的进步，需要能够可靠区分系统性能的测试集合。现有评估集合在技术信息跨语言检索方面存在不足，需要专门的数据集来支持该领域的评估。

Method: 结合TREC NeuCLIR 2023和2024的主题，构建包含110个查询和35,962个文档相关性判断的数据集。包含原生中文技术文档及其英文机器翻译版本，并提供基于强神经检索系统的融合基线。

Result: 创建了NeuCLIRTech评估集合，支持中文单语检索和英文查询的跨语言检索两种场景。数据集具有强大的统计区分能力，并已在Huggingface Datasets上发布。

Conclusion: NeuCLIRTech为技术信息跨语言检索提供了可靠的评估基准，特别为重新排序算法开发者提供了比BM25更强的第一阶段检索基线，促进了该领域的研究进展。

Abstract: Measuring advances in retrieval requires test collections with relevance judgments that can faithfully distinguish systems. This paper presents NeuCLIRTech, an evaluation collection for cross-language retrieval over technical information. The collection consists of technical documents written natively in Chinese and those same documents machine translated into English. It includes 110 queries with relevance judgments. The collection supports two retrieval scenarios: monolingual retrieval in Chinese, and cross-language retrieval with English as the query language. NeuCLIRTech combines the TREC NeuCLIR track topics of 2023 and 2024. The 110 queries with 35,962 document judgments provide strong statistical discriminatory power when trying to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included so that developers of reranking algorithms are not reliant on BM25 as their first stage retriever. The dataset and artifacts are released on Huggingface Datasets

</details>


### [6] [Multi-Field Tool Retrieval](https://arxiv.org/abs/2602.05366)
*Yichen Tang,Weihang Su,Yiqun Liu,Qingyao Ai*

Main category: cs.IR

TL;DR: 提出多字段工具检索框架，解决LLM工具检索中的文档不完整、语义不匹配和多维度效用问题，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 随着可用工具规模增长，有效的工具检索对缓解LLM上下文窗口限制和确保计算效率至关重要。现有方法将工具检索视为传统ad-hoc检索任务，存在三个根本挑战：工具文档的不完整性和结构不一致性；用户查询与技术工具文档之间的显著语义和粒度不匹配；最重要的是工具效用的多维度特性，涉及功能、输入约束、输出格式等不同维度和重要性。

Method: 引入多字段工具检索框架，通过细粒度的多字段建模来对齐用户意图与工具表示。该方法能够处理工具效用的多个维度，包括功能、输入约束、输出格式等不同方面。

Result: 实验结果表明，该框架在五个数据集和一个混合基准测试中实现了SOTA性能，展现出优越的泛化能力和鲁棒性。

Conclusion: 多字段工具检索框架有效解决了现有工具检索方法的局限性，通过细粒度多字段建模显著提升了检索效果，为LLM与外部工具的高效集成提供了更好的解决方案。

Abstract: Integrating external tools enables Large Language Models (LLMs) to interact with real-world environments and solve complex tasks. Given the growing scale of available tools, effective tool retrieval is essential to mitigate constraints of LLMs' context windows and ensure computational efficiency. Existing approaches typically treat tool retrieval as a traditional ad-hoc retrieval task, matching user queries against the entire raw tool documentation. In this paper, we identify three fundamental challenges that limit the effectiveness of this paradigm: (i) the incompleteness and structural inconsistency of tool documentation; (ii) the significant semantic and granular mismatch between user queries and technical tool documents; and, most importantly, (iii) the multi-aspect nature of tool utility, that involves distinct dimensions, such as functionality, input constraints, and output formats, varying in format and importance. To address these challenges, we introduce Multi-Field Tool Retrieval, a framework designed to align user intent with tool representations through fine-grained, multi-field modeling. Experimental results show that our framework achieves SOTA performance on five datasets and a mixed benchmark, exhibiting superior generalizability and robustness.

</details>


### [7] [Rich-Media Re-Ranker: A User Satisfaction-Driven LLM Re-ranking Framework for Rich-Media Search](https://arxiv.org/abs/2602.05408)
*Zihao Guo,Ligang Zhou,Zeyang Tang,Feicheng Li,Ying Nie,Zhiming Peng,Qingyun Sun,Jianxin Li*

Main category: cs.IR

TL;DR: 提出Rich-Media Re-Ranker框架，通过多维细粒度建模提升搜索满意度，整合视觉信号和查询意图分析，采用多任务强化学习增强模型适应性。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法存在两个主要局限：1) 对用户多面意图建模不足；2) 忽视丰富的侧信息（如视觉感知信号）。这限制了用户搜索满意度的提升。

Method: 1) Query Planner分析会话中的查询优化序列，将查询分解为互补子查询；2) 整合候选结果的丰富侧信息，包括VLM生成的视觉内容信号；3) 设计考虑内容相关性、质量、信息增益、新颖性和封面图像视觉呈现的重排序原则；4) LLM-based re-ranker基于这些原则和信号进行整体评估；5) 通过多任务强化学习增强VLM评估器和LLM重排序器的场景适应性。

Result: 实验表明该方法显著优于现有最先进基线。该框架已部署在大型工业搜索系统中，显著提高了在线用户参与率和满意度指标。

Conclusion: Rich-Media Re-Ranker框架通过多维细粒度建模有效解决了现有重排序方法的局限性，整合了查询意图分析和丰富的媒体信号，显著提升了用户搜索满意度，并在实际工业系统中验证了其有效性。

Abstract: Re-ranking plays a crucial role in modern information search systems by refining the ranking of initial search results to better satisfy user information needs. However, existing methods show two notable limitations in improving user search satisfaction: inadequate modeling of multifaceted user intents and neglect of rich side information such as visual perception signals. To address these challenges, we propose the Rich-Media Re-Ranker framework, which aims to enhance user search satisfaction through multi-dimensional and fine-grained modeling. Our approach begins with a Query Planner that analyzes the sequence of query refinements within a session to capture genuine search intents, decomposing the query into clear and complementary sub-queries to enable broader coverage of users' potential intents. Subsequently, moving beyond primary text content, we integrate richer side information of candidate results, including signals modeling visual content generated by the VLM-based evaluator. These comprehensive signals are then processed alongside carefully designed re-ranking principle that considers multiple facets, including content relevance and quality, information gain, information novelty, and the visual presentation of cover images. Then, the LLM-based re-ranker performs the holistic evaluation based on these principles and integrated signals. To enhance the scenario adaptability of the VLM-based evaluator and the LLM-based re-ranker, we further enhance their capabilities through multi-task reinforcement learning. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines. Notably, the proposed framework has been deployed in a large-scale industrial search system, yielding substantial improvements in online user engagement rates and satisfaction metrics.

</details>


### [8] [SciDef: Automating Definition Extraction from Academic Literature with Large Language Models](https://arxiv.org/abs/2602.05413)
*Filip Kučera,Christoph Mandl,Isao Echizen,Radu Timofte,Timo Spinde*

Main category: cs.IR

TL;DR: SciDef：基于LLM的自动定义提取管道，在科学文献中提取定义，测试16种语言模型，多步和DSPy优化提示策略提升性能，NLI方法评估最可靠。


<details>
  <summary>Details</summary>
Motivation: 随着科学出版物数量激增，收集相关定义变得困难，需要自动化工具来提取科学文献中的定义。

Method: 提出SciDef管道，基于LLM自动提取定义；创建DefExtra（人工提取定义）和DefSim（定义对相似性）数据集；测试16种语言模型，采用多步和DSPy优化提示策略；使用NLI方法评估提取结果。

Result: LLM能够从科学文献中提取86.4%的定义；多步和DSPy优化提示策略提高提取性能；NLI评估方法最可靠；但模型倾向于过度生成定义。

Conclusion: LLM能够有效提取科学定义，但未来工作应关注识别相关定义而非仅找到定义，因为模型容易过度生成；代码和数据集已开源。

Abstract: Definitions are the foundation for any scientific work, but with a significant increase in publication numbers, gathering definitions relevant to any keyword has become challenging. We therefore introduce SciDef, an LLM-based pipeline for automated definition extraction. We test SciDef on DefExtra & DefSim, novel datasets of human-extracted definitions and definition-pairs' similarity, respectively. Evaluating 16 language models across prompting strategies, we demonstrate that multi-step and DSPy-optimized prompting improve extraction performance. To evaluate extraction, we test various metrics and show that an NLI-based method yields the most reliable results. We show that LLMs are largely able to extract definitions from scientific literature (86.4% of definitions from our test-set); yet future work should focus not just on finding definitions, but on identifying relevant ones, as models tend to over-generate them.
  Code & datasets are available at https://github.com/Media-Bias-Group/SciDef.

</details>


### [9] [Forward Index Compression for Learned Sparse Retrieval](https://arxiv.org/abs/2602.05445)
*Sebastian Bruch,Martino Fontana,Franco Maria Nardini,Cosimo Rulli,Rossano Venturini*

Main category: cs.IR

TL;DR: 本文研究稀疏检索算法中前向索引的压缩技术，提出DotVByte算法在保持检索效率的同时显著减少存储空间


<details>
  <summary>Details</summary>
Motivation: 稀疏检索算法已成为有效的搜索方法，但前向索引占据大量存储空间，需要在不影响检索质量和延迟的情况下压缩前向索引

Method: 首先评估多种整数压缩技术，发现StreamVByte在内存占用、检索准确性和延迟之间达到最佳平衡；然后提出专门针对内积计算的DotVByte算法进行改进

Result: 在MsMarco数据集上的实验表明，改进后的方法实现了显著的空间节省，同时保持了检索效率

Conclusion: DotVByte算法能够有效压缩稀疏检索中的前向索引，在减少存储空间的同时不影响检索性能，为实际应用提供了可行的解决方案

Abstract: Text retrieval using learned sparse representations of queries and documents has, over the years, evolved into a highly effective approach to search. It is thanks to recent advances in approximate nearest neighbor search-with the emergence of highly efficient algorithms such as the inverted index-based Seismic and the graph-based Hnsw-that retrieval with sparse representations became viable in practice. In this work, we scrutinize the efficiency of sparse retrieval algorithms and focus particularly on the size of a data structure that is common to all algorithmic flavors and that constitutes a substantial fraction of the overall index size: the forward index. In particular, we seek compression techniques to reduce the storage footprint of the forward index without compromising search quality or inner product computation latency. In our examination with various integer compression techniques, we report that StreamVByte achieves the best trade-off between memory footprint, retrieval accuracy, and latency. We then improve StreamVByte by introducing DotVByte, a new algorithm tailored to inner product computation. Experiments on MsMarco show that our improvements lead to significant space savings while maintaining retrieval efficiency.

</details>


### [10] [LMMRec: LLM-driven Motivation-aware Multimodal Recommendation](https://arxiv.org/abs/2602.05474)
*Yicheng Di,Zhanjie Zhang,Yun Wangc,Jinren Liue,Jiaqi Yanf,Jiyu Wei,Xiangyu Chend,Yuan Liu*

Main category: cs.IR

TL;DR: LMMRec是一个基于大语言模型的动机感知多模态推荐框架，通过链式思维提示提取细粒度用户和物品动机，采用双编码器架构进行跨模态对齐，在三个数据集上实现了最高4.98%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统通常将动机视为交互数据中的潜在变量，忽略了评论文本等异构信息。在多模态动机融合中存在两个挑战：1) 在噪声中实现稳定的跨模态对齐；2) 识别反映相同底层动机的跨模态特征。

Method: 提出LMMRec框架：1) 使用链式思维提示从文本中提取细粒度用户和物品动机；2) 采用双编码器架构分别建模文本和交互动机；3) 通过动机协调策略和交互-文本对应方法，利用对比学习和动量更新缓解噪声和语义漂移。

Result: 在三个数据集上的实验表明，LMMRec实现了最高4.98%的性能提升，证明了该框架在动机感知多模态推荐中的有效性。

Conclusion: LMMRec通过大语言模型的深度语义先验和动机理解能力，成功解决了多模态动机融合中的对齐和特征识别问题，为动机感知推荐系统提供了有效的模型无关框架。

Abstract: Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\% performance improvement.

</details>


### [11] [GLASS: A Generative Recommender for Long-sequence Modeling via SID-Tier and Semantic Search](https://arxiv.org/abs/2602.05663)
*Shiteng Cao,Junda She,Ji Liu,Bin Zeng,Chengcheng Guo,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Zhiheng Li,Cheng Yang*

Main category: cs.IR

TL;DR: GLASS是一个将长期用户兴趣整合到生成式推荐系统中的新框架，通过SID-Tier和语义搜索模块，有效处理长历史序列，在淘宝和快手数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统在处理长历史序列时面临挑战，传统检索模型难以处理大规模物品空间，需要有效整合长期用户行为模式来提升推荐准确性。

Method: 提出GLASS框架：1) SID-Tier模块将长期交互映射为统一兴趣向量，增强初始SID令牌预测；2) 语义硬搜索使用生成的粗粒度语义ID作为动态键提取相关历史行为，通过自适应门控融合模块重新校准后续细粒度令牌轨迹；3) 针对数据稀疏性提出语义邻居增强和码本调整策略。

Result: 在两个大规模真实数据集TAOBAO-MM和KuaiRec上的实验表明，GLASS优于现有最先进基线方法，在推荐质量上取得显著提升。

Conclusion: GLASS通过有效整合长期用户兴趣到生成式推荐过程中，解决了长序列建模的挑战，为生成式推荐系统的发展提供了新思路，代码已开源以促进进一步研究。

Abstract: Leveraging long-term user behavioral patterns is a key trajectory for enhancing the accuracy of modern recommender systems. While generative recommender systems have emerged as a transformative paradigm, they face hurdles in effectively modeling extensive historical sequences. To address this challenge, we propose GLASS, a novel framework that integrates long-term user interests into the generative process via SID-Tier and Semantic Search. We first introduce SID-Tier, a module that maps long-term interactions into a unified interest vector to enhance the prediction of the initial SID token. Unlike traditional retrieval models that struggle with massive item spaces, SID-Tier leverages the compact nature of the semantic codebook to incorporate cross features between the user's long-term history and candidate semantic codes. Furthermore, we present semantic hard search, which utilizes generated coarse-grained semantic ID as dynamic keys to extract relevant historical behaviors, which are then fused via an adaptive gated fusion module to recalibrate the trajectory of subsequent fine-grained tokens. To address the inherent data sparsity in semantic hard search, we propose two strategies: semantic neighbor augmentation and codebook resizing. Extensive experiments on two large-scale real-world datasets, TAOBAO-MM and KuaiRec, demonstrate that GLASS outperforms state-of-the-art baselines, achieving significant gains in recommendation quality. Our codes are made publicly available to facilitate further research in generative recommendation.

</details>


### [12] [Evaluating the impact of word embeddings on similarity scoring in practical information retrieval](https://arxiv.org/abs/2602.05734)
*Niall McCarroll,Kevin Curran,Eugene McNamee,Angela Clist,Andrew Brammer*

Main category: cs.IR

TL;DR: 本文评估了一种替代的查询语句相似度测量方法，使用词移距离（WMD）结合词嵌入技术，相比传统的词嵌入质心相似度方法，在检索准确率上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 用户搜索行为通常基于语义，而传统的词嵌入质心相似度方法可能无法充分捕捉查询与答案之间的语义关联。需要探索更有效的语义相似度测量方法。

Method: 采用词移距离（WMD）模型，通过计算查询和语句中单个词语之间的距离来评估相似度，结合预训练的词嵌入技术（如GloVe），并与Doc2Vec、LSA等基线模型进行比较。

Result: WMD+GloVe组合在查询和响应语句的排名中表现出最佳性能，显著优于其他最先进的检索模型，包括Doc2Vec和基线LSA模型，在准确率上取得了显著提升。

Conclusion: 基于大规模数据预训练的词嵌入结合WMD相似度排序方法，能够实现领域无关的语言处理解决方案，可移植到多样化的商业应用场景中。

Abstract: Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers.
  This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.

</details>


### [13] [Bagging-Based Model Merging for Robust General Text Embeddings](https://arxiv.org/abs/2602.05787)
*Hengran Zhang,Keping Bi,Jiafeng Guo,Jiaming Zhang,Wenbo Yang,Daiting Shi,Xueqi Cheng*

Main category: cs.IR

TL;DR: 本文系统研究了文本嵌入模型的多任务训练策略，发现简单的批级混洗效果最好，但存在域外泛化不足和增量学习成本高的问题。为此提出了基于装袋的鲁棒模型合并方法，能提升性能并支持高效增量更新。


<details>
  <summary>Details</summary>
Motivation: 通用文本嵌入模型广泛应用于NLP和信息检索，通常通过大规模多任务语料训练以实现广泛泛化。然而，不同多任务训练策略的实际效果比较尚不明确，且随着新领域和数据类型的不断出现，如何高效适应嵌入模型仍存在挑战。

Method: 本文从数据调度和模型合并两个角度系统研究多任务训练：比较批级混洗、顺序训练变体、两阶段训练和多种合并粒度。为解决批级混洗的局限性，提出了基于装袋的鲁棒模型合并方法，通过训练多个子集模型并合并为单一模型来提升鲁棒性，同时支持通过训练轻量更新模型实现高效增量学习。

Result: 实验表明批级混洗在整体性能上表现最好，但存在域外泛化不足和增量学习成本高的问题。提出的模型合并方法在多样化嵌入基准测试中，相比全语料批级混洗，能持续提升域内和域外性能，同时在增量学习设置中显著降低训练成本。

Conclusion: 批级混洗是多任务嵌入训练的有效策略，但存在实际限制。提出的基于装袋的鲁棒模型合并方法不仅解决了这些限制，提升了模型鲁棒性和泛化能力，还支持高效的增量更新，为持续学习场景提供了实用解决方案。

Abstract: General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.

</details>


### [14] [AgenticTagger: Structured Item Representation for Recommendation with LLM Agents](https://arxiv.org/abs/2602.05945)
*Zhouhang Xie,Bo Peng,Zhankui He,Ziqi Chen,Alice Han,Isabella Ye,Benjamin Coleman,Noveen Sachdeva,Fernando Pereira,Julian McAuley,Wang-Cheng Kang,Derek Zhiyuan Cheng,Beidou Wang,Randolph Brown*

Main category: cs.IR

TL;DR: AgenticTagger是一个LLM驱动的描述符生成框架，通过构建低基数、高质量的描述符词汇表来提升推荐系统表示质量


<details>
  <summary>Details</summary>
Motivation: 高质量表示是有效推荐的核心需求。现有LLM生成描述符的方法存在开放性问题：生成空间难以控制，导致高基数、低性能的描述符，给下游建模带来挑战

Method: 提出AgenticTagger框架，包含两个核心阶段：(1)词汇表构建阶段：通过多智能体反思机制，由架构师LLM迭代优化词汇表，标注师LLM并行验证；(2)词汇表分配阶段：LLM将词汇表中的描述符分配给项目

Result: 在公共和私有数据上的实验表明，AgenticTagger在多种推荐场景中带来一致改进，包括生成式和基于术语的检索、排序以及基于评论的可控推荐

Conclusion: AgenticTagger通过构建层次化、低基数、高质量的描述符词汇表，有效解决了LLM生成描述符的开放性问题，提升了推荐系统的表示质量和性能

Abstract: High-quality representations are a core requirement for effective recommendation. In this work, we study the problem of LLM-based descriptor generation, i.e., keyphrase-like natural language item representation generation frameworks with minimal constraints on downstream applications. We propose AgenticTagger, a framework that queries LLMs for representing items with sequences of text descriptors. However, open-ended generation provides little control over the generation space, leading to high cardinality, low-performance descriptors that renders downstream modeling challenging. To this end, AgenticTagger features two core stages: (1) a vocabulary building stage where a set of hierarchical, low-cardinality, and high-quality descriptors is identified, and (2) a vocabulary assignment stage where LLMs assign in-vocabulary descriptors to items. To effectively and efficiently ground vocabulary in the item corpus of interest, we design a multi-agent reflection mechanism where an architect LLM iteratively refines the vocabulary guided by parallelized feedback from annotator LLMs that validates the vocabulary against item data. Experiments on public and private data show AgenticTagger brings consistent improvements across diverse recommendation scenarios, including generative and term-based retrieval, ranking, and controllability-oriented, critique-based recommendation.

</details>


### [15] [SAGE: Benchmarking and Improving Retrieval for Deep Research Agents](https://arxiv.org/abs/2602.05975)
*Tiansheng Hu,Yilun Zhao,Canyu Zhang,Arman Cohan,Chen Zhao*

Main category: cs.IR

TL;DR: SAGE基准测试显示，现有深度研究代理在科学文献检索中表现不佳，BM25检索器比LLM检索器表现好30%，通过文档增强框架可提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM检索器是否能有效支持深度研究代理工作流，特别是在科学文献检索任务中。

Method: 引入SAGE基准测试（1200个查询，4个科学领域，20万篇论文），评估6个深度研究代理，比较BM25和LLM检索器，提出基于LLM的文档增强框架。

Result: 所有系统在推理密集型检索中都表现不佳，BM25显著优于LLM检索器约30%，文档增强框架在短问题和开放问题上分别带来8%和2%的性能提升。

Conclusion: 现有深度研究代理生成的关键词导向子查询限制了LLM检索器的效果，文档增强能改善检索性能，但需要更好的检索策略。

Abstract: Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.

</details>
