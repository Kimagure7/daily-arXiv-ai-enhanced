<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 21]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [The Environmental Impact of Ensemble Techniques in Recommender Systems](https://arxiv.org/abs/2511.11649)
*Jannik Nitschke*

Main category: cs.IR

TL;DR: 本文首次系统测量了集成推荐系统的能耗和碳足迹，发现集成方法虽然能提升0.3-5.7%的准确率，但能耗增加19-2549%，选择性策略比穷举平均策略更高效。


<details>
  <summary>Details</summary>
Motivation: 集成推荐系统虽然能提升10-30%的准确率，但其环境影响尚未被充分评估。深度学习推荐算法单篇论文可产生3297kg CO2，但集成方法的能耗影响缺乏研究。

Method: 在两个框架(Surprise用于评分预测，LensKit用于排序)上进行了93次实验，使用四个数据集(10万到780万交互)，评估四种集成策略(平均、加权、堆叠/排序融合、最佳表现者)，通过智能插座测量能耗。

Result: 集成方法准确率提升0.3-5.7%，但能耗增加19-2549%。最佳表现者集成在MovieLens-1M上实现0.96% RMSE提升，能耗增加18.8%；在MovieLens-100K上实现5.7% NDCG提升，能耗增加103%。穷举平均策略能耗增加88-270%。最大数据集上集成方法能耗增加2005%，产生53.8mg CO2 vs 单模型2.6mg CO2。

Conclusion: 选择性集成策略比穷举平均策略更高效，但在工业规模存在可扩展性限制，这些发现有助于推荐系统的可持续算法选择决策。

Abstract: Ensemble techniques in recommender systems have demonstrated accuracy improvements of 10-30%, yet their environmental impact remains unmeasured. While deep learning recommendation algorithms can generate up to 3,297 kg CO2 per paper, ensemble methods have not been sufficiently evaluated for energy consumption. This thesis investigates how ensemble techniques influence environmental impact compared to single optimized models.
  We conducted 93 experiments across two frameworks (Surprise for rating prediction, LensKit for ranking) on four datasets spanning 100,000 to 7.8 million interactions. We evaluated four ensemble strategies (Average, Weighted, Stacking/Rank Fusion, Top Performers) against simple baselines and optimized single models, measuring energy consumption with a smart plug.
  Results revealed a non-linear accuracy-energy relationship. Ensemble methods achieved 0.3-5.7% accuracy improvements while consuming 19-2,549% more energy depending on dataset size and strategy. The Top Performers ensemble showed best efficiency: 0.96% RMSE improvement with 18.8% energy overhead on MovieLens-1M, and 5.7% NDCG improvement with 103% overhead on MovieLens-100K. Exhaustive averaging strategies consumed 88-270% more energy for comparable gains. On the largest dataset (Anime, 7.8M interactions), the Surprise ensemble consumed 2,005% more energy (0.21 Wh vs. 0.01 Wh) for 1.2% accuracy improvement, producing 53.8 mg CO2 versus 2.6 mg CO2 for the single model.
  This research provides one of the first systematic measurements of energy and carbon footprint for ensemble recommender systems, demonstrates that selective strategies offer superior efficiency over exhaustive averaging, and identifies scalability limitations at industrial scale. These findings enable informed decisions about sustainable algorithm selection in recommender systems.

</details>


### [2] [GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning](https://arxiv.org/abs/2511.11653)
*Duolin Sun,Meixiu Long,Dan Yang,Yihan Jiao,Zhehao Tan,Jie Feng,Junjie Wang,Yue Shen,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.IR

TL;DR: 提出Groupwise重排序新范式，结合点式方法的灵活性和列表式方法的比较能力，通过组内比较和GRPO训练解决现有重排序方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法存在核心困境：点式方法独立评估文档，容易陷入'排序近视陷阱'；列表式方法能感知全局排序上下文，但存在'列表刚性'问题，在处理大规模候选集时面临严重的可扩展性和灵活性挑战。

Method: 提出Groupwise重排序范式，将查询和一组候选文档共同输入模型进行组内比较，为每个文档分配相关性分数。采用GRPO进行模型训练，集成排序指标和分布奖励的异构奖励函数。还提出合成高质量检索和排序数据的创新流程。

Result: 在两个推理密集型检索基准BRIGHT和R2MED上的广泛实验验证了方法的有效性。

Conclusion: Groupwise范式成功解决了现有重排序方法的局限性，在保持点式方法灵活性的同时实现了列表式方法的比较能力，为RAG系统的重排序提供了有效解决方案。

Abstract: Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.

</details>


### [3] [A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches](https://arxiv.org/abs/2511.11847)
*Ryan Singh,Austin Hamilton,Amanda White,Michael Wise,Ibrahim Yousif,Arthur Carvalho,Zhe Shan,Reza Abrisham Baf,Mohammad Mayyas,Lora A. Cavuoto,Fadel M. Megahed*

Main category: cs.IR

TL;DR: 开发了一个基于大语言模型的多模态聊天机器人，用于工业5.0环境下的安全培训，通过检索增强生成技术实现高准确率、低延迟和低成本的安全指导。


<details>
  <summary>Details</summary>
Motivation: 工业5.0转向以人为本的操作模式，需要满足高精度、低延迟和低成本要求的下一代安全培训系统，以确保工人安全。

Method: 采用设计科学研究方法，开发基于检索增强生成的多模态聊天机器人，使用全因子设计测试24种RAG配置，并通过专家评估验证性能。

Result: 最佳配置在专家验证中达到86.66%的准确率，平均延迟10.04秒，每次查询成本0.005美元，显著优于其他配置。

Conclusion: 该研究提供了三个主要贡献：开源领域安全培训聊天机器人、经过验证的AI辅助安全指导评估基准，以及工业5.0环境下AI驱动安全培训系统的系统设计方法。

Abstract: Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.

</details>


### [4] [ComLQ: Benchmarking Complex Logical Queries in Information Retrieval](https://arxiv.org/abs/2511.12004)
*Ganlin Xu,Zhitao Yin,Linghao Zhang,Jiaqing Liang,Weijia Lu,Xiaodong Zhang,Zhifei Yang,Sihang Jiang,Deqing Yang*

Main category: cs.IR

TL;DR: 提出了一个用于复杂逻辑查询的信息检索数据集ComLQ，包含2,909个查询和11,251个候选段落，并设计了新的评估指标LSNC@K来专门评估检索模型处理否定查询的能力。


<details>
  <summary>Details</summary>
Motivation: 现有IR基准主要关注简单查询，忽略了包含合取、析取和否定等一阶逻辑操作的复杂逻辑查询，无法充分评估IR模型在真实场景中的性能。

Method: 利用大语言模型（如GPT-4o）通过设计子图引导提示来生成具有特定逻辑结构的查询，确保查询-段落对的结构一致性和证据分布，并通过专家标注验证。

Result: 零样本实验结果显示现有检索模型在复杂逻辑查询上表现有限，特别是在处理否定查询时表现出较差的排除建模能力。

Conclusion: ComLQ数据集和LSNC@K指标填补了复杂逻辑查询评估的空白，揭示了当前检索模型在处理否定等复杂逻辑操作方面的不足。

Abstract: Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \emph{complex logical queries} involving first-order logic operations such as conjunction ($\land$), disjunction ($\lor$), and negation ($\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \textbf{ComLQ} for \textbf{Com}plex \textbf{L}ogical \textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \emph{structure conformity} and \emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \textbf{Log-Scaled Negation Consistency} (\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.

</details>


### [5] [From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction](https://arxiv.org/abs/2511.12081)
*Bencheng Yan,Yuejie Lei,Zhiyuan Zeng,Di Wang,Kaiyi Lin,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: 提出Field-Aware Transformer (FAT)来解决CTR预测中Transformer模型与数据语义结构不匹配的问题，通过字段感知注意力机制实现更好的可扩展性和性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在CTR预测中表现出收益递减，因为其序列组合性假设与CTR数据需要的组合推理不匹配，无结构注意力在极端稀疏性下会放大噪声。

Method: 引入字段感知Transformer，通过分解的内容对齐和跨字段调制将基于字段的交互先验嵌入到注意力机制中，使模型复杂度与字段数F而非总词汇量n成比例。

Result: FAT在大型基准测试中AUC提升达+0.51%，在线部署实现+2.33% CTR和+0.66% RPM提升，并观察到AUC随模型宽度增加呈现幂律缩放。

Conclusion: 推荐系统中的有效扩展不是来自模型大小，而是来自与数据语义的结构化表达能力-架构一致性。

Abstract: Despite massive investments in scale, deep models for click-through rate (CTR) prediction often exhibit rapidly diminishing returns - a stark contrast to the smooth, predictable gains seen in large language models. We identify the root cause as a structural misalignment: Transformers assume sequential compositionality, while CTR data demand combinatorial reasoning over high-cardinality semantic fields. Unstructured attention spreads capacity indiscriminately, amplifying noise under extreme sparsity and breaking scalable learning. To restore alignment, we introduce the Field-Aware Transformer (FAT), which embeds field-based interaction priors into attention through decomposed content alignment and cross-field modulation. This design ensures model complexity scales with the number of fields F, not the total vocabulary size n >> F, leading to tighter generalization and, critically, observed power-law scaling in AUC as model width increases. We present the first formal scaling law for CTR models, grounded in Rademacher complexity, that explains and predicts this behavior. On large-scale benchmarks, FAT improves AUC by up to +0.51% over state-of-the-art methods. Deployed online, it delivers +2.33% CTR and +0.66% RPM. Our work establishes that effective scaling in recommendation arises not from size, but from structured expressivity-architectural coherence with data semantics.

</details>


### [6] [Continuous-time Discrete-space Diffusion Model for Recommendation](https://arxiv.org/abs/2511.12114)
*Chengyi Liu,Xiao Chen,Shijie Wang,Wenqi Fan,Qing Li*

Main category: cs.IR

TL;DR: CDRec是一个新颖的连续时间离散空间扩散推荐框架，通过在连续时间上对历史交互进行离散扩散来建模用户行为模式，解决了现有扩散推荐方法在连续空间中操作导致信息损失和计算效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的推荐方法主要在连续空间中通过编码的图基历史交互操作，可能导致潜在信息损失和计算效率低下。

Method: 提出连续时间离散空间扩散推荐框架，使用离散扩散算法通过离散元素操作（如掩码）结合领域知识的转移矩阵，产生更有意义的扩散轨迹。引入流行度感知噪声调度和结合一致性参数化与对比学习目标的高效训练框架。

Result: 在真实世界数据集上的广泛实验表明，CDRec在推荐准确性和计算效率方面都表现出优越性能。

Conclusion: CDRec通过离散扩散和连续时间建模，有效提升了推荐系统的性能和效率，为扩散式推荐提供了新的研究方向。

Abstract: In the era of information explosion, Recommender Systems (RS) are essential for alleviating information overload and providing personalized user experiences. Recent advances in diffusion-based generative recommenders have shown promise in capturing the dynamic nature of user preferences. These approaches explore a broader range of user interests by progressively perturbing the distribution of user-item interactions and recovering potential preferences from noise, enabling nuanced behavioral understanding. However, existing diffusion-based approaches predominantly operate in continuous space through encoded graph-based historical interactions, which may compromise potential information loss and suffer from computational inefficiency. As such, we propose CDRec, a novel Continuous-time Discrete-space Diffusion Recommendation framework, which models user behavior patterns through discrete diffusion on historical interactions over continuous time. The discrete diffusion algorithm operates via discrete element operations (e.g., masking) while incorporating domain knowledge through transition matrices, producing more meaningful diffusion trajectories. Furthermore, the continuous-time formulation enables flexible adaptive sampling. To better adapt discrete diffusion models to recommendations, CDRec introduces: (1) a novel popularity-aware noise schedule that generates semantically meaningful diffusion trajectories, and (2) an efficient training framework combining consistency parameterization for fast sampling and a contrastive learning objective guided by multi-hop collaborative signals for personalized recommendation. Extensive experiments on real-world datasets demonstrate CDRec's superior performance in both recommendation accuracy and computational efficiency.

</details>


### [7] [Task-Aware Retrieval Augmentation for Dynamic Recommendation](https://arxiv.org/abs/2511.12495)
*Zhen Tao,Xinke Jiang,Qingshuai Feng,Haoyu Zhang,Lun Du,Yuchen Fang,Hao Miao,Bangquan Xie,Qingqiang Sun*

Main category: cs.IR

TL;DR: TarDGR是一个任务感知的检索增强框架，通过结合任务感知模型和检索增强技术来解决动态推荐系统中图神经网络在预训练和微调阶段的时间差异导致的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练动态图神经网络在时间序列行为数据上建模用户-物品交互时，由于预训练和微调阶段的时间差异，导致模型泛化能力受限，无法有效捕捉用户偏好的演变。

Method: 提出TarDGR框架：1）任务感知评估机制识别语义相关的历史子图；2）基于图Transformer的任务感知模型整合语义和结构编码评估子图相关性；3）在推理时检索并融合任务感知子图与查询子图。

Result: 在多个大规模动态图数据集上的实验表明，TarDGR持续优于最先进的方法，广泛的实证证据证实了其卓越的准确性和泛化能力。

Conclusion: TarDGR通过任务感知检索增强有效缓解了动态推荐系统中的时间泛化问题，提升了模型的准确性和泛化性能。

Abstract: Dynamic recommendation systems aim to provide personalized suggestions by modeling temporal user-item interactions across time-series behavioral data. Recent studies have leveraged pre-trained dynamic graph neural networks (GNNs) to learn user-item representations over temporal snapshot graphs. However, fine-tuning GNNs on these graphs often results in generalization issues due to temporal discrepancies between pre-training and fine-tuning stages, limiting the model's ability to capture evolving user preferences. To address this, we propose TarDGR, a task-aware retrieval-augmented framework designed to enhance generalization capability by incorporating task-aware model and retrieval-augmentation. Specifically, TarDGR introduces a Task-Aware Evaluation Mechanism to identify semantically relevant historical subgraphs, enabling the construction of task-specific datasets without manual labeling. It also presents a Graph Transformer-based Task-Aware Model that integrates semantic and structural encodings to assess subgraph relevance. During inference, TarDGR retrieves and fuses task-aware subgraphs with the query subgraph, enriching its representation and mitigating temporal generalization issues. Experiments on multiple large-scale dynamic graph datasets demonstrate that TarDGR consistently outperforms state-of-the-art methods, with extensive empirical evidence underscoring its superior accuracy and generalization capabilities.

</details>


### [8] [DualGR: Generative Retrieval with Long and Short-Term Interests Modeling](https://arxiv.org/abs/2511.12518)
*Zhongchao Yi,Kai Feng,Xiaojian Ma,Yalong Wang,Yongqi Liu,Han Li,Zhengyang Zhou,Yang Wang*

Main category: cs.IR

TL;DR: DualGR是一个生成式检索框架，通过双分支长短期路由、基于搜索的语义ID解码和曝光感知的下一个令牌预测损失，解决了用户兴趣平衡、噪声干扰和负反馈建模三大挑战，在快手短视频推荐系统中取得了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 解决生成式检索中存在的三个关键挑战：1）如何平衡用户的长期和短期兴趣；2）生成分层语义ID时的噪声干扰；3）对曝光但未点击等负反馈缺乏显式建模。

Method: 1）双分支长短期路由（DBR）显式建模用户长短期行为；2）基于搜索的语义ID解码（S2D）控制上下文噪声并提升计算效率；3）曝光感知的下一个令牌预测损失（ENTP-Loss）将曝光未点击项作为硬负样本。

Result: 在快手短视频推荐系统中，在线A/B测试显示视频观看量提升0.527%，观看时长提升0.432%。

Conclusion: DualGR为工业级生成式检索提供了一个实用且有效的范式，能够显著提升推荐系统性能。

Abstract: In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats "exposed-but-unclicked" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.

</details>


### [9] [MindRec: Mind-inspired Coarse-to-fine Decoding for Generative Recommendation](https://arxiv.org/abs/2511.12597)
*Mengyao Gao,Chongming Gao,Haoyan Liu,Qingpeng Cai,Peng Jiang,Jiajia Chen,Shuai Yuan,Xiangnan He*

Main category: cs.IR

TL;DR: MindRec是一个受人类思维启发的推荐系统框架，通过生成关键token来模拟人类决策过程，使用分层类别树和扩散束搜索算法提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的推荐系统采用自回归生成方式，受限于从左到右的贪婪解码策略，无法产生全局最优推荐。而人类思维过程更加灵活，通常从关键词或直觉开始，然后逐步细化。

Method: 1) 首先生成反映用户偏好的关键token；2) 将关键token扩展为完整项目；3) 使用分层类别树结构，从粗粒度类别逐步细化到具体项目；4) 设计扩散束搜索算法解决贪婪解码的局部最优问题。

Result: 实验结果显示，MindRec在top-1推荐性能上比现有最先进方法平均提升9.5%。

Conclusion: MindRec通过模拟人类思维过程，显著提升了推荐系统的准确性，证明了人类启发式方法在推荐系统中的有效性。

Abstract: Recent advancements in large language model-based recommendation systems often represent items as text or semantic IDs and generate recommendations in an auto-regressive manner. However, due to the left-to-right greedy decoding strategy and the unidirectional logical flow, such methods often fail to produce globally optimal recommendations. In contrast, human reasoning does not follow a rigid left-to-right sequence. Instead, it often begins with keywords or intuitive insights, which are then refined and expanded. Inspired by this fact, we propose Mind-inspired Recommender (MindRec), a novel generative framework that emulates human thought processes. Particularly, our method first generates key tokens that reflect user preferences, and then expands them into the complete item, enabling flexible and human-like generation. To further emulate the structured nature of human decision-making, we organize items into a hierarchical category tree. This structure guides the model to first produce the coarse-grained category and then progressively refine its selection through finer-grained subcategories before generating the specific item. To mitigate the local optimum problem inherent in greedy decoding, we design a novel beam search algorithm, Diffusion Beam Search, tailored for our mind-inspired generation paradigm. Experimental results demonstrate that MindRec yields a 9.5\% average improvement in top-1 recommendation performance over state-of-the-art methods, highlighting its potential to enhance recommendation accuracy. The implementation is available via https://github.com/Mr-Peach0301/MindRec.

</details>


### [10] [Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation](https://arxiv.org/abs/2511.12922)
*Yu Hou,Won-Yong Shin*

Main category: cs.IR

TL;DR: 提出了UniTok统一项目标记化框架，通过MoE架构和多码本将不同领域的项目转换为离散标记，实现跨领域语义保留的可扩展标记化。


<details>
  <summary>Details</summary>
Motivation: 现有项目标记化方法需要为每个项目领域训练单独模型，限制了泛化能力，且不同领域的分布和语义差异使得难以构建统一的标记化方法。

Method: 使用共享编码器将不同领域项目投影到统一潜在空间，通过领域特定专家捕获独特语义，共享专家编码跨领域通用知识，并引入互信息校准机制平衡语义信息。

Result: 在广泛真实数据集上实验显示：性能提升达51.89%，理论分析验证架构设计有效性，无需领域重训练即可在多样化领域展现稳健性能。

Conclusion: UniTok框架在保持跨领域语义信息的同时实现了可扩展的项目标记化，解决了现有方法的泛化限制问题。

Abstract: Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.

</details>


### [11] [A Plug-and-Play Spatially-Constrained Representation Enhancement Framework for Local-Life Recommendation](https://arxiv.org/abs/2511.12947)
*Hao Jiang,Guoquan Wang,Sheng Yu,Yang Zeng,Wencong Zeng,Guorui Zhou*

Main category: cs.IR

TL;DR: 提出了ReST框架，通过元ID预热网络和空间约束ID表示增强网络来解决本地生活推荐中的空间约束和长尾稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 本地生活推荐面临空间约束和长尾稀疏两大挑战：空间约束限制了物品的曝光范围，长尾稀疏导致高质量长尾物品被忽视。现有方法多从用户角度出发，而本文认为应从物品角度增强长尾物品在空间约束下的表示。

Method: 提出ReST框架，包含元ID预热网络（注入基本属性语义信息初始化ID表示）和空间约束ID表示增强网络SIDENet（基于对比学习，采用空间约束硬采样策略和动态表示对齐策略）。

Result: 该框架能够自适应识别弱ID表示，在空间约束特性下捕捉潜在物品关系，同时保持与热门物品的兼容性。

Conclusion: ReST是一个即插即用的空间约束表示增强框架，有效解决了本地生活推荐中的长尾问题，从物品角度提升了推荐性能。

Abstract: Local-life recommendation have witnessed rapid growth, providing users with convenient access to daily essentials. However, this domain faces two key challenges: (1) spatial constraints, driven by the requirements of the local-life scenario, where items are usually shown only to users within a limited geographic area, indirectly reducing their exposure probability; and (2) long-tail sparsity, where few popular items dominate user interactions, while many high-quality long-tail items are largely overlooked due to imbalanced interaction opportunities. Existing methods typically adopt a user-centric perspective, such as modeling spatial user preferences or enhancing long-tail representations with collaborative filtering signals. However, we argue that an item-centric perspective is more suitable for this domain, focusing on enhancing long-tail items representation that align with the spatially-constrained characteristics of local lifestyle services. To tackle this issue, we propose ReST, a Plug-And-Play Spatially-Constrained Representation Enhancement Framework for Long-Tail Local-Life Recommendation. Specifically, we first introduce a Meta ID Warm-up Network, which initializes fundamental ID representations by injecting their basic attribute-level semantic information. Subsequently, we propose a novel Spatially-Constrained ID Representation Enhancement Network (SIDENet) based on contrastive learning, which incorporates two efficient strategies: a spatially-constrained hard sampling strategy and a dynamic representation alignment strategy. This design adaptively identifies weak ID representations based on their attribute-level information during training. It additionally enhances them by capturing latent item relationships within the spatially-constrained characteristics of local lifestyle services, while preserving compatibility with popular items.

</details>


### [12] [Can We Predict the Next Question? A Collaborative Filtering Approach to Modeling User Behavior](https://arxiv.org/abs/2511.12949)
*Bokang Fu,Jiahao Wang,Xiaojing Liu,Yuli Liu*

Main category: cs.IR

TL;DR: 提出了CFQP框架，通过结合个性化记忆模块和图基偏好传播，动态建模用户-问题交互，有效预测用户提问序列。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型系统通常静态建模用户偏好，无法捕捉交互行为的动态性和序列性，用户历史问题序列包含丰富的兴趣演化信号但难以利用。

Method: CFQP框架整合个性化记忆模块和图基偏好传播机制，从用户特定历史中自适应学习，并通过相似用户的协作信号优化预测。

Result: 实验结果表明该方法能有效生成模拟真实用户提问模式的智能体，展示了构建主动适应对话系统的潜力。

Conclusion: CFQP框架成功解决了语言建模与行为序列建模之间的脱节问题，为构建动态用户建模系统提供了有效方案。

Abstract: In recent years, large language models (LLMs) have excelled in language understanding and generation, powering advanced dialogue and recommendation systems. However, a significant limitation persists: these systems often model user preferences statically, failing to capture the dynamic and sequential nature of interactive behaviors. The sequence of a user's historical questions provides a rich, implicit signal of evolving interests and cognitive patterns, yet leveraging this temporal data for predictive tasks remains challenging due to the inherent disconnect between language modeling and behavioral sequence modeling.
  To bridge this gap, we propose a Collaborative Filtering-enhanced Question Prediction (CFQP) framework. CFQP dynamically models evolving user-question interactions by integrating personalized memory modules with graph-based preference propagation. This dual mechanism allows the system to adaptively learn from user-specific histories while refining predictions through collaborative signals from similar users. Experimental results demonstrate that our approach effectively generates agents that mimic real-user questioning patterns, highlighting its potential for building proactive and adaptive dialogue systems.

</details>


### [13] [Personalized Federated Recommendation With Knowledge Guidance](https://arxiv.org/abs/2511.12959)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Dongha Kim,Hwanjo Yu*

Main category: cs.IR

TL;DR: FedRKG是一个解决联邦推荐系统内存与性能困境的模型无关框架，通过知识引导机制在单知识模型内存占用下实现双知识模型的个性化效果


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐模型面临两难：内存高效的单知识模型会丢弃有价值的个性化信息，而高性能的双知识模型内存占用过大，难以在实际设备上部署

Method: 提出知识引导机制，避免完全替换，而是将全局知识融合到保留的本地嵌入中；引入自适应引导机制，为每个用户-物品交互动态调整引导强度

Result: 在基准数据集上的广泛实验表明，FedRKG显著优于最先进的方法，验证了方法的有效性

Conclusion: FedRKG成功解决了联邦推荐系统的内存-性能权衡问题，在单知识模型内存占用下实现了双知识模型的个性化性能

Abstract: Federated Recommendation (FedRec) has emerged as a key paradigm for building privacy-preserving recommender systems. However, existing FedRec models face a critical dilemma: memory-efficient single-knowledge models suffer from a suboptimal knowledge replacement practice that discards valuable personalization, while high-performance dual-knowledge models are often too memory-intensive for practical on-device deployment. We propose Federated Recommendation with Knowledge Guidance (FedRKG), a model-agnostic framework that resolves this dilemma. The core principle, Knowledge Guidance, avoids full replacement and instead fuses global knowledge into preserved local embeddings, attaining the personalization benefits of dual-knowledge within a single-knowledge memory footprint. Furthermore, we introduce Adaptive Guidance, a fine-grained mechanism that dynamically modulates the intensity of this guidance for each user-item interaction, overcoming the limitations of static fusion methods. Extensive experiments on benchmark datasets demonstrate that FedRKG significantly outperforms state-of-the-art methods, validating the effectiveness of our approach. The code is available at https://github.com/Jaehyung-Lim/fedrkg.

</details>


### [14] [Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning](https://arxiv.org/abs/2511.13041)
*Miaomiao Cai,Min Hou,Lei Chen,Le Wu,Haoyue Bai,Yong Li,Meng Wang*

Main category: cs.IR

TL;DR: 提出AURL框架，通过表示分布视角解决推荐系统中的偏见问题，使用组对齐和全局均匀性正则化器来缓解流行度偏见。


<details>
  <summary>Details</summary>
Motivation: CF推荐方法因训练数据不平衡而产生偏见，倾向于推荐热门商品且对不活跃用户表现不佳。现有方法可能牺牲准确性或对权重策略敏感。

Method: 提出AURL框架，识别表示分布中的组差异和全局坍缩问题，使用组对齐和全局均匀性两个正则化器来优化表示分布。

Result: 在三个真实数据集和多种推荐骨干网络上的广泛实验验证了所提框架的优越性。

Conclusion: AURL框架通过直接优化表示分布能有效缓解推荐偏见，且方法简单有效。

Abstract: Collaborative Filtering~(CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. In this paper, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework.

</details>


### [15] [Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact](https://arxiv.org/abs/2511.13057)
*Satyanarayan Pati*

Main category: cs.IR

TL;DR: 对密集检索模型向量嵌入的压缩策略进行实证研究，比较维度缩减（自编码器）和精度缩减（量化）两种方法在BEIR SciFact基准上的效果。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型的高维高精度向量嵌入在真实部署中面临显著的存储和内存挑战，需要有效的压缩策略。

Method: 在BEIR SciFact基准上系统评估两种压缩策略：1）通过深度自编码器进行维度缩减（384维降至12维）；2）通过量化进行精度缩减（float16、int8和二进制）。

Result: int8标量量化在4倍压缩比下效果最佳，nDCG@10仅下降1-2%；自编码器在同等压缩比下性能损失更大；二进制量化因性能急剧下降而不适用。

Conclusion: int8量化是部署高效高性能检索系统的最佳实践选择，在压缩比和性能保持之间提供了最佳平衡。

Abstract: Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the "performance loss" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective "sweet spot," achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.

</details>


### [16] [Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users](https://arxiv.org/abs/2511.13166)
*Zhaoxin Shen,Dan Wu*

Main category: cs.IR

TL;DR: 提出一种名为局部协同过滤(LCF)的新方法，通过利用用户间的局部相似性和大数定律来更有效地利用用户行为数据，在Steam游戏数据集上的实验结果符合实际需求。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地利用互联网中的用户行为数据来改进推荐系统

Method: 提出局部协同过滤(LCF)方法，利用用户间的局部相似性，并基于大数定律整合用户数据

Result: 在Steam游戏数据集上的实验结果表明LCF方法符合现实需求

Conclusion: LCF方法能够有效提升用户行为数据的利用率，在推荐系统中具有实际应用价值

Abstract: To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.

</details>


### [17] [Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation](https://arxiv.org/abs/2511.13201)
*Hao Hu,Yifan Feng,Ruoxue Li,Rundong Xue,Xingliang Hou,Zhiqiang Tian,Yue Gao,Shaoyi Du*

Main category: cs.IR

TL;DR: 提出了Cog-RAG框架，通过主题超图和实体超图的双重结构，结合认知启发的两阶段检索策略，显著提升了RAG系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG方法主要关注低阶成对实体关系，无法捕捉多实体间的高阶关联；而超图方法又局限于块间实体级表示，忽略了全局主题组织和跨块对齐。

Method: 设计主题对齐的双超图RAG框架，包含主题超图捕获块间主题结构，实体超图建模高阶语义关系；采用认知启发的两阶段检索策略：先激活查询相关主题内容，再引导细粒度召回和扩散。

Result: 广泛的实验表明，Cog-RAG显著优于现有的最先进基线方法。

Conclusion: Cog-RAG通过模拟人类自上而下的认知推理过程，实现了从全局主题到局部细节的语义对齐和一致生成，有效提升了RAG系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.

</details>


### [18] [Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference](https://arxiv.org/abs/2511.13389)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.IR

TL;DR: 应用时间序列因果推断框架识别感应炉熔炼中影响能效的操作因素，通过聚类和PCMCI+算法发现能效的核心驱动因素和集群特异性差异。


<details>
  <summary>Details</summary>
Motivation: 工业铸造过程能耗高且变量间存在复杂依赖关系，基于相关性的分析难以区分真实因果驱动因素与虚假关联，限制了决策有效性。

Method: 整合时间序列聚类将熔炼周期分割为不同操作模式，使用PCMCI+因果发现算法在每个模式内揭示因果关系。

Result: 发现能耗、炉温和材料重量之间的稳健因果关系是能效核心驱动因素，电压对冷却水温度有延迟影响；高效集群特征为稳定因果结构，低效集群存在强化反馈环和非典型依赖。

Conclusion: 研究提出了聚类-因果推断集成管道作为分析高能耗过程的方法创新，为铸造厂操作人员提供了可操作的优化性能、降低能耗和排放的见解。

Abstract: Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.

</details>


### [19] [Attention Grounded Enhancement for Visual Document Retrieval](https://arxiv.org/abs/2511.13415)
*Wanqing Cui,Wei Huang,Yazhi Guo,Yibo Hu,Meiguang Jin,Junfeng Ma,Keping Bi*

Main category: cs.IR

TL;DR: AGREE框架通过利用多模态大语言模型的跨模态注意力作为局部监督信号，结合全局监督共同优化文档检索器，提升对非抽取式查询的处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有检索器仅使用粗粒度的全局相关性标签进行训练，无法揭示支持匹配的具体区域，导致依赖表面线索且难以捕捉隐式语义连接。

Method: 提出AGREE框架，利用多模态大语言模型的跨模态注意力作为代理局部监督，指导识别相关文档区域，结合局部和全局信号联合优化检索器。

Result: 在ViDoRe V2基准测试中显著优于仅使用全局监督的基线，定量和定性分析显示AGREE促进了查询术语与文档区域之间更深层次的对齐。

Conclusion: AGREE框架通过局部监督使检索器能够学习驱动相关性的具体内容，实现了更准确和可解释的检索，超越了表面级匹配。

Abstract: Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \textbf{A}ttention-\textbf{G}rounded \textbf{RE}triever \textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.

</details>


### [20] [Exploring Multi-Table Retrieval Through Iterative Search](https://arxiv.org/abs/2511.13418)
*Allaa Boutaleb,Bernd Amann,Rafael Angarita,Hubert Naacke*

Main category: cs.IR

TL;DR: 提出了一种迭代式多表检索框架，通过贪婪连接感知检索算法平衡相关性、覆盖率和可连接性，在保持竞争力的同时比MIP方法快4-400倍


<details>
  <summary>Details</summary>
Motivation: 解决数据湖中多表检索的挑战，需要在语义相关性和结构连贯性（如可连接性）之间取得平衡，而精确优化方法计算复杂度过高，简单启发式方法又难以找到连贯的可连接表集

Method: 将多表检索构建为迭代搜索过程，提出贪婪连接感知检索算法，综合考虑相关性、覆盖率和可连接性进行表选择

Result: 在5个NL2SQL基准测试中，迭代方法相比MIP方法实现了竞争力的检索性能，同时速度提升4-400倍

Conclusion: 迭代启发式方法在实用性、可扩展性和组合感知检索方面具有巨大潜力

Abstract: Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.

</details>


### [21] [Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports](https://arxiv.org/abs/2511.13523)
*Nikita Neveditsin,Pawan Lingras,Salil Patil,Swarup Patil,Vijay Mago*

Main category: cs.IR

TL;DR: 紧凑多模态模型在转录嘈杂临床文档方面优于传统OCR系统，是医疗数字化中隐私保护的可行方案


<details>
  <summary>Details</summary>
Motivation: 医疗记录数字化常依赖智能手机拍摄打印报告，这些图像因模糊、阴影等噪声而质量下降，传统OCR系统在真实条件下表现不佳

Method: 使用印度医疗环境中常见的产科超声报告，比较8个系统在转录准确性、噪声敏感性、数字准确性和计算效率方面的表现

Result: 紧凑多模态模型始终优于经典和神经OCR流程，尽管计算成本更高，但具有鲁棒性和语言适应性

Conclusion: 紧凑多模态模型因其鲁棒性和语言适应性，成为本地化医疗数字化的可行候选方案

Abstract: Digitization of medical records often relies on smartphone photographs of printed reports, producing images degraded by blur, shadows, and other noise. Conventional OCR systems, optimized for clean scans, perform poorly under such real-world conditions. This study evaluates compact multimodal language models as privacy-preserving alternatives for transcribing noisy clinical documents. Using obstetric ultrasound reports written in regionally inflected medical English common to Indian healthcare settings, we compare eight systems in terms of transcription accuracy, noise sensitivity, numeric accuracy, and computational efficiency. Compact multimodal models consistently outperform both classical and neural OCR pipelines. Despite higher computational costs, their robustness and linguistic adaptability position them as viable candidates for on-premises healthcare digitization.

</details>
