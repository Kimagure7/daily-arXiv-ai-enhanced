<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts](https://arxiv.org/abs/2510.19986)
*Drew B. Thomas*

Main category: cs.IR

TL;DR: 使用LLM和RAG技术结合向量数据库对早期现代宗教图像进行分类的新方法，在分类精度上显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 改进早期现代宗教图像的分类方法，传统图像和基于关键词的搜索方法效果有限，需要更准确的分类工具

Method: 利用LLM生成包含视觉和文本元素的完整页面描述，通过混合向量搜索匹配到相关的Iconclass代码

Result: 在五级和四级分类上分别达到87%和92%的精确度，显著优于传统图像和关键词搜索方法

Conclusion: 该方法展示了LLM和RAG在艺术史和数字人文学科研究中的巨大潜力，为大规模分析早期现代视觉档案提供了强大工具

Abstract: This paper presents a novel methodology for classifying early modern
religious images by using Large Language Models (LLMs) and vector databases in
combination with Retrieval-Augmented Generation (RAG). The approach leverages
the full-page context of book illustrations from the Holy Roman Empire,
allowing the LLM to generate detailed descriptions that incorporate both visual
and textual elements. These descriptions are then matched to relevant Iconclass
codes through a hybrid vector search. This method achieves 87% and 92%
precision at five and four levels of classification, significantly
outperforming traditional image and keyword-based searches. By employing
full-page descriptions and RAG, the system enhances classification accuracy,
offering a powerful tool for large-scale analysis of early modern visual
archives. This interdisciplinary approach demonstrates the growing potential of
LLMs and RAG in advancing research within art history and digital humanities.

</details>


### [2] [Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning](https://arxiv.org/abs/2510.20150)
*Yaochen Zhu,Harald Steck,Dawen Liang,Yinhan He,Jundong Li,Nathan Kallus*

Main category: cs.IR

TL;DR: 提出ConvRec-R1框架，通过两阶段训练解决LLM在推荐系统中的问题：第一阶段使用Remap-Reflect-Adjust管道构建行为克隆数据集，第二阶段提出Rank-GRPO方法优化推荐排名质量。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐系统中面临生成目录外项目、违反输出格式和排名质量下降的问题，需要专门的对齐方法。

Method: 两阶段框架：第一阶段使用Remap-Reflect-Adjust管道构建高质量演示数据；第二阶段提出Rank-GRPO，将排名作为优化单位，重新定义奖励并引入排名级重要性比率。

Result: 在Reddit-v2数据集上，ConvRec-R1比GRPO基线收敛更快，Recall和NDCG指标更高。

Conclusion: ConvRec-R1有效解决了LLM在推荐系统中的对齐问题，提升了推荐质量和训练效率。

Abstract: Large language models (LLMs) are reshaping the recommender system paradigm by
enabling users to express preferences and receive recommendations through
conversations. Yet, aligning LLMs to the recommendation task remains
challenging: pretrained LLMs often generate out-of-catalog items, violate
required output formats, and their ranking quality degrades sharply toward the
end of the generated list. To this end, we propose ConvRec-R1, a two-stage
framework for end-to-end training of LLM-based conversational recommender
systems. In Stage 1, we construct a behavioral-cloning dataset with a
Remap-Reflect-Adjust pipeline, which produces high-quality, catalog-grounded
demonstrations from powerful blackbox LLMs to warm-start the RL training. In
Stage 2, we propose Rank-GRPO, a principled extension of group relative policy
optimization (GRPO) tailored to tasks with rank-style outputs. Rank-GRPO treats
each rank in the recommendation list as the unit instead of token (too
fine-grained) or sequence (too coarse), redefining rewards to remove non-causal
credit assignment and introducing a rank-level importance ratio based on the
geometric mean of rank-wise token probabilities to stabilize policy updates.
Experiments on the public Reddit-v2 dataset show that ConvRec-R1 converges
faster and achieves higher Recall and NDCG than GRPO-style baselines. Code and
datasets are released at https://github.com/yaochenzhu/Rank-GRPO.

</details>


### [3] [Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures](https://arxiv.org/abs/2510.20193)
*Rahul Raja,Arpita Vats*

Main category: cs.IR

TL;DR: 这篇论文综述了多媒体问答系统的最新进展，重点关注融合视觉、语言和音频模态的检索增强架构，分析了检索方法、融合技术和答案生成策略，并讨论了跨模态对齐、延迟-准确性权衡等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 随着多媒体内容的快速增长，传统基于结构化文本的问答系统面临新挑战，需要整合图像、音频、视频和结构化元数据来增强问答能力。

Method: 通过分类检索方法、融合技术和答案生成策略来系统分析多媒体问答系统架构，并评估基准数据集和性能权衡。

Result: 综述了多媒体检索增强问答系统的最新进展，识别了不同方法的性能特点和适用场景。

Conclusion: 多媒体问答系统在跨模态对齐、语义基础和延迟-准确性权衡方面仍面临挑战，需要进一步研究来构建更鲁棒和上下文感知的系统。

Abstract: Question Answering (QA) systems have traditionally relied on structured text
data, but the rapid growth of multimedia content (images, audio, video, and
structured metadata) has introduced new challenges and opportunities for
retrieval-augmented QA. In this survey, we review recent advancements in QA
systems that integrate multimedia retrieval pipelines, focusing on
architectures that align vision, language, and audio modalities with user
queries. We categorize approaches based on retrieval methods, fusion
techniques, and answer generation strategies, and analyze benchmark datasets,
evaluation protocols, and performance tradeoffs. Furthermore, we highlight key
challenges such as cross-modal alignment, latency-accuracy tradeoffs, and
semantic grounding, and outline open problems and future research directions
for building more robust and context-aware QA systems leveraging multimedia
data.

</details>


### [4] [Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates](https://arxiv.org/abs/2510.20260)
*Changping Meng,Hongyi Ling,Jianling Wang,Yifan Liu,Shuzhou Zhang,Dapeng Hong,Mingyan Gao,Onkar Dalal,Ed Chi,Lichan Hong,Haokai Lu,Ningren Han*

Main category: cs.IR

TL;DR: 本文研究LLM推荐系统的更新策略，比较持续微调与RAG方法的优劣，提出结合两者优势的混合更新策略，并在十亿用户平台上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 用户兴趣和内容的动态变化使得LLM推荐系统需要有效的更新机制，初始微调无法捕捉实时变化，需要研究稳健的更新方法。

Method: 使用LLM驱动的用户兴趣探索系统作为案例研究，比较持续微调和RAG方法在成本、敏捷性和知识整合等维度的表现，提出结合周期性微调和低成本RAG的混合策略。

Result: 通过在十亿用户平台上的实时A/B实验证明，混合方法在用户满意度方面取得了统计显著的提升。

Conclusion: 混合更新策略提供了实用且成本效益高的框架，能够维持高质量的LLM推荐系统。

Abstract: Large Language Models (LLMs) empower recommendation systems through their
advanced reasoning and planning capabilities. However, the dynamic nature of
user interests and content poses a significant challenge: While initial
fine-tuning aligns LLMs with domain knowledge and user preferences, it fails to
capture such real-time changes, necessitating robust update mechanisms. This
paper investigates strategies for updating LLM-powered recommenders, focusing
on the trade-offs between ongoing fine-tuning and Retrieval-Augmented
Generation (RAG). Using an LLM-powered user interest exploration system as a
case study, we perform a comparative analysis of these methods across
dimensions like cost, agility, and knowledge incorporation. We propose a hybrid
update strategy that leverages the long-term knowledge adaptation of periodic
fine-tuning with the agility of low-cost RAG. We demonstrate through live A/B
experiments on a billion-user platform that this hybrid approach yields
statistically significant improvements in user satisfaction, offering a
practical and cost-effective framework for maintaining high-quality LLM-powered
recommender systems.

</details>


### [5] [From Generation to Attribution: Music AI Agent Architectures for the Post-Streaming Era](https://arxiv.org/abs/2510.20276)
*Wonil Kim,Hyeongseok Wi,Seungsoon Park,Taejun Kim,Sangeun Keum,Keunhyoung Kim,Taewan Kim,Jongmin Jung,Taehyoung Kim,Gaetan Guerrero,Mael Le Goff,Julie Po,Dongjoo Moon,Juhan Nam,Jongpil Lee*

Main category: cs.IR

TL;DR: 提出基于内容块的音乐AI代理架构，通过细粒度组件管理和实时归属追踪，解决AI音乐创作中的版权归属和经济分配问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑音乐创作，但现有流媒体系统无法应对AI驱动生产的规模和复杂性，存在归属、权利管理和经济模型的结构性差距。

Method: 设计基于块的音乐AI代理架构，将音乐组织为细粒度组件存储在BlockDB中，通过归属层事件实现透明溯源和实时结算。

Result: 该框架将AI从生成工具转变为公平AI媒体平台的基础设施，支持细粒度归属、公平补偿和参与式互动。

Conclusion: 该方案指向后流媒体范式，使音乐从静态目录转变为协作自适应的生态系统。

Abstract: Generative AI is reshaping music creation, but its rapid growth exposes
structural gaps in attribution, rights management, and economic models. Unlike
past media shifts, from live performance to recordings, downloads, and
streaming, AI transforms the entire lifecycle of music, collapsing boundaries
between creation, distribution, and monetization. However, existing streaming
systems, with opaque and concentrated royalty flows, are ill-equipped to handle
the scale and complexity of AI-driven production. We propose a content-based
Music AI Agent architecture that embeds attribution directly into the creative
workflow through block-level retrieval and agentic orchestration. Designed for
iterative, session-based interaction, the system organizes music into granular
components (Blocks) stored in BlockDB; each use triggers an Attribution Layer
event for transparent provenance and real-time settlement. This framework
reframes AI from a generative tool into infrastructure for a Fair AI Media
Platform. By enabling fine-grained attribution, equitable compensation, and
participatory engagement, it points toward a post-streaming paradigm where
music functions not as a static catalog but as a collaborative and adaptive
ecosystem.

</details>


### [6] [Rotate Both Ways: Time-and-Order RoPE for Generative Recommendation](https://arxiv.org/abs/2510.20455)
*Xiaokai Wei,Jiajun Wu,Daiyao Yi,Reza Shirkavand,Michelle Gong*

Main category: cs.IR

TL;DR: 提出了TO-RoPE方法，通过旋转位置编码联合建模用户行为序列中的时间和顺序信息，在生成式推荐系统中优于现有时间编码方法。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统需要同时考虑交互事件在序列中的位置（索引）和实际发生时间（时间戳），现有方法如学习嵌入或相对注意力偏差存在局限性。

Method: 提出了TO-RoPE方法，将索引和时间作为角度源来塑造查询-键几何结构，包含三种实现：早期融合、按维度分割和按头分割。

Result: 在公开数据集和工业数据集上的实验表明，TO-RoPE变体在准确性上持续优于现有的时间和索引编码方法。

Conclusion: 旋转位置嵌入为生成式推荐提供了一个简单、有原则且易于部署的基础框架。

Abstract: Generative recommenders, typically transformer-based autoregressive models,
predict the next item or action from a user's interaction history. Their
effectiveness depends on how the model represents where an interaction event
occurs in the sequence (discrete index) and when it occurred in wall-clock
time. Prevailing approaches inject time via learned embeddings or relative
attention biases. In this paper, we argue that RoPE-based approaches, if
designed properly, can be a stronger alternative for jointly modeling temporal
and sequential information in user behavior sequences. While vanilla RoPE in
LLMs considers only token order, generative recommendation requires
incorporating both event time and token index. To address this, we propose
Time-and-Order RoPE (TO-RoPE), a family of rotary position embedding designs
that treat index and time as angle sources shaping the query-key geometry
directly. We present three instantiations: early fusion, split-by-dim, and
split-by-head. Extensive experiments on both publicly available datasets and a
proprietary industrial dataset show that TO-RoPE variants consistently improve
accuracy over existing methods for encoding time and index. These results
position rotary embeddings as a simple, principled, and deployment-friendly
foundation for generative recommendation.

</details>


### [7] [Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE](https://arxiv.org/abs/2510.20674)
*Rakshith R,Shubham Sharma,Mohammed Sameer Khan,Ankush Chopra*

Main category: cs.IR

TL;DR: 该研究开发了多语言电商搜索系统，通过数据增强和模型微调在Query-Category和Query-Item相关性任务上取得良好表现，最终在排行榜上获得第4名。


<details>
  <summary>Details</summary>
Motivation: 解决多语言电商搜索中的查询-类别相关性和查询-商品相关性评估问题，确保对所有目标语言的完整覆盖。

Method: 通过翻译现有数据集进行数据增强，使用Gemma-3 12B和Qwen-2.5 14B模型进行微调，采用多种策略包括原始数据、翻译数据和少数类数据创建。

Result: Gemma-3 12B（4位量化）模型在QC任务上使用原始和翻译数据表现最佳，在QI任务上使用原始、翻译和少数类数据创建表现最佳，最终在私有测试集上平均F1分数达到0.8857。

Conclusion: 数据增强和模型微调策略在多语言电商搜索任务中有效，Gemma-3 12B模型在两个相关性任务上都取得了最佳性能，证明了该方法在多语言环境下的可行性。

Abstract: This study presents the multilingual e-commerce search system developed by
the Tredence_AICOE team. The competition features two multilingual relevance
tasks: Query-Category (QC) Relevance, which evaluates how well a user's search
query aligns with a product category, and Query-Item (QI) Relevance, which
measures the match between a multilingual search query and an individual
product listing. To ensure full language coverage, we performed data
augmentation by translating existing datasets into languages missing from the
development set, enabling training across all target languages. We fine-tuned
Gemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies.
The Gemma-3 12B (4-bit) model achieved the best QC performance using original
and translated data, and the best QI performance using original, translated,
and minority class data creation. These approaches secured 4th place on the
final leaderboard, with an average F1-score of 0.8857 on the private test set.

</details>


### [8] [Generative Reasoning Recommendation via LLMs](https://arxiv.org/abs/2510.20815)
*Minjie Hong,Zetong Zhou,Zirun Guo,Ziang Zhang,Ruofan Hu,Weinan Gan,Jieming Zhu,Zhou Zhao*

Main category: cs.IR

TL;DR: GREAM框架通过整合协同语义对齐、推理课程激活和稀疏正则化组策略优化，将预训练LLM适配为生成式推理推荐模型，实现理解-推理-预测的统一方式。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多个领域展现出强大推理能力，但作为生成式推理推荐模型存在建模差距，难以将文本语义与协同过滤信号结合，且用户反馈稀疏随机。

Method: 提出GREAM框架：1)协同语义对齐构建离散项目索引；2)推理课程激活创建合成数据集；3)SRPO通过残差敏感可验证奖励和奖励校准组优势估计进行稳定后训练。

Result: 在三个数据集上的实验显示，GREAM相比强基线模型获得一致性能提升。

Conclusion: GREAM为可验证强化学习驱动的LLM推荐器提供了实用路径，支持两种推理模式：直接序列推荐和高吞吐部署，以及顺序推理推荐提供因果透明度。

Abstract: Despite their remarkable reasoning capabilities across diverse domains, large
language models (LLMs) face fundamental challenges in natively functioning as
generative reasoning recommendation models (GRRMs), where the intrinsic
modeling gap between textual semantics and collaborative filtering signals,
combined with the sparsity and stochasticity of user feedback, presents
significant obstacles. This work explores how to build GRRMs by adapting
pre-trained LLMs, which achieves a unified understanding-reasoning-prediction
manner for recommendation tasks. We propose GREAM, an end-to-end framework that
integrates three components: (i) Collaborative-Semantic Alignment, which fuses
heterogeneous textual evidence to construct semantically consistent, discrete
item indices and auxiliary alignment tasks that ground linguistic
representations in interaction semantics; (ii) Reasoning Curriculum Activation,
which builds a synthetic dataset with explicit Chain-of-Thought supervision and
a curriculum that progresses through behavioral evidence extraction, latent
preference modeling, intent inference, recommendation formulation, and denoised
sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization
(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward
and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end
optimization under verifiable signals despite sparse successes. GREAM natively
supports two complementary inference modes: Direct Sequence Recommendation for
high-throughput, low-latency deployment, and Sequential Reasoning
Recommendation that first emits an interpretable reasoning chain for causal
transparency. Experiments on three datasets demonstrate consistent gains over
strong baselines, providing a practical path toward verifiable-RL-driven LLM
recommenders.

</details>
