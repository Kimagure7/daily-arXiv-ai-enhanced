<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [LLM-based Semantic Search for Conversational Queries in E-commerce](https://arxiv.org/abs/2601.16492)
*Emad Siddiqui,Venkatesh Terikuti,Xuan Lu*

Main category: cs.IR

TL;DR: 提出基于LLM的语义搜索框架，通过领域特定嵌入和结构化过滤捕捉对话查询的用户意图，使用合成数据微调模型，结合相似性检索和约束过滤提升电商搜索效果。


<details>
  <summary>Details</summary>
Motivation: 传统电商平台的搜索系统主要针对关键词查询优化，难以处理日益复杂的对话式用户查询，需要更有效地捕捉用户意图。

Method: 1) 使用LLM生成合成数据指导微调；2) 微调嵌入模型使语义相似产品在表示空间中靠近；3) 微调生成模型将自然语言查询转换为结构化约束；4) 结合相似性检索和约束过滤。

Result: 在真实世界数据集上，相比基线方法，该框架在各种设置下都实现了较强的精确率和召回率。

Conclusion: 提出的LLM语义搜索框架能有效处理对话式查询，通过结合领域特定嵌入和结构化过滤，在有限标注数据情况下仍能取得良好搜索效果。

Abstract: Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.

</details>


### [2] [PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation](https://arxiv.org/abs/2601.16556)
*Dengzhao Fang,Jingtong Gao,Yu Li,Xiangyu Zhao,Yi Chang*

Main category: cs.IR

TL;DR: PRISM是一个新的生成式序列推荐框架，通过纯化语义量化和集成语义建模解决现有方法在语义标记化和生成质量上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式序列推荐框架面临两个关键限制：1）不纯且不稳定的语义标记化，量化方法难以处理交互噪声和码本崩溃，导致语义ID具有模糊区分性；2）有损且弱结构化的生成，仅依赖粗粒度离散标记会引入信息损失并忽略项目的层次逻辑。

Method: 提出PRISM框架，包含：1）纯化语义量化器，通过自适应协同去噪和层次语义锚定机制构建鲁棒码本；2）集成语义推荐器，通过动态语义集成机制整合细粒度语义，并通过语义结构对齐目标强制逻辑有效性。

Result: PRISM在四个真实世界数据集上持续优于最先进的基线方法，特别是在高稀疏性场景中表现出显著的性能提升。

Conclusion: PRISM通过解决语义标记化和生成质量的问题，为生成式序列推荐提供了一个有效的解决方案，在高稀疏性场景中尤其有效。

Abstract: Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.

</details>


### [3] [LLM-powered Real-time Patent Citation Recommendation for Financial Technologies](https://arxiv.org/abs/2601.16775)
*Tianang Deng,Yu Deng,Tianchen Gao,Yonghong Hu,Rui Pan*

Main category: cs.IR

TL;DR: 提出一个针对金融专利的实时引用推荐框架，使用LLM嵌入、近似最近邻搜索和增量索引策略，在动态专利系统中实现高效准确的引用推荐。


<details>
  <summary>Details</summary>
Motivation: 金融创新快速发展导致专利申请激增，传统静态索引或定期重训练的专利检索和引用推荐方法难以应对这种动态环境，需要实时有效的解决方案。

Method: 构建三阶段推荐流程：1) 使用LLM嵌入表示专利摘要语义内容；2) 应用近似最近邻搜索构建候选集；3) 按语义相似度排序生成top-k推荐。采用基于HNSW图的增量索引策略，支持新专利添加而无需重建整个索引。

Result: 在428,843个中国金融专利数据集上验证，增量更新策略在提高召回率的同时显著降低计算成本，优于传统文本基线和替代最近邻检索方法。

Conclusion: 提出的实时专利引用推荐框架能有效应对金融专利系统的动态特性，为快速变化的专利环境提供高效准确的引用推荐解决方案。

Abstract: Rapid financial innovation has been accompanied by a sharp increase in patenting activity, making timely and comprehensive prior-art discovery more difficult. This problem is especially evident in financial technologies, where innovations develop quickly, patent collections grow continuously, and citation recommendation systems must be updated as new applications arrive. Existing patent retrieval and citation recommendation methods typically rely on static indexes or periodic retraining, which limits their ability to operate effectively in such dynamic settings. In this study, we propose a real-time patent citation recommendation framework designed for large and fast-changing financial patent corpora. Using a dataset of 428,843 financial patents granted by the China National Intellectual Property Administration (CNIPA) between 2000 and 2024, we build a three-stage recommendation pipeline. The pipeline uses large language model (LLM) embeddings to represent the semantic content of patent abstracts, applies efficient approximate nearest-neighbor search to construct a manageable candidate set, and ranks candidates by semantic similarity to produce top-k citation recommendations. In addition to improving recommendation accuracy, the proposed framework directly addresses the dynamic nature of patent systems. By using an incremental indexing strategy based on hierarchical navigable small-world (HNSW) graphs, newly issued patents can be added without rebuilding the entire index. A rolling day-by-day update experiment shows that incremental updating improves recall while substantially reducing computational cost compared with rebuild-based indexing. The proposed method also consistently outperforms traditional text-based baselines and alternative nearest-neighbor retrieval approaches.

</details>


### [4] [PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework](https://arxiv.org/abs/2601.16815)
*Shaoqing Wang,Yingcai Ma,Kairui Fu,Ziyang Wang,Dunxian Huang,Yuliang Yan,Jian Wu*

Main category: cs.IR

TL;DR: 提出PI2I两阶段检索框架，通过放宽截断阈值和引入交互式评分模型，提升推荐系统的个性化能力，在淘宝"猜你喜欢"中实现交易率提升1.05%


<details>
  <summary>Details</summary>
Motivation: 传统方法（如item-to-item协同过滤和双塔模型）在捕捉复杂用户-物品交互方面存在不足，主要受限于均匀截断策略和用户-物品交叉建模的局限性

Method: 提出PI2I两阶段框架：1) 索引构建阶段(IBS)放宽截断阈值最大化命中率；2) 个性化检索阶段(PRS)引入交互式评分模型替代内积计算，并基于触发-目标关系构建负样本

Result: 离线实验在大规模真实数据集上优于传统CF方法，媲美双塔模型；在线部署于淘宝"猜你喜欢"实现交易率提升1.05%；同时发布了包含1.3亿用户交互的公开数据集

Conclusion: PI2I框架有效解决了传统推荐方法的局限性，通过两阶段个性化检索显著提升推荐效果，为研究社区提供了有价值的基准数据集

Abstract: Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the "Guess You Like" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.

</details>


### [5] [Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation](https://arxiv.org/abs/2601.16858)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 大规模实证研究揭示Google搜索与生成式AI服务在信息来源、领域类型、查询意图和信息新鲜度等方面存在显著差异，并探讨LLM预训练知识库对实时搜索的影响，分析答案引擎优化(AEO)与传统搜索引擎优化(SEO)的区别。


<details>
  <summary>Details</summary>
Motivation: 生成式AI作为主要信息来源的兴起，正在从传统网络搜索中引发范式转变。需要量化Google搜索与领先生成式AI服务返回结果之间的根本差异，理解这两种信息生态系统的不同机制。

Method: 进行大规模实证研究，从多个维度分析AI生成答案与网络搜索结果的差异：咨询的源领域、领域类型（如赚取媒体vs自有媒体、社交媒体）、查询意图和信息新鲜度。同时研究LLM预训练作为塑造这些差异的关键因素，分析其内在知识库如何与实时网络搜索互动并产生影响。

Result: AI生成答案与网络搜索结果在多个维度上存在显著差异。LLM预训练知识库是塑造这些差异的关键因素，当启用实时网络搜索时，这种内在知识库会与外部信息互动并产生影响。研究揭示了这两种信息生态系统的不同机制。

Conclusion: 研究结果对新兴的答案引擎优化(AEO)领域及其与传统搜索引擎优化(SEO)的对比提出了关键观察。生成式AI作为信息源与传统搜索存在根本性差异，这需要新的优化策略和方法论。

Abstract: The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).

</details>


### [6] [From Atom to Community: Structured and Evolving Agent Memory for User Behavior Modeling](https://arxiv.org/abs/2601.16872)
*Yuxin Liao,Le Wu,Min Hou,Yu Wang,Han Wu,Meng Wang*

Main category: cs.IR

TL;DR: STEAM是一个结构化、演化的智能体记忆框架，将用户偏好分解为原子记忆单元，通过社区组织和原型记忆利用协作信号，自适应演化机制提升推荐准确性、模拟保真度和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的记忆机制主要针对文本对话设计，在建模非文本行为（如点击）时面临挑战。单一非结构化摘要会导致多面兴趣混淆、偏好演化时遗忘、稀疏交互缺乏协作信号等问题。

Method: STEAM将用户偏好分解为原子记忆单元，每个单元捕获一个独立的兴趣维度并与观察到的行为明确链接。通过跨用户组织相似记忆形成社区，生成原型记忆进行信号传播。采用自适应演化机制，包括记忆精炼的巩固过程和捕获新兴兴趣的形成过程。

Result: 在三个真实世界数据集上的实验表明，STEAM在推荐准确性、模拟保真度和多样性方面显著优于最先进的基线方法。

Conclusion: STEAM通过结构化组织和自适应演化机制，有效解决了现有智能体记忆在建模非文本行为时的局限性，为个性化应用中的用户行为建模提供了更优的解决方案。

Abstract: User behavior modeling lies at the heart of personalized applications like recommender systems. With LLM-based agents, user preference representation has evolved from latent embeddings to semantic memory. While existing memory mechanisms show promise in textual dialogues, modeling non-textual behaviors remains challenging, as preferences must be inferred from implicit signals like clicks without ground truth supervision. Current approaches rely on a single unstructured summary, updated through simple overwriting. However, this is suboptimal: users exhibit multi-faceted interests that get conflated, preferences evolve yet naive overwriting causes forgetting, and sparse individual interactions necessitate collaborative signals. We present STEAM (\textit{\textbf{ST}ructured and \textbf{E}volving \textbf{A}gent \textbf{M}emory}), a novel framework that reimagines how agent memory is organized and updated. STEAM decomposes preferences into atomic memory units, each capturing a distinct interest dimension with explicit links to observed behaviors. To exploit collaborative patterns, STEAM organizes similar memories across users into communities and generates prototype memories for signal propagation. The framework further incorporates adaptive evolution mechanisms, including consolidation for refining memories and formation for capturing emerging interests. Experiments on three real-world datasets demonstrate that STEAM substantially outperforms state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity.

</details>


### [7] [Explaining Group Recommendations via Counterfactuals](https://arxiv.org/abs/2601.16882)
*Maria Stratigi,Nikos Bikakis*

Main category: cs.IR

TL;DR: 提出群组反事实解释框架，揭示移除特定历史交互如何改变群组推荐，通过启发式算法平衡效用与公平性


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统解释方法主要针对个体用户，缺乏对群组推荐的解释能力，导致群组成员不清楚推荐背后的原因

Method: 提出群组反事实解释框架，形式化群组反事实概念，引入群组效用和公平性度量，设计帕累托过滤和增长-剪枝等启发式算法

Result: 实验表明存在明显权衡：低成本方法产生更大但公平性较差的解释，其他方法以更高成本获得更简洁平衡的结果；帕累托过滤在稀疏场景下效率显著提升

Conclusion: 群组反事实解释框架能有效解释群组推荐，不同算法在解释质量、公平性和计算成本间存在权衡，为群组推荐透明度提供了新方法

Abstract: Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.

</details>
