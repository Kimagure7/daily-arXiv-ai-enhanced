<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [FeDecider: An LLM-Based Framework for Federated Cross-Domain Recommendation](https://arxiv.org/abs/2602.16034)
*Xinrui He,Ting-Wei Li,Tianxin Wei,Xuying Ning,Xinyu He,Wenxuan Bao,Hanghang Tong,Jingrui He*

Main category: cs.IR

TL;DR: FeDecider是一个基于大语言模型的联邦跨域推荐框架，通过解耦低秩更新和共享方向分量来解决域特定适配器过拟合问题，并学习个性化权重实现数据感知的跨域集成。


<details>
  <summary>Details</summary>
Motivation: 在联邦跨域推荐中采用基于大语言模型的推荐模型面临两个主要挑战：1) 域特定本地适配器容易过拟合，本地优化参数更新的幅度在不同域间差异导致聚合偏差和向域特定分布过拟合；2) 与传统推荐模型不同，大语言模型通过自回归文本生成训练隐式编码知识，难以在异构环境下有效衡量跨域相似性。

Method: 提出FeDecider框架：1) 通过解耦每个客户端的低秩更新并仅共享其方向分量来处理尺度特定噪声问题；2) 每个客户端进一步学习个性化权重，实现从其他域更新的数据感知集成。

Result: 在多个不同数据集上的广泛实验验证了所提出的FeDecider框架的有效性。

Conclusion: FeDecider成功解决了基于大语言模型的联邦跨域推荐中的过拟合和跨域相似性衡量挑战，通过解耦低秩更新和个性化权重学习实现了有效的跨域协作推荐。

Abstract: Federated cross-domain recommendation (Federated CDR) aims to collaboratively learn personalized recommendation models across heterogeneous domains while preserving data privacy. Recently, large language model (LLM)-based recommendation models have demonstrated impressive performance by leveraging LLMs' strong reasoning capabilities and broad knowledge. However, adopting LLM-based recommendation models in Federated CDR scenarios introduces new challenges. First, there exists a risk of overfitting with domain-specific local adapters. The magnitudes of locally optimized parameter updates often vary across domains, causing biased aggregation and overfitting toward domain-specific distributions. Second, unlike traditional recommendation models (e.g., collaborative filtering, bipartite graph-based methods) that learn explicit and comparable user/item representations, LLMs encode knowledge implicitly through autoregressive text generation training. This poses additional challenges for effectively measuring the cross-domain similarities under heterogeneity. To address these challenges, we propose an LLM-based framework for federated cross-domain recommendation, FeDecider. Specifically, FeDecider tackles the challenge of scale-specific noise by disentangling each client's low-rank updates and sharing only their directional components. To handle the need for flexible and effective integration, each client further learns personalized weights that achieve the data-aware integration of updates from other domains. Extensive experiments across diverse datasets validate the effectiveness of our proposed FeDecider.

</details>


### [2] [Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System](https://arxiv.org/abs/2602.16124)
*Jiang Zhang,Yubo Wang,Wei Chang,Lu Han,Xingying Cheng,Feng Zhang,Min Li,Songhao Jiang,Wei Zheng,Harry Tran,Zhen Wang,Lei Chen,Yueming Wang,Benyu Zhang,Xiangjun Fan,Bi Xue,Qifan Wang*

Main category: cs.IR

TL;DR: MFLI提出了一种可扩展的实时检索范式，通过统一框架学习多面项嵌入和索引，在服务时完全避免ANN搜索，显著提升召回率和服务效率。


<details>
  <summary>Details</summary>
Motivation: 传统ANN检索存在两个关键限制：1) 项嵌入和索引通常是分阶段学习的，索引在嵌入训练后离线构建，导致检索质量次优，特别是对新创建项；2) ANN虽然提供亚线性查询时间，但仍需为每个请求运行，在工业规模下产生大量计算成本。

Method: 通过残差量化构建多面分层码本，并与项嵌入共同训练；引入支持实时更新的高效多面索引结构和机制；在服务时直接使用学习的分层索引识别相关项，完全避免ANN搜索。

Result: 在包含数十亿用户的真实世界数据上，MFLI相比先前最先进方法：在参与任务上召回率提升高达11.8%，冷内容交付提升高达57.29%，语义相关性提升13.5%；在线部署显示参与度提高、流行度偏差减少、服务效率更高。

Conclusion: MFLI提供了一个统一框架，将多面项嵌入学习和索引构建结合，消除了服务时的ANN搜索需求，显著提高了大规模推荐系统中检索的质量、效率和实时更新能力。

Abstract: Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\%, cold-content delivery by up to 57.29\%, and semantic relevance by 13.5\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency.

</details>


### [3] [Retrieval Collapses When AI Pollutes the Web](https://arxiv.org/abs/2602.16136)
*Hongyeon Yu,Dongchan Kim,Young-Bum Kim*

Main category: cs.IR

TL;DR: 检索崩溃：AI生成内容主导搜索结果导致信息检索生态系统级风险


<details>
  <summary>Details</summary>
Motivation: AI生成内容在Web上的快速扩散对信息检索构成结构性风险，搜索引擎和RAG系统越来越多地消费LLM生成的证据，可能导致检索系统质量下降的自我强化循环。

Method: 通过控制实验分析两种场景：高质量SEO风格内容和对抗性内容。在SEO场景中模拟67%的池污染；在对抗场景中比较BM25和LLM排序器的表现。

Result: SEO场景中67%的池污染导致超过80%的暴露污染，形成同质化但看似健康的状态；对抗场景中BM25暴露约19%有害内容，而LLM排序器表现出更强的抑制能力。

Conclusion: 检索管道正悄然转向合成证据，需要检索感知策略来防止Web基础系统中质量下降的自我强化循环。

Abstract: The rapid proliferation of AI-generated content on the Web presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG) systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates search results, eroding source diversity, and (2) low-quality or adversarial content infiltrates the retrieval pipeline. We analyzed this dynamic through controlled experiments involving both high-quality SEO-style content and adversarially crafted content. In the SEO scenario, a 67\% pool contamination led to over 80\% exposure contamination, creating a homogenized yet deceptively healthy state where answer accuracy remains stable despite the reliance on synthetic sources. Conversely, under adversarial contamination, baselines like BM25 exposed $\sim$19\% of harmful content, whereas LLM-based rankers demonstrated stronger suppression capabilities. These findings highlight the risk of retrieval pipelines quietly shifting toward synthetic evidence and the need for retrieval-aware strategies to prevent a self-reinforcing cycle of quality decline in Web-grounded systems.

</details>


### [4] [MICE: Minimal Interaction Cross-Encoders for efficient Re-ranking](https://arxiv.org/abs/2602.16299)
*Mathias Vast,Victor Morand,Basile van Cooten,Laure Soulier,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: MICE是一种新型的交叉编码器架构，通过最小化不必要的交互来降低推理延迟，在保持交叉编码器效果的同时达到与ColBERT等延迟交互模型相当的推理速度。


<details>
  <summary>Details</summary>
Motivation: 交叉编码器在信息检索中效果最好但推理成本高，无法作为第一级排序器使用。现有方法要么加速交叉编码器推理，要么改进第一级检索效果，但两者分离。本文旨在桥接这两种方法。

Method: 基于对交叉编码器内部机制的深入理解，通过仔细移除有害或不必要的交互，从交叉编码器推导出新的延迟交互式架构MICE（最小交互交叉编码器）。

Result: MICE将推理延迟降低四倍，与ColBERT等延迟交互模型相当，同时保留了大部分交叉编码器的域内效果，并在域外数据集上展现出更好的泛化能力。

Conclusion: MICE成功桥接了交叉编码器加速和第一级检索改进两种方法，实现了高效且有效的检索排序，在延迟和效果之间取得了良好平衡。

Abstract: Cross-encoders deliver state-of-the-art ranking effectiveness in information retrieval, but have a high inference cost. This prevents them from being used as first-stage rankers, but also incurs a cost when re-ranking documents. Prior work has addressed this bottleneck from two largely separate directions: accelerating cross-encoder inference by sparsifying the attention process or improving first-stage retrieval effectiveness using more complex models, e.g. late-interaction ones. In this work, we propose to bridge these two approaches, based on an in-depth understanding of the internal mechanisms of cross-encoders. Starting from cross-encoders, we show that it is possible to derive a new late-interaction-like architecture by carefully removing detrimental or unnecessary interactions. We name this architecture MICE (Minimal Interaction Cross-Encoders). We extensively evaluate MICE across both in-domain (ID) and out-of-domain (OOD) datasets. MICE decreases fourfold the inference latency compared to standard cross-encoders, matching late-interaction models like ColBERT while retaining most of cross-encoder ID effectiveness and demonstrating superior generalization abilities in OOD.

</details>


### [5] [The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems](https://arxiv.org/abs/2602.16315)
*Gabriele Barlacchi,Margherita Lalli,Emanuele Ferragina,Fosca Giannotti,Dino Pedreschi,Luca Pappalardo*

Main category: cs.IR

TL;DR: 推荐系统反馈循环研究：用户行为与算法推荐随时间共同演化，传统静态评估存在局限，需要关注动态反馈效应


<details>
  <summary>Details</summary>
Motivation: 推荐系统通过反馈循环影响用户选择，但现有研究对系统性效应理解不足，主要原因是模拟研究中的假设不切实际

Method: 提出反馈循环模型，捕捉隐式反馈、定期重训练、推荐采纳概率和异构推荐系统，应用于在线零售和音乐流媒体数据

Result: 增加推荐采纳可能导致个体消费多样化，但集体需求以模型和领域依赖方式重新分配，常放大流行度集中；时间分析显示静态评估中的个体多样性增加是假象

Conclusion: 需要超越静态评估，在设计推荐系统时明确考虑反馈循环动态

Abstract: Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems.

</details>


### [6] [Variable-Length Semantic IDs for Recommender Systems](https://arxiv.org/abs/2602.16375)
*Kirill Khrylchenko*

Main category: cs.IR

TL;DR: 提出可变长度语义标识符（semantic IDs）用于推荐系统，通过离散变分自编码器学习自适应长度的物品表示，解决传统固定长度语义ID的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有语义标识符方法使用固定长度表示所有物品，这效率低下，与自然语言不匹配，且忽略了现实世界目录中热门物品和长尾物品具有不同信息需求的特性。

Method: 采用离散变分自编码器（discrete variational autoencoder）结合Gumbel-Softmax重参数化，在概率框架下学习自适应长度的物品表示，避免基于REINFORCE训练的不稳定性和先前语义ID方法的固定长度限制。

Result: 该方法能够为不同频率的物品生成可变长度的语义标识符，使热门物品获得更短的描述，长尾物品获得更长的描述，提高表示效率。

Conclusion: 将推荐系统与涌现通信理论相结合，提出可变长度语义标识符框架，为处理大规模物品空间和自然语言集成提供了更高效、更灵活的解决方案。

Abstract: Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem.
  However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems.
  In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods.

</details>


### [7] [From Latent to Observable Position-Based Click Models in Carousel Interfaces](https://arxiv.org/abs/2602.16541)
*Santiago de Leon-Martinez,Robert Moro,Branislav Kveton,Maria Bielikova*

Main category: cs.IR

TL;DR: 本文研究了轮播界面中的点击模型，提出了三种新的基于位置的轮播点击模型，其中OEPBM首次使用眼动追踪数据作为观察到的检查信号，无需潜在变量。实验表明梯度优化效果更好，但仅靠点击数据无法准确建模用户检查行为。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统平台越来越多地使用轮播等复杂界面，而现有点击模型主要针对单一排名列表设计，无法有效建模用户在轮播界面中的复杂浏览行为。

Method: 提出了三种专门针对轮播界面的基于位置点击模型，包括首个无需潜在变量、使用眼动追踪数据作为观察检查信号的OEPBM模型。开发了通用实现框架，支持多种优化技术，包括梯度优化、期望最大化(EM)和最大似然估计(MLE)。

Result: 梯度优化方法在点击似然度上表现最好；OEPBM模型在点击预测和用户行为对齐方面表现最强；但研究发现点击拟合效果好并不代表能准确建模用户检查模式。

Conclusion: 仅依赖点击数据的模型在复杂界面中存在根本局限性，设计轮播推荐系统的点击模型时需要纳入额外的行为信号。

Abstract: Click models are a central component of learning and evaluation in recommender systems, yet most existing models are designed for single ranked-list interfaces. In contrast, modern recommender platforms increasingly use complex interfaces such as carousels, which consist of multiple swipeable lists that enable complex user browsing behaviors.
  In this paper, we study position-based click models in carousel interfaces and examine optimization methods, model structure, and alignment with user behavior. We propose three novel position-based models tailored to carousels, including the first position-based model without latent variables that incorporates observed examination signals derived from eye tracking data, called the Observed Examination Position-Based Model (OEPBM). We develop a general implementation of these carousel click models, supporting multiple optimization techniques and conduct experiments comparing gradient-based methods with classical approaches, namely expectation-maximization and maximum likelihood estimation.
  Our results show that gradient-based optimization consistently achieve better click likelihoods. Among the evaluated models, the OEPBM achieves the strongest performance in click prediction and produces examination patterns that most closely align to user behavior. However, we also demonstrate that strong click fit does not imply realistic modeling of user examination and browsing patterns. This reveals a fundamental limitation of click-only models in complex interfaces and the need for incorporating additional behavioral signals when designing click models for carousel-based recommender systems.

</details>


### [8] [Why Thinking Hurts? Diagnosing and Rectifying the Reasoning Shift in Foundation Recommender Models](https://arxiv.org/abs/2602.16587)
*Luankang Zhang,Yonghao Huang,Hang Lv,Mingjia Yin,Liangyue Li,Zulong Chen,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 论文提出推理时子空间对齐框架，解决CoT推理在语义ID推荐模型中导致性能下降的问题，通过压缩推理链和偏置减除对比解码来校准推理。


<details>
  <summary>Details</summary>
Motivation: 在语义ID推荐基础模型（如OpenOneRec）中引入链式思维推理会降低推荐性能，原因是通用子空间中的文本惯性导致模型忽视关键语义ID。

Method: 提出无需训练的推理时子空间对齐框架：压缩推理链以减少冗余文本，应用偏置减除对比解码来减轻未接地的文本漂移。

Result: 实验表明该方法有效校准推理，使基础模型能够利用推理能力而不牺牲基于ID的准确性。

Conclusion: 通过推理时子空间对齐可以解决CoT推理在语义ID推荐模型中的性能下降问题，实现推理能力与ID基础准确性的平衡。

Abstract: Integrating Chain-of-Thought (CoT) reasoning into Semantic ID-based recommendation foundation models (such as OpenOneRec) often paradoxically degrades recommendation performance. We identify the root cause as textual inertia from the General Subspace, where verbose reasoning dominates inference and causes the model to neglect critical Semantic ID. To address this, we propose a training-free Inference-Time Subspace Alignment framework. By compressing reasoning chains and applying bias-subtracted contrastive decoding, our approach mitigates ungrounded textual drift. Experiments show this effectively calibrates inference, allowing foundation models to leverage reasoning without sacrificing ID-grounded accuracy.

</details>
