{"id": "2510.21711", "categories": ["cs.IR", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.21711", "abs": "https://arxiv.org/abs/2510.21711", "authors": ["Rauf Aliev"], "title": "Improving E-commerce Search with Category-Aligned Retrieval", "comment": null, "summary": "Traditional e-commerce search systems often struggle with the semantic gap\nbetween user queries and product catalogs. In this paper, we propose a\nCategory-Aligned Retrieval System (CARS) that improves search relevance by\nfirst predicting the product category from a user's query and then boosting\nproducts within that category. We introduce a novel method for creating\n\"Trainable Category Prototypes\" from query embeddings. We evaluate this method\nwith two models: a lightweight all-MiniLM-L6-v2 and OpenAI's\ntext-embedding-ada-002. Our offline evaluation shows this method is highly\neffective, with the OpenAI model increasing Top-3 category prediction accuracy\nfrom a zero-shot baseline of 43.8% to 83.2% after training. The end-to-end\nsimulation, however, highlights the limitations of blindly applying category\nboosts in a complex retrieval pipeline: while accuracy is high, naive\nintegration can negatively affect search relevance metrics such as nDCG@10. We\nargue that this is partly due to dataset-specific ambiguities (e.g., polysemous\nqueries in the Amazon ESCI corpus) and partly due to the sensitivity of\nretrieval systems to over-constraining filters. Crucially, these results do not\ndiminish the value of the approach; rather, they emphasize the need for\nconfidence-aware and adaptive integration strategies."}
{"id": "2510.21712", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21712", "abs": "https://arxiv.org/abs/2510.21712", "authors": ["Hao Sun", "Zile Qiao", "Bo Wang", "Guoxin Chen", "Yingyan Hou", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Yan Zhang"], "title": "DecoupleSearch: Decouple Planning and Search via Hierarchical Reward Modeling", "comment": "EMNLP 2025 Main Conference", "summary": "Retrieval-Augmented Generation (RAG) systems have emerged as a pivotal\nmethodology for enhancing Large Language Models (LLMs) through the dynamic\nintegration of external knowledge. To further improve RAG's flexibility,\nAgentic RAG introduces autonomous agents into the workflow. However, Agentic\nRAG faces several challenges: (1) the success of each step depends on both\nhigh-quality planning and accurate search, (2) the lack of supervision for\nintermediate reasoning steps, and (3) the exponentially large candidate space\nfor planning and searching. To address these challenges, we propose\nDecoupleSearch, a novel framework that decouples planning and search processes\nusing dual value models, enabling independent optimization of plan reasoning\nand search grounding. Our approach constructs a reasoning tree, where each node\nrepresents planning and search steps. We leverage Monte Carlo Tree Search to\nassess the quality of each step. During inference, Hierarchical Beam Search\niteratively refines planning and search candidates with dual value models.\nExtensive experiments across policy models of varying parameter sizes,\ndemonstrate the effectiveness of our method."}
{"id": "2510.21713", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21713", "abs": "https://arxiv.org/abs/2510.21713", "authors": ["Yin Sun", "Yiwen Liu", "Junjie Song", "Chenyu Zhang", "Xinyuan Zhang", "Lingjie Liu", "Siqi Chen", "Yuji Cao"], "title": "asLLR: LLM based Leads Ranking in Auto Sales", "comment": null, "summary": "In the area of commercial auto sales system, high-quality lead score\nsequencing determines the priority of a sale's work and is essential for\noptimizing the efficiency of the sales system. Since CRM (Customer Relationship\nManagement) system contains plenty of textual interaction features between\nsales and customers, traditional techniques such as Click Through Rate (CTR)\nprediction struggle with processing the complex information inherent in natural\nlanguage features, which limits their effectiveness in sales lead ranking.\nBridging this gap is critical for enhancing business intelligence and\ndecision-making. Recently, the emergence of large language models (LLMs) has\nopened new avenues for improving recommendation systems, this study introduces\nasLLR (LLM-based Leads Ranking in Auto Sales), which integrates CTR loss and\nQuestion Answering (QA) loss within a decoder-only large language model\narchitecture. This integration enables the simultaneous modeling of both\ntabular and natural language features. To verify the efficacy of asLLR, we\nconstructed an innovative dataset derived from the customer lead pool of a\nprominent new energy vehicle brand, with 300,000 training samples and 40,000\ntesting samples. Our experimental results demonstrate that asLLR effectively\nmodels intricate patterns in commercial datasets, achieving the AUC of 0.8127,\nsurpassing traditional CTR estimation methods by 0.0231. Moreover, asLLR\nenhances CTR models when used for extracting text features by 0.0058. In\nreal-world sales scenarios, after rigorous online A/B testing, asLLR increased\nthe sales volume by about 9.5% compared to the traditional method, providing a\nvaluable tool for business intelligence and operational decision-making."}
{"id": "2510.21714", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21714", "abs": "https://arxiv.org/abs/2510.21714", "authors": ["Xian Hu", "Ming Yue", "Zhixiang Feng", "Junwei Pan", "Junjie Zhai", "Ximei Wang", "Xinrui Miao", "Qian Li", "Xun Liu", "Shangyu Zhang", "Letian Wang", "Hua Lu", "Zijian Zeng", "Chen Cai", "Wei Wang", "Fei Xiong", "Pengfei Xiong", "Jintao Zhang", "Zhiyuan Wu", "Chunhui Zhang", "Anan Liu", "Jiulong You", "Chao Deng", "Yuekui Yang", "Shudong Huang", "Dapeng Liu", "Haijie Gu"], "title": "Practice on Long Behavior Sequence Modeling in Tencent Advertising", "comment": null, "summary": "Long-sequence modeling has become an indispensable frontier in recommendation\nsystems for capturing users' long-term preferences. However, user behaviors\nwithin advertising domains are inherently sparse, posing a significant barrier\nto constructing long behavioral sequences using data from a single advertising\ndomain alone. This motivates us to collect users' behaviors not only across\ndiverse advertising scenarios, but also beyond the boundaries of the\nadvertising domain into content domains-thereby constructing unified commercial\nbehavior trajectories. This cross-domain or cross-scenario integration gives\nrise to the following challenges: (1) feature taxonomy gaps between distinct\nscenarios and domains, (2) inter-field interference arising from irrelevant\nfeature field pairs, and (3) target-wise interference in temporal and semantic\npatterns when optimizing for different advertising targets. To address these\nchallenges, we propose several practical approaches within the two-stage\nframework for long-sequence modeling. In the first (search) stage, we design a\nhierarchical hard search method for handling complex feature taxonomy\nhierarchies, alongside a decoupled embedding-based soft search to alleviate\nconflicts between attention mechanisms and feature representation. In the\nsecond (sequence modeling) stage, we introduce: (a) Decoupled Side Information\nTemporal Interest Networks (TIN) to mitigate inter-field conflicts; (b)\nTarget-Decoupled Positional Encoding and Target-Decoupled SASRec to address\ntarget-wise interference; and (c) Stacked TIN to model high-order behavioral\ncorrelations. Deployed in production on Tencent's large-scale advertising\nplatforms, our innovations delivered significant performance gains: an overall\n4.22% GMV lift in WeChat Channels and an overall 1.96% GMV increase in WeChat\nMoments."}
{"id": "2510.21724", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21724", "abs": "https://arxiv.org/abs/2510.21724", "authors": ["Apoorva Chavali", "Reeve Menezes"], "title": "Words to Waves: Emotion-Adaptive Music Recommendation System", "comment": null, "summary": "Current recommendation systems often tend to overlook emotional context and\nrely on historical listening patterns or static mood tags. This paper\nintroduces a novel music recommendation framework employing a variant of Wide\nand Deep Learning architecture that takes in real-time emotional states\ninferred directly from natural language as inputs and recommends songs that\nclosely portray the mood. The system captures emotional contexts from\nuser-provided textual descriptions by using transformer-based embeddings, which\nwere finetuned to predict the emotional dimensions of valence-arousal. The deep\ncomponent of the architecture utilizes these embeddings to generalize unseen\nemotional patterns, while the wide component effectively memorizes user-emotion\nand emotion-genre associations through cross-product features. Experimental\nresults show that personalized music selections positively influence the user's\nemotions and lead to a significant improvement in emotional relevance."}
{"id": "2510.21726", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21726", "abs": "https://arxiv.org/abs/2510.21726", "authors": ["Weichen Wang", "Chengchun Shi"], "title": "From Authors to Reviewers: Leveraging Rankings to Improve Peer Review", "comment": null, "summary": "This paper is a discussion of the 2025 JASA discussion paper by Su et al.\n(2025). We would like to congratulate the authors on conducting a comprehensive\nand insightful empirical investigation of the 2023 ICML ranking data. The\nreview quality of machine learning (ML) conferences has become a big concern in\nrecent years, due to the rapidly growing number of submitted manuscripts. In\nthis discussion, we propose an approach alternative to Su et al. (2025) that\nleverages ranking information from reviewers rather than authors. We simulate\nreview data that closely mimics the 2023 ICML conference submissions. Our\nresults show that (i) incorporating ranking information from reviewers can\nsignificantly improve the evaluation of each paper's quality, often\noutperforming the use of ranking information from authors alone; and (ii)\ncombining ranking information from both reviewers and authors yields the most\naccurate evaluation of submitted papers in most scenarios."}
{"id": "2510.21727", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21727", "abs": "https://arxiv.org/abs/2510.21727", "authors": ["Yichi Zhang", "Jun Bai", "Zhixin Cai", "Shuhan Qin", "Zhuofan Chen", "Jinghua Guan", "Wenge Rong"], "title": "Your Dense Retriever is Secretly an Expeditious Reasoner", "comment": "16 pages, 11 figures", "summary": "Dense retrievers enhance retrieval by encoding queries and documents into\ncontinuous vectors, but they often struggle with reasoning-intensive queries.\nAlthough Large Language Models (LLMs) can reformulate queries to capture\ncomplex reasoning, applying them universally incurs significant computational\ncost. In this work, we propose Adaptive Query Reasoning (AdaQR), a hybrid query\nrewriting framework. Within this framework, a Reasoner Router dynamically\ndirects each query to either fast dense reasoning or deep LLM reasoning. The\ndense reasoning is achieved by the Dense Reasoner, which performs LLM-style\nreasoning directly in the embedding space, enabling a controllable trade-off\nbetween efficiency and accuracy. Experiments on large-scale retrieval\nbenchmarks BRIGHT show that AdaQR reduces reasoning cost by 28% while\npreserving-or even improving-retrieval performance by 7%."}
{"id": "2510.21728", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21728", "abs": "https://arxiv.org/abs/2510.21728", "authors": ["Mahsa Goodarzi", "M. Abdullah Canbaz"], "title": "Modeling Bias Evolution in Fashion Recommender Systems: A System Dynamics Approach", "comment": "Published in the proceedings of the 43rd International System\n  Dynamics Conference (ISDC 25):\n  https://proceedings.systemdynamics.org/2025/papers/P1254.pdf", "summary": "Bias in recommender systems not only distorts user experience but also\nperpetuates and amplifies existing societal stereotypes, particularly in\nsectors like fashion e-commerce. This study employs a dynamic modeling approach\nto scrutinize the mechanisms of bias activation and reinforcement within\nFashion Recommender Systems (FRS). By leveraging system dynamics modeling and\nexperimental simulations, we dissect the temporal evolution of bias and its\nmultifaceted impacts on system performance. Our analysis reveals that inductive\nbiases exert a more substantial influence on system outcomes than user biases,\nsuggesting critical areas for intervention. We demonstrate that while current\ndebiasing strategies, including data rebalancing and algorithmic\nregularization, are effective to an extent, they require further enhancement to\ncomprehensively mitigate biases. This research underscores the necessity for\nadvancing these strategies and extending system boundaries to incorporate\nbroader contextual factors such as user demographics and item diversity, aiming\nto foster inclusivity and fairness in FRS. The findings advocate for a\nproactive approach in recommender system design to counteract bias propagation\nand ensure equitable user experiences."}
{"id": "2510.21729", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21729", "abs": "https://arxiv.org/abs/2510.21729", "authors": ["Nathan Paull"], "title": "CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora", "comment": null, "summary": "Dense embedding models have become critical for modern information retrieval,\nparticularly in RAG pipelines, but their performance often degrades when\napplied to specialized corpora outside their pre-training distribution. To\naddress thi we introduce \\textbf{CustomIR}, a framework for unsupervised\nadaptation of pre-trained language embedding models to domain-specific corpora\nusing synthetically generated query-document pairs. CustomIR leverages large\nlanguage models (LLMs) to create diverse queries grounded in a known target\ncorpus, paired with LLM-verified hard negatives, eliminating the need for\ncostly human annotation. Experiments on enterprise email and messaging datasets\nshow that CustomIR consistently improves retrieval effectiveness with small\nmodels gaining up to 2.3 points in Recall@10. This performance increase allows\nthese small models to rival the performance of much larger alternatives,\nallowing for cheaper RAG deployments. These results highlight that targeted\nsynthetic fine-tuning offers a scalable and cost-efficient strategy for\nincreasing domain-specific performance."}
{"id": "2510.21730", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21730", "abs": "https://arxiv.org/abs/2510.21730", "authors": ["Hao Wang"], "title": "TriMat: Context-aware Recommendation by Tri-Matrix Factorization", "comment": null, "summary": "Search engine is the symbolic technology of Web 2.0, and many people used to\nbelieve recommender systems is the new frontier of Web 3.0. In the past 10\nyears, with the advent of TikTok and similar apps, recommender systems has\nmaterialized the vision of the machine learning pioneers. However, many\nresearch topics of the field remain unfixed until today. One such topic is CARS\n(Context-aware Recommender Systems) , which is largely a theoretical topic\nwithout much advance in real-world applications. In this paper, we utilize\ntri-matrix factorization technique to incorporate contextual information into\nour matrix factorization framework, and prove that our technique is effective\nin improving both the accuracy and fairness metrics in our experiments."}
{"id": "2510.21733", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21733", "abs": "https://arxiv.org/abs/2510.21733", "authors": ["Jia-Huei Ju", "Eugene Yang", "Trevor Adriaanse", "Andrew Yates"], "title": "Augmenting Researchy Questions with Sub-question Judgments", "comment": "3 pages", "summary": "The Researchy Questions dataset provides about 100k question queries with\ncomplex information needs that require retrieving information about several\naspects of a topic. Each query in ResearchyQuestions is associated with\nsub-questions that were produced by prompting GPT-4. While ResearchyQuestions\ncontains labels indicating what documents were clicked after issuing the query,\nthere are no associations in the dataset between sub-questions and relevant\ndocuments. In this work, we augment the Researchy Questions dataset with\nLLM-judged labels for each sub-question using a Llama3.3 70B model. We intend\nthese sub-question labels to serve as a resource for training retrieval models\nthat better support complex information needs."}
{"id": "2510.21737", "categories": ["cs.IR", "68T30, 68T50", "I.2.7; I.2.4; H.3.3"], "pdf": "https://arxiv.org/pdf/2510.21737", "abs": "https://arxiv.org/abs/2510.21737", "authors": ["Liangliang Zhang", "Nandana Mihindukulasooriya", "Niharika S. D'Souza", "Sola Shirai", "Sarthak Dash", "Yao Ma", "Horst Samulowitz"], "title": "From Factoid Questions to Data Product Requests: Benchmarking Data Product Discovery over Tables and Text", "comment": "9 pages, 1 figure, 2 tables", "summary": "Data products are reusable, self-contained assets designed for specific\nbusiness use cases. Automating their discovery and generation is of great\nindustry interest, as it enables discovery in large data lakes and supports\nanalytical Data Product Requests (DPRs). Currently, there is no benchmark\nestablished specifically for data product discovery. Existing datasets focus on\nanswering single factoid questions over individual tables rather than\ncollecting multiple data assets for broader, coherent products. To address this\ngap, we introduce DPBench, the first user-request-driven data product benchmark\nover hybrid table-text corpora. Our framework systematically repurposes\nexisting table-text QA datasets by clustering related tables and passages into\ncoherent data products, generating professional-level analytical requests that\nspan both data sources, and validating benchmark quality through multi-LLM\nevaluation. DPBench preserves full provenance while producing actionable,\nanalyst-like data product requests. Baseline experiments with hybrid retrieval\nmethods establish the feasibility of DPR evaluation, reveal current\nlimitations, and point to new opportunities for automatic data product\ndiscovery research.\n  Code and datasets are available at:\nhttps://anonymous.4open.science/r/data-product-benchmark-BBA7/"}
{"id": "2510.21805", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21805", "abs": "https://arxiv.org/abs/2510.21805", "authors": ["Zhao Liu", "Yichen Zhu", "Yiqing Yang", "Guoping Tang", "Rui Huang", "Qiang Luo", "Xiao Lv", "Ruiming Tang", "Kun Gai", "Guorui Zhou"], "title": "DiffGRM: Diffusion-based Generative Recommendation Model", "comment": "13 pages, 5 figures", "summary": "Generative recommendation (GR) is an emerging paradigm that represents each\nitem via a tokenizer as an n-digit semantic ID (SID) and predicts the next item\nby autoregressively generating its SID conditioned on the user's history.\nHowever, two structural properties of SIDs make ARMs ill-suited. First,\nintra-item consistency: the n digits jointly specify one item, yet the\nleft-to-right causality trains each digit only under its prefix and blocks\nbidirectional cross-digit evidence, collapsing supervision to a single causal\npath. Second, inter-digit heterogeneity: digits differ in semantic granularity\nand predictability, while the uniform next-token objective assigns equal weight\nto all digits, overtraining easy digits and undertraining hard digits. To\naddress these two issues, we propose DiffGRM, a diffusion-based GR model that\nreplaces the autoregressive decoder with a masked discrete diffusion model\n(MDM), thereby enabling bidirectional context and any-order parallel generation\nof SID digits for recommendation. Specifically, we tailor DiffGRM in three\naspects: (1) tokenization with Parallel Semantic Encoding (PSE) to decouple\ndigits and balance per-digit information; (2) training with On-policy Coherent\nNoising (OCN) that prioritizes uncertain digits via coherent masking to\nconcentrate supervision on high-value signals; and (3) inference with\nConfidence-guided Parallel Denoising (CPD) that fills higher-confidence digits\nfirst and generates diverse Top-K candidates. Experiments show consistent gains\nover strong generative and discriminative recommendation baselines on multiple\ndatasets, improving NDCG@10 by 6.9%-15.5%. Code is available at\nhttps://github.com/liuzhao09/DiffGRM."}
{"id": "2510.21812", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21812", "abs": "https://arxiv.org/abs/2510.21812", "authors": ["Chanyoung Chung", "Kyeongryul Lee", "Sunbin Park", "Joyce Jiyoung Whang"], "title": "Unifying Inductive, Cross-Domain, and Multimodal Learning for Robust and Generalizable Recommendation", "comment": "7 pages, 3 figures, and 4 tables. International Workshop on\n  Multimodal Generative Search and Recommendation (MMGenSR) at The 34th ACM\n  International Conference on Information and Knowledge Management (CIKM 2025)", "summary": "Recommender systems have long been built upon the modeling of interactions\nbetween users and items, while recent studies have sought to broaden this\nparadigm by generalizing to new users and items, incorporating diverse\ninformation sources, and transferring knowledge across domains. Nevertheless,\nthese efforts have largely focused on individual aspects, hindering their\nability to tackle the complex recommendation scenarios that arise in daily\nconsumptions across diverse domains. In this paper, we present MICRec, a\nunified framework that fuses inductive modeling, multimodal guidance, and\ncross-domain transfer to capture user contexts and latent preferences in\nheterogeneous and incomplete real-world data. Moving beyond the inductive\nbackbone of INMO, our model refines expressive representations through\nmodality-based aggregation and alleviates data sparsity by leveraging\noverlapping users as anchors across domains, thereby enabling robust and\ngeneralizable recommendation. Experiments show that MICRec outperforms 12\nbaselines, with notable gains in domains with limited training data."}
{"id": "2510.21831", "categories": ["cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.21831", "abs": "https://arxiv.org/abs/2510.21831", "authors": ["Alok Dutta", "Nilanjana Roy", "Rhythm Sen", "Sougata Dutta", "Prabhat Das"], "title": "Development of an Automated Web Application for Efficient Web Scraping: Design and Implementation", "comment": null, "summary": "This paper presents the design and implementation of a user-friendly,\nautomated web application that simplifies and optimizes the web scraping\nprocess for non-technical users. The application breaks down the complex task\nof web scraping into three main stages: fetching, extraction, and execution. In\nthe fetching stage, the application accesses target websites using the HTTP\nprotocol, leveraging the requests library to retrieve HTML content. The\nextraction stage utilizes powerful parsing libraries like BeautifulSoup and\nregular expressions to extract relevant data from the HTML. Finally, the\nexecution stage structures the data into accessible formats, such as CSV,\nensuring the scraped content is organized for easy use. To provide personalized\nand secure experiences, the application includes user registration and login\nfunctionalities, supported by MongoDB, which stores user data and scraping\nhistory. Deployed using the Flask framework, the tool offers a scalable, robust\nenvironment for web scraping. Users can easily input website URLs, define data\nextraction parameters, and download the data in a simplified format, without\nneeding technical expertise. This automated tool not only enhances the\nefficiency of web scraping but also democratizes access to data extraction by\nempowering users of all technical levels to gather and manage data tailored to\ntheir needs. The methodology detailed in this paper represents a significant\nadvancement in making web scraping tools accessible, efficient, and easy to use\nfor a broader audience."}
{"id": "2510.21962", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21962", "abs": "https://arxiv.org/abs/2510.21962", "authors": ["Yunsen Lei", "Kexin Bai", "Quan Li", "H. Howie Huang"], "title": "Temporal Graph Theoretic Analysis of Geopolitical Dynamics in the U.S. Entity List", "comment": "13 pages, 9 figures. Under review", "summary": "Export controls have become one of America's most prominent tools of economic\nstatecraft. They aim to block rival countries' access to sensitive\ntechnologies, safeguard U.S. supply chains, protect national security, and\nshape geopolitical competition. Among various instruments, the U.S. Entity List\nhas emerged as the most salient, yet its dynamics remain underexplored. This\npaper introduces a novel temporal graph framework that transforms the Entity\nList documents from a static registry of foreign entities of concern into a\ndynamic representation of geopolitical strategy. We construct the first\nevent-based dataset of U.S. government foreign entity designations and model\nthem as a temporal bipartite graph. Building on this representation, we develop\na multi-level analytical approach that reveals shifting roles, enforcement\nstrategy, and broader sanction ecosystems. Applied to 25 years of data, the\nframework uncovers dynamic patterns of escalation, persistence, and\ncoordination that static views cannot capture. More broadly, our study\ndemonstrates how temporal graph analysis offers systematic computational\ninsights into the geopolitical dynamics of export controls."}
{"id": "2510.22023", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.22023", "abs": "https://arxiv.org/abs/2510.22023", "authors": ["Yifan Liu", "Qianfeng Wen", "Jiazhou Liang", "Mark Zhao", "Justin Cui", "Anton Korikov", "Armin Torogh", "Junyoung Kim", "Scott Sanner"], "title": "Multimodal Item Scoring for Natural Language Recommendation via Gaussian Process Regression with LLM Relevance Judgments", "comment": "16 pages,20 figures", "summary": "Natural Language Recommendation (NLRec) generates item suggestions based on\nthe relevance between user-issued NL requests and NL item description passages.\nExisting NLRec approaches often use Dense Retrieval (DR) to compute item\nrelevance scores from aggregation of inner products between user request\nembeddings and relevant passage embeddings. However, DR views the request as\nthe sole relevance label, thus leading to a unimodal scoring function centered\non the query embedding that is often a weak proxy for query relevance. To\nbetter capture the potential multimodal distribution of the relevance scoring\nfunction that may arise from complex NLRec data, we propose GPR-LLM that uses\nGaussian Process Regression (GPR) with LLM relevance judgments for a subset of\ncandidate passages. Experiments on four NLRec datasets and two LLM backbones\ndemonstrate that GPR-LLM with an RBF kernel, capable of modeling multimodal\nrelevance scoring functions, consistently outperforms simpler unimodal kernels\n(dot product, cosine similarity), as well as baseline methods including DR,\ncross-encoder, and pointwise LLM-based relevance scoring by up to 65%. Overall,\nGPR-LLM provides an efficient and effective approach to NLRec within a minimal\nLLM labeling budget."}
{"id": "2510.22049", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22049", "abs": "https://arxiv.org/abs/2510.22049", "authors": ["Zhimin Chen", "Chenyu Zhao", "Ka Chun Mo", "Yunjiang Jiang", "Jane H. Lee", "Shouwei Chen", "Khushhall Chandra Mahajan", "Ning Jiang", "Kai Ren", "Jinhui Li", "Wen-Yun Yang"], "title": "Massive Memorization with Hundreds of Trillions of Parameters for Sequential Transducer Generative Recommenders", "comment": null, "summary": "Modern large-scale recommendation systems rely heavily on user interaction\nhistory sequences to enhance the model performance. The advent of large\nlanguage models and sequential modeling techniques, particularly\ntransformer-like architectures, has led to significant advancements recently\n(e.g., HSTU, SIM, and TWIN models). While scaling to ultra-long user histories\n(10k to 100k items) generally improves model performance, it also creates\nsignificant challenges on latency, queries per second (QPS) and GPU cost in\nindustry-scale recommendation systems. Existing models do not adequately\naddress these industrial scalability issues. In this paper, we propose a novel\ntwo-stage modeling framework, namely VIrtual Sequential Target Attention\n(VISTA), which decomposes traditional target attention from a candidate item to\nuser history items into two distinct stages: (1) user history summarization\ninto a few hundred tokens; followed by (2) candidate item attention to those\ntokens. These summarization token embeddings are then cached in storage system\nand then utilized as sequence features for downstream model training and\ninference. This novel design for scalability enables VISTA to scale to lifelong\nuser histories (up to one million items) while keeping downstream training and\ninference costs fixed, which is essential in industry. Our approach achieves\nsignificant improvements in offline and online metrics and has been\nsuccessfully deployed on an industry leading recommendation platform serving\nbillions of users."}
{"id": "2510.22055", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22055", "abs": "https://arxiv.org/abs/2510.22055", "authors": ["V Venktesh", "Deepali Prabhu", "Avishek Anand"], "title": "A Benchmark for Open-Domain Numerical Fact-Checking Enhanced by Claim Decomposition", "comment": "16 pages", "summary": "Fact-checking numerical claims is critical as the presence of numbers provide\nmirage of veracity despite being fake potentially causing catastrophic impacts\non society. The prior works in automatic fact verification do not primarily\nfocus on natural numerical claims. A typical human fact-checker first retrieves\nrelevant evidence addressing the different numerical aspects of the claim and\nthen reasons about them to predict the veracity of the claim. Hence, the search\nprocess of a human fact-checker is a crucial skill that forms the foundation of\nthe verification process. Emulating a real-world setting is essential to aid in\nthe development of automated methods that encompass such skills. However,\nexisting benchmarks employ heuristic claim decomposition approaches augmented\nwith weakly supervised web search to collect evidences for verifying claims.\nThis sometimes results in less relevant evidences and noisy sources with\ntemporal leakage rendering a less realistic retrieval setting for claim\nverification. Hence, we introduce QuanTemp++: a dataset consisting of natural\nnumerical claims, an open domain corpus, with the corresponding relevant\nevidence for each claim. The evidences are collected through a claim\ndecomposition process approximately emulating the approach of human\nfact-checker and veracity labels ensuring there is no temporal leakage. Given\nthis dataset, we also characterize the retrieval performance of key claim\ndecomposition paradigms. Finally, we observe their effect on the outcome of the\nverification pipeline and draw insights. The code for data pipeline along with\nlink to data can be found at https://github.com/VenkteshV/QuanTemp_Plus"}
{"id": "2510.22101", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22101", "abs": "https://arxiv.org/abs/2510.22101", "authors": ["Kayhan Behdin", "Qingquan Song", "Sriram Vasudevan", "Jian Sheng", "Xiaojing Ma", "Z Zhou", "Chuanrui Zhu", "Guoyao Li", "Chanh Nguyen", "Sayan Ghosh", "Hejian Sang", "Ata Fatahi Baarzi", "Sundara Raman Ramachandran", "Xiaoqing Wang", "Qing Lan", "Vinay Y S", "Qi Guo", "Caleb Johnson", "Zhipeng Wang", "Fedor Borisyuk"], "title": "Scaling Up Efficient Small Language Models Serving and Deployment for Semantic Job Search", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive quality when\napplied to predictive tasks such as relevance ranking and semantic search.\nHowever, deployment of such LLMs remains prohibitively expensive for industry\napplications with strict latency and throughput requirements. In this work, we\npresent lessons and efficiency insights from developing a purely text-based\ndecoder-only Small Language Model (SLM) for a semantic search application at\nLinkedIn. Particularly, we discuss model compression techniques such as pruning\nthat allow us to reduce the model size by up to $40\\%$ while maintaining the\naccuracy. Additionally, we present context compression techniques that allow us\nto reduce the input context length by up to $10$x with minimal loss of\naccuracy. Finally, we present practical lessons from optimizing the serving\ninfrastructure for deploying such a system on GPUs at scale, serving millions\nof requests per second. Taken together, this allows us to increase our system's\nthroughput by $10$x in a real-world deployment, while meeting our quality bar."}
{"id": "2510.22215", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.22215", "abs": "https://arxiv.org/abs/2510.22215", "authors": ["Juyeon Kim", "Geon Lee", "Dongwon Choi", "Taeuk Kim", "Kijung Shin"], "title": "Hybrid-Vector Retrieval for Visually Rich Documents: Combining Single-Vector Efficiency and Multi-Vector Accuracy", "comment": null, "summary": "Retrieval over visually rich documents is essential for tasks such as legal\ndiscovery, scientific search, and enterprise knowledge management. Existing\napproaches fall into two paradigms: single-vector retrieval, which is efficient\nbut coarse, and multi-vector retrieval, which is accurate but computationally\nexpensive. To address this trade-off, we propose HEAVEN, a two-stage\nhybrid-vector framework. In the first stage, HEAVEN efficiently retrieves\ncandidate pages using a single-vector method over Visually-Summarized Pages\n(VS-Pages), which assemble representative visual layouts from multiple pages.\nIn the second stage, it reranks candidates with a multi-vector method while\nfiltering query tokens by linguistic importance to reduce redundant\ncomputations. To evaluate retrieval systems under realistic conditions, we also\nintroduce ViMDOC, the first benchmark for visually rich, multi-document, and\nlong-document retrieval. Across four benchmarks, HEAVEN attains 99.87% of the\nRecall@1 performance of multi-vector models on average while reducing per-query\ncomputation by 99.82%, achieving efficiency and accuracy. Our code and datasets\nare available at: https://github.com/juyeonnn/HEAVEN"}
{"id": "2510.22242", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22242", "abs": "https://arxiv.org/abs/2510.22242", "authors": ["Yutao Wu", "Xiao Liu", "Yunhao Feng", "Jiale Ding", "Xingjun Ma"], "title": "PaperAsk: A Benchmark for Reliability Evaluation of LLMs in Paper Search and Reading", "comment": null, "summary": "Large Language Models (LLMs) increasingly serve as research assistants, yet\ntheir reliability in scholarly tasks remains under-evaluated. In this work, we\nintroduce PaperAsk, a benchmark that systematically evaluates LLMs across four\nkey research tasks: citation retrieval, content extraction, paper discovery,\nand claim verification. We evaluate GPT-4o, GPT-5, and Gemini-2.5-Flash under\nrealistic usage conditions-via web interfaces where search operations are\nopaque to the user. Through controlled experiments, we find consistent\nreliability failures: citation retrieval fails in 48-98% of multi-reference\nqueries, section-specific content extraction fails in 72-91% of cases, and\ntopical paper discovery yields F1 scores below 0.32, missing over 60% of\nrelevant literature. Further human analysis attributes these failures to the\nuncontrolled expansion of retrieved context and the tendency of LLMs to\nprioritize semantically relevant text over task instructions. Across basic\ntasks, the LLMs display distinct failure behaviors: ChatGPT often withholds\nresponses rather than risk errors, whereas Gemini produces fluent but\nfabricated answers. To address these issues, we develop lightweight reliability\nclassifiers trained on PaperAsk data to identify unreliable outputs. PaperAsk\nprovides a reproducible and diagnostic framework for advancing the reliability\nevaluation of LLM-based scholarly assistance systems."}
{"id": "2510.22670", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.22670", "abs": "https://arxiv.org/abs/2510.22670", "authors": ["Xuan Lu", "Haohang Huang", "Rui Meng", "Yaohui Jin", "Wenjun Zeng", "Xiaoyu Shen"], "title": "Tools are under-documented: Simple Document Expansion Boosts Tool Retrieval", "comment": null, "summary": "Large Language Models (LLMs) have recently demonstrated strong capabilities\nin tool use, yet progress in tool retrieval remains hindered by incomplete and\nheterogeneous tool documentation. To address this challenge, we introduce\nTool-DE, a new benchmark and framework that systematically enriches tool\ndocumentation with structured fields to enable more effective tool retrieval,\ntogether with two dedicated models, Tool-Embed and Tool-Rank. We design a\nscalable document expansion pipeline that leverages both open- and\nclosed-source LLMs to generate, validate, and refine enriched tool profiles at\nlow cost, producing large-scale corpora with 50k instances for embedding-based\nretrievers and 200k for rerankers. On top of this data, we develop two models\nspecifically tailored for tool retrieval: Tool-Embed, a dense retriever, and\nTool-Rank, an LLM-based reranker. Extensive experiments on ToolRet and Tool-DE\ndemonstrate that document expansion substantially improves retrieval\nperformance, with Tool-Embed and Tool-Rank achieving new state-of-the-art\nresults on both benchmarks. We further analyze the contribution of individual\nfields to retrieval effectiveness, as well as the broader impact of document\nexpansion on both training and evaluation. Overall, our findings highlight both\nthe promise and limitations of LLM-driven document expansion, positioning\nTool-DE, along with the proposed Tool-Embed and Tool-Rank, as a foundation for\nfuture research in tool retrieval."}
{"id": "2510.22681", "categories": ["cs.IR", "H.3.3; H.3.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.22681", "abs": "https://arxiv.org/abs/2510.22681", "authors": ["Rikiya Takehi", "Fernando Diaz", "Tetsuya Sakai"], "title": "Diversification as Risk Minimization", "comment": "Preprint, accepted at WSDM 2026 (Full Paper). 16 pages, 8 figures", "summary": "Users tend to remember failures of a search session more than its many\nsuccesses. This observation has led to work on search robustness, where systems\nare penalized if they perform very poorly on some queries. However, this\nprinciple of robustness has been overlooked within a single query. An ambiguous\nor underspecified query (e.g., ``jaguar'') can have several user intents, where\npopular intents often dominate the ranking, leaving users with minority intents\nunsatisfied. Although the diversification literature has long recognized this\nissue, existing metrics only model the average relevance across intents and\nprovide no robustness guarantees. More surprisingly, we show theoretically and\nempirically that many well-known diversification algorithms are no more robust\nthan a naive, non-diversified algorithm. To address this critical gap, we\npropose to frame diversification as a risk-minimization problem. We introduce\nVRisk, which measures the expected risk faced by the least-served fraction of\nintents in a query. Optimizing VRisk produces a robust ranking, reducing the\nlikelihood of poor user experiences. We then propose VRisker, a fast greedy\nre-ranker with provable approximation guarantees. Finally, experiments on NTCIR\nINTENT-2, TREC Web 2012, and MovieLens show the vulnerability of existing\nmethods. VRisker reduces worst-case intent failures by up to 33% with a minimal\n2% drop in average performance."}
{"id": "2510.22739", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22739", "abs": "https://arxiv.org/abs/2510.22739", "authors": ["Yiwen Tang", "Qiuyu Zhao", "Zenghui Sun", "Jinsong Lan", "Xiaoyong Zhu", "Bo Zheng", "Kaifu Zhang"], "title": "REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for E-commerce Visual Search System Optimization", "comment": null, "summary": "In Taobao e-commerce visual search, user behavior analysis reveals a large\nproportion of no-click requests, suggesting diverse and implicit user intents.\nThese intents are expressed in various forms and are difficult to mine and\ndiscover, thereby leading to the limited adaptability and lag in platform\nstrategies. This greatly restricts users' ability to express diverse intents\nand hinders the scalability of the visual search system. This mismatch between\nuser implicit intent expression and system response defines the User-SearchSys\nIntent Discrepancy. To alleviate the issue, we propose a novel framework\nREVISION. This framework integrates offline reasoning mining with online\ndecision-making and execution, enabling adaptive strategies to solve implicit\nuser demands. In the offline stage, we construct a periodic pipeline to mine\ndiscrepancies from historical no-click requests. Leveraging large models, we\nanalyze implicit intent factors and infer optimal suggestions by jointly\nreasoning over query and product metadata. These inferred suggestions serve as\nactionable insights for refining platform strategies. In the online stage,\nREVISION-R1-3B, trained on the curated offline data, performs holistic analysis\nover query images and associated historical products to generate optimization\nplans and adaptively schedule strategies across the search pipeline. Our\nframework offers a streamlined paradigm for integrating large models with\ntraditional search systems, enabling end-to-end intelligent optimization across\ninformation aggregation and user interaction. Experimental results demonstrate\nthat our approach improves the efficiency of implicit intent mining from\nlarge-scale search logs and significantly reduces the no-click rate."}
{"id": "2510.22865", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.22865", "abs": "https://arxiv.org/abs/2510.22865", "authors": ["James Meese", "Kyle Herbertson"], "title": "Civic Ground Truth in News Recommenders: A Method for Public Value Scoring", "comment": "Presented at NORMalize 2025: The Third Workshop on the Normative\n  Design and Evaluation of Recommender Systems, co-located with the ACM\n  Conference on Recommender Systems 2025 (RecSys 2025), Prague", "summary": "Research in news recommendation systems (NRS) continues to explore the best\nways to integrate normative goals such as editorial objectives and public\nservice values into existing systems. Prior efforts have incorporated expert\ninput or audience feedback to quantify these values, laying the groundwork for\nmore civic-minded recommender systems. This paper contributes to that\ntrajectory, introducing a method for embedding civic values into NRS through\nlarge-scale, structured audience evaluations. The proposed civic ground truth\napproach aims to generate value-based labels through a nationally\nrepresentative survey that are generalisable across a wider news corpus, using\nautomated metadata enrichment."}
{"id": "2510.22888", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.22888", "abs": "https://arxiv.org/abs/2510.22888", "authors": ["Shihao Cai", "Chongming Gao", "Haoyan Liu", "Wentao Shi", "Jianshan Sun", "Ruiming Tang", "Fuli Feng"], "title": "MGFRec: Towards Reinforced Reasoning Recommendation with Multiple Groundings and Feedback", "comment": null, "summary": "The powerful reasoning and generative capabilities of large language models\n(LLMs) have inspired researchers to apply them to reasoning-based\nrecommendation tasks, which require in-depth reasoning about user interests and\nthe generation of recommended items. However, previous reasoning-based\nrecommendation methods have typically performed inference within the language\nspace alone, without incorporating the actual item space. This has led to\nover-interpreting user interests and deviating from real items. Towards this\nresearch gap, we propose performing multiple rounds of grounding during\ninference to help the LLM better understand the actual item space, which could\nensure that its reasoning remains aligned with real items. Furthermore, we\nintroduce a user agent that provides feedback during each grounding step,\nenabling the LLM to better recognize and adapt to user interests. Comprehensive\nexperiments conducted on three Amazon review datasets demonstrate the\neffectiveness of incorporating multiple groundings and feedback. These findings\nunderscore the critical importance of reasoning within the actual item space,\nrather than being confined to the language space, for recommendation tasks."}
{"id": "2510.23018", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.23018", "abs": "https://arxiv.org/abs/2510.23018", "authors": ["JaeEun Lim", "Soomin Kim", "Jaeyong Seo", "Iori Ono", "Qimu Ran", "Jae-woong Lee"], "title": "Improving Product Search Relevance with EAR-MP: A Solution for the CIKM 2025 AnalytiCup", "comment": null, "summary": "Multilingual e-commerce search is challenging due to linguistic diversity and\nthe noise inherent in user-generated queries. This paper documents the solution\nemployed by our team (EAR-MP) for the CIKM 2025 AnalytiCup, which addresses two\ncore tasks: Query-Category (QC) relevance and Query-Item (QI) relevance. Our\napproach first normalizes the multilingual dataset by translating all text into\nEnglish, then mitigates noise through extensive data cleaning and\nnormalization. For model training, we build on DeBERTa-v3-large and improve\nperformance with label smoothing, self-distillation, and dropout. In addition,\nwe introduce task-specific upgrades, including hierarchical token injection for\nQC and a hybrid scoring mechanism for QI. Under constrained compute, our method\nachieves competitive results, attaining an F1 score of 0.8796 on QC and 0.8744\non QI. These findings underscore the importance of systematic data\npreprocessing and tailored training strategies for building robust,\nresource-efficient multilingual relevance systems."}
{"id": "2510.23066", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.23066", "abs": "https://arxiv.org/abs/2510.23066", "authors": ["Yichao Jin", "Yushuo Wang", "Qishuai Zhong", "Kent Chiu Jin-Chun", "Kenneth Zhu Ke", "Donald MacDonald"], "title": "Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models", "comment": null, "summary": "Financial documents are essential sources of information for regulators,\nauditors, and financial institutions, particularly for assessing the wealth and\ncompliance of Small and Medium-sized Businesses. However, SMB documents are\noften difficult to parse. They are rarely born digital and instead are\ndistributed as scanned images that are none machine readable. The scans\nthemselves are low in resolution, affected by skew or rotation, and often\ncontain noisy backgrounds. These documents also tend to be heterogeneous,\nmixing narratives, tables, figures, and multilingual content within the same\nreport. Such characteristics pose major challenges for automated information\nextraction, especially when relying on end to end large Vision Language Models,\nwhich are computationally expensive, sensitive to noise, and slow when applied\nto files with hundreds of pages.\n  We propose a multistage pipeline that leverages traditional image processing\nmodels and OCR extraction, together with compact VLMs for structured field\nextraction of large-scale financial documents. Our approach begins with image\npre-processing, including segmentation, orientation detection, and size\nnormalization. Multilingual OCR is then applied to recover page-level text.\nUpon analyzing the text information, pages are retrieved for coherent sections.\nFinally, compact VLMs are operated within these narrowed-down scopes to extract\nstructured financial indicators.\n  Our approach is evaluated using an internal corpus of multi-lingual, scanned\nfinancial documents. The results demonstrate that compact VLMs, together with a\nmultistage pipeline, achieves 8.8 times higher field level accuracy relative to\ndirectly feeding the whole document into large VLMs, only at 0.7 percent of the\nGPU cost and 92.6 percent less end-to-end service latency."}
{"id": "2510.23077", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23077", "abs": "https://arxiv.org/abs/2510.23077", "authors": ["Xiaoyu Kong", "Junguang Jiang", "Bin Liu", "Ziru Xu", "Han Zhu", "Jian Xu", "Bo Zheng", "Jiancan Wu", "Xiang Wang"], "title": "Think before Recommendation: Autonomous Reasoning-enhanced Recommender", "comment": "NeurIPS 2025 poster", "summary": "The core task of recommender systems is to learn user preferences from\nhistorical user-item interactions. With the rapid development of large language\nmodels (LLMs), recent research has explored leveraging the reasoning\ncapabilities of LLMs to enhance rating prediction tasks. However, existing\ndistillation-based methods suffer from limitations such as the teacher model's\ninsufficient recommendation capability, costly and static supervision, and\nsuperficial transfer of reasoning ability. To address these issues, this paper\nproposes RecZero, a reinforcement learning (RL)-based recommendation paradigm\nthat abandons the traditional multi-model and multi-stage distillation\napproach. Instead, RecZero trains a single LLM through pure RL to autonomously\ndevelop reasoning capabilities for rating prediction. RecZero consists of two\nkey components: (1) \"Think-before-Recommendation\" prompt construction, which\nemploys a structured reasoning template to guide the model in step-wise\nanalysis of user interests, item features, and user-item compatibility; and (2)\nrule-based reward modeling, which adopts group relative policy optimization\n(GRPO) to compute rewards for reasoning trajectories and optimize the LLM.\nAdditionally, the paper explores a hybrid paradigm, RecOne, which combines\nsupervised fine-tuning with RL, initializing the model with cold-start\nreasoning samples and further optimizing it with RL. Experimental results\ndemonstrate that RecZero and RecOne significantly outperform existing baseline\nmethods on multiple benchmark datasets, validating the superiority of the RL\nparadigm in achieving autonomous reasoning-enhanced recommender systems."}
