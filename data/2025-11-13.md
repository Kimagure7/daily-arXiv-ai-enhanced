<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Efficient Model-Agnostic Continual Learning for Next POI Recommendation](https://arxiv.org/abs/2511.08941)
*Chenhao Wang,Shanshan Feng,Lisi Chen,Fan Li,Shuo Shang*

Main category: cs.IR

TL;DR: GIRAM是一个用于持续下一个兴趣点推荐的模型无关框架，通过整合上下文感知的持续兴趣和近期兴趣，在动态适应不断变化的用户行为的同时保持高效性。


<details>
  <summary>Details</summary>
Motivation: 现有的下一个兴趣点推荐方法大多依赖静态数据集和固定模型，无法适应随时间变化的用户行为。需要开发能够持续更新、动态适应用户兴趣演变的推荐系统。

Method: 提出GIRAM框架，包含四个组件：兴趣记忆库、上下文感知键编码模块、基于生成键的检索模块、自适应兴趣更新与融合模块。该框架可与现有推荐模型无缝集成。

Result: 在三个真实世界数据集上的实验表明，GIRAM在更新时间和内存消耗方面保持高效率的同时，持续优于最先进的方法。

Conclusion: GIRAM为解决持续下一个POI推荐任务提供了一种高效且有效的解决方案，能够动态适应用户兴趣变化，同时保持较低的计算和内存开销。

Abstract: Next point-of-interest (POI) recommendation improves personalized location-based services by predicting users' next destinations based on their historical check-ins. However, most existing methods rely on static datasets and fixed models, limiting their ability to adapt to changes in user behavior over time. To address this limitation, we explore a novel task termed continual next POI recommendation, where models dynamically adapt to evolving user interests through continual updates. This task is particularly challenging, as it requires capturing shifting user behaviors while retaining previously learned knowledge. Moreover, it is essential to ensure efficiency in update time and memory usage for real-world deployment. To this end, we propose GIRAM (Generative Key-based Interest Retrieval and Adaptive Modeling), an efficient, model-agnostic framework that integrates context-aware sustained interests with recent interests. GIRAM comprises four components: (1) an interest memory to preserve historical preferences; (2) a context-aware key encoding module for unified interest key representation; (3) a generative key-based retrieval module to identify diverse and relevant sustained interests; and (4) an adaptive interest update and fusion module to update the interest memory and balance sustained and recent interests. In particular, GIRAM can be seamlessly integrated with existing next POI recommendation models. Experiments on three real-world datasets demonstrate that GIRAM consistently outperforms state-of-the-art methods while maintaining high efficiency in both update time and memory consumption.

</details>


### [2] [NeuroCLIP: Brain-Inspired Prompt Tuning for EEG-to-Image Multimodal Contrastive Learning](https://arxiv.org/abs/2511.09250)
*Jiyuan Wang,Li Zhang,Haipeng Lin,Qile Liu,Gan Huang,Ziyu Li,Zhen Liang,Xia Wu*

Main category: cs.IR

TL;DR: NeuroCLIP是一个针对EEG-图像对比学习的提示调优框架，通过双流视觉嵌入、视觉提示令牌和神经科学启发的对比损失，在THINGS-EEG2数据集上实现了63.2%的Top-1零样本图像检索准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将CLIP视为静态特征提取器，忽视了其对神经表示的适应性以及EEG-图像对齐中固有的生理-符号鸿沟。

Method: 1. 双流视觉嵌入管道结合动态滤波和令牌级融合生成实例级自适应提示；2. 首次在EEG-图像对齐中引入视觉提示令牌作为全局模态级提示；3. 基于人类视觉编码神经科学原理提出改进的对比损失。

Result: 在THINGS-EEG2数据集上，NeuroCLIP实现了63.2%的Top-1零样本图像检索准确率，比之前最佳方法提升12.3%，在跨被试条件下也表现出强泛化能力（+4.6% Top-1）。

Conclusion: 生理感知的提示调优在桥接脑信号和视觉语义方面具有巨大潜力。

Abstract: Recent advances in brain-inspired artificial intelligence have sought to align neural signals with visual semantics using multimodal models such as CLIP. However, existing methods often treat CLIP as a static feature extractor, overlooking its adaptability to neural representations and the inherent physiological-symbolic gap in EEG-image alignment. To address these challenges, we present NeuroCLIP, a prompt tuning framework tailored for EEG-to-image contrastive learning. Our approach introduces three core innovations: (1) We design a dual-stream visual embedding pipeline that combines dynamic filtering and token-level fusion to generate instance-level adaptive prompts, which guide the adjustment of patch embedding tokens based on image content, thereby enabling fine-grained modulation of visual representations under neural constraints; (2) We are the first to introduce visual prompt tokens into EEG-image alignment, acting as global, modality-level prompts that work in conjunction with instance-level adjustments. These visual prompt tokens are inserted into the Transformer architecture to facilitate neural-aware adaptation and parameter optimization at a global level; (3) Inspired by neuroscientific principles of human visual encoding, we propose a refined contrastive loss that better model the semantic ambiguity and cross-modal noise present in EEG signals. On the THINGS-EEG2 dataset, NeuroCLIP achieves a Top-1 accuracy of 63.2% in zero-shot image retrieval, surpassing the previous best method by +12.3%, and demonstrates strong generalization under inter-subject conditions (+4.6% Top-1), highlighting the potential of physiology-aware prompt tuning for bridging brain signals and visual semantics.

</details>


### [3] [Sim4IA-Bench: A User Simulation Benchmark Suite for Next Query and Utterance Prediction](https://arxiv.org/abs/2511.09329)
*Andreas Konstantin Kruff,Christin Katharina Kreutz,Timo Breuer,Philipp Schaer,Krisztian Balog*

Main category: cs.IR

TL;DR: 提出了Sim4IA-Bench，这是IR社区首个用于预测用户下一个查询和话语的模拟基准套件，包含160个真实搜索会话和模拟器运行数据。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏成熟的衡量标准和基准，验证用户模拟一直是一个困难任务，难以评估模拟器是否准确反映真实用户行为。

Method: 构建包含160个真实搜索会话的数据集，其中70个会话包含最多62次模拟器运行，分为预测下一个搜索查询（任务A）和预测用户话语（任务B）两个子任务。

Result: 创建了首个公开可用的基准，将真实搜索会话与模拟的下一个查询预测联系起来，为评估用户模拟方法提供了基础。

Conclusion: Sim4IA-Bench促进了可重复研究，并刺激了信息访问中现实和可解释用户模拟的进一步工作。

Abstract: Validating user simulation is a difficult task due to the lack of established measures and benchmarks, which makes it challenging to assess whether a simulator accurately reflects real user behavior. As part of the Sim4IA Micro-Shared Task at the Sim4IA Workshop, SIGIR 2025, we present Sim4IA-Bench, a simulation benchmark suit for the prediction of the next queries and utterances, the first of its kind in the IR community. Our dataset as part of the suite comprises 160 real-world search sessions from the CORE search engine. For 70 of these sessions, up to 62 simulator runs are available, divided into Task A and Task B, in which different approaches predicted users next search queries or utterances. Sim4IA-Bench provides a basis for evaluating and comparing user simulation approaches and for developing new measures of simulator validity. Although modest in size, the suite represents the first publicly available benchmark that links real search sessions with simulated next-query predictions. In addition to serving as a testbed for next query prediction, it also enables exploratory studies on query reformulation behavior, intent drift, and interaction-aware retrieval evaluation. We also introduce a new measure for evaluating next-query predictions in this task. By making the suite publicly available, we aim to promote reproducible research and stimulate further work on realistic and explainable user simulation for information access: https://github.com/irgroup/Sim4IA-Bench.

</details>


### [4] [Practical RAG Evaluation: A Rarity-Aware Set-Based Metric and Cost-Latency-Quality Trade-offs](https://arxiv.org/abs/2511.09545)
*Etienne Dallaire*

Main category: cs.IR

TL;DR: 本文针对生产RAG系统中的猜测游戏问题，提出了RA-nWG@K评估指标、rag-gs黄金集构建管道、综合基准测试和针对性诊断方法，为实践者提供可复现的决策指导。


<details>
  <summary>Details</summary>
Motivation: 传统IR指标不适用于RAG系统，缺乏标准化的黄金集构建方法，现有排行榜缺少端到端基准测试，以及嵌入模型处理专有名词和对话噪声的能力不透明。

Method: 提出RA-nWG@K评估指标（考虑稀有性和查询归一化）、rag-gs黄金集构建管道（使用Plackett-Luce列表优化）、在科学论文语料上的综合基准测试，以及通过身份破坏和格式消融的针对性诊断。

Result: 建立了完整的RAG评估框架，包括评估指标、黄金集构建方法、基准测试结果和模型诊断分析，为实践者提供成本-延迟-质量权衡的指导。

Conclusion: 该研究为生产RAG系统提供了可复现、可审计的评估框架，支持预算和服务水平协议感知的决策制定。

Abstract: This paper addresses the guessing game in building production RAG. Classical rank-centric IR metrics (nDCG/MAP/MRR) are a poor fit for RAG, where LLMs consume a set of passages rather than a browsed list; position discounts and prevalence-blind aggregation miss what matters: whether the prompt at cutoff K contains the decisive evidence. Second, there is no standardized, reproducible way to build and audit golden sets. Third, leaderboards exist but lack end-to-end, on-corpus benchmarking that reflects production trade-offs. Fourth, how state-of-the-art embedding models handle proper-name identity signals and conversational noise remains opaque. To address these, we contribute: (1) RA-nWG@K, a rarity-aware, per-query-normalized set score, and operational ceilings via the pool-restricted oracle ceiling (PROC) and the percentage of PROC (%PROC) to separate retrieval from ordering headroom within a Cost-Latency-Quality (CLQ) lens; (2) rag-gs (MIT), a lean golden-set pipeline with Plackett-Luce listwise refinement whose iterative updates outperform single-shot LLM ranking; (3) a comprehensive benchmark on a production RAG (scientific-papers corpus) spanning dense retrieval, hybrid dense+BM25, embedding models and dimensions, cross-encoder rerankers, ANN (HNSW), and quantization; and (4) targeted diagnostics that quantify proper-name identity signal and conversational-noise sensitivity via identity-destroying and formatting ablations. Together, these components provide practitioner Pareto guidance and auditable guardrails to support reproducible, budget/SLA-aware decisions.

</details>
