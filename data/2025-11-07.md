<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Caption Injection for Optimization in Generative Search Engine](https://arxiv.org/abs/2511.04080)
*Xiaolu Chen,Yong Liao*

Main category: cs.IR

TL;DR: 提出了首个多模态生成搜索引擎优化方法Caption Injection，通过从图像中提取标题并注入文本内容来增强内容在生成式搜索中的主观可见性。


<details>
  <summary>Details</summary>
Motivation: 现有G-SEO方法仅限于基于文本的优化，无法充分利用多模态数据，而随着多模态检索增强生成技术的发展，需要能够处理多模态内容的G-SEO方法。

Method: Caption Injection方法从图像中提取标题并将其注入到文本内容中，整合视觉语义来增强内容在生成式搜索场景中的主观可见性。

Result: 在MRAMG基准测试中，Caption Injection在G-Eval指标下显著优于仅文本的G-SEO基线方法。

Conclusion: 多模态集成在G-SEO中对于提高用户感知的内容可见性是必要且有效的。

Abstract: Generative Search Engines (GSEs) leverage Retrieval-Augmented Generation
(RAG) techniques and Large Language Models (LLMs) to integrate multi-source
information and provide users with accurate and comprehensive responses. Unlike
traditional search engines that present results in ranked lists, GSEs shift
users' attention from sequential browsing to content-driven subjective
perception, driving a paradigm shift in information retrieval. In this context,
enhancing the subjective visibility of content through Generative Search Engine
Optimization (G-SEO) methods has emerged as a new research focus. With the
rapid advancement of Multimodal Retrieval-Augmented Generation (MRAG)
techniques, GSEs can now efficiently integrate text, images, audio, and video,
producing richer responses that better satisfy complex information needs.
Existing G-SEO methods, however, remain limited to text-based optimization and
fail to fully exploit multimodal data. To address this gap, we propose Caption
Injection, the first multimodal G-SEO approach, which extracts captions from
images and injects them into textual content, integrating visual semantics to
enhance the subjective visibility of content in generative search scenarios. We
systematically evaluate Caption Injection on MRAMG, a benchmark for MRAG, under
both unimodal and multimodal settings. Experimental results show that Caption
Injection significantly outperforms text-only G-SEO baselines under the G-Eval
metric, demonstrating the necessity and effectiveness of multimodal integration
in G-SEO to improve user-perceived content visibility.

</details>


### [2] [E-CARE: An Efficient LLM-based Commonsense-Augmented Framework for E-Commerce](https://arxiv.org/abs/2511.04087)
*Ge Zhang,Rohan Deepak Ajwani,Tony Zheng,Hongjian Gu,Yaochen Hu,Wei Guo,Mark Coates,Yingxue Zhang*

Main category: cs.IR

TL;DR: 提出E-CARE方法，通过构建常识推理因子图，在电商推荐中高效利用LLMs的常识推理能力，仅需单次前向传播即可提升推荐精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的电商推荐方法存在实时推理成本高、需要人工标注和微调的问题，需要一种更高效的常识推理增强方案。

Method: 构建常识推理因子图来编码LLMs的推理模式，在推理时仅需单次LLM前向传播即可获得常识推理能力。

Result: 在2个下游任务上，precision@5指标最高提升12.1%。

Conclusion: E-CARE能够高效利用LLMs的常识推理能力，显著提升电商推荐性能，同时大幅降低计算成本。

Abstract: Finding relevant products given a user query plays a pivotal role in an
e-commerce platform, as it can spark shopping behaviors and result in revenue
gains. The challenge lies in accurately predicting the correlation between
queries and products. Recently, mining the cross-features between queries and
products based on the commonsense reasoning capacity of Large Language Models
(LLMs) has shown promising performance. However, such methods suffer from high
costs due to intensive real-time LLM inference during serving, as well as human
annotations and potential Supervised Fine Tuning (SFT). To boost efficiency
while leveraging the commonsense reasoning capacity of LLMs for various
e-commerce tasks, we propose the Efficient Commonsense-Augmented Recommendation
Enhancer (E-CARE). During inference, models augmented with E-CARE can access
commonsense reasoning with only a single LLM forward pass per query by
utilizing a commonsense reasoning factor graph that encodes most of the
reasoning schema from powerful LLMs. The experiments on 2 downstream tasks show
an improvement of up to 12.1% on precision@5.

</details>


### [3] [Transforming Mentorship: An AI Powered Chatbot Approach to University Guidance](https://arxiv.org/abs/2511.04172)
*Mashrur Rahman,Mantaqa abedin,Monowar Zamil Abir,Faizul Islam Ansari,Adib Reza,Farig Yousuf Sadeque,Niloy Farhan*

Main category: cs.IR

TL;DR: 开发了一个AI驱动的聊天机器人，作为BRAC大学学生的导师，通过混合检索方法和LLaMA-3.3-70B模型提供个性化指导。


<details>
  <summary>Details</summary>
Motivation: 大学生在本科阶段面临巨大挑战，缺乏个性化的按需指导，现有数字工具无法提供规模化定制化辅导。

Method: 构建数据摄取管道处理CSV文件和大学网页信息，采用BM25词汇排序与ChromaDB语义检索的混合方法，使用LLaMA-3.3-70B大语言模型生成对话响应。

Result: 生成文本语义相关性高，BERTScore为0.831，METEOR分数为0.809；数据管道效率高，更新耗时106.82秒，新数据处理耗时368.62秒。

Conclusion: 该聊天机器人能够帮助学生解答疑问，更好地理解大学生活，并在开放学分制大学中协助规划学期日程。

Abstract: University students face immense challenges during their undergraduate lives,
often being deprived of personalized on-demand guidance that mentors fail to
provide at scale. Digital tools exist, but there is a serious lack of
customized coaching for newcomers. This paper presents an AI-powered chatbot
that will serve as a mentor for the students of BRAC University. The main
component is a data ingestion pipeline that efficiently processes and updates
information from diverse sources, such as CSV files and university webpages.
The chatbot retrieves information through a hybrid approach, combining BM25
lexical ranking with ChromaDB semantic retrieval, and uses a Large Language
Model, LLaMA-3.3-70B, to generate conversational responses. The generated text
was found to be semantically highly relevant, with a BERTScore of 0.831 and a
METEOR score of 0.809. The data pipeline was also very efficient, taking 106.82
seconds for updates, compared to 368.62 seconds for new data. This chatbot will
be able to help students by responding to their queries, helping them to get a
better understanding of university life, and assisting them to plan better
routines for their semester in the open-credit university.

</details>


### [4] [Coordination-Free Lane Partitioning for Convergent ANN Search](https://arxiv.org/abs/2511.04221)
*Carl Kugblenu,Petri Vuorimaa*

Main category: cs.IR

TL;DR: 提出了一种无协调的分区方法，将向量搜索系统中的并行处理从重复工作转变为互补工作，在不增加成本或延迟的情况下显著提高召回率。


<details>
  <summary>Details</summary>
Motivation: 生产向量搜索系统通常通过并行处理来满足延迟SLO，但这些并行通道会重复发现相同的候选结果，导致计算资源浪费而无法提高覆盖率。

Method: 为每个查询：(1)构建确定性的候选池，大小等于总top-k预算；(2)应用每查询伪随机排列；(3)为每个通道分配不相交的位置切片，从而实现无运行时协调的不同结果返回。

Result: 在4个通道、总候选预算64的情况下，SIFT1M数据集上recall@10从0.249提升到0.999，通道重叠从接近100%降至0%；MS MARCO数据集上hit@10从0.200提升到0.601，MRR@10从0.133提升到0.330。

Conclusion: 提出了简单的操作指南：将每查询池大小设置为总预算，确定性地跨通道分区位置，在不改变预算或截止时间的情况下将冗余扇出转化为互补覆盖。

Abstract: Production vector search systems often fan out each query across parallel
lanes (threads, replicas, or shards) to meet latency service-level objectives
(SLOs). In practice, these lanes rediscover the same candidates, so extra
compute does not increase coverage. We present a coordination-free lane
partitioner that turns duplication into complementary work at the same cost and
deadline. For each query we (1) build a deterministic candidate pool sized to
the total top-k budget, (2) apply a per-query pseudorandom permutation, and (3)
assign each lane a disjoint slice of positions. Lanes then return different
results by construction, with no runtime coordination.
  At equal cost with four lanes (total candidate budget 64), on SIFT1M (1M SIFT
feature vectors) with Hierarchical Navigable Small World graphs (HNSW)
recall@10 rises from 0.249 to 0.999 while lane overlap falls from nearly 100%
to 0%. On MS MARCO (8.8M passages) with HNSW, hit@10 improves from 0.200 to
0.601 and Mean Reciprocal Rank at 10 (MRR@10) from 0.133 to 0.330. For inverted
file (IVF) indexes we see smaller but consistent gains (for example, +11% on MS
MARCO) by de-duplicating list routing. A microbenchmark shows planner overhead
of ~37 microseconds per query (mean at the main setting) with linear growth in
the number of merged candidates.
  These results yield a simple operational guideline: size the per-query pool
to the total budget, deterministically partition positions across lanes, and
turn redundant fan-out into complementary coverage without changing budget or
deadline.

</details>


### [5] [Denoised Recommendation Model with Collaborative Signal Decoupling](https://arxiv.org/abs/2511.04237)
*Zefeng Li,Ning Yang*

Main category: cs.IR

TL;DR: 提出DRCSD模型，通过协作信号解耦和按阶去噪来解决推荐系统中用户-物品交互矩阵噪声问题，避免传统单图去噪方法导致的协作信号衰减。


<details>
  <summary>Details</summary>
Motivation: 传统协同过滤算法因用户-物品交互矩阵中的噪声导致推荐性能不佳，现有去噪方法多在单图上进行，会中断节点间的路径从而削弱路径依赖的协作信息。

Method: DRCSD模型包含协作信号解耦模块（按结构特征分解信号为不同阶次）和按阶去噪模块（对每阶进行针对性去噪），并改进传统GNN聚合机制以避免跨阶信号干扰。

Result: 在三个公开真实数据集上的实验表明，DRCSD对不稳定交互具有优越的鲁棒性，在推荐准确度指标上相比最先进基线模型取得统计显著的性能提升。

Conclusion: DRCSD通过解耦协作信号和按阶去噪有效解决了传统去噪方法的局限性，显著提升了推荐系统的准确性和鲁棒性。

Abstract: Although the collaborative filtering (CF) algorithm has achieved remarkable
performance in recommendation systems, it suffers from suboptimal
recommendation performance due to noise in the user-item interaction matrix.
Numerous noise-removal studies have improved recommendation models, but most
existing approaches conduct denoising on a single graph. This may cause
attenuation of collaborative signals: removing edges between two nodes can
interrupt paths between other nodes, weakening path-dependent collaborative
information. To address these limitations, this study proposes a novel
GNN-based CF model called DRCSD for denoising unstable interactions. DRCSD
includes two core modules: a collaborative signal decoupling module (decomposes
signals into distinct orders by structural characteristics) and an order-wise
denoising module (performs targeted denoising on each order). Additionally, the
information aggregation mechanism of traditional GNN-based CF models is
modified to avoid cross-order signal interference until the final pooling
operation. Extensive experiments on three public real-world datasets show that
DRCSD has superior robustness against unstable interactions and achieves
statistically significant performance improvements in recommendation accuracy
metrics compared to state-of-the-art baseline models.

</details>


### [6] [LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems](https://arxiv.org/abs/2511.04541)
*Baptiste Bonin,Maxime Heuillet,Audrey Durand*

Main category: cs.IR

TL;DR: 研究探索LLM如何通过slate上的成对推理作为用户偏好的世界模型，在三个数据集任务上的实证研究表明LLM性能与偏好函数特性相关。


<details>
  <summary>Details</summary>
Motivation: 跨领域建模用户偏好是slate推荐中的关键挑战，需要探索LLM作为用户偏好世界模型的有效性。

Method: 使用多个LLM在三个不同数据集任务上进行实证研究，通过成对推理分析slate推荐。

Result: 结果显示任务性能与LLM捕获的偏好函数特性之间存在关系，揭示了改进方向和LLM在推荐系统中的潜力。

Conclusion: LLM有潜力作为推荐系统中的世界模型，研究为改进方向提供了启示。

Abstract: Modeling user preferences across domains remains a key challenge in slate
recommendation (i.e. recommending an ordered sequence of items) research. We
investigate how Large Language Models (LLM) can effectively act as world models
of user preferences through pairwise reasoning over slates. We conduct an
empirical study involving several LLMs on three tasks spanning different
datasets. Our results reveal relationships between task performance and
properties of the preference function captured by LLMs, hinting towards areas
for improvement and highlighting the potential of LLMs as world models in
recommender systems.

</details>
