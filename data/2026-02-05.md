<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Nemotron ColEmbed V2: Top-Performing Late Interaction embedding models for Visual Document Retrieval](https://arxiv.org/abs/2602.03992)
*Gabriel de Souza P. Moreira,Ronay Ak,Mengyao Xu,Oliver Holworthy,Benedikt Schifferer,Zhiding Yu,Yauhen Babakhin,Radek Osmulski,Jiarui Cai,Ryan Chesler,Bo Liu,Even Oldridge*

Main category: cs.IR

TL;DR: Nemotron ColEmbed V2是一个基于视觉语言模型的视觉文档检索系统家族，在ViDoRe基准测试中达到SOTA性能，8B参数模型在ViDoRe V3排行榜上排名第一。


<details>
  <summary>Details</summary>
Motivation: 随着视觉文档检索需求的增长，以及现有RAG系统中视觉信息保留不足和OCR文本提取流程复杂的问题，需要开发更高效的视觉文档检索模型。

Method: 基于预训练的视觉语言模型（Eagle 2、Qwen3-VL）构建3B、4B、8B三个变体，采用聚类采样、困难负样本挖掘、双向注意力、延迟交互和模型融合等技术。

Result: 8B模型在ViDoRe V3排行榜上排名第一，平均NDCG@10达到63.42，展示了在视觉文档检索任务上的卓越性能。

Conclusion: Nemotron ColEmbed V2系列模型在视觉文档检索任务上取得了最先进的性能，同时讨论了延迟交互机制带来的计算和存储工程挑战，并提供了在准确性和存储效率之间的平衡方案。

Abstract: Retrieval-Augmented Generation (RAG) systems have been popular for generative applications, powering language models by injecting external knowledge. Companies have been trying to leverage their large catalog of documents (e.g. PDFs, presentation slides) in such RAG pipelines, whose first step is the retrieval component. Dense retrieval has been a popular approach, where embedding models are used to generate a dense representation of the user query that is closer to relevant content embeddings. More recently, VLM-based embedding models have become popular for visual document retrieval, as they preserve visual information and simplify the indexing pipeline compared to OCR text extraction.
  Motivated by the growing demand for visual document retrieval, we introduce Nemotron ColEmbed V2, a family of models that achieve state-of-the-art performance on the ViDoRe benchmarks. We release three variants - with 3B, 4B, and 8B parameters - based on pre-trained VLMs: NVIDIA Eagle 2 with Llama 3.2 3B backbone, Qwen3-VL-4B-Instruct and Qwen3-VL-8B-Instruct, respectively. The 8B model ranks first on the ViDoRe V3 leaderboard as of February 03, 2026, achieving an average NDCG@10 of 63.42.
  We describe the main techniques used across data processing, training, and post-training - such as cluster-based sampling, hard-negative mining, bidirectional attention, late interaction, and model merging - that helped us build our top-performing models. We also discuss compute and storage engineering challenges posed by the late interaction mechanism and present experiments on how to balance accuracy and storage with lower dimension embeddings.

</details>


### [2] [Following the TRAIL: Predicting and Explaining Tomorrow's Hits with a Fine-Tuned LLM](https://arxiv.org/abs/2602.04225)
*Yinan Zhang,Zhixi Chen,Jiazheng Jing,Zhiqi Shen*

Main category: cs.IR

TL;DR: TRAIL是一个微调的LLM，联合预测短期物品流行度并生成忠实自然语言解释，通过对比学习对齐评分和解释与结构化趋势信号。


<details>
  <summary>Details</summary>
Motivation: LLMs难以从大规模稀疏的用户-物品日志中提取用户偏好，且实时全目录排序不切实际；现有推荐系统往往只关注排序而忽视解释，解释能提高预测准确性并使推荐更具说服力。

Method: TRAIL使用微调的LLM联合预测短期物品流行度并生成自然语言解释，采用对比学习（正负样本对）来对齐其评分和解释与结构化趋势信号。

Result: 广泛实验表明TRAIL优于强基线方法，并能生成连贯、有充分依据的解释。

Conclusion: TRAIL通过联合预测物品流行度和生成忠实解释，实现了准确且可解释的流行度预测，解决了LLMs在推荐系统中的实际应用挑战。

Abstract: Large Language Models (LLMs) have been widely applied across multiple domains for their broad knowledge and strong reasoning capabilities. However, applying them to recommendation systems is challenging since it is hard for LLMs to extract user preferences from large, sparse user-item logs, and real-time per-user ranking over the full catalog is too time-consuming to be practical. Moreover, many existing recommender systems focus solely on ranking items while overlooking explanations, which could help improve predictive accuracy and make recommendations more convincing to users. Inspired by recent works that achieve strong recommendation performance by forecasting near-term item popularity, we propose TRAIL (TRend and explAnation Integrated Learner). TRAIL is a fine-tuned LLM that jointly predicts short-term item popularity and generates faithful natural-language explanations. It employs contrastive learning with positive and negative pairs to align its scores and explanations with structured trend signals, yielding accurate and explainable popularity predictions. Extensive experiments show that TRAIL outperforms strong baselines and produces coherent, well-grounded explanations.

</details>


### [3] [LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval](https://arxiv.org/abs/2602.04263)
*Joohyung Yun,Doyup Lee,Wook-Shin Han*

Main category: cs.IR

TL;DR: LILaC是一个多模态文档检索框架，通过分层组件图和基于边缘的子图检索方法，解决了固定粒度检索单元和跨文档多跳推理的挑战，在五个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态文档检索面临两个主要挑战：1) 固定、单一粒度的检索单元会导致无关内容干扰；2) 需要支持跨文档的多跳推理，有效捕捉组件间的语义关系。

Method: 提出LILaC框架，包含两个核心创新：1) 分层组件图，在粗粒度和细粒度两个层次上显式表示多模态信息；2) 基于晚交互的子图检索方法，先识别粗粒度节点进行高效候选生成，然后通过晚交互进行细粒度推理。

Result: 在五个基准测试中都达到了最先进的检索性能，且无需额外微调。

Conclusion: LILaC通过分层表示和边缘检索方法有效解决了多模态文档检索的挑战，实现了高效且精确的检索性能。

Abstract: Multimodal document retrieval aims to retrieve query-relevant components from documents composed of textual, tabular, and visual elements. An effective multimodal retriever needs to handle two main challenges: (1) mitigate the effect of irrelevant contents caused by fixed, single-granular retrieval units, and (2) support multihop reasoning by effectively capturing semantic relationships among components within and across documents. To address these challenges, we propose LILaC, a multimodal retrieval framework featuring two core innovations. First, we introduce a layered component graph, explicitly representing multimodal information at two layers - each representing coarse and fine granularity - facilitating efficient yet precise reasoning. Second, we develop a late-interaction-based subgraph retrieval method, an edge-based approach that initially identifies coarse-grained nodes for efficient candidate generation, then performs fine-grained reasoning via late interaction. Extensive experiments demonstrate that LILaC achieves state-of-the-art retrieval performance on all five benchmarks, notably without additional fine-tuning. We make the artifacts publicly available at github.com/joohyung00/lilac.

</details>


### [4] [MiniRec: Data-Efficient Reinforcement Learning for LLM-based Recommendation](https://arxiv.org/abs/2602.04278)
*Lin Wang,Yang Zhang,Jingfan Chen,Xiaoyan Zhao,Fengbin Zhu,Qing Li,Tat-Seng Chua*

Main category: cs.IR

TL;DR: MiniRec是一个针对RL-based LLM推荐系统的数据选择框架，通过奖励信号和梯度轨迹评估样本可学习性和代表性，结合课程学习策略，显著降低训练成本同时保持性能。


<details>
  <summary>Details</summary>
Motivation: RL-based LLM推荐系统面临效率挑战，全数据训练成本高昂。现有数据选择方法基于可学习性或代表性，但其损失/梯度驱动或数据集覆盖标准与RL学习动态不匹配，导致性能不理想。

Method: MiniRec框架：1) 使用RL关键信号——奖励评估样本可学习性，修剪太容易（奖励过高）或太困难（持续低奖励）的样本；2) 通过将样本梯度与近似的"理想"全局RL优化轨迹对齐来评估代表性，选择主要驱动模型更新的样本；3) 强制多样性以减少冗余；4) 结合从易到难样本的课程学习策略。

Result: 大量实验证明MiniRec的有效性，显著降低训练成本同时很大程度上保持性能，突出了奖励对齐、轨迹知情的数据选择在RL-based LLM推荐中的重要性。

Conclusion: MiniRec为RL-based LLM推荐提供了一个高效的数据选择框架，通过奖励对齐和轨迹感知的样本选择，解决了现有方法与RL学习动态不匹配的问题，实现了成本与性能的良好平衡。

Abstract: The integration of reinforcement learning (RL) into large language models (LLMs) has opened new opportunities for recommender systems by eliciting reasoning and improving user preference modeling. However, RL-based LLM recommendation faces significant efficiency challenges, making full-data training costly. Existing data selection methods define sample value based on learnability or representativeness, yet their loss- or gradient-driven or dataset coverage-driven criteria often misalign with RL learning dynamics, resulting in suboptimal performance. To address this, we propose MiniRec, a data selection framework tailored for RL-based LLM recommendation. MiniRec evaluates sample learnability using key RL signals -- rewards -- pruning samples that are too easy (too high reward) or too difficult (consistently low reward). It assesses representativeness by aligning sample gradients with the approximated "ideal" global RL optimization trajectory, selecting samples that mainly drive model updates, and it also enforces diversity to reduce redundancy. Combined with a curriculum learning strategy from easy to hard samples, MiniRec significantly reduces training cost while largely preserving performance. Extensive experiments demonstrate MiniRec's effectiveness, highlighting the importance of reward-aligned, trajectory-informed data selection in RL-based LLM recommendation.

</details>


### [5] [SDR-CIR: Semantic Debias Retrieval Framework for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2602.04451)
*Yi Sun,Jinyu Xu,Qing Xie,Jiachen Li,Yanchun Ma,Yongjian Liu*

Main category: cs.IR

TL;DR: SDR-CIR是一种无需训练的语义去偏排序方法，通过选择性思维链和两步去偏策略，在组合图像检索中减少语义偏差并提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合图像检索方法使用多模态大语言模型生成目标图像描述，但由于模糊匹配特性，生成的描述容易产生语义偏差，导致检索性能下降。

Method: 提出SDR-CIR方法：1）选择性思维链指导MLLM提取与修改文本相关的视觉内容；2）语义去偏排序包含锚定步骤（融合参考图像特征与目标描述特征）和去偏步骤（建模参考图像对描述的视觉语义贡献作为惩罚项）。

Result: 在三个标准CIR基准测试中，SDR-CIR在单阶段方法中取得了最先进的结果，同时保持了高效率。

Conclusion: SDR-CIR通过补充遗漏线索同时抑制冗余信息，有效缓解了语义偏差问题，提升了组合图像检索的性能。

Abstract: Composed Image Retrieval (CIR) aims to retrieve a target image from a query composed of a reference image and modification text. Recent training-free zero-shot methods often employ Multimodal Large Language Models (MLLMs) with Chain-of-Thought (CoT) to compose a target image description for retrieval. However, due to the fuzzy matching nature of ZS-CIR, the generated description is prone to semantic bias relative to the target image. We propose SDR-CIR, a training-free Semantic Debias Ranking method based on CoT reasoning. First, Selective CoT guides the MLLM to extract visual content relevant to the modification text during image understanding, thereby reducing visual noise at the source. We then introduce a Semantic Debias Ranking with two steps, Anchor and Debias, to mitigate semantic bias. In the Anchor step, we fuse reference image features with target description features to reinforce useful semantics and supplement omitted cues. In the Debias step, we explicitly model the visual semantic contribution of the reference image to the description and incorporate it into the similarity score as a penalty term. By supplementing omitted cues while suppressing redundancy, SDR-CIR mitigates semantic bias and improves retrieval performance. Experiments on three standard CIR benchmarks show that SDR-CIR achieves state-of-the-art results among one-stage methods while maintaining high efficiency. The code is publicly available at https://github.com/suny105/SDR-CIR.

</details>


### [6] [DOS: Dual-Flow Orthogonal Semantic IDs for Recommendation in Meituan](https://arxiv.org/abs/2602.04460)
*Junwei Yin,Senjie Kou,Changhao Li,Shuli Wang,Xue Wei,Yinqiu Huang,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.IR

TL;DR: DOS方法通过用户-物品双流框架和对角残差量化，解决语义ID在生成推荐系统中的上下文感知不足和语义损失问题


<details>
  <summary>Details</summary>
Motivation: 现有语义ID方法存在两个主要问题：1) 生成任务缺乏上下文感知，导致语义ID码本空间与生成空间存在差距，产生次优推荐；2) 次优的量化方法加剧了LLM中的语义损失

Method: 提出双流正交语义ID(DOS)方法：1) 使用用户-物品双流框架，利用协同信号对齐语义ID码本空间与生成空间；2) 引入正交残差量化方案，旋转语义空间到适当方向以最大化语义保留

Result: 广泛的离线实验和在线A/B测试证明了DOS的有效性，该方法已在美团移动应用中成功部署，服务数亿用户

Conclusion: DOS方法通过双流框架和正交量化有效解决了语义ID在生成推荐系统中的关键问题，实现了语义空间对齐和语义保留最大化

Abstract: Semantic IDs serve as a key component in generative recommendation systems. They not only incorporate open-world knowledge from large language models (LLMs) but also compress the semantic space to reduce generation difficulty. However, existing methods suffer from two major limitations: (1) the lack of contextual awareness in generation tasks leads to a gap between the Semantic ID codebook space and the generation space, resulting in suboptimal recommendations; and (2) suboptimal quantization methods exacerbate semantic loss in LLMs. To address these issues, we propose Dual-Flow Orthogonal Semantic IDs (DOS) method. Specifically, DOS employs a user-item dual flow-framework that leverages collaborative signals to align the Semantic ID codebook space with the generation space. Furthermore, we introduce an orthogonal residual quantization scheme that rotates the semantic space to an appropriate orientation, thereby maximizing semantic preservation. Extensive offline experiments and online A/B testing demonstrate the effectiveness of DOS. The proposed method has been successfully deployed in Meituan's mobile application, serving hundreds of millions of users.

</details>


### [7] [VK-LSVD: A Large-Scale Industrial Dataset for Short-Video Recommendation](https://arxiv.org/abs/2602.04567)
*Aleksandr Poslavsky,Alexander D'yakonov,Yuriy Dorn,Andrey Zimovnov*

Main category: cs.IR

TL;DR: VK-LSVD是最大的公开短视频推荐数据集，包含400亿次交互、1000万用户、2000万视频，用于解决短视频推荐中用户兴趣快速变化建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 短视频推荐面临用户兴趣快速变化的建模挑战，但缺乏反映真实平台动态的大规模开放数据集，限制了该领域的研究进展。

Method: 构建了VK大规模短视频数据集(VK-LSVD)，包含超过400亿次交互、1000万用户、近2000万视频的6个月数据，提供内容嵌入、多样化反馈信号和上下文元数据等丰富特征。

Result: 数据集质量和多样性得到验证，已应用于VK RecSys Challenge 2025，为序列推荐、冷启动场景和下一代推荐系统研究提供重要基准。

Conclusion: VK-LSVD填补了短视频推荐领域大规模开放数据集的空白，将加速序列推荐、冷启动和下一代推荐系统的研究进展。

Abstract: Short-video recommendation presents unique challenges, such as modeling rapid user interest shifts from implicit feedback, but progress is constrained by a lack of large-scale open datasets that reflect real-world platform dynamics. To bridge this gap, we introduce the VK Large Short-Video Dataset (VK-LSVD), the largest publicly available industrial dataset of its kind. VK-LSVD offers an unprecedented scale of over 40 billion interactions from 10 million users and almost 20 million videos over six months, alongside rich features including content embeddings, diverse feedback signals, and contextual metadata. Our analysis supports the dataset's quality and diversity. The dataset's immediate impact is confirmed by its central role in the live VK RecSys Challenge 2025. VK-LSVD provides a vital, open dataset to use in building realistic benchmarks to accelerate research in sequential recommendation, cold-start scenarios, and next-generation recommender systems.

</details>


### [8] [AIANO: Enhancing Information Retrieval with AI-Augmented Annotation](https://arxiv.org/abs/2602.04579)
*Sameh Khattab,Marie Bauer,Lukas Heine,Till Rostalski,Jens Kleesiek,Julian Friedrich*

Main category: cs.IR

TL;DR: AIANO是一个专门用于信息检索数据集标注的工具，通过AI增强的工作流程将人类专业知识与LLM辅助紧密结合，相比基线工具几乎将标注速度提高了一倍，同时更易用且提高了检索准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和检索增强生成的兴起，对高质量、精心策划的信息检索数据集需求急剧增加。然而，当前使用现成的标注工具使得标注过程复杂且低效。

Method: 开发了专门的标注工具AIANO，采用AI增强的标注工作流程，将人类专业知识与LLM辅助紧密集成，使标注者能够利用AI建议同时保持对标注决策的完全控制。

Result: 在15名参与者的用户研究中，使用AIANO创建问答数据集时，标注速度相比基线工具几乎提高了一倍，同时工具更易用且提高了检索准确性。

Conclusion: AIANO的AI增强方法加速并增强了信息检索任务的数据集创建，推动了检索密集型领域的标注能力发展。

Abstract: The rise of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) has rapidly increased the need for high-quality, curated information retrieval datasets. These datasets, however, are currently created with off-the-shelf annotation tools that make the annotation process complex and inefficient. To streamline this process, we developed a specialized annotation tool - AIANO. By adopting an AI-augmented annotation workflow that tightly integrates human expertise with LLM assistance, AIANO enables annotators to leverage AI suggestions while retaining full control over annotation decisions. In a within-subject user study ($n = 15$), participants created question-answering datasets using both a baseline tool and AIANO. AIANO nearly doubled annotation speed compared to the baseline while being easier to use and improving retrieval accuracy. These results demonstrate that AIANO's AI-augmented approach accelerates and enhances dataset creation for information retrieval tasks, advancing annotation capabilities in retrieval-intensive domains.

</details>


### [9] [Multi-Source Retrieval and Reasoning for Legal Sentencing Prediction](https://arxiv.org/abs/2602.04690)
*Junjie Chen,Haitao Li,Qilei Zhang,Zhenghua Li,Ya Zhang,Quan Zhou,Cheng Luo,Yiqun Liu,Dongsheng Guo,Qingyao Ai*

Main category: cs.IR

TL;DR: 提出MSR²框架，通过多源检索与推理结合强化学习，提升法律量刑预测的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 法律判决预测中的量刑预测任务面临挑战，需要细粒度客观知识和灵活主观推理，现有方法在这方面表现不佳

Method: MSR²框架：1）让LLMs基于推理需求进行多源检索；2）应用过程级奖励指导中间主观推理步骤；3）结合强化学习优化

Result: 在两个真实世界数据集上，MSR²显著提高了法律量刑预测的准确性和可解释性

Conclusion: MSR²为实用法律AI提供了有前景的解决方案，通过检索与推理的集成改善了复杂法律任务的性能

Abstract: Legal judgment prediction (LJP) aims to predict judicial outcomes from case facts and typically includes law article, charge, and sentencing prediction. While recent methods perform well on the first two subtasks, legal sentencing prediction (LSP) remains difficult due to its need for fine-grained objective knowledge and flexible subjective reasoning. To address these limitations, we propose $MSR^2$, a framework that integrates multi-source retrieval and reasoning in LLMs with reinforcement learning. $MSR^2$ enables LLMs to perform multi-source retrieval based on reasoning needs and applies a process-level reward to guide intermediate subjective reasoning steps. Experiments on two real-world datasets show that $MSR^2$ improves both accuracy and interpretability in LSP, providing a promising step toward practical legal AI. Our code is available at https://anonymous.4open.science/r/MSR2-FC3B.

</details>


### [10] [Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention](https://arxiv.org/abs/2602.04711)
*Sagie Dekel,Moshe Tennenholtz,Oren Kurland*

Main category: cs.IR

TL;DR: SDAG是一种针对RAG系统知识库投毒攻击的新型防御方法，通过稀疏文档注意力机制阻止检索文档间的交叉注意力，显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: RAG系统容易受到知识库投毒攻击，攻击者通过注入误导性文档来操控LLM输出。标准因果注意力机制在攻击场景下允许有害的跨文档交互，需要防御机制。

Method: 提出稀疏文档注意力RAG（SDAG），这是一种块稀疏注意力机制，禁止检索文档之间的交叉注意力。只需在推理时修改注意力掩码，无需微调或架构更改。

Result: SDAG在LLM问答任务的各种攻击策略下，显著优于标准因果注意力机制的攻击成功率。与现有防御方法集成后，性能显著优于当前最优方法。

Conclusion: SDAG是一种简单有效的RAG防御方法，通过限制跨文档注意力来抵御知识库投毒攻击，且易于与现有防御技术集成，提供更强的保护。

Abstract: Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corpus to steer an LLMs' output to an undesired response. We argue that the standard causal attention mechanism in LLMs enables harmful cross-document interactions, specifically in cases of attacks. Accordingly, we introduce a novel defense approach for RAG: Sparse Document Attention RAG (SDAG). This is a block-sparse attention mechanism that disallows cross-attention between retrieved documents. SDAG requires a minimal inference-time change to the attention mask; furthermore, no fine-tuning or additional architectural changes are needed. We present an empirical evaluation of LLM-based question answering (QA) with a variety of attack strategies on RAG. We show that our SDAG method substantially outperforms the standard causal attention mechanism in terms of attack success rate. We further demonstrate the clear merits of integrating SDAG with state-of-the-art RAG defense methods. Specifically, the integration results in performance that is statistically significantly better than the state-of-the-art.

</details>
