<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 20]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [GCRank: A Generative Contextual Comprehension Paradigm for Takeout Ranking Model](https://arxiv.org/abs/2601.02361)
*Ziheng Ni,Congcong Liu,Cai Shang,Yiming Sun,Junjie Li,Zhiwei Fang,Guangpeng Chen,Jian Li,Zehua Zhang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.IR

TL;DR: 提出生成式上下文理解框架，将广告排序重构为上下文理解任务，通过统一架构建模异构信号，在食品配送广告平台取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有广告排序模型依赖碎片化模块和手工特征，难以理解复杂用户意图，特别是在食品配送等位置服务中，用户决策受动态空间、时间和个体上下文影响，需要更强大的上下文理解能力。

Method: 提出生成式框架，包含生成式上下文编码器(GCE)和生成式上下文融合(GCF)。GCE包含三个专门模块：个性化上下文增强器(PCE)建模用户特定特征，集体上下文增强器(CCE)建模群体模式，动态上下文增强器(DCE)实现实时情境适应。GCF通过低秩适应无缝整合这些上下文表示。

Result: 实验证明该方法在关键业务指标上取得显著提升，包括点击率和平台收入。已成功部署在大型食品配送广告平台，展示了实际应用价值。

Conclusion: 这项工作为生成式推荐开辟了新视角，突出了其在工业广告系统中的实际潜力，通过统一架构建模异构上下文信号，有效解决了广告排序中的复杂意图理解问题。

Abstract: The ranking stage serves as the central optimization and allocation hub in advertising systems, governing economic value distribution through eCPM and orchestrating the user-centric blending of organic and advertising content. Prevailing ranking models often rely on fragmented modules and hand-crafted features, limiting their ability to interpret complex user intent. This challenge is further amplified in location-based services such as food delivery, where user decisions are shaped by dynamic spatial, temporal, and individual contexts. To address these limitations, we propose a novel generative framework that reframes ranking as a context comprehension task, modeling heterogeneous signals in a unified architecture. Our architecture consists of two core components: the Generative Contextual Encoder (GCE) and the Generative Contextual Fusion (GCF). The GCE comprises three specialized modules: a Personalized Context Enhancer (PCE) for user-specific modeling, a Collective Context Enhancer (CCE) for group-level patterns, and a Dynamic Context Enhancer (DCE) for real-time situational adaptation. The GCF module then seamlessly integrates these contextual representations through low-rank adaptation. Extensive experiments confirm that our method achieves significant gains in critical business metrics, including click-through rate and platform revenue. We have successfully deployed our method on a large-scale food delivery advertising platform, demonstrating its substantial practical impact. This work pioneers a new perspective on generative recommendation and highlights its practical potential in industrial advertising systems.

</details>


### [2] [The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control](https://arxiv.org/abs/2601.02362)
*Itzhak Ziv,Moshe Unger,Hilah Geva*

Main category: cs.IR

TL;DR: 研究探讨AI生成评论对推荐系统的影响，发现人类评论质量优于AI评论，平台控制AI内容生成策略对推荐效果至关重要


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的发展，推荐系统面临AI生成内容与人类创作内容并存的新环境，需要研究AI内容如何影响推荐系统性能和商业结果

Method: 使用TripAdvisor酒店评论数据集，通过LLM生成合成评论，评估用户中心（用户使用AI工具优化评论）和平台中心（平台从结构化元数据生成评论）两种AI内容引入途径的影响

Result: AI生成评论在多个文本维度上与人类评论存在系统性差异；人类评论训练的模型表现最佳；人类训练模型能很好泛化到AI内容，而AI训练模型对两种内容类型都表现不佳；基于语调的框架策略能显著提升平台生成评论的效果

Conclusion: 平台在控制AI生成评论的生成和整合方面具有战略重要性，需要确保合成内容能够补充推荐的鲁棒性和可持续商业价值

Abstract: The rise of generative AI technologies is reshaping content-based recommender systems (RSes), which increasingly encounter AI-generated content alongside human-authored content. This study examines how the introduction of AI-generated reviews influences RS performance and business outcomes. We analyze two distinct pathways through which AI content can enter RSes: user-centric, in which individuals use AI tools to refine their reviews, and platform-centric, in which platforms generate synthetic reviews directly from structured metadata. Using a large-scale dataset of hotel reviews from TripAdvisor, we generate synthetic reviews using LLMs and evaluate their impact across the training and deployment phases of RSes. We find that AI-generated reviews differ systematically from human-authored reviews across multiple textual dimensions. Although both user- and platform-centric AI reviews enhance RS performance relative to models without textual data, models trained on human reviews consistently achieve superior performance, underscoring the quality of authentic human data. Human-trained models generalize robustly to AI content, whereas AI-trained models underperform on both content types. Furthermore, tone-based framing strategies (encouraging, constructive, or critical) substantially enhance platform-generated review effectiveness. Our findings highlight the strategic importance of platform control in governing the generation and integration of AI-generated reviews, ensuring that synthetic content complements recommendation robustness and sustainable business value.

</details>


### [3] [Towards Trustworthy LLM-Based Recommendation via Rationale Integration](https://arxiv.org/abs/2601.02364)
*Chung Park,Taesan Kim,Hyeongjun Yun,Dongjoon Hong,Junui Hong,Kijung Park,MinCheol Cho,Mira Myong,Jihoon Oh,Min sung Choi*

Main category: cs.IR

TL;DR: 提出LLM-Rec推荐系统，通过自注释理由数据集和指令调优，以"理由优先"格式生成逻辑基础的理由，在预测物品前先解释推荐原因，提升透明度和推荐性能。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统主要优化准确性和短期参与度，忽视了透明度和可信度。虽然亚马逊和Instagram等平台开始提供推荐理由，但大多仍将其视为事后产物，需要更系统地将理由生成整合到推荐过程中。

Method: 使用LLM构建推荐系统，采用自注释理由数据集和指令调优，以"理由优先"格式生成推荐理由（先解释再推荐物品），并使用思维链风格表示理由，增强逻辑基础。

Result: 在Amazon Review数据集的时尚和科学领域实验中，相比现有基线方法取得了显著改进，既提升了推荐性能又增强了可解释性。

Conclusion: LLM-Rec通过整合逻辑基础的理由生成，有效解决了推荐系统的透明度和可信度问题，同时提高了推荐质量。公开了包含用户历史、理由和推荐物品的数据集以促进可复现性和未来研究。

Abstract: Traditional recommender systems (RS) have been primarily optimized for accuracy and short-term engagement, often overlooking transparency and trustworthiness. Recently, platforms such as Amazon and Instagram have begun providing recommendation rationales to users, acknowledging their critical role in fostering trust and enhancing engagement; however, most existing systems still treat them as post-hoc artifacts. We propose an LLM-based recommender (LLM-Rec) that not only predicts items but also generates logically grounded rationales. Our approach leverages a self-annotated rationale dataset and instruction tuning in a rationale-first format, where the model generates an explanation before outputting the recommended item. By adopting this strategy and representing rationales in a chain-of-thought (CoT) style, LLM-Rec strengthens both interpretability and recommendation performance. Experiments on the Fashion and Scientific domains of the Amazon Review dataset demonstrate significant improvements over well-established baselines. To encourage reproducibility and future research, we publicly release a rationale-augmented recommendation dataset containing user histories, rationales, and recommended items.

</details>


### [4] [FUSE : Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation](https://arxiv.org/abs/2601.02365)
*Tushar Vatsa,Vibha Belavadi,Priya Shanmugasundaram,Suhas Suresha,Dewang Sultania*

Main category: cs.IR

TL;DR: FUSE提出了一种失败感知的多模态搜索推荐系统，通过紧凑的GDR表示替代原始图像提示，采用七种上下文预算策略，其中上下文压缩策略在各项指标上表现最优。


<details>
  <summary>Details</summary>
Motivation: 多模态创意助手在检索过程中存在多个失败点：用户意图理解、内容类型选择、候选查找和结果排序。同时，处理和传输图像成本高昂，使得朴素的多模态方法不切实际。

Method: FUSE系统使用紧凑的GDR（基于画布元素的JSON表示）替代原始图像提示，实现七种上下文预算策略：基线提示、上下文压缩、思维链推理、小样本优化、检索增强上下文、两阶段处理和零样本最小化，并建立管道归因层监控系统性能。

Result: 在788个评估查询上的系统评估显示，上下文压缩策略在所有管道阶段表现最优：意图准确率93.3%，路由成功率86.8%（含回退），召回率99.4%，NDCG@5为88.5%。

Conclusion: 战略性的上下文总结优于全面和最小化的上下文策略，FUSE通过紧凑表示和智能上下文管理有效解决了多模态检索中的失败点和成本问题。

Abstract: Multimodal creative assistants decompose user goals and route tasks to subagents for layout, styling, retrieval, and generation. Retrieval quality is pivotal, yet failures can arise at several stages: understanding user intent, choosing content types, finding candidates (recall), or ranking results. Meanwhile, sending and processing images is costly, making naive multimodal approaches impractical. We present FUSE: Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation. FUSE replaces most raw-image prompting with a compact Grounded Design Representation (GDR): a selection aware JSON of canvas elements (image, text, shape, icon, video, logo), structure, styles, salient colors, and user selection provided by the Planner team. FUSE implements seven context budgeting strategies: comprehensive baseline prompting, context compression, chain-of-thought reasoning, mini-shot optimization, retrieval-augmented context, two-stage processing, and zero-shot minimalism. Finally, a pipeline attribution layer monitors system performance by converting subagent signals into simple checks: intent alignment, content-type/routing sanity, recall health (e.g., zero-hit and top-match strength), and ranking displacement analysis. We evaluate the seven context budgeting variants across 788 evaluation queries from diverse users and design templates (refer Figure 3). Our systematic evaluation reveals that Context Compression achieves optimal performance across all pipeline stages, with 93.3% intent accuracy, 86.8% routing success(with fallbacks), 99.4% recall, and 88.5% NDCG@5. This approach demonstrates that strategic context summarization outperforms both comprehensive and minimal contextualization strategies.

</details>


### [5] [TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer](https://arxiv.org/abs/2601.02366)
*Yiwen Chen,Yiqing Wu,Huishi Luo,Fuzhen Zhuang,Deqing Wang*

Main category: cs.IR

TL;DR: TextBridgeGNN：一个利用文本作为语义桥梁的图推荐预训练框架，通过多级图传播连接不同领域，实现知识迁移


<details>
  <summary>Details</summary>
Motivation: 传统基于ID嵌入的图推荐模型难以跨领域迁移，主要面临两个挑战：1) ID嵌入因领域隔离而不可迁移；2) 跨领域异构交互图的结构不兼容。需要构建能够有效迁移知识的预训练图推荐模型。

Method: 提出TextBridgeGNN框架，使用文本作为语义桥梁连接不同领域。预训练阶段：利用文本信息打破多领域数据孤岛，设计分层GNN学习领域特定和全局知识；微调阶段：提出相似性迁移机制，通过语义相关节点初始化目标域ID嵌入，实现ID嵌入和图模式的迁移。

Result: 实验表明TextBridgeGNN在跨领域、多领域和无训练设置下均优于现有方法，能够有效整合预训练语言模型的语义与基于图的协同过滤，无需昂贵的语言模型微调或实时推理开销。

Conclusion: TextBridgeGNN成功解决了图推荐模型跨领域迁移的挑战，通过文本语义桥梁实现了有效的知识迁移，为构建预训练图推荐模型提供了可行方案。

Abstract: Graph-based recommendation has achieved great success in recent years. The classical graph recommendation model utilizes ID embedding to store essential collaborative information. However, this ID-based paradigm faces challenges in transferring to a new domain, making it hard to build a pre-trained graph recommendation model. This phenomenon primarily stems from two inherent challenges: (1) the non-transferability of ID embeddings due to isolated domain-specific ID spaces, and (2) structural incompatibility between heterogeneous interaction graphs across domains.
  To address these issues, we propose TextBridgeGNN, a pre-training and fine-tuning framework that can effectively transfer knowledge from a pre-trained GNN to downstream tasks. We believe the key lies in how to build the relationship between domains. Specifically, TextBridgeGNN uses text as a semantic bridge to connect domains through multi-level graph propagation. During the pre-training stage, textual information is utilized to break the data islands formed by multiple domains, and hierarchical GNNs are designed to learn both domain-specific and domain-global knowledge with text features, ensuring the retention of collaborative signals and the enhancement of semantics. During the fine-tuning stage, a similarity transfer mechanism is proposed. This mechanism initializes ID embeddings in the target domain by transferring from semantically related nodes, successfully transferring the ID embeddings and graph pattern.
  Experiments demonstrate that TextBridgeGNN outperforms existing methods in cross-domain, multi-domain, and training-free settings, highlighting its ability to integrate Pre-trained Language Model (PLM)-driven semantics with graph-based collaborative filtering without costly language model fine-tuning or real-time inference overhead.

</details>


### [6] [Distillation-based Scenario-Adaptive Mixture-of-Experts for the Matching Stage of Multi-scenario Recommendation](https://arxiv.org/abs/2601.02368)
*Ruibing Wang,Shuhan Guo,Haotong Du,Quanming Yao*

Main category: cs.IR

TL;DR: DSMOE通过场景自适应投影模块和跨架构知识蒸馏框架，解决了多场景推荐中独立双塔架构的盲目优化和头部场景参数主导问题，显著提升了长尾场景的检索质量。


<details>
  <summary>Details</summary>
Motivation: 多场景推荐中，MMOE在排序阶段表现良好，但在匹配阶段面临两个主要问题：独立双塔架构的盲目优化，以及头部场景参数主导导致长尾场景表现不佳。

Method: 提出DSMOE框架，包含两个核心组件：1) 场景自适应投影模块(SAP)，生成轻量级、场景特定的参数，防止专家模型在长尾场景中崩溃；2) 跨架构知识蒸馏框架，使用交互感知的教师模型指导双塔学生模型学习复杂匹配模式。

Result: 在真实世界数据集上的大量实验表明，DSMOE优于现有方法，特别是在显著提升数据稀疏、代表性不足的长尾场景的检索质量方面表现突出。

Conclusion: DSMOE通过解决多场景推荐匹配阶段的结构性和分布性瓶颈，有效提升了整体推荐性能，特别是在长尾场景中取得了显著改进。

Abstract: Multi-scenario recommendation is pivotal for optimizing user experience across diverse contexts. While Multi-gate Mixture-of-Experts (MMOE) thrives in ranking, its transfer to the matching stage is hindered by the blind optimization inherent to independent two-tower architectures and the parameter dominance of head scenarios. To address these structural and distributional bottlenecks, we propose Distillation-based Scenario-Adaptive Mixture-of-Experts (DSMOE). Specially, we devise a Scenario-Adaptive Projection (SAP) module to generate lightweight, context-specific parameters, effectively preventing expert collapse in long-tail scenarios. Concurrently, we introduce a cross-architecture knowledge distillation framework, where an interaction-aware teacher guides the two-tower student to capture complex matching patterns. Extensive experiments on real-world datasets demonstrate DSMOE's superiority, particularly in significantly improving retrieval quality for under-represented, data-sparse scenarios.

</details>


### [7] [Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning](https://arxiv.org/abs/2601.02372)
*Eunice Kingenga,Mike Wa Nkongolo*

Main category: cs.IR

TL;DR: 提出结合混合情感分析与强化学习的自适应新闻推荐框架，通过Q-learning学习推荐策略，提升情感匹配度


<details>
  <summary>Details</summary>
Motivation: 传统新闻推荐系统在情感分析方面存在模糊性、词典不一致和上下文理解有限的问题，特别是在多源新闻环境中。现有模型通常将情感作为次要特征，难以适应用户的情感偏好。

Method: 开发自适应情感感知新闻推荐框架，整合混合情感分析与强化学习。使用BBC新闻数据集，结合VADER、AFINN、TextBlob和SentiWordNet四种工具生成文章级情感估计。将文章分类为积极、消极或中性，并将这些情感状态嵌入Q-learning架构中，指导智能体学习最优推荐策略。

Result: 提出的系统能有效识别并推荐情感匹配的文章，通过迭代Q-learning更新持续改进个性化推荐。结果表明，混合情感建模与强化学习结合为以用户为中心的新闻推荐提供了可行、可解释和自适应的方法。

Conclusion: 结合混合情感分析与强化学习的方法能够解决传统新闻推荐系统在情感理解方面的局限性，提供更适应个人情感偏好的推荐服务，具有实用性和可扩展性。

Abstract: News recommendation systems rely on automated sentiment analysis to personalise content and enhance user engagement. Conventional approaches often struggle with ambiguity, lexicon inconsistencies, and limited contextual understanding, particularly in multi-source news environments. Existing models typically treat sentiment as a secondary feature, reducing their ability to adapt to users' affective preferences. To address these limitations, this study develops an adaptive, sentiment-aware news recommendation framework by integrating hybrid sentiment analysis with reinforcement learning. Using the BBC News dataset, a hybrid sentiment model combines VADER, AFINN, TextBlob, and SentiWordNet scores to generate robust article-level sentiment estimates. Articles are categorised as positive, negative, or neutral, and these sentiment states are embedded within a Q-learning architecture to guide the agent in learning optimal recommendation policies. The proposed system effectively identifies and recommends articles with aligned emotional profiles while continuously improving personalisation through iterative Q-learning updates. The results demonstrate that coupling hybrid sentiment modelling with reinforcement learning provides a feasible, interpretable, and adaptive approach for user-centred news recommendation.

</details>


### [8] [A Lay User Explainable Food Recommendation System Based on Hybrid Feature Importance Extraction and Large Language Models](https://arxiv.org/abs/2601.02374)
*Melissa Tessa,Diderot D. Cidjeu,Rachele Carli,Sarah Abchiche,Ahmad Aldarwishd,Igor Tchappi,Amro Najjar*

Main category: cs.IR

TL;DR: 使用LLM和SHAP结合的方法，为食品推荐系统生成更详细、动态且易于理解的解释，提升用户信任和透明度


<details>
  <summary>Details</summary>
Motivation: 当前食品推荐系统的解释通常不够详细和易懂，特别是对普通用户而言。需要一种方法能提供更全面、动态且易于理解的解释，以增强用户信任和系统透明度。

Method: 结合大型语言模型(LLM)和SHAP（SHapley Additive exPlanations）的混合关键变量提取方法，开发后处理过程来生成更详细的解释。LLM用于生成自然语言解释，SHAP用于识别影响推荐结果的关键变量。

Result: 相比文献中的现有方法，该方法能产生更动态、更有说服力且更全面的解释，特别适合普通用户理解。系统生成的解释更容易让用户理解复杂的推荐结果。

Conclusion: 通过结合LLM和SHAP的方法，可以有效提升食品推荐系统的解释能力，增强用户信任和系统透明度，使复杂推荐结果对普通用户更加易懂。

Abstract: Large Language Models (LLM) have experienced strong development in recent years, with varied applications. This paper uses LLMs to develop a post-hoc process that provides more elaborated explanations of the results of food recommendation systems. By combining LLM with a hybrid extraction of key variables using SHAP, we obtain dynamic, convincing and more comprehensive explanations to lay user, compared to those in the literature. This approach enhances user trust and transparency by making complex recommendation outcomes easier to understand for a lay user.

</details>


### [9] [TAG-HGT: A Scalable and Cost-Effective Framework for Inductive Cold-Start Academic Recommendation](https://arxiv.org/abs/2601.02381)
*Zhexiang Li*

Main category: cs.IR

TL;DR: TAG-HGT：一种用于学术冷启动推荐的高效神经符号框架，通过解耦的"语义优先、结构优化"范式，将LLM语义知识蒸馏到轻量级图Transformer中，实现高质量推荐同时大幅降低推理延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 解决工业学术平台中冷启动推荐的关键问题：新学者无历史交互记录，现有生成图模型推理延迟高（13分钟/1000请求）、计算成本大，无法满足实时百万级应用需求。

Method: 采用"语义优先、结构优化"的解耦范式：1) 使用冻结的DeepSeek-V3 LLM作为离线语义工厂；2) 通过跨视图对比学习将LLM知识蒸馏到轻量级异构图Transformer中；3) 结合LLM的全局召回能力和图结构的局部判别能力。

Result: 在OpenAlex数据集上，TAG-HGT达到SOTA系统召回率91.97%，比纯结构基线提升20.7%。推理延迟降低5个数量级（从780秒降至1.73毫秒），成本从1.50美元降至<0.001美元/1000查询，实现99.9%成本削减。

Conclusion: TAG-HGT成功解决了生成质量与工业可扩展性之间的鸿沟，通过神经符号方法实现了高质量冷启动推荐，同时大幅降低延迟和成本，使高精度学术推荐民主化。

Abstract: Inductive cold-start recommendation remains the "Achilles' Heel" of industrial academic platforms, where thousands of new scholars join daily without historical interaction records. While recent Generative Graph Models (e.g., HiGPT, OFA) demonstrate promising semantic capabilities, their prohibitive inference latency (often exceeding 13 minutes per 1,000 requests) and massive computational costs render them practically undeployable for real-time, million-scale applications. To bridge this gap between generative quality and industrial scalability, we propose TAG-HGT, a cost-effective neuro-symbolic framework. Adopting a decoupled "Semantics-First, Structure-Refined" paradigm, TAG-HGT utilizes a frozen Large Language Model (DeepSeek-V3) as an offline semantic factory and distills its knowledge into a lightweight Heterogeneous Graph Transformer (HGT) via Cross-View Contrastive Learning (CVCL). We present a key insight: while LLM semantics provide necessary global recall, structural signals offer the critical local discrimination needed to distinguish valid collaborators from semantically similar but socially unreachable strangers in dense embedding spaces. Validated under a strict Time-Machine Protocol on the massive OpenAlex dataset, TAG-HGT achieves a SOTA System Recall@10 of 91.97%, outperforming structure-only baselines by 20.7%. Most significantly, from an industrial perspective, TAG-HGT reduces inference latency by five orders of magnitude ($4.5 \times 10^{5}\times$) compared to generative baselines (from 780s down to 1.73 ms), and slashes inference costs from $\sim$$1.50 to $<$$0.001 per 1k queries. This 99.9% cost reduction democratizes high-precision academic recommendation.

</details>


### [10] [Tree of Preferences for Diversified Recommendation](https://arxiv.org/abs/2601.02386)
*Hanyang Yuan,Ning Tang,Tongya Zheng,Jiarong Xu,Xintong Hu,Renhong Huang,Shunyu Liu,Jiacong Hu,Jiawei Chen,Mingli Song*

Main category: cs.IR

TL;DR: 提出基于大语言模型的多样化推荐方法，通过构建偏好树挖掘用户未充分探索的兴趣，生成合成交互数据训练推荐模型，提升推荐多样性


<details>
  <summary>Details</summary>
Motivation: 现有多样化推荐方法主要从观察到的用户反馈推断偏好多样性，但由于数据偏差，未充分探索的用户兴趣可能被掩盖，导致推荐多样性不足

Method: 1) 构建Tree of Preferences结构，让LLM从粗到细推理用户行为背后的偏好；2) 采用数据为中心的方法，识别匹配用户偏好的候选物品并生成反映未探索偏好的合成交互；3) 整合这些交互训练通用推荐模型；4) 动态选择有影响力的用户优化效率

Result: 在多样性和相关性评估中，该方法在大多数情况下优于现有方法，在其他情况下达到接近最优性能，且推理延迟合理

Conclusion: 通过利用LLM的世界知识和推理能力挖掘用户未充分探索的偏好，可以有效提升推荐系统的多样性，同时保持相关性

Abstract: Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items. Existing approaches predominantly aim to infer the diversity of user preferences from observed user feedback. Nonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap, this work aims to study diversified recommendation from a data-bias perspective. Inspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations. To achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences. To guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences. These interactions are integrated to train a general recommender for diversification. Moreover, we scale up overall efficiency by dynamically selecting influential users during optimization. Extensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.

</details>


### [11] [Socially-Aware Recommender Systems Mitigate Opinion Clusterization](https://arxiv.org/abs/2601.02412)
*Lukas Schüepp,Carmen Amo Alonso,Florian Dörfler,Giulia De Pasquale*

Main category: cs.IR

TL;DR: 该论文提出了一种考虑用户社交网络结构的推荐系统，通过利用用户社交网络拓扑来平衡个性化与内容多样性，从而缓解过滤气泡和意见极化问题。


<details>
  <summary>Details</summary>
Motivation: 推荐系统、内容创作者和用户之间形成了复杂的反馈循环：推荐系统根据用户偏好匹配内容，创作者为提升流行度而调整内容，用户偏好又受到推荐内容和社交圈内容的双重影响。这种循环是导致过滤气泡和意见极化的关键原因。

Method: 开发了一种社交网络感知的推荐系统，明确考虑用户-创作者反馈互动，并策略性地利用用户自身社交网络的拓扑结构来促进内容多样化。

Result: 证明意见集群化与推荐内容对用户意见的影响力呈正相关。提出的方法展示了社交感知推荐系统在对抗意见极化和集群化现象方面的能力。

Conclusion: 在推荐系统设计中考虑并利用用户社交网络对于平衡内容多样性与个性化、缓解过滤气泡效应至关重要。社交感知推荐系统是应对意见极化和集群化现象的有效工具。

Abstract: Recommender systems shape online interactions by matching users with creators content to maximize engagement. Creators, in turn, adapt their content to align with users preferences and enhance their popularity. At the same time, users preferences evolve under the influence of both suggested content from the recommender system and content shared within their social circles. This feedback loop generates a complex interplay between users, creators, and recommender algorithms, which is the key cause of filter bubbles and opinion polarization. We develop a social network-aware recommender system that explicitly accounts for this user-creators feedback interaction and strategically exploits the topology of the user's own social network to promote diversification. Our approach highlights how accounting for and exploiting user's social network in the recommender system design is crucial to mediate filter bubble effects while balancing content diversity with personalization. Provably, opinion clusterization is positively correlated with the influence of recommended content on user opinions. Ultimately, the proposed approach shows the power of socially-aware recommender systems in combating opinion polarization and clusterization phenomena.

</details>


### [12] [A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance](https://arxiv.org/abs/2601.02428)
*Okan Bursa*

Main category: cs.IR

TL;DR: ARM是一个动态记忆检索增强生成框架，通过选择性记忆和遗忘机制替代静态向量索引，实现高效检索性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用静态向量索引存在效率问题，需要更智能的记忆管理机制来平衡检索质量、延迟和内存效率

Method: 采用动态记忆基板，基于认知巩固和遗忘原理：频繁检索的项目被巩固保护，很少使用的项目逐渐衰减，嵌入层仅需约22M参数

Result: 在轻量级检索基准测试中达到接近SOTA性能（NDCG@5≈0.940，Recall@5=1.000），在超高效模型（<25M参数）中效率最佳；Llama 3.1+静态RAG获得最高关键词覆盖率（67.2%），GPT-4o+动态检索策略响应最快（平均8.2秒）

Conclusion: ARM提供了竞争性的准确性、自我调节的内存增长和可解释的保留动态，无需重新训练生成器，为生产和研究RAG系统提供了质量、延迟和内存效率之间的实用权衡

Abstract: We introduce \emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\approx$ 0.940, Recall@5 $=1.000$) with only $\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.
  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.

</details>


### [13] [CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory](https://arxiv.org/abs/2601.02708)
*HuiJeong Son,Hyeongu Kang,Sunho Kim,Subeen Ho,SeongKu Kang,Dongha Lee,Susik Yoon*

Main category: cs.IR

TL;DR: CREAM是一个用于动态数据流信息检索的自监督持续学习框架，通过软内存结构适应数据分布变化，无需真实标签即可处理未见查询和文档。


<details>
  <summary>Details</summary>
Motivation: 动态数据流中的分布偏移会降低AI信息检索系统性能，现有基于内存的持续学习方法依赖固定查询集和真实相关文档，无法泛化到未见查询和文档，限制了实际应用。

Method: 提出CREAM框架：1) 细粒度相似度估计；2) 正则化聚类原型；3) 分层核心集采样。通过动态结构化的软内存捕获流式查询和文档的演化语义，在无监督设置下适应已见和未见主题。

Result: 在两个基准数据集上，CREAM在无标签设置下比最强方法平均提升27.79%的Success@5和44.5%的Recall@10，性能达到甚至超过监督方法水平。

Conclusion: CREAM通过自监督框架有效解决了动态数据流信息检索中的分布偏移问题，无需真实标签即可适应新语料库的未见主题，具有实际应用价值。

Abstract: Information retrieval (IR) in dynamic data streams is emerging as a challenging task, as shifts in data distribution degrade the performance of AI-powered IR systems. To mitigate this issue, memory-based continual learning has been widely adopted for IR. However, existing methods rely on a fixed set of queries with ground-truth relevant documents, which limits generalization to unseen queries and documents, making them impractical for real-world applications. To enable more effective learning with unseen topics of a new corpus without ground-truth labels, we propose CREAM, a self-supervised framework for memory-based continual retrieval. CREAM captures the evolving semantics of streaming queries and documents into dynamically structured soft memory and leverages it to adapt to both seen and unseen topics in an unsupervised setting. We realize this through three key techniques: fine-grained similarity estimation, regularized cluster prototyping, and stratified coreset sampling. Experiments on two benchmark datasets demonstrate that CREAM exhibits superior adaptability and retrieval accuracy, outperforming the strongest method in a label-free setting by 27.79\% in Success@5 and 44.5\% in Recall@10 on average, and achieving performance comparable to or even exceeding that of supervised methods.

</details>


### [14] [Ahead of the Spread: Agent-Driven Virtual Propagation for Early Fake News Detection](https://arxiv.org/abs/2601.02750)
*Bincheng Gu,Min Gao,Junliang Yu,Zongwei Wang,Zhiyi Liu,Kai Shu,Hongyu Zhang*

Main category: cs.IR

TL;DR: AVOID：基于智能体驱动的虚拟传播早期假新闻检测新范式，通过LLM智能体模拟传播行为而非被动等待真实传播数据，显著提升早期检测性能。


<details>
  <summary>Details</summary>
Motivation: 早期假新闻检测面临挑战，因为传播初期缺乏可观测的传播信号。现有方法依赖内容分析或需要等待传播形成，无法在早期阶段有效检测。

Method: 提出AVOID框架，将早期检测重新定义为证据生成范式。使用具有差异化角色和数据驱动人设的LLM智能体，主动模拟早期传播行为，构建虚拟传播轨迹。通过去噪引导的融合策略将模拟传播与内容语义对齐。

Result: 在基准数据集上的广泛实验表明，AVOID持续优于最先进的基线方法，验证了虚拟传播增强对早期假新闻检测的有效性和实用价值。

Conclusion: AVOID通过主动模拟传播信号而非被动等待真实传播，为早期假新闻检测提供了新范式，显著提升了检测性能，具有重要的实际应用价值。

Abstract: Early detection of fake news is critical for mitigating its rapid dissemination on social media, which can severely undermine public trust and social stability. Recent advancements show that incorporating propagation dynamics can significantly enhance detection performance compared to previous content-only approaches. However, this remains challenging at early stages due to the absence of observable propagation signals. To address this limitation, we propose AVOID, an \underline{a}gent-driven \underline{v}irtual pr\underline{o}pagat\underline{i}on for early fake news \underline{d}etection. AVOID reformulates early detection as a new paradigm of evidence generation, where propagation signals are actively simulated rather than passively observed. Leveraging LLM-powered agents with differentiated roles and data-driven personas, AVOID realistically constructs early-stage diffusion behaviors without requiring real propagation data. The resulting virtual trajectories provide complementary social evidence that enriches content-based detection, while a denoising-guided fusion strategy aligns simulated propagation with content semantics. Extensive experiments on benchmark datasets demonstrate that AVOID consistently outperforms state-of-the-art baselines, highlighting the effectiveness and practical value of virtual propagation augmentation for early fake news detection. The code and data are available at https://github.com/Ironychen/AVOID.

</details>


### [15] [Netflix Artwork Personalization via LLM Post-training](https://arxiv.org/abs/2601.02764)
*Hyunji Nam,Sejoon Oh,Emma Kong,Yesu Feng,Moumita Bhattacharya*

Main category: cs.IR

TL;DR: 论文提出使用LLM进行个性化艺术作品推荐，通过后训练使模型能根据用户偏好选择最适合的标题视觉呈现，在Netflix数据集上相比生产模型提升3-5%


<details>
  <summary>Details</summary>
Motivation: 用户在娱乐平台（如Netflix）有不同偏好，同一标题的艺术作品（如海报）可能包含不同主题和风格，需要个性化推荐而非一刀切方案

Method: 对预训练LLM（Llama 3.1 8B）进行后训练，使其能根据用户偏好选择最合适的标题视觉呈现，使用11万数据点训练，5千用户-标题对评估

Result: 后训练的LLM相比Netflix生产模型提升3-5%性能，表明使用LLM进行细粒度个性化推荐是可行方向

Conclusion: LLM后训练能有效实现个性化艺术作品推荐，提升用户满意度和参与度，为细粒度个性化推荐提供了有前景的技术路径

Abstract: Large language models (LLMs) have demonstrated success in various applications of user recommendation and personalization across e-commerce and entertainment. On many entertainment platforms such as Netflix, users typically interact with a wide range of titles, each represented by an artwork. Since users have diverse preferences, an artwork that appeals to one type of user may not resonate with another with different preferences. Given this user heterogeneity, our work explores the novel problem of personalized artwork recommendations according to diverse user preferences. Similar to the multi-dimensional nature of users' tastes, titles contain different themes and tones that may appeal to different viewers. For example, the same title might feature both heartfelt family drama and intense action scenes. Users who prefer romantic content may like the artwork emphasizing emotional warmth between the characters, while those who prefer action thrillers may find high-intensity action scenes more intriguing. Rather than a one-size-fits-all approach, we conduct post-training of pre-trained LLMs to make personalized artwork recommendations, selecting the most preferred visual representation of a title for each user and thereby improving user satisfaction and engagement. Our experimental results with Llama 3.1 8B models (trained on a dataset of 110K data points and evaluated on 5K held-out user-title pairs) show that the post-trained LLMs achieve 3-5\% improvements over the Netflix production model, suggesting a promising direction for granular personalized recommendations using LLMs.

</details>


### [16] [COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems](https://arxiv.org/abs/2601.02807)
*Sohini Roychowdhury,Doris Wang,Qian Ge,Joy Mu,Srihari Reddy*

Main category: cs.IR

TL;DR: 提出三维框架增强用户-广告表示，通过多源数据、长历史序列和丰富属性提升广告推荐效果，在不增加推理复杂度下显著改善AUC和CTR预测。


<details>
  <summary>Details</summary>
Motivation: 商业广告推荐模型需要多样化和丰富的数据源来准确评估用户兴趣，特别是在用户与内容交互前后。虽然扩展的用户参与历史可以改善用户兴趣预测，但同样重要的是嵌入来自多个来源的活动序列，以确保用户和广告表示的新鲜度，遵循扩展定律原则。

Method: 提出新颖的三维框架：第一维度考察整合多样化事件源的影响；第二维度考虑更长用户历史的好处；第三维度专注于通过额外事件属性和多模态嵌入来丰富数据。通过比较有机用户参与源（如内容观看）与广告展示源来评估投资回报率。

Result: 该方法可以将广告展示源的AUC和扩展曲线斜率提升1.56到2倍，即使在线序列长度仅为100到10K。使用丰富的广告展示事件源时，CTR预测比基线生产广告推荐系统提高0.56% AUC，改善了长序列和离线用户-广告表示的扩展分辨率。

Conclusion: 三维数据源丰富框架能有效增强用户-广告表示，在不增加模型推理或服务复杂度的情况下显著提升广告推荐性能，特别是在广告展示源方面表现出色，为商业广告推荐系统提供了实用的改进方案。

Abstract: Diverse and enriched data sources are essential for commercial ads-recommendation models to accurately assess user interest both before and after engagement with content. While extended user-engagement histories can improve the prediction of user interests, it is equally important to embed activity sequences from multiple sources to ensure freshness of user and ad-representations, following scaling law principles. In this paper, we present a novel three-dimensional framework for enhancing user-ad representations without increasing model inference or serving complexity. The first dimension examines the impact of incorporating diverse event sources, the second considers the benefits of longer user histories, and the third focuses on enriching data with additional event attributes and multi-modal embeddings. We assess the return on investment (ROI) of our source enrichment framework by comparing organic user engagement sources, such as content viewing, with ad-impression sources. The proposed method can boost the area under curve (AUC) and the slope of scaling curves for ad-impression sources by 1.56 to 2 times compared to organic usage sources even for short online-sequence lengths of 100 to 10K. Additionally, click-through rate (CTR) prediction improves by 0.56% AUC over the baseline production ad-recommendation system when using enriched ad-impression event sources, leading to improved sequence scaling resolutions for longer and offline user-ad representations.

</details>


### [17] [HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation](https://arxiv.org/abs/2601.02955)
*Boyang Xia,Zhou Yu,Zhiliang Zhu,Hanxiao Sun,Biyun Han,Jun Wang,Runnan Liu,Wenwu Ou*

Main category: cs.IR

TL;DR: 提出HarmonRank框架，解决直播电商推荐中多目标排序问题，通过排序任务对齐和跨目标对齐，显著提升推荐效果


<details>
  <summary>Details</summary>
Motivation: 直播电商推荐与传统电商不同，需要平衡购买和用户-主播互动等多目标。现有集成模型使用多个独立的二分类损失，存在两个问题：1) 二分类任务的优化方向与排序任务（AUC评估）不一致；2) 忽略了目标之间的对齐关系（如评论和购买行为的相关性）

Method: 提出HarmonRank多目标集成框架：1) 排序对齐：将排序指标AUC公式化为秩和问题，利用可微分排序技术进行排序导向优化；2) 跨目标对齐：将原始一步集成范式改为两步关系感知集成方案

Result: 在两个工业数据集上的离线实验和在线实验表明，该方法显著优于现有最先进方法。已在快手直播电商推荐平台（4亿日活用户）全面部署，贡献超过2%的购买增益

Conclusion: HarmonRank通过同时实现排序任务对齐和跨目标对齐，有效解决了直播电商推荐中的多目标排序问题，显著提升了推荐系统的长期生态效果

Abstract: Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.
  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.
  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.

</details>


### [18] [Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation](https://arxiv.org/abs/2601.02962)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 提出一种新方法，通过递归算法询问技术创建建议树，获取更多潜意识的搜索查询建议，以解决搜索查询建议偏见识别中的数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 搜索查询建议在在线信息搜索中扮演重要角色，但相关研究较少。主要问题在于上下文稀疏性和数据基础有限（每个查询最多10条建议），这给识别搜索查询建议中的偏见带来了显著挑战。

Method: 采用递归算法询问技术，创建搜索建议树，从而获取更多潜意识的搜索查询建议。基于这些建议，研究政治领域中人物相关搜索的主题群体偏见。

Result: 该方法能够深化偏见分析的数据基础，提供了一种替代现有方法的新途径，现有方法主要依赖同一查询随时间变化的后续搜索建议。

Conclusion: 通过递归算法询问构建建议树的方法，为解决搜索查询建议偏见识别中的数据稀疏性问题提供了有效的新方案，特别适用于人物相关政治搜索的主题偏见分析。

Abstract: Despite their important role in online information search, search query suggestions have not been researched as much as most other aspects of search engines. Although reasons for this are multi-faceted, the sparseness of context and the limited data basis of up to ten suggestions per search query pose the most significant problem in identifying bias in search query suggestions. The most proven method to reduce sparseness and improve the validity of bias identification of search query suggestions so far is to consider suggestions from subsequent searches over time for the same query. This work presents a new, alternative approach to search query bias identification that includes less high-level suggestions to deepen the data basis of bias analyses. We employ recursive algorithm interrogation techniques and create suggestion trees that enable access to more subliminal search query suggestions. Based on these suggestions, we investigate topical group bias in person-related searches in the political domain.

</details>


### [19] [Parallel Latent Reasoning for Sequential Recommendation](https://arxiv.org/abs/2601.03153)
*Jiakai Tang,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: PLR提出并行潜在推理框架，通过同时探索多个多样化推理轨迹来解决序列推荐中稀疏行为序列的复杂用户偏好建模问题，超越了传统的深度级推理扩展。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法仅依赖单一轨迹的深度级扩展，随着推理深度增加会出现收益递减问题，无法有效捕捉稀疏行为序列中的复杂用户偏好。

Method: PLR框架通过宽度级计算扩展，在连续潜在空间中构建并行推理流，使用可学习触发令牌，通过全局推理正则化保持流间多样性，并通过混合推理流聚合自适应合成多流输出。

Result: 在三个真实世界数据集上的实验表明，PLR显著优于最先进的基线方法，同时保持实时推理效率。理论分析进一步验证了并行推理在提高泛化能力方面的有效性。

Conclusion: PLR为序列推荐中的推理能力增强开辟了新途径，超越了现有的深度扩展方法，通过并行推理探索实现了更好的用户偏好建模。

Abstract: Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.

</details>


### [20] [Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers](https://arxiv.org/abs/2601.03211)
*Yue Kang,Zhuoyi Huang,Benji Schussheim,Diana Licon,Dina Atia,Shixing Cao,Jacob Danovitch,Kunho Kim,Billy Norcilien,Jonah Karpman,Mahmound Sayed,Mike Taylor,Tao Sun,Pavel Metrikov,Vipul Agarwal,Chris Quirk,Ye-Yi Wang,Nick Craswell,Irene Shaffer,Tianwei Chen,Sulaiman Vesal,Soundar Srinivasan*

Main category: cs.IR

TL;DR: 提出一種高效方法，透過合成數據生成和知識蒸餾，將小型語言模型微調為高品質的相關性標註器，在企業搜索領域實現與大型語言模型相當或更好的標註質量，同時大幅提升吞吐量和成本效益。


<details>
  <summary>Details</summary>
Motivation: 企業搜索中，由於難以獲取標註數據，構建高質量大規模數據集是一大挑戰。現有方法依賴昂貴的大型語言模型進行標註，成本高且吞吐量低，限制了企業級檢索應用的可擴展性。

Method: 1. 使用LLM從種子文檔合成真實的企業查詢；2. 應用BM25檢索困難負樣本；3. 使用教師LLM分配相關性分數；4. 將生成的數據集蒸餾到小型語言模型中，產生緊湊的相關性標註器。

Result: 在923個企業查詢-文檔對的高質量基準測試中，蒸餾後的小型模型與人類判斷的一致性達到或超過教師LLM。吞吐量提升17倍，成本效益提高19倍。

Conclusion: 該方法為企業級檢索應用提供了可擴展且成本效益高的相關性標註解決方案，支持現實環境中的快速離線評估和迭代。

Abstract: In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.

</details>
