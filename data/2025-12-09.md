<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 14]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Enhanced Multimodal Video Retrieval System: Integrating Query Expansion and Cross-modal Temporal Event Retrieval](https://arxiv.org/abs/2512.06334)
*Van-Thinh Vo,Minh-Khoi Nguyen,Minh-Huy Tran,Anh-Quan Nguyen-Tran,Duy-Tan Nguyen,Khanh-Loi Nguyen,Anh-Minh Phan*

Main category: cs.IR

TL;DR: 提出跨模态时序事件检索框架，允许不同查询模态描述序列中的不同场景，通过KDE-GMM算法自适应确定场景转换阈值，提取关键帧作为高质量视觉示例，结合LLM优化查询，在胡志明AI挑战赛2025中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频多模态检索系统通常使用单一查询模态描述整个序列，在复杂时序场景中鲁棒性不足。需要能够支持不同查询模态描述序列中不同场景的检索框架。

Method: 提出跨模态时序事件检索框架：1) 使用KDE-GMM算法自适应确定场景转换和幻灯片变化的决策阈值，实现最优关键帧选择；2) 提取的关键帧作为紧凑高质量视觉示例，保留每个片段的语义本质；3) 结合大语言模型(LLM)优化和扩展用户查询。

Result: 在胡志明AI挑战赛2025中展示了系统的有效性和鲁棒性，取得了优异的检索结果。

Conclusion: 提出的跨模态时序事件检索框架能够有效处理复杂时序场景，通过自适应阈值确定和LLM查询优化，显著提升了视频多模态检索的精度和效率。

Abstract: Multimedia information retrieval from videos remains a challenging problem. While recent systems have advanced multimodal search through semantic, object, and OCR queries - and can retrieve temporally consecutive scenes - they often rely on a single query modality for an entire sequence, limiting robustness in complex temporal contexts. To overcome this, we propose a cross-modal temporal event retrieval framework that enables different query modalities to describe distinct scenes within a sequence. To determine decision thresholds for scene transition and slide change adaptively, we build Kernel Density Gaussian Mixture Thresholding (KDE-GMM) algorithm, ensuring optimal keyframe selection. These extracted keyframes act as compact, high-quality visual exemplars that retain each segment's semantic essence, improving retrieval precision and efficiency. Additionally, the system incorporates a large language model (LLM) to refine and expand user queries, enhancing overall retrieval performance. The proposed system's effectiveness and robustness were demonstrated through its strong results in the Ho Chi Minh AI Challenge 2025.

</details>


### [2] [Beyond Existing Retrievals: Cross-Scenario Incremental Sample Learning Framework](https://arxiv.org/abs/2512.06381)
*Tao Wang,Xun Luo,Jinlong Guo,Yuliang Yan,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: 提出IncRec框架，专注于跨场景增量样本学习，通过构建未被现有模型检索的增量样本和一致性对齐模块，提升推荐系统检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有并行多检索架构在推荐系统中广泛使用，但许多方法在整合跨场景样本时忽略了部分样本已被现有模型检索的事实，导致边际效用递减，无法实现真正的性能提升。

Method: 1. 构建极端跨场景增量样本（未被任何现有模型检索的样本）；2. 设计增量样本学习框架，专注于捕捉增量表示；3. 引入一致性感知对齐模块，使模型偏好具有高曝光概率的增量样本。

Result: 通过离线和在线A/B测试验证了框架的优越性，在淘宝首页推荐中部署IncRec，实现了在线交易量1%的增长，证明了其实际应用价值。

Conclusion: IncRec框架通过专注于跨场景增量样本学习，有效解决了现有检索方法中样本重叠导致的边际效用递减问题，显著提升了推荐系统的检索性能。

Abstract: The parallelized multi-retrieval architecture has been widely adopted in large-scale recommender systems for its computational efficiency and comprehensive coverage of user interests. Many retrieval methods typically integrate additional cross-scenario samples to enhance the overall performance ceiling. However, those model designs neglect the fact that a part of the cross-scenario samples have already been retrieved by existing models within a system, leading to diminishing marginal utility in delivering incremental performance gains. In this paper, we propose a novel retrieval framework IncRec, specifically for cross-scenario incremental sample learning. The innovations of IncRec can be highlighted as two aspects. Firstly, we construct extreme cross-scenario incremental samples that are not retrieved by any existing model. And we design an incremental sample learning framework which focuses on capturing incremental representation to improve the overall retrieval performance. Secondly, we introduce a consistency-aware alignment module to further make the model prefer incremental samples with high exposure probability. Extensive offline and online A/B tests validate the superiority of our framework over state-of-the-art retrieval methods. In particular, we deploy IncRec in the Taobao homepage recommendation, achieving a 1% increase in online transaction count, demonstrating its practical applicability.

</details>


### [3] [Enhancing Medical Cross-Modal Hashing Retrieval using Dropout-Voting Mixture-of-Experts Fusion](https://arxiv.org/abs/2512.06449)
*Jaewon Ahn,Woosung Jang,Beakcheol Jang*

Main category: cs.IR

TL;DR: 提出MCMFH模型，結合dropout voting和MoE對比融合模塊的CLIP跨模態哈希檢索框架，實現高精度、快速檢索和低內存消耗


<details>
  <summary>Details</summary>
Motivation: 醫療領域多模態數據豐富，跨模態檢索對圖像解釋、診斷支持和醫學教育日益重要。隨著醫療數據分佈式整合和數據量激增，需要優化檢索系統的速度、內存效率和準確性

Method: 提出MCMFH模型：1) 基於CLIP的跨模態哈希檢索結構；2) 引入dropout voting機制；3) 混合專家(MoE)對比融合模塊；4) 應用混合損失函數

Result: 在放射學和非放射學醫療數據集上實驗證明，模型能在低內存環境下同時實現高準確性和快速檢索速度

Conclusion: 提出的MCMFH框架有效解決了醫療跨模態檢索中速度、內存和準確性的平衡問題，為醫療數據檢索提供了高效解決方案

Abstract: In recent years, cross-modal retrieval using images and text has become an active area of research, especially in the medical domain. The abundance of data in various modalities in this field has led to a growing importance of cross-modal retrieval for efficient image interpretation, data-driven diagnostic support, and medical education. In the context of the increasing integration of distributed medical data across healthcare facilities with the objective of enhancing interoperability, it is imperative to optimize the performance of retrieval systems in terms of the speed, memory efficiency, and accuracy of the retrieved data. This necessity arises in response to the substantial surge in data volume that characterizes contemporary medical practices. In this study, we propose a novel framework that incorporates dropout voting and mixture-of-experts (MoE) based contrastive fusion modules into a CLIP-based cross-modal hashing retrieval structure. We also propose the application of hybrid loss. So we now call our model MCMFH which is a medical cross-modal fusion hashing retrieval. Our method enables the simultaneous achievement of high accuracy and fast retrieval speed in low-memory environments. The model is demonstrated through experiments on radiological and non-radiological medical datasets.

</details>


### [4] [Towards Efficient Hypergraph and Multi-LLM Agent Recommender Systems](https://arxiv.org/abs/2512.06590)
*Tendai Mukande,Esraa Ali,Annalina Caputo,Ruihai Dong,Noel OConnor*

Main category: cs.IR

TL;DR: HGLMRec：一种基于多LLM代理的推荐系统，使用超图编码器捕捉用户与物品间的复杂多行为关系，通过仅检索相关token降低计算成本并提升性能


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统面临幻觉问题（降低推荐性能）和实际场景中的高计算成本问题，需要一种能同时解决这两个挑战的解决方案

Method: 提出HGLMRec模型，采用多LLM代理架构，集成超图编码器捕捉用户与物品间的复杂多行为关系，在推理时仅检索相关token以减少计算开销

Result: 实验结果显示HGLMRec在较低计算成本下，性能优于现有最先进的基线方法

Conclusion: HGLMRec通过超图编码和多LLM代理架构，有效解决了生成式推荐系统的幻觉和计算成本问题，实现了性能提升与效率优化的平衡

Abstract: Recommender Systems (RSs) have become the cornerstone of various applications such as e-commerce and social media platforms. The evolution of RSs is paramount in the digital era, in which personalised user experience is tailored to the user's preferences. Large Language Models (LLMs) have sparked a new paradigm - generative retrieval and recommendation. Despite their potential, generative RS methods face issues such as hallucination, which degrades the recommendation performance, and high computational cost in practical scenarios. To address these issues, we introduce HGLMRec, a novel Multi-LLM agent-based RS that incorporates a hypergraph encoder designed to capture complex, multi-behaviour relationships between users and items. The HGLMRec model retrieves only the relevant tokens during inference, reducing computational overhead while enriching the retrieval context. Experimental results show performance improvement by HGLMRec against state-of-the-art baselines at lower computational cost.

</details>


### [5] [An Index-based Approach for Efficient and Effective Web Content Extraction](https://arxiv.org/abs/2512.06641)
*Yihan Chen,Benfeng Xu,Xiaorui Wang,Zhendong Mao*

Main category: cs.IR

TL;DR: 提出基于索引的网页内容提取方法，将提取任务从缓慢的生成式过程转变为高效的判别式索引预测，解决了LLM上下文管理中大规模网页处理的问题。


<details>
  <summary>Details</summary>
Motivation: 网络代理（如Deep Research）需要处理大量网页，但现有内容提取方法存在不足：生成式模型延迟高，基于规则的方法缺乏适应性，分块重排序方法忽略网页结构。需要一种既高效又准确的内容提取方案。

Method: 将HTML分割为结构感知、可寻址的片段，然后仅提取与查询相关的内容位置索引。这种方法将提取延迟与内容长度解耦，实现快速、查询相关的提取。

Result: 在RAG QA系统中作为后检索处理组件使用时提高了QA准确性。在两种场景（主要内容提取ME和查询相关提取QE）中，该方法在准确性和速度上都优于现有工作。

Conclusion: 基于索引的网页内容提取方法有效解决了LLM与海量网页之间的差距问题，实现了高效且准确的内容提取，为智能代理和RAG管道提供了基础技术支持。

Abstract: As web agents (e.g., Deep Research) routinely consume massive volumes of web pages to gather and analyze information, LLM context management -- under large token budgets and low signal density -- emerges as a foundational, high-importance, and technically challenging problem for agentic and RAG pipelines. Existing solutions for extracting relevant content are inadequate: generative extraction models suffer from high latency, rule-based heuristics lack adaptability, and chunk-and-rerank methods are blind to webpage structure. To overcome these issues, we introduce Index-based Web Content Extraction to reframe the extraction process from slow, token-by-token generation into a highly efficient, discriminative task of index prediction, achieving both effectiveness and efficiency. We partition HTML into structure-aware, addressable segments, and extract only the positional indices of content relevant to a given query. This method decouples extraction latency from content length, enabling rapid, query-relevant extraction. We first evaluate our method as a post-retrieval processing component within an RAG QA system and find that it improves QA accuracy. Then we directly measure its match rate with the target content in two scenarios: main content extraction (ME) and query-relevant extraction (QE). Experimental results show that our method outperforms existing works in both accuracy and speed, effectively bridging the gap between LLMs and the vast webpages.

</details>


### [6] [Foresight Prediction Enhanced Live-Streaming Recommendation](https://arxiv.org/abs/2512.06700)
*Jiangxia Cao,Ruochen Yang,Xiang Chen,Changxin Lao,Yueyang Liu,Yusheng Huang,Yuanhao Tian,Xiangyu Wu,Shuang Yang,Zhaojie Liu,Guorui Zhou*

Main category: cs.IR

TL;DR: 论文提出一种直播推荐方法，通过语义量化直播片段获取语义ID，编码历史序列捕捉作者特征，建模语义ID演化趋势来预测未来内容，从而提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 直播作为一种新兴媒体，内容动态变化且时间敏感，对推荐算法提出了更高要求。研究发现用户在直播高光时刻体验更好且行为更积极，但由于推荐时模型无法访问未来内容，而用户参与度取决于后续内容是否符合其兴趣，因此需要预测未来直播内容。

Method: 1. 对直播片段进行语义量化获得语义ID；2. 编码历史语义ID序列捕捉作者特征；3. 建模语义ID演化趋势以实现对未来内容的预见性预测；4. 将这种预见性通过精细化特征增强排序模型。

Result: 通过大量离线和在线实验验证了方法的有效性。

Conclusion: 提出的方法能够有效预测直播未来内容，通过语义量化和演化趋势建模提升推荐系统性能，改善用户体验。

Abstract: Live-streaming, as an emerging media enabling real-time interaction between authors and users, has attracted significant attention. Unlike the stable playback time of traditional TV live or the fixed content of short video, live-streaming, due to the dynamics of content and time, poses higher requirements for the recommendation algorithm of the platform - understanding the ever-changing content in real time and push it to users at the appropriate moment. Through analysis, we find that users have a better experience and express more positive behaviors during highlight moments of the live-streaming. Furthermore, since the model lacks access to future content during recommendation, yet user engagement depends on how well subsequent content aligns with their interests, an intuitive solution is to predict future live-streaming content. Therefore, we perform semantic quantization on live-streaming segments to obtain Semantic ids (Sid), encode the historical Sid sequence to capture the author's characteristics, and model Sid evolution trend to enable foresight prediction of future content. This foresight enhances the ranking model through refined features. Extensive offline and online experiments demonstrate the effectiveness of our method.

</details>


### [7] [WisPaper: Your AI Scholar Search Engine](https://arxiv.org/abs/2512.06879)
*Li Ju,Jun Zhao,Mingxu Chai,Ziyu Shen,Xiangyang Wang,Yage Geng,Chunchun Ma,Hao Peng,Guangbin Li,Tao Li,Chengyong Liao,Fu Wang,Xiaolong Wang,Junshen Chen,Rui Gong,Shijia Liang,Feiyan Li,Ming Zhang,Kexin Tan,Jujie Ye,Zhiheng Xi,Shihan Dou,Tao Gui,Yuankai Ying,Yang Shi,Yue Zhang,Qi Zhang*

Main category: cs.IR

TL;DR: WisPaper是一个智能学术检索与文献管理平台，集成了学者搜索、文献库和AI推荐三大功能，为研究人员提供从发现到管理的闭环工作流。


<details>
  <summary>Details</summary>
Motivation: 随着科学出版物呈指数级增长，研究人员难以高效定位和管理相关文献。现有学术工具无法提供从文献发现到持续跟踪的完整闭环工作流。

Method: WisPaper通过三个集成功能解决这一问题：1) Scholar Search（快速关键词搜索和深度智能搜索模式）；2) Library（可定制的知识库用于系统化文献组织）；3) AI Feeds（基于用户兴趣自动推荐相关新出版物的智能推荐系统）。

Result: 该多语言、多学科系统显著减少了不同背景研究人员在文献筛选和管理上花费的时间，使他们能够专注于核心研究活动。平台已公开可用，服务于学术界和工业界的研究人员。

Conclusion: WisPaper提供了一个独特的闭环工作流，无缝连接文献发现、管理和研究前沿的持续跟踪，解决了现有学术工具的局限性，提升了研究效率。

Abstract: Researchers struggle to efficiently locate and manage relevant literature within the exponentially growing body of scientific publications. We present \textsc{WisPaper}, an intelligent academic retrieval and literature management platform that addresses this challenge through three integrated capabilities: (1) \textit{Scholar Search}, featuring both quick keyword-based and deep agentic search modes for efficient paper discovery; (2) \textit{Library}, a customizable knowledge base for systematic literature organization; and (3) \textit{AI Feeds}, an intelligent recommendation system that automatically delivers relevant new publications based on user interests. Unlike existing academic tools, \textsc{WisPaper} provides a closed-loop workflow that seamlessly connects literature discovery, management, and continuous tracking of research frontiers. Our multilingual and multidisciplinary system significantly reduces the time researchers from diverse backgrounds spend on paper screening and management, enabling them to focus on their core research activities. The platform is publicly accessible and serves researchers across academia and industry.

</details>


### [8] [Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation](https://arxiv.org/abs/2512.06883)
*Zhongtao Rao,Peilin Zhou,Dading Chong,Zhiwei Chen,Shoujin Wang,Nan Tang*

Main category: cs.IR

TL;DR: SDA框架通过结构对齐和模态解耦适配，解决多模态推荐中LVLMs的表示不对齐和梯度冲突问题，显著提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 多模态推荐依赖高质量跨模态表示，大型视觉语言模型(LVLMs)提供了统一表示学习能力，但应用于推荐时面临两个挑战：1) 表示不对齐（领域差距导致嵌入空间不匹配），2) 梯度冲突（共享适配器导致干扰和判别能力不足）

Method: 提出SDA框架，包含两个组件：1) 跨模态结构对齐(CMSA)：使用模态内结构作为软教师对齐嵌入；2) 模态解耦适配(MoDA)：通过专家化、门控低秩路径解耦梯度流，缓解梯度冲突

Result: 在三个Amazon数据集上，SDA与现有多模态和序列推荐器无缝集成，平均提升Hit@10 6.15%，NDCG@10 8.64%，长尾物品上分别提升12.83%和18.70%，推理开销最小

Conclusion: SDA有效解决了LVLMs在推荐中的表示不对齐和梯度冲突问题，显著提升了多模态推荐性能，特别是在长尾物品上表现突出

Abstract: Multimodal recommendation enhances accuracy by leveraging visual and textual signals, and its success largely depends on learning high-quality cross-modal representations. Recent advances in Large Vision-Language Models (LVLMs) offer unified multimodal representation learning, making them a promising backbone. However, applying LVLMs to recommendation remains challenging due to (i) representation misalignment, where domain gaps between item data and general pre-training lead to unaligned embedding spaces, and (ii) gradient conflicts during fine-tuning, where shared adapters cause interference and a lack of discriminative power. To address this, we propose SDA, a lightweight framework for Structural and Disentangled Adaptation, which integrates two components: Cross-Modal Structural Alignment (CMSA) and Modality-Disentangled Adaptation. CMSA aligns embeddings using intra-modal structures as a soft teacher, while MoDA mitigates gradient conflicts via expertized, gated low-rank paths to disentangle gradient flows. Experiments on three public Amazon datasets show SDA integrates seamlessly with existing multimodal and sequential recommenders, yielding average gains of 6.15% in Hit@10 and 8.64% in NDCG@10. It also achieves up to 12.83% and 18.70% gains on long-tail items with minimal inference overhead. Our code and full experimental results are available at https://github.com/RaoZhongtao/SDA.

</details>


### [9] [Benchmarking Deep Neural Networks for Modern Recommendation Systems](https://arxiv.org/abs/2512.07000)
*Abderaouf Bahi,Ibtissem Gasmi*

Main category: cs.IR

TL;DR: 论文评估了七种神经网络架构在三个推荐系统数据集上的表现，发现GNN擅长处理电商复杂关系，RNN适合时序动态，Siamese网络能提升推荐多样性，建议采用混合方法平衡准确性与多样性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过系统评估不同神经网络架构在推荐系统中的应用效果，为开发更有效的推荐系统提供指导，解决现有模型在准确性、多样性、计算效率等方面的平衡问题。

Method: 在三个数据集（零售电商、亚马逊产品、Netflix Prize）上部署七种神经网络架构（CNN、RNN、GNN、Autoencoder、Transformer、NCF、Siamese Networks），使用准确率、召回率、F1分数和多样性等指标进行评估。

Result: GNN在电商环境中处理复杂物品关系表现最佳；RNN在Netflix等平台的时序动态捕捉中效果显著；Siamese网络在零售场景中能有效提升推荐多样性。所有模型都面临计算需求高、数据依赖性强、准确性与多样性难以平衡等问题。

Conclusion: 建议采用混合方法结合不同模型的优势，以更好地满足用户偏好和适应现代数字平台的演进需求，推动推荐系统的发展。

Abstract: This paper examines the deployment of seven different neural network architectures CNN, RNN, GNN, Autoencoder, Transformer, NCF, and Siamese Networks on three distinct datasets: Retail E-commerce, Amazon Products, and Netflix Prize. It evaluates their effectiveness through metrics such as accuracy, recall, F1-score, and diversity in recommendations. The results demonstrate that GNNs are particularly adept at managing complex item relationships in e-commerce environments, whereas RNNs are effective in capturing the temporal dynamics that are essential for platforms such as Netflix.. Siamese Networks are emphasized for their contribution to the diversification of recommendations, particularly in retail settings. Despite their benefits, issues like computational demands, reliance on extensive data, and the challenge of balancing accurate and diverse recommendations are addressed. The study seeks to inform the advancement of recommendation systems by suggesting hybrid methods that merge the strengths of various models to better satisfy user preferences and accommodate the evolving demands of contemporary digital platforms.

</details>


### [10] [MUSE: A Simple Yet Effective Multimodal Search-Based Framework for Lifelong User Interest Modeling](https://arxiv.org/abs/2512.07216)
*Bin Wu,Feifan Yang,Zhangming Chan,Yu-Ran Gu,Jiawei Feng,Chao Yi,Xiang-Rong Sheng,Han Zhu,Jian Xu,Mang Ye,Bo Zheng*

Main category: cs.IR

TL;DR: MUSE是一个用于淘宝展示广告系统的多模态搜索框架，通过简单高效的检索机制处理超长用户行为序列，在工业部署中显著提升推荐效果


<details>
  <summary>Details</summary>
Motivation: 现有终身用户兴趣建模方法主要依赖ID特征，在长尾项目上泛化能力差且语义表达能力有限。虽然最近工作探索了在通用搜索单元(GSU)中使用多模态表示进行行为检索，但往往忽略了在精确搜索单元(ESU)的细粒度建模阶段的多模态整合

Method: 提出MUSE多模态搜索框架，采用两阶段方法：在GSU阶段使用轻量级余弦相似度与高质量多模态嵌入进行检索；在ESU阶段进行丰富的多模态序列建模和有效的ID-多模态融合。支持10万长度的用户行为序列建模

Result: 已在淘宝展示广告系统部署，能够处理10万长度的用户行为序列，在关键指标上取得显著提升，且在线延迟开销可忽略不计。同时开源了首个包含超长行为序列和高质量多模态嵌入的大规模数据集

Conclusion: 通过系统分析发现，在GSU阶段简单性足够，而ESU阶段需要丰富的多模态序列建模和融合。MUSE框架简单有效，已在工业场景成功部署，为社区研究提供了宝贵资源和实践经验

Abstract: Lifelong user interest modeling is crucial for industrial recommender systems, yet existing approaches rely predominantly on ID-based features, suffering from poor generalization on long-tail items and limited semantic expressiveness. While recent work explores multimodal representations for behavior retrieval in the General Search Unit (GSU), they often neglect multimodal integration in the fine-grained modeling stage -- the Exact Search Unit (ESU). In this work, we present a systematic analysis of how to effectively leverage multimodal signals across both stages of the two-stage lifelong modeling framework. Our key insight is that simplicity suffices in the GSU: lightweight cosine similarity with high-quality multimodal embeddings outperforms complex retrieval mechanisms. In contrast, the ESU demands richer multimodal sequence modeling and effective ID-multimodal fusion to unlock its full potential. Guided by these principles, we propose MUSE, a simple yet effective multimodal search-based framework. MUSE has been deployed in Taobao display advertising system, enabling 100K-length user behavior sequence modeling and delivering significant gains in top-line metrics with negligible online latency overhead. To foster community research, we share industrial deployment practices and open-source the first large-scale dataset featuring ultra-long behavior sequences paired with high-quality multimodal embeddings. Our code and data is available at https://taobao-mm.github.io.

</details>


### [11] [On the Impact of Graph Neural Networks in Recommender Systems: A Topological Perspective](https://arxiv.org/abs/2512.07384)
*Daniele Malitesta,Claudio Pomo,Vito Walter Anelli,Alberto Carlo Maria Mancino,Alejandro Bellogín,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 该专著从拓扑学角度分析GNN推荐系统，提出统一的概念框架，将数据集特征与模型性能联系起来，为下一代拓扑感知推荐系统指明方向。


<details>
  <summary>Details</summary>
Motivation: 尽管GNN在推荐系统中表现出色，但其相对于传统协同过滤方法的系统优势原因尚不完全清楚。作者认为需要从用户-物品图的结构特性及其与GNN架构设计的交互角度来全面理解这些模型的性能。

Method: 1) 提出以拓扑为中心的分析视角；2) 建立形式化分类法，将11种代表性GNN推荐方法统一为概念管道；3) 形式化13个经典和拓扑数据集特征；4) 分析GNN推荐架构如何编码这些特性；5) 构建解释性框架，将可测量的数据集特征与模型行为和性能联系起来。

Result: 建立了GNN推荐系统的拓扑学分析框架，揭示了数据集结构特性与模型性能之间的关系，为理解GNN推荐优势提供了理论解释。

Conclusion: 该专著通过拓扑学基础重新构建了GNN推荐系统，并指出了下一代拓扑感知推荐系统在理论、数据中心和评估方面的开放挑战。

Abstract: In recommender systems, user-item interactions can be modeled as a bipartite graph, where user and item nodes are connected by undirected edges. This graph-based view has motivated the rapid adoption of graph neural networks (GNNs), which often outperform collaborative filtering (CF) methods such as latent factor models, deep neural networks, and generative strategies. Yet, despite their empirical success, the reasons why GNNs offer systematic advantages over other CF approaches remain only partially understood. This monograph advances a topology-centered perspective on GNN-based recommendation. We argue that a comprehensive understanding of these models' performance should consider the structural properties of user-item graphs and their interaction with GNN architectural design. To support this view, we introduce a formal taxonomy that distills common modeling patterns across eleven representative GNN-based recommendation approaches and consolidates them into a unified conceptual pipeline. We further formalize thirteen classical and topological characteristics of recommendation datasets and reinterpret them through the lens of graph machine learning. Using these definitions, we analyze the considered GNN-based recommender architectures to assess how and to what extent they encode such properties. Building on this analysis, we derive an explanatory framework that links measurable dataset characteristics to model behavior and performance. Taken together, this monograph re-frames GNN-based recommendation through its topological underpinnings and outlines open theoretical, data-centric, and evaluation challenges for the next generation of topology-aware recommender systems.

</details>


### [12] [OnePiece: The Great Route to Generative Recommendation -- A Case Study from Tencent Algorithm Competition](https://arxiv.org/abs/2512.07424)
*Jiangxia Cao,Shuo Yang,Zijun Wang,Qinghai Tan*

Main category: cs.IR

TL;DR: 论文探讨生成式推荐系统是否遵循缩放定律，通过统一编码器-解码器框架验证ANN和自回归两种范式的缩放规律，发现两者损失都严格遵循幂律缩放定律。


<details>
  <summary>Details</summary>
Motivation: 受到OpenAI缩放定律在语言模型中的启发，研究者想知道生成式推荐系统是否也存在类似的缩放定律。生成式推荐通常指检索阶段，但没有真实的下一个物品作为监督信号，这引发了一个哲学问题：生成式推荐是否也存在潜在的缩放定律？

Method: 设计了一个统一的编码器-解码器框架，同时验证两种生成式推荐技术范式：1) ANN-based框架（使用压缩用户嵌入在嵌入空间中检索最近邻物品）；2) 自回归框架（使用beam search从整个空间解码物品）。在该统一架构下验证它们的缩放定律。

Result: 实证发现两种范式的损失都严格遵循幂律缩放定律（R²>0.9），表明生成式推荐系统确实存在缩放定律。

Conclusion: 生成式推荐系统确实存在缩放定律，ANN和自回归两种范式在统一架构下都表现出严格的幂律缩放关系，这为推荐系统的规模化发展提供了理论依据。

Abstract: In past years, the OpenAI's Scaling-Laws shows the amazing intelligence with the next-token prediction paradigm in neural language modeling, which pointing out a free-lunch way to enhance the model performance by scaling the model parameters. In RecSys, the retrieval stage is also follows a 'next-token prediction' paradigm, to recall the hunderds of items from the global item set, thus the generative recommendation usually refers specifically to the retrieval stage (without Tree-based methods). This raises a philosophical question: without a ground-truth next item, does the generative recommendation also holds a potential scaling law? In retrospect, the generative recommendation has two different technique paradigms: (1) ANN-based framework, utilizing the compressed user embedding to retrieve nearest other items in embedding space, e.g, Kuaiformer. (2) Auto-regressive-based framework, employing the beam search to decode the item from whole space, e.g, OneRec. In this paper, we devise a unified encoder-decoder framework to validate their scaling-laws at same time. Our empirical finding is that both of their losses strictly adhere to power-law Scaling Laws ($R^2$>0.9) within our unified architecture.

</details>


### [13] [From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models](https://arxiv.org/abs/2512.07452)
*Clarisse Bardiot,Pierre-Carl Langlais,Bernard Jacquemin,Jacob Hart,Antonios Lagarias,Nicolas Foucault,Aurélie Lemaître-Legargeant,Jeanne Fras*

Main category: cs.IR

TL;DR: 提出一个结合多模态大语言模型、本体推理模型和Linked Art框架的工作流，将剧院节目单转化为结构化数据，实现大规模、可互操作的表演艺术数据分析。


<details>
  <summary>Details</summary>
Motivation: 许多文化遗产机构收藏了大量剧院节目单，但由于其复杂布局和缺乏结构化元数据，这些资源大多未被充分利用。需要一种方法将这些文档转化为结构化数据，以支持大规模表演艺术数据分析。

Method: 1) 使用视觉-语言模型准确解析和转录数字原生和数字化节目单；2) 训练基于本体的推理模型(POntAvignon)，采用强化学习方法结合形式化和语义化奖励；3) 扩展Linked Art框架，实现自动RDF三元组生成并与现有知识图谱对齐。

Result: 视觉-语言模型实现了超过98%的正确提取率。通过阿维尼翁艺术节语料库的案例研究，展示了大规模、本体驱动的表演艺术数据分析潜力。该方法支持可互操作、可解释和可持续的计算戏剧史学。

Conclusion: 提出的工作流成功将复杂剧院节目单转化为结构化数据，为文化遗产机构提供了新的分析可能性。该方法结合多模态LLM、本体推理和Linked Art框架，实现了自动化、可扩展的表演艺术数据转换，为计算戏剧史学开辟了新途径。

Abstract: Many heritage institutions hold extensive collections of theatre programmes, which remain largely underused due to their complex layouts and lack of structured metadata. In this paper, we present a workflow for transforming such documents into structured data using a combination of multimodal large language models (LLMs), an ontology-based reasoning model, and a custom extension of the Linked Art framework. We show how vision-language models can accurately parse and transcribe born-digital and digitised programmes, achieving over 98% of correct extraction. To overcome the challenges of semantic annotation, we train a reasoning model (POntAvignon) using reinforcement learning with both formal and semantic rewards. This approach enables automated RDF triple generation and supports alignment with existing knowledge graphs. Through a case study based on the Festival d'Avignon corpus, we demonstrate the potential for large-scale, ontology-driven analysis of performing arts data. Our results open new possibilities for interoperable, explainable, and sustainable computational theatre historiography.

</details>


### [14] [Exploring Test-time Scaling via Prediction Merging on Large-Scale Recommendation](https://arxiv.org/abs/2512.07650)
*Fuyuan Lyu,Zhentai Chen,Jingyan Jiang,Lingjie Li,Xing Tang,Xiuqiang He,Xue Liu*

Main category: cs.IR

TL;DR: 提出测试时扩展方法，通过模型架构异质性或同构模型随机初始化生成多样化输出，在相同推理预算下优于参数扩展，并可无缝加速部署


<details>
  <summary>Details</summary>
Motivation: 虽然语言模型成功推动了推荐系统的扩展，但现有方法主要关注训练时参数扩展，测试时如何高效利用计算资源仍未被充分探索。测试时扩展可作为正交改进方向，为推荐系统带来新的扩展效率提升

Method: 提出两种测试时扩展方法：1) 利用不同模型架构的异质性生成多样化输出；2) 在同构架构下利用模型初始化的随机性生成多样化输出。在8个模型（包括经典和SOTA模型）和3个基准上进行评估

Result: 两种解决方案均被证明有效。在相同推理预算下，测试时扩展能够超越参数扩展。测试时扩展还可随着并行服务器增加而无缝加速，且不影响用户端推理时间

Conclusion: 测试时扩展是推荐系统扩展的有效正交方法，能够高效利用计算资源，在相同预算下优于传统参数扩展，并支持在线部署时的无缝加速

Abstract: Inspired by the success of language models (LM), scaling up deep learning recommendation systems (DLRS) has become a recent trend in the community. All previous methods tend to scale up the model parameters during training time. However, how to efficiently utilize and scale up computational resources during test time remains underexplored, which can prove to be a scaling-efficient approach and bring orthogonal improvements in LM domains. The key point in applying test-time scaling to DLRS lies in effectively generating diverse yet meaningful outputs for the same instance. We propose two ways: One is to explore the heterogeneity of different model architectures. The other is to utilize the randomness of model initialization under a homogeneous architecture. The evaluation is conducted across eight models, including both classic and SOTA models, on three benchmarks. Sufficient evidence proves the effectiveness of both solutions. We further prove that under the same inference budget, test-time scaling can outperform parameter scaling. Our test-time scaling can also be seamlessly accelerated with the increase in parallel servers when deployed online, without affecting the inference time on the user side. Code is available.

</details>
