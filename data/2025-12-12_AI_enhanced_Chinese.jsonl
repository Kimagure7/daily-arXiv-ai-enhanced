{"id": "2512.10149", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10149", "abs": "https://arxiv.org/abs/2512.10149", "authors": ["Han Chen", "Steven Zhu", "Yingrui Li"], "title": "STARS: Semantic Tokens with Augmented Representations for Recommendation at Scale", "comment": null, "summary": "Real-world ecommerce recommender systems must deliver relevant items under strict tens-of-milliseconds latency constraints despite challenges such as cold-start products, rapidly shifting user intent, and dynamic context including seasonality, holidays, and promotions. We introduce STARS, a transformer-based sequential recommendation framework built for large-scale, low-latency ecommerce settings. STARS combines several innovations: dual-memory user embeddings that separate long-term preferences from short-term session intent; semantic item tokens that fuse pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, strengthening content-based matching, long-tail coverage, and cold-start performance; context-aware scoring with learned calendar and event offsets; and a latency-conscious two-stage retrieval pipeline that performs offline embedding generation and online maximum inner-product search with filtering, enabling tens-of-milliseconds response times. In offline evaluations on production-scale data, STARS improves Hit@5 by more than 75 percent relative to our existing LambdaMART system. A large-scale A/B test on 6 million visits shows statistically significant lifts, including Total Orders +0.8%, Add-to-Cart on Home +2.0%, and Visits per User +0.5%. These results demonstrate that combining semantic enrichment, multi-intent modeling, and deployment-oriented design can yield state-of-the-art recommendation quality in real-world environments without sacrificing serving efficiency.", "AI": {"tldr": "STARS\u662f\u4e00\u4e2a\u4e3a\u5927\u89c4\u6a21\u3001\u4f4e\u5ef6\u8fdf\u7535\u5546\u573a\u666f\u8bbe\u8ba1\u7684Transformer\u5e8f\u5217\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8bb0\u5fc6\u7528\u6237\u5d4c\u5165\u3001\u8bed\u4e49\u7269\u54c1\u6807\u8bb0\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u8bc4\u5206\u548c\u5ef6\u8fdf\u654f\u611f\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u7ba1\u9053\uff0c\u5728\u4fdd\u6301\u6beb\u79d2\u7ea7\u54cd\u5e94\u65f6\u95f4\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u7535\u5546\u63a8\u8350\u7cfb\u7edf\u5728\u51b7\u542f\u52a8\u4ea7\u54c1\u3001\u5feb\u901f\u53d8\u5316\u7684\u7528\u6237\u610f\u56fe\u3001\u52a8\u6001\u4e0a\u4e0b\u6587\uff08\u5b63\u8282\u6027\u3001\u8282\u5047\u65e5\u3001\u4fc3\u9500\uff09\u7b49\u6311\u6218\u4e0b\uff0c\u4ecd\u9700\u6ee1\u8db3\u4e25\u683c\u7684\u6beb\u79d2\u7ea7\u5ef6\u8fdf\u7ea6\u675f\u7684\u73b0\u5b9e\u9700\u6c42\u3002", "method": "1. \u53cc\u8bb0\u5fc6\u7528\u6237\u5d4c\u5165\uff1a\u5206\u79bb\u957f\u671f\u504f\u597d\u548c\u77ed\u671f\u4f1a\u8bdd\u610f\u56fe\uff1b2. \u8bed\u4e49\u7269\u54c1\u6807\u8bb0\uff1a\u878d\u5408\u9884\u8bad\u7ec3\u6587\u672c\u5d4c\u5165\u3001\u53ef\u5b66\u4e60\u589e\u91cf\u3001LLM\u751f\u6210\u7684\u5c5e\u6027\u6807\u7b7e\uff1b3. \u4e0a\u4e0b\u6587\u611f\u77e5\u8bc4\u5206\uff1a\u5b66\u4e60\u65e5\u5386\u548c\u4e8b\u4ef6\u504f\u79fb\uff1b4. \u5ef6\u8fdf\u654f\u611f\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u7ba1\u9053\uff1a\u79bb\u7ebf\u5d4c\u5165\u751f\u6210\u548c\u5728\u7ebf\u6700\u5927\u5185\u79ef\u641c\u7d22\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u4e2d\uff0cSTARS\u76f8\u6bd4\u73b0\u6709LambdaMART\u7cfb\u7edf\u63d0\u5347Hit@5\u8d85\u8fc775%\uff1b\u5927\u89c4\u6a21A/B\u6d4b\u8bd5\uff08600\u4e07\u6b21\u8bbf\u95ee\uff09\u663e\u793a\u663e\u8457\u63d0\u5347\uff1a\u603b\u8ba2\u5355+0.8%\uff0c\u9996\u9875\u52a0\u8d2d+2.0%\uff0c\u7528\u6237\u8bbf\u95ee\u6b21\u6570+0.5%\u3002", "conclusion": "\u7ed3\u5408\u8bed\u4e49\u589e\u5f3a\u3001\u591a\u610f\u56fe\u5efa\u6a21\u548c\u9762\u5411\u90e8\u7f72\u7684\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u670d\u52a1\u6548\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u63a8\u8350\u8d28\u91cf\u3002"}}
{"id": "2512.10388", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10388", "abs": "https://arxiv.org/abs/2512.10388", "authors": ["Ziwei Liu", "Yejing Wang", "Qidong Liu", "Zijian Zhang", "Chong Chen", "Wei Huang", "Xiangyu Zhao"], "title": "The Best of the Two Worlds: Harmonizing Semantic and Hash IDs for Sequential Recommendation", "comment": null, "summary": "Conventional Sequential Recommender Systems (SRS) typically assign unique Hash IDs (HID) to construct item embeddings. These HID embeddings effectively learn collaborative information from historical user-item interactions, making them vulnerable to situations where most items are rarely consumed (the long-tail problem). Recent methods that incorporate auxiliary information often suffer from noisy collaborative sharing caused by co-occurrence signals or semantic homogeneity caused by flat dense embeddings. Semantic IDs (SIDs), with their capability of code sharing and multi-granular semantic modeling, provide a promising alternative. However, the collaborative overwhelming phenomenon hinders the further development of SID-based methods. The quantization mechanisms commonly compromise the uniqueness of identifiers required for modeling head items, creating a performance seesaw between head and tail items. To address this dilemma, we propose \\textbf{\\name}, a novel framework that harmonizes the SID and HID. Specifically, we devise a dual-branch modeling architecture that enables the model to capture both the multi-granular semantics within SID while preserving the unique collaborative identity of HID. Furthermore, we introduce a dual-level alignment strategy that bridges the two representations, facilitating knowledge transfer and supporting robust preference modeling. Extensive experiments on three real-world datasets show that \\name~ effectively balances recommendation quality for both head and tail items while surpassing the existing baselines. The implementation code can be found online\\footnote{https://github.com/ziwliu8/H2Rec}.", "AI": {"tldr": "\u63d0\u51faH2Rec\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u8bed\u4e49ID\u548c\u54c8\u5e0cID\u6765\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u5934\u90e8\u548c\u5c3e\u90e8\u7269\u54c1\u7684\u6027\u80fd\u6743\u8861\u95ee\u9898", "motivation": "\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u4f7f\u7528\u54c8\u5e0cID\u5b58\u5728\u957f\u5c3e\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u8bed\u4e49ID\u7684\u65b9\u6cd5\u53c8\u9762\u4e34\u534f\u4f5c\u538b\u5012\u73b0\u8c61\uff0c\u5bfc\u81f4\u5934\u90e8\u548c\u5c3e\u90e8\u7269\u54c1\u6027\u80fd\u6743\u8861", "method": "\u8bbe\u8ba1\u53cc\u5206\u652f\u5efa\u6a21\u67b6\u6784\uff0c\u540c\u65f6\u6355\u6349\u8bed\u4e49ID\u7684\u591a\u7c92\u5ea6\u8bed\u4e49\u548c\u54c8\u5e0cID\u7684\u72ec\u7279\u534f\u4f5c\u8eab\u4efd\uff1b\u5f15\u5165\u53cc\u7ea7\u5bf9\u9f50\u7b56\u7565\u6865\u63a5\u4e24\u79cd\u8868\u793a", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cH2Rec\u80fd\u6709\u6548\u5e73\u8861\u5934\u90e8\u548c\u5c3e\u90e8\u7269\u54c1\u7684\u63a8\u8350\u8d28\u91cf\uff0c\u5e76\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "H2Rec\u6846\u67b6\u6210\u529f\u534f\u8c03\u4e86\u8bed\u4e49ID\u548c\u54c8\u5e0cID\uff0c\u89e3\u51b3\u4e86\u5e8f\u5217\u63a8\u8350\u4e2d\u5934\u90e8\u548c\u5c3e\u90e8\u7269\u54c1\u7684\u6027\u80fd\u6743\u8861\u95ee\u9898"}}
{"id": "2512.10688", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10688", "abs": "https://arxiv.org/abs/2512.10688", "authors": ["Lingfeng Liu", "Yixin Song", "Dazhong Shen", "Bing Yin", "Hao Li", "Yanyong Zhang", "Chao Wang"], "title": "Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition", "comment": "Accepted by SIGKDD 2026(First Cycle)", "summary": "Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant \"popularity direction\" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u8d1d\u53f6\u65af\u6210\u5bf9\u6392\u5e8f\u4f18\u5316\u4e2d\u7684\u6d41\u884c\u5ea6\u504f\u5dee\u662f\u51e0\u4f55\u7ed3\u6784\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b9\u5411\u5206\u89e3\u4e0e\u6821\u6b63\u6846\u67b6\u6765\u4ece\u51e0\u4f55\u6839\u6e90\u89e3\u8026\u504f\u597d\u4e0e\u6d41\u884c\u5ea6", "motivation": "\u6d41\u884c\u5ea6\u504f\u5dee\u4e25\u91cd\u635f\u5bb3\u4e86\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u7684\u4e2a\u6027\u5316\u80fd\u529b\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u63a8\u8350\u70ed\u95e8\u9879\u76ee\u800c\u5ffd\u89c6\u7528\u6237\u5bf9\u5229\u57fa\u5185\u5bb9\u7684\u771f\u5b9e\u504f\u597d\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u5176\u89c6\u4e3a\u5916\u90e8\u6df7\u6742\u56e0\u7d20\uff0c\u4f46\u672c\u6587\u53d1\u73b0\u8fd9\u662fBPR\u4f18\u5316\u4e2d\u7684\u5185\u5728\u51e0\u4f55\u4f2a\u5f71", "method": "\u63d0\u51fa\u65b9\u5411\u5206\u89e3\u4e0e\u6821\u6b63\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u5bf9\u79f0\u65b9\u5411\u66f4\u65b0\u6765\u7ea0\u6b63\u5d4c\u5165\u51e0\u4f55\u3002\u8be5\u6846\u67b6\u5f15\u5bfc\u6b63\u5411\u4ea4\u4e92\u6cbf\u4e2a\u6027\u5316\u504f\u597d\u65b9\u5411\uff0c\u540c\u65f6\u4f7f\u8d1f\u5411\u4ea4\u4e92\u8fdc\u79bb\u5168\u5c40\u6d41\u884c\u5ea6\u65b9\u5411\uff0c\u4ece\u51e0\u4f55\u6e90\u5934\u89e3\u8026\u504f\u597d\u4e0e\u6d41\u884c\u5ea6", "result": "\u5728\u591a\u4e2a\u57fa\u4e8eBPR\u7684\u67b6\u6784\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cDDC\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u53bb\u504f\u65b9\u6cd5\uff0c\u5c06\u8bad\u7ec3\u635f\u5931\u964d\u4f4e\u5230\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u76845%\u4ee5\u4e0b\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u597d\u7684\u63a8\u8350\u8d28\u91cf\u548c\u516c\u5e73\u6027", "conclusion": "\u6d41\u884c\u5ea6\u504f\u5dee\u662fBPR\u4f18\u5316\u4e2d\u7684\u5185\u5728\u51e0\u4f55\u95ee\u9898\uff0c\u901a\u8fc7\u65b9\u5411\u5206\u89e3\u4e0e\u6821\u6b63\u6846\u67b6\u53ef\u4ee5\u4ece\u51e0\u4f55\u6839\u6e90\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u53bb\u504f\u6548\u679c"}}
