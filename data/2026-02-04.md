<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Design and Evaluation of Whole-Page Experience Optimization for E-commerce Search](https://arxiv.org/abs/2602.02514)
*Pratik Lahiri,Bingqing Ge,Zhou Qin,Aditya Jumde,Shuning Huo,Lucas Scottini,Yi Liu,Mahmoud Mamlouk,Wenyang Liu*

Main category: cs.IR

TL;DR: 提出一个全页面体验优化框架，解决电商搜索结果页从线性列表向复杂非线性布局转变的问题，同时优化长期用户满意度指标


<details>
  <summary>Details</summary>
Motivation: 电商搜索结果页正从线性列表演变为复杂的非线性布局，传统基于位置的排序模型已不足够。现有优化框架通常只最大化短期信号（如点击率、当日收入），而长期满意度指标（如预期两周收入）涉及延迟反馈和长期信用分配难题

Method: 提出全页面体验优化框架，明确建模商品相关性、二维位置布局和视觉元素之间的相互作用。使用因果框架基于准实验数据开发长期用户满意度度量指标

Result: 通过行业规模的A/B测试验证，模型在品牌相关性（主要客户体验指标）上提升了1.86%，同时实现了+0.05%的统计显著收入增长

Conclusion: 该框架成功解决了电商搜索结果页复杂布局下的优化问题，能够同时提升短期和长期业务指标，为电商平台提供了有效的全页面体验优化方案

Abstract: E-commerce Search Results Pages (SRPs) are evolving from linear lists to complex, non-linear layouts, rendering traditional position-biased ranking models insufficient. Moreover, existing optimization frameworks typically maximize short-term signals (e.g., clicks, same-day revenue) because long-term satisfaction metrics (e.g., expected two-week revenue) involve delayed feedback and challenging long-horizon credit attribution. To bridge these gaps, we propose a novel Whole-Page Experience Optimization Framework. Unlike traditional list-wise rankers, our approach explicitly models the interplay between item relevance, 2D positional layout, and visual elements. We use a causal framework to develop metrics for measuring long-term user satisfaction based on quasi-experimental data. We validate our approach through industry-scale A/B testing, where the model demonstrated a 1.86% improvement in brand relevance (our primary customer experience metric) while simultaneously achieving a statistically significant revenue uplift of +0.05%

</details>


### [2] [Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval](https://arxiv.org/abs/2602.02827)
*Roi Pony,Adi Raz,Oshri Naparstek,Idan Friedman,Udi Barzelay*

Main category: cs.IR

TL;DR: Col-Bandit是一种查询时剪枝算法，通过将重排序建模为有限群体Top-K识别问题，自适应地揭示必要的MaxSim条目，在保持排序质量的同时将计算量减少5倍。


<details>
  <summary>Details</summary>
Motivation: 多向量延迟交互检索器（如ColBERT）在查询时需要为每个候选文档计算token级别的MaxSim交互，计算成本高昂。现有的单向量近似方法虽然降低了成本，但往往导致显著的准确率损失。

Method: Col-Bandit将重排序建模为有限群体Top-K识别问题，维护部分观测文档分数的不确定性感知边界，自适应地揭示必要的(document, query token) MaxSim条目。该方法作为零样本、即插即用层运行于标准多向量系统之上，无需索引修改、离线预处理或模型重训练。

Result: 在文本（BEIR）和多模态（REAL-MM-RAG）基准测试中，Col-Bandit在保持排序保真度的同时，将MaxSim FLOPs减少了高达5倍，表明密集的延迟交互评分包含大量冗余，可以在查询时高效识别和剪枝。

Conclusion: Col-Bandit通过查询时自适应剪枝有效解决了多向量检索器的计算瓶颈问题，证明了延迟交互评分中存在可被高效利用的冗余，为平衡检索质量和计算效率提供了实用解决方案。

Abstract: Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-$K$ identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5$\times$, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.

</details>


### [3] [Efficiency Optimizations for Superblock-based Sparse Retrieval](https://arxiv.org/abs/2602.02883)
*Parker Carlson,Wentai Xie,Rohil Shah,Tao Yang*

Main category: cs.IR

TL;DR: 提出一种简单有效的超块剪枝方案，结合紧凑索引结构和零配置，在保持相关性的同时减少计算开销，为高效稀疏检索提供强有力替代方案


<details>
  <summary>Details</summary>
Motivation: 学习稀疏检索结合了语言模型的语义匹配和高效CPU友好算法，但现有方法使用超块快速跳过块访问时，超块分数计算开销较大，需要更高效的剪枝方案

Method: 提出简单有效的超块剪枝方案，结合紧凑索引结构和鲁棒的零配置，适用于不同LSR模型和数据集，减少超块分数计算开销

Result: 在MS MARCO和BEIR数据集上评估，方案在保持竞争力的相关性的同时显著减少计算开销，成为高效稀疏检索的强有力替代方案

Conclusion: 提出的超块剪枝方案简单有效，结合紧凑索引和零配置，为学习稀疏检索提供高效实用的解决方案，具有广泛适用性

Abstract: Learned sparse retrieval (LSR) is a popular method for first-stage retrieval because it combines the semantic matching of language models with efficient CPU-friendly algorithms. Previous work aggregates blocks into "superblocks" to quickly skip the visitation of blocks during query processing by using an advanced pruning heuristic. This paper proposes a simple and effective superblock pruning scheme that reduces the overhead of superblock score computation while preserving competitive relevance. It combines this scheme with a compact index structure and a robust zero-shot configuration that is effective across LSR models and multiple datasets. This paper provides an analytical justification and evaluation on the MS MARCO and BEIR datasets, demonstrating that the proposed scheme can be a strong alternative for efficient sparse retrieval.

</details>


### [4] [ALPBench: A Benchmark for Attribution-level Long-term Personal Behavior Understanding](https://arxiv.org/abs/2602.03056)
*Lu Ren,Junda She,Xinchen Luo,Tao Wang,Xin Ye,Xu Zhang,Muxuan Wang,Xiao Yang,Chenguang Wang,Fei Xie,Yiwei Zhou,Danjun Wu,Guodong Zhang,Yifei Hu,Guoying Zheng,Shujie Yang,Xingmei Wang,Shiyao Wang,Yukun Zhou,Fan Yang,Size Li,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: ALPBench是一个用于评估LLMs在属性级别长期个人行为理解能力的新基准，专注于预测用户感兴趣的属性组合而非具体物品


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在准确捕捉用户长期偏好方面存在挑战，而大型语言模型具有强大的推理和泛化能力，为建模长期用户行为提供了新机会，需要系统评估这种能力

Method: 引入ALPBench基准，将用户历史行为表示为自然语言序列，专注于预测用户感兴趣的属性组合任务，而非具体物品推荐，支持对新引入物品进行真实评估

Result: ALPBench能够对个性化推荐进行细粒度评估，特别关注预测属性组合这一对当前LLMs极具挑战性的任务，因为需要捕捉多个属性间的复杂交互并对长期用户行为序列进行推理

Conclusion: ALPBench为评估LLMs在长期个人行为理解能力提供了系统框架，通过属性组合预测任务更好地反映用户持久兴趣，支持基于推理的可解释个性化推荐

Abstract: Recent advances in large language models have highlighted their potential for personalized recommendation, where accurately capturing user preferences remains a key challenge. Leveraging their strong reasoning and generalization capabilities, LLMs offer new opportunities for modeling long-term user behavior. To systematically evaluate this, we introduce ALPBench, a Benchmark for Attribution-level Long-term Personal Behavior Understanding. Unlike item-focused benchmarks, ALPBench predicts user-interested attribute combinations, enabling ground-truth evaluation even for newly introduced items. It models preferences from long-term historical behaviors rather than users' explicitly expressed requests, better reflecting enduring interests. User histories are represented as natural language sequences, allowing interpretable, reasoning-based personalization. ALPBench enables fine-grained evaluation of personalization by focusing on the prediction of attribute combinations task that remains highly challenging for current LLMs due to the need to capture complex interactions among multiple attributes and reason over long-term user behavior sequences.

</details>


### [5] [PAMAS: Self-Adaptive Multi-Agent System with Perspective Aggregation for Misinformation Detection](https://arxiv.org/abs/2602.03158)
*Zongwei Wang,Min Gao,Junliang Yu,Tong Chen,Chenghua Lin*

Main category: cs.IR

TL;DR: PAMAS是一个基于多智能体系统的虚假信息检测框架，通过视角聚合机制解决信息淹没问题，提高检测准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的虚假信息具有多样性和上下文依赖性，传统多智能体系统存在信息淹没问题，即大量真实内容淹没了稀疏的欺骗线索，导致检测困难。

Method: 提出PAMAS框架，包含三种角色：审计员从特定特征子集捕捉异常线索；协调员聚合不同视角以增强覆盖同时保持多样性；决策者通过演化记忆和完整上下文访问综合所有信息做出最终判断。还包含自适应机制进行动态拓扑优化和基于路由的推理。

Result: 在多个基准数据集上的广泛实验表明，PAMAS在准确性和效率方面都表现出优越性能，为虚假信息检测提供了可扩展且可信赖的方法。

Conclusion: PAMAS通过视角聚合的多智能体框架有效解决了信息淹没问题，提高了虚假信息检测的准确性和效率，为社交媒体上的虚假信息检测提供了新的解决方案。

Abstract: Misinformation on social media poses a critical threat to information credibility, as its diverse and context-dependent nature complicates detection. Large language model-empowered multi-agent systems (MAS) present a promising paradigm that enables cooperative reasoning and collective intelligence to combat this threat. However, conventional MAS suffer from an information-drowning problem, where abundant truthful content overwhelms sparse and weak deceptive cues. With full input access, agents tend to focus on dominant patterns, and inter-agent communication further amplifies this bias. To tackle this issue, we propose PAMAS, a multi-agent framework with perspective aggregation, which employs hierarchical, perspective-aware aggregation to highlight anomaly cues and alleviate information drowning. PAMAS organizes agents into three roles: Auditors, Coordinators, and a Decision-Maker. Auditors capture anomaly cues from specialized feature subsets; Coordinators aggregate their perspectives to enhance coverage while maintaining diversity; and the Decision-Maker, equipped with evolving memory and full contextual access, synthesizes all subordinate insights to produce the final judgment. Furthermore, to improve efficiency in multi-agent collaboration, PAMAS incorporates self-adaptive mechanisms for dynamic topology optimization and routing-based inference, enhancing both efficiency and scalability. Extensive experiments on multiple benchmark datasets demonstrate that PAMAS achieves superior accuracy and efficiency, offering a scalable and trustworthy way for misinformation detection.

</details>


### [6] [Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction](https://arxiv.org/abs/2602.03223)
*Jiahao Liu,Hongji Ruan,Weimin Zhang,Ziye Tong,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: DAES：面向流式训练场景的数值特征嵌入框架，通过自适应调制机制整合分布信息，解决传统静态分箱方法的语义漂移问题


<details>
  <summary>Details</summary>
Motivation: 传统静态分箱方法依赖离线统计，在流式环境中容易产生语义漂移；神经嵌入方法虽然支持端到端学习，但丢弃了显式的分布信息。流式特征通常违反i.i.d.假设，且数值分布的上下文依赖性常被忽视

Method: 提出DAES端到端框架：1）基于蓄水池采样的高效分布估计方法；2）两种场感知分布调制策略，捕捉流式分布和场依赖语义

Result: DAES在离线和在线实验中显著优于现有方法，已在拥有数亿日活用户的领先短视频平台全面部署

Conclusion: DAES成功解决了流式训练场景中数值特征嵌入的挑战，通过整合分布信息和自适应调制机制，实现了更准确的特征表示

Abstract: This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.

</details>


### [7] [To Search or Not to Search: Aligning the Decision Boundary of Deep Search Agents via Causal Intervention](https://arxiv.org/abs/2602.03304)
*Wenlin Zhang,Kuicai Dong,Junyi Li,Yingyi Zhang,Xiaopeng Li,Pengyue Jia,Yi Wen,Derong Xu,Maolin Wang,Yichao Wang,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 提出DAS框架，通过因果干预诊断和决策边界对齐，解决深度搜索代理中过度搜索和搜索不足的问题，提升搜索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前深度搜索代理在复杂信息寻求任务中存在效率低下的问题，主要原因是无法准确判断何时停止搜索并开始回答。这源于以结果为中心的训练方式，优先考虑最终结果而非搜索过程本身。根本原因是决策边界错位，导致过度搜索（已有足够知识仍冗余搜索）和搜索不足（过早终止导致错误答案）。

Method: 提出包含两个关键组件的综合框架：1) 基于因果干预的诊断方法，通过比较每个决策点的实际和反事实轨迹来识别边界错误；2) 决策边界对齐方法(DAS)，从因果反馈构建偏好数据集，并通过偏好优化对齐策略。

Result: 实验表明决策边界错误在现有最先进代理中普遍存在。DAS方法能有效校准这些边界，同时缓解过度搜索和搜索不足问题，在准确性和效率方面取得显著提升。

Conclusion: DAS框架通过诊断决策边界错误并进行策略对齐，能够显著改善深度搜索代理的搜索效率和准确性，为解决代理搜索过程中的边界判断问题提供了有效方案。

Abstract: Deep search agents, which autonomously iterate through multi-turn web-based reasoning, represent a promising paradigm for complex information-seeking tasks. However, current agents suffer from critical inefficiency: they conduct excessive searches as they cannot accurately judge when to stop searching and start answering. This stems from outcome-centric training that prioritize final results over the search process itself. We identify the root cause as misaligned decision boundaries, the threshold determining when accumulated information suffices to answer. This causes over-search (redundant searching despite sufficient knowledge) and under-search (premature termination yielding incorrect answers). To address these errors, we propose a comprehensive framework comprising two key components. First, we introduce causal intervention-based diagnosis that identifies boundary errors by comparing factual and counterfactual trajectories at each decision point. Second, we develop Decision Boundary Alignment for Deep Search agents (DAS), which constructs preference datasets from causal feedback and aligns policies via preference optimization. Experiments on public datasets demonstrate that decision boundary errors are pervasive across state-of-the-art agents. Our DAS method effectively calibrates these boundaries, mitigating both over-search and under-search to achieve substantial gains in accuracy and efficiency. Our code and data are publicly available at: https://github.com/Applied-Machine-Learning-Lab/WWW2026_DAS.

</details>


### [8] [Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval](https://arxiv.org/abs/2602.03306)
*Zhanyu Wu,Richong Zhang,Zhijie Nie*

Main category: cs.IR

TL;DR: 提出查询感知自适应维度选择框架，通过学习从查询嵌入预测每个维度的重要性，在推理时基于查询嵌入选择维度子集进行相似度计算，无需伪相关反馈。


<details>
  <summary>Details</summary>
Motivation: 密集检索将查询和文档表示为高维嵌入，但这些表示在查询层面可能存在冗余：对于给定的信息需求，只有一部分维度对排序有帮助。现有方法要么依赖噪声伪相关反馈信号，要么学习全局变换而不显式建模查询感知的维度重要性。

Method: 首先使用监督相关性标签构建嵌入维度上的oracle维度重要性分布，然后训练一个预测器将查询嵌入映射到这些标签蒸馏的重要性分数。在推理时，预测器仅基于查询嵌入选择查询感知的维度子集进行相似度计算。

Result: 在多个密集检索器和基准测试上的实验表明，学习的维度选择器在检索效果上优于全维度基线、基于PRF的掩码方法和监督适配器基线。

Conclusion: 提出的查询感知自适应维度选择框架能够有效识别和利用查询相关的维度，提高检索效果，且无需伪相关反馈，仅基于查询嵌入即可进行维度选择。

Abstract: Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.

</details>


### [9] [SCASRec: A Self-Correcting and Auto-Stopping Model for Generative Route List Recommendation](https://arxiv.org/abs/2602.03324)
*Chao Chen,Longfei Xu,Daohan Su,Tengfei Liu,Hanyu Guo,Yihai Duan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: SCASRec提出统一的生成式框架，将排序和冗余消除整合为端到端过程，解决多阶段推荐系统中训练目标与在线指标不对齐、冗余消除规则僵化、阶段分离导致次优等问题。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段推荐系统存在三个关键问题：1) 离线训练目标与在线指标不对齐，离线增益不一定转化为在线改进；2) 冗余消除依赖僵化的手工规则，无法适应用户意图的高方差和现实场景的复杂性；3) 精细排序和重排序阶段严格分离导致次优性能，各模块独立优化无法实现联合优化的全局最优。

Method: 提出SCASRec统一生成式框架，集成排序和冗余消除到单一端到端过程。引入逐步校正奖励(SCR)通过关注困难样本来指导列表级优化，采用可学习的推荐结束(EOR)标记在预期无进一步改进时自适应终止生成。

Result: 在两个大规模开源路线推荐数据集上的实验表明，SCASRec在离线和在线设置中均达到最先进水平。该框架已在真实导航应用中完全部署，证明了其有效性。

Conclusion: SCASRec通过统一生成式框架成功解决了多阶段推荐系统的关键局限性，实现了端到端的优化，在离线和在线环境中均表现出优越性能，并在实际应用中验证了其有效性。

Abstract: Route recommendation systems commonly adopt a multi-stage pipeline involving fine-ranking and re-ranking to produce high-quality ordered recommendations. However, this paradigm faces three critical limitations. First, there is a misalignment between offline training objectives and online metrics. Offline gains do not necessarily translate to online improvements. Actual performance must be validated through A/B testing, which may potentially compromise the user experience. Second, redundancy elimination relies on rigid, handcrafted rules that lack adaptability to the high variance in user intent and the unstructured complexity of real-world scenarios. Third, the strict separation between fine-ranking and re-ranking stages leads to sub-optimal performance. Since each module is optimized in isolation, the fine-ranking stage remains oblivious to the list-level objectives (e.g., diversity) targeted by the re-ranker, thereby preventing the system from achieving a jointly optimized global optimum. To overcome these intertwined challenges, we propose \textbf{SCASRec} (\textbf{S}elf-\textbf{C}orrecting and \textbf{A}uto-\textbf{S}topping \textbf{Rec}ommendation), a unified generative framework that integrates ranking and redundancy elimination into a single end-to-end process. SCASRec introduces a stepwise corrective reward (SCR) to guide list-wise refinement by focusing on hard samples, and employs a learnable End-of-Recommendation (EOR) token to terminate generation adaptively when no further improvement is expected. Experiments on two large-scale, open-sourced route recommendation datasets demonstrate that SCASRec establishes an SOTA in offline and online settings. SCASRec has been fully deployed in a real-world navigation app, demonstrating its effectiveness.

</details>


### [10] [Beyond Exposure: Optimizing Ranking Fairness with Non-linear Time-Income Functions](https://arxiv.org/abs/2602.03345)
*Xuancheng Li,Tao Yang,Yujia Zhou,Qingyao Ai,Yiqun Liu*

Main category: cs.IR

TL;DR: 本文提出了一种考虑时间等上下文因素对提供商收入影响的收入公平性概念，超越了仅基于位置的曝光公平性，并开发了相应的度量指标和优化算法。


<details>
  <summary>Details</summary>
Motivation: 当前排名优化中的公平性概念主要关注基于位置的曝光公平性，但忽略了时间等其他显著影响提供商收入的因素。当提供商效用既不等于也不与项目曝光成比例时，需要更全面的公平性框架。

Method: 提出了收入公平性的正式定义和度量指标。开发了动态收入导数感知排名公平性算法，基于当前时间步的边际收入增益，使用泰勒展开梯度同时优化效果和收入公平性。

Result: 模拟实验显示，现有的基于曝光公平性的排名算法无法优化提出的收入公平性。DIDRF算法在具有不同时间收入函数的离线和在线设置中，始终优于最先进的方法。

Conclusion: 研究强调了在排名优化中考虑上下文因素对提供商收入影响的重要性，提出的收入公平性框架和DIDRF算法为同时优化排名效果和公平性提供了有效解决方案。

Abstract: Ranking is central to information distribution in web search and recommendation. Nowadays, in ranking optimization, the fairness to item providers is viewed as a crucial factor alongside ranking relevance for users. There are currently numerous concepts of fairness and one widely recognized fairness concept is Exposure Fairness. However, it relies primarily on exposure determined solely by position, overlooking other factors that significantly influence income, such as time. To address this limitation, we propose to study ranking fairness when the provider utility is influenced by other contextual factors and is neither equal to nor proportional to item exposure. We give a formal definition of Income Fairness and develop a corresponding measurement metric. Simulated experiments show that existing-exposure-fairness-based ranking algorithms fail to optimize the proposed income fairness. Therefore, we propose the Dynamic-Income-Derivative-aware Ranking Fairness algorithm, which, based on the marginal income gain at the present timestep, uses Taylor-expansion-based gradients to simultaneously optimize effectiveness and income fairness. In both offline and online settings with diverse time-income functions, DIDRF consistently outperforms state-of-the-art methods.

</details>


### [11] [AesRec: A Dataset for Aesthetics-Aligned Clothing Outfit Recommendation](https://arxiv.org/abs/2602.03416)
*Wenxin Ye,Lin Li,Ming Li,Yang Shen,Kanghong Wang,Jimmy Xiangji Huang*

Main category: cs.IR

TL;DR: 提出AesRec基准数据集，包含系统化的服装美学量化标注，用于开发美学对齐的推荐系统，通过多维度指标评估单品和搭配的美学特征，并利用视觉语言模型进行大规模美学评分。


<details>
  <summary>Details</summary>
Motivation: 现有服装推荐方法主要依赖用户-物品-搭配交互行为，忽略了服装美学的显式表示，无法提供美学指导。需要建立包含系统化美学标注的数据集来弥补这一空白。

Method: 基于专业服装质量标准和时尚美学原则，定义多维度美学指标：单品层面评估轮廓、色彩、材质、工艺、穿着性和单品印象；搭配层面保留前五个核心属性，增加风格协同、视觉和谐和搭配印象。利用视觉语言模型进行大规模美学评分，并通过人机一致性验证确保可靠性。

Result: 建立了AesRec基准数据集，包含系统化的美学量化标注。实验证明，将量化的美学信息整合到服装推荐模型中，既能满足用户个性化需求，又能提供美学指导。

Conclusion: AesRec数据集填补了服装推荐领域美学标注的空白，通过系统化的美学量化指标和视觉语言模型评分，能够开发美学对齐的推荐系统，为用户提供美学指导的同时满足个性化需求。

Abstract: Clothing recommendation extends beyond merely generating personalized outfits; it serves as a crucial medium for aesthetic guidance. However, existing methods predominantly rely on user-item-outfit interaction behaviors while overlooking explicit representations of clothing aesthetics. To bridge this gap, we present the AesRec benchmark dataset featuring systematic quantitative aesthetic annotations, thereby enabling the development of aesthetics-aligned recommendation systems. Grounded in professional apparel quality standards and fashion aesthetic principles, we define a multidimensional set of indicators. At the item level, six dimensions are independently assessed: silhouette, chromaticity, materiality, craftsmanship, wearability, and item-level impression. Transitioning to the outfit level, the evaluation retains the first five core attributes while introducing stylistic synergy, visual harmony, and outfit-level impression as distinct metrics to capture the collective aesthetic impact. Given the increasing human-like proficiency of Vision-Language Models in multimodal understanding and interaction, we leverage them for large-scale aesthetic scoring. We conduct rigorous human-machine consistency validation on a fashion dataset, confirming the reliability of the generated ratings. Experimental results based on AesRec further demonstrate that integrating quantified aesthetic information into clothing recommendation models can provide aesthetic guidance for users while fulfilling their personalized requirements.

</details>


### [12] [RankSteer: Activation Steering for Pointwise LLM Ranking](https://arxiv.org/abs/2602.03422)
*Yumeng Wang,Catherine Chen,Suzan Verberne*

Main category: cs.IR

TL;DR: RankSteer：一种通过激活导向改进零样本LLM排序的后处理框架，无需修改模型权重或提示工程


<details>
  <summary>Details</summary>
Motivation: LLM作为零样本排序器对提示工程敏感，特别是角色扮演指令。研究发现角色相关信号与查询-文档表示分离，这启发了直接在激活层面而非脆弱的提示工程中引导排序行为

Method: 提出RankSteer框架，在表示空间中识别三个可引导方向：决策方向（映射隐藏状态到相关性分数）、证据方向（捕获未充分利用的相关性信号）、角色方向（调节模型行为但不注入相关性信息）。通过推理时的投影干预联合控制这些方向

Result: 在TREC DL 20和多个BEIR基准测试中，RankSteer仅使用少量锚点查询就能持续提升排序质量，表明点式LLM排序器中存在大量未充分利用的排序能力

Conclusion: 几何分析显示，导向通过稳定排序几何和减少离散度来改进排序，为LLM内部如何表示和校准相关性判断提供了新见解。激活导向是改进零样本LLM排序的有效方法

Abstract: Large language models (LLMs) have recently shown strong performance as zero-shot rankers, yet their effectiveness is highly sensitive to prompt formulation, particularly role-play instructions. Prior analyses suggest that role-related signals are encoded along activation channels that are largely separate from query-document representations, raising the possibility of steering ranking behavior directly at the activation level rather than through brittle prompt engineering. In this work, we propose RankSteer, a post-hoc activation steering framework for zero-shot pointwise LLM ranking. We characterize ranking behavior through three disentangled and steerable directions in representation space: a \textbf{decision direction} that maps hidden states to relevance scores, an \textbf{evidence direction} that captures relevance signals not directly exploited by the decision head, and a \textbf{role direction} that modulates model behavior without injecting relevance information. Using projection-based interventions at inference time, RankSteer jointly controls these directions to calibrate ranking behavior without modifying model weights or introducing explicit cross-document comparisons. Experiments on TREC DL 20 and multiple BEIR benchmarks show that RankSteer consistently improves ranking quality using only a small number of anchor queries, demonstrating that substantial ranking capacity remains under-utilized in pointwise LLM rankers. We further provide a geometric analysis revealing that steering improves ranking by stabilizing ranking geometry and reducing dispersion, offering new insight into how LLMs internally represent and calibrate relevance judgments.

</details>


### [13] [Failure is Feedback: History-Aware Backtracking for Agentic Traversal in Multimodal Graphs](https://arxiv.org/abs/2602.03432)
*Joohyung Yun,Doyup Lee,Wook-Shin Han*

Main category: cs.IR

TL;DR: FiF提出了一种基于失败反馈的开放域多模态文档检索方法，通过历史感知回溯机制和经济理性代理工作流，在检索准确性和计算成本之间实现动态平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索方法存在两个主要问题：1) 使用统一的相似性度量，忽略了跳转特定的语义；2) 固定的预定义检索计划阻碍了动态错误纠正。需要一种能够适应演化上下文并能智能从死胡同恢复的检索器。

Method: 将子图检索建模为序列决策过程，引入两个关键创新：1) 历史感知回溯机制，利用失败遍历的上下文信息，而不仅仅是简单回退状态；2) 经济理性代理工作流，采用成本感知的遍历方法动态管理检索准确性和推理成本之间的权衡，仅在先前失败证明合理时才升级到密集的LLM推理。

Result: 在MultimodalQA、MMCoQA和WebQA基准测试中，FiF实现了最先进的检索性能。

Conclusion: FiF通过将失败视为反馈，引入智能回溯和成本感知决策，有效解决了开放域多模态文档检索中的动态适应和错误恢复问题，在多个基准测试中取得了优异表现。

Abstract: Open-domain multimodal document retrieval aims to retrieve specific components (paragraphs, tables, or images) from large and interconnected document corpora. Existing graph-based retrieval approaches typically rely on a uniform similarity metric that overlooks hop-specific semantics, and their rigid pre-defined plans hinder dynamic error correction. These limitations suggest that a retriever should adapt its reasoning to the evolving context and recover intelligently from dead ends. To address these needs, we propose Failure is Feedback (FiF), which casts subgraph retrieval as a sequential decision process and introduces two key innovations. (i) We introduce a history-aware backtracking mechanism; unlike standard backtracking that simply reverts the state, our approach piggybacks on the context of failed traversals, leveraging insights from previous failures. (ii) We implement an economically-rational agentic workflow. Unlike conventional agents with static strategies, our orchestrator employs a cost-aware traversal method to dynamically manage the trade-off between retrieval accuracy and inference costs, escalating to intensive LLM-based reasoning only when the prior failure justifies the additional computational investment. Extensive experiments show that FiF achieves state-of-the-art retrieval on the benchmarks of MultimodalQA, MMCoQA and WebQA.

</details>


### [14] [Tutorial on Reasoning for IR & IR for Reasoning](https://arxiv.org/abs/2602.03640)
*Mohanna Hoveyda,Panagiotis Efstratiadis,Arjen de Vries,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该教程为信息检索领域提出了一个统一的推理分析框架，帮助整合跨学科的研究方法，推动IR系统从语义匹配向结构化推理发展。


<details>
  <summary>Details</summary>
Motivation: 传统信息检索主要关注语义相关性排序，但现实信息需求需要逻辑约束、多步推理和证据综合等推理能力。当前推理研究分散在不同学科，IR研究者难以识别相关思路和机会。

Method: 首先在IR背景下定义推理的工作定义，并从中推导出统一分析框架。该框架将现有方法映射到反映定义核心组件的轴上，提供全面概述并展示权衡与互补性。

Result: 通过框架映射现有方法，揭示了不同方法的权衡与互补性，展示了IR如何从跨学科进展中受益，以及检索过程如何在更广泛的推理系统中发挥核心作用。

Conclusion: 该教程为参与者提供了概念框架和实践指导，以增强具备推理能力的IR系统，同时将IR定位为既受益于又能贡献于更广泛推理方法发展的领域。

Abstract: Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.

</details>


### [15] [Bringing Reasoning to Generative Recommendation Through the Lens of Cascaded Ranking](https://arxiv.org/abs/2602.03692)
*Xinyu Lin,Pengyuan Liu,Wenjie Wang,Yicheng Hu,Chen Xu,Fuli Feng,Qifan Wang,Tat-Seng Chua*

Main category: cs.IR

TL;DR: 论文提出CARE框架解决生成式推荐中的偏差放大问题，通过渐进历史编码和查询锚定推理机制提升推荐多样性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐模型存在偏差放大问题，即token级偏差随着生成过程逐步放大，限制了推荐多样性并损害用户体验。与传统多阶段流水线相比，生成式推荐存在两个局限性：对编码历史的同质依赖，以及固定的计算预算阻碍了更深层次的用户偏好理解。

Method: 提出CARE框架：1) 渐进历史编码机制，随着生成过程推进逐步纳入更细粒度的历史信息；2) 查询锚定推理机制，通过并行推理步骤对历史信息进行更深层次理解。在三个生成式推荐骨干模型上实例化CARE。

Result: 在四个数据集上的实验结果表明，CARE在推荐准确性、多样性、效率和可扩展性方面均表现出优越性。

Conclusion: CARE框架有效解决了生成式推荐中的偏差放大问题，通过引入异构信息和动态计算资源分配，显著提升了推荐系统的性能。

Abstract: Generative Recommendation (GR) has become a promising end-to-end approach with high FLOPS utilization for resource-efficient recommendation. Despite the effectiveness, we show that current GR models suffer from a critical \textbf{bias amplification} issue, where token-level bias escalates as token generation progresses, ultimately limiting the recommendation diversity and hurting the user experience. By comparing against the key factor behind the success of traditional multi-stage pipelines, we reveal two limitations in GR that can amplify the bias: homogeneous reliance on the encoded history, and fixed computational budgets that prevent deeper user preference understanding.
  To combat the bias amplification issue, it is crucial for GR to 1) incorporate more heterogeneous information, and 2) allocate greater computational resources at each token generation step. To this end, we propose CARE, a simple yet effective cascaded reasoning framework for debiased GR. To incorporate heterogeneous information, we introduce a progressive history encoding mechanism, which progressively incorporates increasingly fine-grained history information as the generation process advances. To allocate more computations, we propose a query-anchored reasoning mechanism, which seeks to perform a deeper understanding of historical information through parallel reasoning steps. We instantiate CARE on three GR backbones. Empirical results on four datasets show the superiority of CARE in recommendation accuracy, diversity, efficiency, and promising scalability. The codes and datasets are available at https://github.com/Linxyhaha/CARE.

</details>


### [16] [Multimodal Generative Recommendation for Fusing Semantic and Collaborative Signals](https://arxiv.org/abs/2602.03713)
*Moritz Vandenhirtz,Kaveh Hassani,Shervin Ghasemlou,Shuai Shao,Hamid Eghbalzadeh,Fuchun Peng,Jun Liu,Michael Louis Iuzzolino*

Main category: cs.IR

TL;DR: MSCGRec是一种多模态语义与协同生成式推荐系统，通过结合多种语义模态和协同信号，在大型数据集上超越了传统序列推荐和生成式推荐方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法虽然通过离散语义编码减少内存开销，但在大型项目集上性能仍不及传统序列推荐器，限制了其在实际大规模场景中的应用。

Method: 提出MSCGRec：1) 整合多模态语义信息；2) 基于DINO框架的自监督量化学习方法处理图像；3) 从序列推荐器中提取协同特征作为独立模态；4) 提出约束序列学习，在训练时限制输出空间到允许的标记集合。

Result: 在三个大型真实世界数据集上的实验表明，MSCGRec超越了序列推荐和生成式推荐基线方法，并通过广泛的消融研究验证了各组件的影响。

Conclusion: MSCGRec成功解决了生成式推荐在大型项目集上的性能瓶颈，通过多模态语义融合和协同信号整合，实现了优于传统方法的推荐性能。

Abstract: Sequential recommender systems rank relevant items by modeling a user's interaction history and computing the inner product between the resulting user representation and stored item embeddings. To avoid the significant memory overhead of storing large item sets, the generative recommendation paradigm instead models each item as a series of discrete semantic codes. Here, the next item is predicted by an autoregressive model that generates the code sequence corresponding to the predicted item. However, despite promising ranking capabilities on small datasets, these methods have yet to surpass traditional sequential recommenders on large item sets, limiting their adoption in the very scenarios they were designed to address. To resolve this, we propose MSCGRec, a Multimodal Semantic and Collaborative Generative Recommender. MSCGRec incorporates multiple semantic modalities and introduces a novel self-supervised quantization learning approach for images based on the DINO framework. Additionally, MSCGRec fuses collaborative and semantic signals by extracting collaborative features from sequential recommenders and treating them as a separate modality. Finally, we propose constrained sequence learning that restricts the large output space during training to the set of permissible tokens. We empirically demonstrate on three large real-world datasets that MSCGRec outperforms both sequential and generative recommendation baselines and provide an extensive ablation study to validate the impact of each component.

</details>
