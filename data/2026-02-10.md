<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 31]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Reasoning-Augmented Representations for Multimodal Retrieval](https://arxiv.org/abs/2602.07125)
*Jianrui Zhang,Anirudh Sundara Rajan,Brandon Han,Soochahn Lee,Sukanta Ganguly,Yong Jae Lee*

Main category: cs.IR

TL;DR: UMR提出数据增强框架，通过外部化推理来改进多模态检索，在M-BEIR基准上取得显著提升


<details>
  <summary>Details</summary>
Motivation: 现有多模态检索模型在处理需要潜在推理的查询时表现脆弱，如图像包含"沉默"证据或查询语义不明确时，单次嵌入需要同时完成推理和压缩，容易导致虚假特征匹配

Method: 使用强大的视觉-语言模型进行数据增强：1) 为语料库条目生成密集字幕使视觉证据显式化；2) 解析查询中的模糊多模态引用；3) 将冗长指令重写为简洁检索约束。然后在这些语义密集表示上训练检索器

Result: 在M-BEIR基准测试中，推理增强训练方法相比强基线获得一致提升，消融实验显示语料增强主要帮助知识密集型查询，查询增强对组合修改请求至关重要

Conclusion: 通过外部化推理并将检索器训练在语义密集表示上，可以有效解决多模态检索中的潜在推理问题，提升模型性能

Abstract: Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints). We argue this brittleness is often data-induced: when images carry "silent" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurious feature matching. We propose a data-centric framework that decouples these roles by externalizing reasoning before retrieval. Using a strong Vision--Language Model, we make implicit semantics explicit by densely captioning visual evidence in corpus entries, resolving ambiguous multimodal references in queries, and rewriting verbose instructions into concise retrieval constraints. Inference-time enhancement alone is insufficient; the retriever must be trained on these semantically dense representations to avoid distribution shift and fully exploit the added signal. Across M-BEIR, our reasoning-augmented training method yields consistent gains over strong baselines, with ablations showing that corpus enhancement chiefly benefits knowledge-intensive queries while query enhancement is critical for compositional modification requests. We publicly release our code at https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval.

</details>


### [2] [Multimodal Enhancement of Sequential Recommendation](https://arxiv.org/abs/2602.07207)
*Bucher Sahyouni,Matthew Vowels,Liqun Chen,Simon Hadfield*

Main category: cs.IR

TL;DR: MuSTRec是一个统一多模态和序列推荐的框架，通过构建物品-物品图捕获跨物品相似性和协同过滤信号，使用频率自注意力模块捕获用户短期和长期偏好，在多个Amazon数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统通常单独处理多模态推荐或序列推荐，缺乏统一框架来同时利用多模态信息和用户序列行为。

Method: 提出MuSTRec框架：1) 从文本和视觉特征构建物品-物品图捕获跨物品相似性和协同过滤信号；2) 使用频率自注意力模块捕获用户短期和长期偏好；3) 统一多模态和序列推荐范式。

Result: 在多个Amazon数据集上，MuSTRec相比多模态和序列推荐的最先进方法有显著提升（最高33.5%改进）。将用户嵌入整合到序列推荐中，在小数据集上短期指标提升高达200%。

Conclusion: MuSTRec成功统一了多模态和序列推荐，展示了新推荐范式的潜力，包括需要新的数据划分机制，以及用户嵌入对序列推荐的显著提升作用。

Abstract: We propose a novel recommender framework, MuSTRec (Multimodal and Sequential Transformer-based Recommendation), that unifies multimodal and sequential recommendation paradigms. MuSTRec captures cross-item similarities and collaborative filtering signals, by building item-item graphs from extracted text and visual features. A frequency-based self-attention module additionally captures the short- and long-term user preferences. Across multiple Amazon datasets, MuSTRec demonstrates superior performance (up to 33.5% improvement) over multimodal and sequential state-of-the-art baselines. Finally, we detail some interesting facets of this new recommendation paradigm. These include the need for a new data partitioning regime, and a demonstration of how integrating user embeddings into sequential recommendation leads to drastically increased short-term metrics (up to 200% improvement) on smaller datasets. Our code is availabe at https://anonymous.4open.science/r/MuSTRec-D32B/ and will be made publicly available.

</details>


### [3] [Sequences as Nodes for Contrastive Multimodal Graph Recommendation](https://arxiv.org/abs/2602.07208)
*Bucher Sahyouni,Matthew Vowels,Liqun Chen,Simon Hadfield*

Main category: cs.IR

TL;DR: MuSICRec是一个多视图图推荐系统，结合协同过滤、序列和多模态信号，通过序列-项目视图和ID引导门控缓解冷启动和数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统虽然使用多模态、序列和对比学习技术来缓解冷启动和数据稀疏问题，但这些增强方法往往会引入噪声并破坏有用的语义信息。

Method: 构建序列-项目视图：通过注意力池化用户交互项目形成序列节点；在SI图上传播获得第二视图（替代人工数据增强）；使用ID引导门控调节文本和视觉特征的贡献以减轻模态噪声和对齐多模态信息。

Result: 在Amazon Baby、Sports和Electronics数据集上，采用严格的leave-two-out划分，MuSICRec在所有模型类型中都优于最先进的基线方法，对短历史用户的提升最大。

Conclusion: MuSICRec通过多视图图结构和ID引导门控有效缓解了推荐系统中的冷启动和数据稀疏问题，特别适合短历史用户，代码已公开。

Abstract: To tackle cold-start and data sparsity issues in recommender systems, numerous multimodal, sequential, and contrastive techniques have been proposed. While these augmentations can boost recommendation performance, they tend to add noise and disrupt useful semantics. To address this, we propose MuSICRec (Multimodal Sequence-Item Contrastive Recommender), a multi-view graph-based recommender that combines collaborative, sequential, and multimodal signals. We build a sequence-item (SI) view by attention pooling over the user's interacted items to form sequence nodes. We propagate over the SI graph, obtaining a second view organically as an alternative to artificial data augmentation, while simultaneously injecting sequential context signals. Additionally, to mitigate modality noise and align the multimodal information, the contribution of text and visual features is modulated according to an ID-guided gate.
  We evaluate under a strict leave-two-out split against a broad range of sequential, multimodal, and contrastive baselines. On the Amazon Baby, Sports, and Electronics datasets, MuSICRec outperforms state-of-the-art baselines across all model types. We observe the largest gains for short-history users, mitigating sparsity and cold-start challenges. Our code is available at https://anonymous.4open.science/r/MuSICRec-3CEE/ and will be made publicly available.

</details>


### [4] [Progressive Searching for Retrieval in RAG](https://arxiv.org/abs/2602.07297)
*Taehee Jeong,Xingzhe Zhao,Peizu Li,Markus Valvur,Weihua Zhao*

Main category: cs.IR

TL;DR: 提出一种用于RAG系统的渐进式搜索算法，通过从低维嵌入开始逐步细化候选集，在保持准确性的同时减少检索时间。


<details>
  <summary>Details</summary>
Motivation: RAG系统通过检索外部文档来缓解LLMs的过时信息和幻觉问题，但高效准确的搜索对RAG性能至关重要。现有方法在高维向量搜索时计算成本高，需要一种成本效益更高的搜索算法。

Method: 提出渐进式搜索算法，采用分层搜索策略：从低维嵌入开始搜索，逐步细化候选集，最终在目标高维空间中进行搜索。这种多阶段方法通过早期过滤减少高维搜索的计算量。

Result: 渐进式搜索在RAG系统中实现了维度、速度和准确性之间的平衡，即使在大型数据库上也能实现可扩展的高性能检索，显著减少检索时间同时保持所需准确性。

Conclusion: 渐进式搜索算法为RAG系统提供了一种成本效益高的检索解决方案，通过分层搜索策略优化了检索效率，使RAG系统能够更好地处理大规模数据库的检索需求。

Abstract: Retrieval Augmented Generation (RAG) is a promising technique for mitigating two key limitations of large language models (LLMs): outdated information and hallucinations. RAG system stores documents as embedding vectors in a database. Given a query, search is executed to find the most related documents. Then, the topmost matching documents are inserted into LLMs' prompt to generate a response. Efficient and accurate searching is critical for RAG to get relevant information. We propose a cost-effective searching algorithm for retrieval process. Our progressive searching algorithm incrementally refines the candidate set through a hierarchy of searches, starting from low-dimensional embeddings and progressing into a higher, target-dimensionality. This multi-stage approach reduces retrieval time while preserving the desired accuracy. Our findings demonstrate that progressive search in RAG systems achieves a balance between dimensionality, speed, and accuracy, enabling scalable and high-performance retrieval even for large databases.

</details>


### [5] [Principled Synthetic Data Enables the First Scaling Laws for LLMs in Recommendation](https://arxiv.org/abs/2602.07298)
*Benyu Zhang,Qiang Zhang,Jianpeng Cheng,Hong-You Chen,Qifei Wang,Wei Sun,Shen Li,Jia Li,Jiahao Wu,Xiangjun Fan,Hong Yan*

Main category: cs.IR

TL;DR: 本文提出了一种分层框架生成高质量合成数据，首次在推荐领域展示了LLM的稳健幂律缩放规律，使基于合成数据的模型性能显著超越基于真实数据的模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐系统中具有巨大潜力，但缺乏可预测的缩放规律阻碍了其发展。作者认为这可能源于以往持续预训练中使用的原始用户交互数据存在噪声、偏见和不完整性。

Method: 提出了一种新颖的分层框架，通过创建精心策划的教学课程来生成高质量合成数据，避免原始数据的问题。使用这种原则性合成数据对LLM进行持续预训练。

Result: 1. 使用合成数据训练的模型在推荐排名任务中显著优于使用真实数据的模型（SasRec的recall@100提升130%）
2. 首次实证展示了在高质量推荐特定数据上进行持续预训练的LLM具有稳健的幂律缩放规律
3. 在多种合成数据模态上观察到一致且可预测的困惑度降低

Conclusion: 该研究为推荐领域可靠扩展LLM能力建立了基础方法学，将研究重点从缓解数据缺陷转向利用高质量结构化信息，为推荐系统的LLM发展提供了可预测的缩放规律。

Abstract: Large Language Models (LLMs) represent a promising frontier for recommender systems, yet their development has been impeded by the absence of predictable scaling laws, which are crucial for guiding research and optimizing resource allocation. We hypothesize that this may be attributed to the inherent noise, bias, and incompleteness of raw user interaction data in prior continual pre-training (CPT) efforts. This paper introduces a novel, layered framework for generating high-quality synthetic data that circumvents such issues by creating a curated, pedagogical curriculum for the LLM. We provide powerful, direct evidence for the utility of our curriculum by showing that standard sequential models trained on our principled synthetic data significantly outperform ($+130\%$ on recall@100 for SasRec) models trained on real data in downstream ranking tasks, demonstrating its superiority for learning generalizable user preference patterns. Building on this, we empirically demonstrate, for the first time, robust power-law scaling for an LLM that is continually pre-trained on our high-quality, recommendation-specific data. Our experiments reveal consistent and predictable perplexity reduction across multiple synthetic data modalities. These findings establish a foundational methodology for reliable scaling LLM capabilities in the recommendation domain, thereby shifting the research focus from mitigating data deficiencies to leveraging high-quality, structured information.

</details>


### [6] [LIT-GRAPH: Evaluating Deep vs. Shallow Graph Embeddings for High-Quality Text Recommendation in Domain-Specific Knowledge Graphs](https://arxiv.org/abs/2602.07307)
*Nirmal Gelal,Chloe Snow,Kathleen M. Jagodnik,Ambyr Rios,Hande Küçük McGinty*

Main category: cs.IR

TL;DR: LIT-GRAPH是一个基于知识图谱的推荐系统，帮助高中英语教师选择多样化、符合教学法的文学作品，通过比较四种图嵌入方法发现R-GCN在语义排序上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决高中英语课程停滞问题，帮助教师选择多样化且符合教学目标的文学作品，克服传统推荐系统在教学内容匹配上的不足。

Method: 构建英语文学本体知识图谱，比较四种图嵌入方法：DeepWalk、偏置随机游走、混合方法（拼接前两者向量）和关系图卷积网络（R-GCN）。

Result: 浅层模型在结构链接预测上表现优异，而R-GCN在语义排序上表现最佳，能够优先考虑教学相关性而非原始连接性，提供更高质量的领域特定推荐。

Conclusion: R-GCN通过关系特定的消息传递机制，在语义理解方面优于传统图嵌入方法，为教育领域的知识图谱推荐系统提供了更有效的解决方案。

Abstract: This study presents LIT-GRAPH (Literature Graph for Recommendation and Pedagogical Heuristics), a novel knowledge graph-based recommendation system designed to scaffold high school English teachers in selecting diverse, pedagogically aligned instructional literature. The system is built upon an ontology for English literature, addressing the challenge of curriculum stagnation, where we compare four graph embedding paradigms: DeepWalk, Biased Random Walk (BRW), Hybrid (concatenated DeepWalk and BRW vectors), and the deep model Relational Graph Convolutional Network (R-GCN). Results reveal a critical divergence: while shallow models excelled in structural link prediction, R-GCN dominated semantic ranking. By leveraging relation-specific message passing, the deep model prioritizes pedagogical relevance over raw connectivity, resulting in superior, high-quality, domain-specific recommendations.

</details>


### [7] [Semantic Search At LinkedIn](https://arxiv.org/abs/2602.07309)
*Fedor Borisyuk,Sriram Vasudevan,Muchen Wu,Guoyao Li,Benjamin Le,Shaobo Zhang,Qianqi Kay Shen,Yuchin Juan,Kayhan Behdin,Liming Dong,Kaixu Yang,Shusen Jing,Ravi Pothamsetty,Rajat Arora,Sophie Yanying Sheng,Vitaly Abdrashitov,Yang Zhao,Lin Su,Xiaoqing Wang,Chujie Zheng,Sarang Metkar,Rupesh Gupta,Igor Lapchuk,David N. Racca,Madhumitha Mohan,Yanbo Li,Haojun Li,Saloni Gandhi,Xueying Lu,Chetan Bhole,Ali Hooshmand,Xin Yang,Raghavan Muthuregunathan,Jiajun Zhang,Mathew Teoh,Adam Coler,Abhinav Gupta,Xiaojing Ma,Sundara Raman Ramachandran,Morteza Ramezani,Yubo Wang,Lijuan Zhang,Richard Li,Jian Sheng,Chanh Nguyen,Yen-Chi Chen,Chuanrui Zhu,Claire Zhang,Jiahao Xu,Deepti Kulkarni,Qing Lan,Arvind Subramaniam,Ata Fatahibaarzi,Steven Shimizu,Yanning Chen,Zhipeng Wang,Ran He,Zhengze Zhou,Qingquan Song,Yun Dai,Caleb Johnson,Ping Liu,Shaghayegh Gharghabi,Gokulraj Mohanasundaram,Juan Bottaro,Santhosh Sachindran,Qi Guo,Yunxiang Ren,Chengming Jiang,Di Mo,Luke Simon,Jianqiang Shen,Jingwei Wu,Wenjing Zhang*

Main category: cs.IR

TL;DR: LinkedIn开发了一个基于大语言模型的语义搜索框架，通过多教师蒸馏训练小型语言模型，结合推理架构优化，在保持高相关性的同时将排名吞吐量提升75倍以上。


<details>
  <summary>Details</summary>
Motivation: 虽然基于大语言模型的语义搜索能够通过含义而非关键词匹配进行检索，但其扩展需要显著的推理效率提升。LinkedIn需要为AI职位搜索和AI人才搜索开发高效的语义搜索系统。

Method: 结合LLM相关性判断器、基于嵌入的检索，以及通过多教师蒸馏训练的紧凑小型语言模型来联合优化相关性和参与度。采用预填充导向的推理架构，结合模型剪枝、上下文压缩和文本-嵌入混合交互。

Result: 在固定延迟约束下，排名吞吐量提升超过75倍，同时保持接近教师模型水平的NDCG（归一化折损累计增益）。实现了首个生产级LLM排名系统，效率与传统方法相当，质量和用户参与度显著提升。

Conclusion: 通过创新的模型压缩和推理架构优化，成功实现了高效的生产级LLM语义搜索系统，在保持质量的同时大幅提升效率，为大规模部署LLM搜索提供了可行方案。

Abstract: Semantic search with large language models (LLMs) enables retrieval by meaning rather than keyword overlap, but scaling it requires major inference efficiency advances. We present LinkedIn's LLM-based semantic search framework for AI Job Search and AI People Search, combining an LLM relevance judge, embedding-based retrieval, and a compact Small Language Model trained via multi-teacher distillation to jointly optimize relevance and engagement. A prefill-oriented inference architecture co-designed with model pruning, context compression, and text-embedding hybrid interactions boosts ranking throughput by over 75x under a fixed latency constraint while preserving near-teacher-level NDCG, enabling one of the first production LLM-based ranking systems with efficiency comparable to traditional approaches and delivering significant gains in quality and user engagement.

</details>


### [8] [High Fidelity Textual User Representation over Heterogeneous Sources via Reinforcement Learning](https://arxiv.org/abs/2602.07333)
*Rajat Arora,Ye Tao,Jianqiang Shen,Ping Liu,Muchen Wu,Qianqi Shen,Benjamin Le,Fedor Borisyuk,Jingwei Wu,Wenjing Zhang*

Main category: cs.IR

TL;DR: 提出基于强化学习的框架，从异构文本数据中合成统一的用户表示，用于LinkedIn等大规模招聘平台的个性化推荐


<details>
  <summary>Details</summary>
Motivation: 大型招聘平台需要从用户资料、职业数据和搜索活动日志等异构文本源建模用户，随着推荐系统越来越多采用大语言模型，创建统一、可解释且简洁的用户表示变得至关重要，尤其是在延迟敏感的在线环境中

Method: 提出新颖的强化学习框架，利用隐式用户参与信号（如点击、申请）作为主要奖励来提炼关键信息，同时结合基于规则的奖励来强制格式和长度约束

Result: 在LinkedIn多个产品上进行的大量离线实验显示，关键下游业务指标有显著改善

Conclusion: 这项工作为构建可解释的用户表示提供了实用、无需标注且可扩展的解决方案，这些表示直接兼容基于大语言模型的系统

Abstract: Effective personalization on large-scale job platforms requires modeling members based on heterogeneous textual sources, including profiles, professional data, and search activity logs. As recommender systems increasingly adopt Large Language Models (LLMs), creating unified, interpretable, and concise representations from heterogeneous sources becomes critical, especially for latency-sensitive online environments. In this work, we propose a novel Reinforcement Learning (RL) framework to synthesize a unified textual representation for each member. Our approach leverages implicit user engagement signals (e.g., clicks, applies) as the primary reward to distill salient information. Additionally, the framework is complemented by rule-based rewards that enforce formatting and length constraints. Extensive offline experiments across multiple LinkedIn products, one of the world's largest job platforms, demonstrate significant improvements in key downstream business metrics. This work provides a practical, labeling-free, and scalable solution for constructing interpretable user representations that are directly compatible with LLM-based systems.

</details>


### [9] [MDL: A Unified Multi-Distribution Learner in Large-scale Industrial Recommendation through Tokenization](https://arxiv.org/abs/2602.07520)
*Shanlei Mu,Yuchen Jiang,Shikang Wu,Shiyong Hong,Tianmu Sha,Junjie Zhang,Jie Zhu,Zhe Chen,Zhe Wang,Jingjian Lin*

Main category: cs.IR

TL;DR: 提出统一的多分布学习框架MDL，将场景和任务信息作为特殊token处理，通过三层注意力机制实现深度交互，显著提升工业推荐系统性能


<details>
  <summary>Details</summary>
Motivation: 现有多场景学习和多任务学习方法存在两个关键问题：1）大规模模型参数因与复杂特征模块交互有限而未被充分利用；2）难以在统一框架中联合建模场景和任务信息

Method: 提出MDL框架，受大语言模型"提示"范式启发，将场景和任务信息作为特殊token而非辅助输入或门控信号。包含统一信息token化模块和三层协同机制：特征token自注意力、领域-特征注意力、领域融合聚合

Result: 在真实工业数据集上显著优于最先进的多场景学习和多任务学习基线。在抖音搜索平台在线A/B测试一个月，LT30提升+0.0626%，变更查询率降低-0.3267%。已完全部署生产，每日服务数亿用户

Conclusion: MDL通过将场景和任务信息作为特殊token，实现层级的深度交互，有效激活模型参数空间，为工业推荐系统提供了一种统一的多分布学习解决方案

Abstract: Industrial recommender systems increasingly adopt multi-scenario learning (MSL) and multi-task learning (MTL) to handle diverse user interactions and contexts, but existing approaches suffer from two critical drawbacks: (1) underutilization of large-scale model parameters due to limited interaction with complex feature modules, and (2) difficulty in jointly modeling scenario and task information in a unified framework. To address these challenges, we propose a unified \textbf{M}ulti-\textbf{D}istribution \textbf{L}earning (MDL) framework, inspired by the "prompting" paradigm in large language models (LLMs). MDL treats scenario and task information as specialized tokens rather than auxiliary inputs or gating signals. Specifically, we introduce a unified information tokenization module that transforms features, scenarios, and tasks into a unified tokenized format. To facilitate deep interaction, we design three synergistic mechanisms: (1) feature token self-attention for rich feature interactions, (2) domain-feature attention for scenario/task-adaptive feature activation, and (3) domain-fused aggregation for joint distribution prediction. By stacking these interactions, MDL enables scenario and task information to "prompt" and activate the model's vast parameter space in a bottom-up, layer-wise manner. Extensive experiments on real-world industrial datasets demonstrate that MDL significantly outperforms state-of-the-art MSL and MTL baselines. Online A/B testing on Douyin Search platform over one month yields +0.0626\% improvement in LT30 and -0.3267\% reduction in change query rate. MDL has been fully deployed in production, serving hundreds of millions of users daily.

</details>


### [10] [IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory](https://arxiv.org/abs/2602.07525)
*Xingliang Hou,Yuyan Liu,Qi Sun,haoxiu wang,Hao Hu,Shaoyi Du,Zhiqiang Tian*

Main category: cs.IR

TL;DR: IGMiRAG是一个基于人类直觉推理的检索增强生成框架，通过分层异质超图对齐多粒度知识，结合双向扩散算法和动态资源分配，显著提升RAG性能同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于图和超图的RAG方法虽然能捕捉实体关系，但存在内存组织不对齐、检索成本高且分散的问题，需要更高效、更符合人类推理过程的解决方案。

Method: 1. 构建分层异质超图对齐多粒度知识，包含演绎路径模拟真实记忆结构；2. 通过问题解析器提取直觉策略控制挖掘深度和记忆窗口；3. 使用双焦点检索激活即时记忆作为锚点；4. 设计双向扩散算法在演绎路径上导航挖掘深度记忆。

Result: 在广泛评估中，IGMiRAG比最先进基线在EM上提升4.8%，F1提升5.0%，token成本根据任务复杂度自适应调整（平均6.3k+，最低3.0k+），实现了效率和效果的双重提升。

Conclusion: IGMiRAG提出了一种成本效益高的RAG范式，通过模拟人类直觉推理过程，在提升检索增强生成性能的同时优化计算资源分配，为RAG系统提供了更高效、更有效的解决方案。

Abstract: Retrieval-augmented generation (RAG) equips large language models (LLMs) with reliable knowledge memory. To strengthen cross-text associations, recent research integrates graphs and hypergraphs into RAG to capture pairwise and multi-entity relations as structured links. However, their misaligned memory organization necessitates costly, disjointed retrieval. To address these limitations, we propose IGMiRAG, a framework inspired by human intuition-guided reasoning. It constructs a hierarchical heterogeneous hypergraph to align multi-granular knowledge, incorporating deductive pathways to simulate realistic memory structures. During querying, IGMiRAG distills intuitive strategies via a question parser to control mining depth and memory window, and activates instantaneous memories as anchors using dual-focus retrieval. Mirroring human intuition, the framework guides retrieval resource allocation dynamically. Furthermore, we design a bidirectional diffusion algorithm that navigates deductive paths to mine in-depth memories, emulating human reasoning processes. Extensive evaluations indicate IGMiRAG outperforms the state-of-the-art baseline by 4.8% EM and 5.0% F1 overall, with token costs adapting to task complexity (average 6.3k+, minimum 3.0k+). This work presents a cost-effective RAG paradigm that improves both efficiency and effectiveness.

</details>


### [11] [MSN: A Memory-based Sparse Activation Scaling Framework for Large-scale Industrial Recommendation](https://arxiv.org/abs/2602.07526)
*Shikang Wu,Hui Lu,Jinqiu Jin,Zheng Chai,Shiyong Hong,Junjie Zhang,Shanlei Mu,Kaiyuan Ma,Tianyi Liu,Yuchao Zheng,Zhe Wang,Jingjian Lin*

Main category: cs.IR

TL;DR: MSN是一个基于内存的稀疏激活扩展框架，用于推荐系统，通过动态检索个性化表征并集成到下游特征交互模块，在保持高效的同时提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度推荐模型扩展方法计算开销大，难以在严格延迟约束下部署。稀疏激活方法（如稀疏混合专家）虽然减少计算，但仍存在高内存访问成本和有限个性化能力的问题。

Method: MSN框架包含：1）从大型参数化内存动态检索个性化表征；2）通过内存门控机制集成到下游特征交互模块；3）采用产品键内存机制将检索复杂度从线性降至亚线性；4）引入归一化和过参数化技术平衡内存利用；5）设计定制稀疏收集算子和AirTopK算子提升工业环境效率。

Result: 实验表明MSN能持续提升推荐性能同时保持高效率。已在抖音搜索排序系统成功部署，在离线评估指标和大规模在线A/B测试中均显著优于现有最优模型。

Conclusion: MSN是一个高效的内存稀疏激活扩展框架，解决了推荐模型扩展中的计算开销和个性化能力限制问题，在实际工业系统中验证了其有效性和实用性。

Abstract: Scaling deep learning recommendation models is an effective way to improve model expressiveness. Existing approaches often incur substantial computational overhead, making them difficult to deploy in large-scale industrial systems under strict latency constraints. Recent sparse activation scaling methods, such as Sparse Mixture-of-Experts, reduce computation by activating only a subset of parameters, but still suffer from high memory access costs and limited personalization capacity due to the large size and small number of experts. To address these challenges, we propose MSN, a memory-based sparse activation scaling framework for recommendation models. MSN dynamically retrieves personalized representations from a large parameterized memory and integrates them into downstream feature interaction modules via a memory gating mechanism, enabling fine-grained personalization with low computational overhead. To enable further expansion of the memory capacity while keeping both computational and memory access costs under control, MSN adopts a Product-Key Memory (PKM) mechanism, which factorizes the memory retrieval complexity from linear time to sub-linear complexity. In addition, normalization and over-parameterization techniques are introduced to maintain balanced memory utilization and prevent memory retrieval collapse. We further design customized Sparse-Gather operator and adopt the AirTopK operator to improve training and inference efficiency in industrial settings. Extensive experiments demonstrate that MSN consistently improves recommendation performance while maintaining high efficiency. Moreover, MSN has been successfully deployed in the Douyin Search Ranking System, achieving significant gains over deployed state-of-the-art models in both offline evaluation metrics and large-scale online A/B test.

</details>


### [12] [HypRAG: Hyperbolic Dense Retrieval for Retrieval Augmented Generation](https://arxiv.org/abs/2602.07739)
*Hiren Madhu,Ngoc Bui,Ali Maatouk,Leandros Tassiulas,Smita Krishnaswamy,Menglin Yang,Sukanta Ganguly,Kiran Srinivasan,Rex Ying*

Main category: cs.IR

TL;DR: 论文提出双曲稠密检索方法，通过双曲空间嵌入更好地保留自然语言的层次结构，相比欧几里得嵌入在RAG任务中显著提升检索质量并减少幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 当前RAG中的稠密检索器主要局限于欧几里得空间，但自然语言具有从广泛主题到具体实体的层次结构，欧几里得嵌入无法保留这种结构，导致语义上较远的文档出现虚假相似性，增加了幻觉风险。

Method: 提出双曲稠密检索方法，在双曲空间的洛伦兹模型中开发两种变体：HyTE-FH（完全双曲Transformer）和HyTE-H（将预训练欧几里得嵌入投影到双曲空间的混合架构）。引入向外爱因斯坦中点作为几何感知的池化算子，防止序列聚合过程中的表示崩溃。

Result: 在MTEB基准上，HyTE-FH优于等效的欧几里得基线；在RAGBench上，HyTE-H在上下文相关性和答案相关性方面比欧几里得基线提升高达29%，且使用比当前最先进检索器小得多的模型。双曲表示通过基于范数的分离编码文档特异性，从一般概念到具体概念的径向增加超过20%。

Conclusion: 双曲几何嵌入能更好地保留自然语言的层次结构，显著提升RAG系统的检索质量和忠实度，证明了几何归纳偏置在构建可信RAG系统中的关键作用。

Abstract: Embedding geometry plays a fundamental role in retrieval quality, yet dense retrievers for retrieval-augmented generation (RAG) remain largely confined to Euclidean space. However, natural language exhibits hierarchical structure from broad topics to specific entities that Euclidean embeddings fail to preserve, causing semantically distant documents to appear spuriously similar and increasing hallucination risk. To address these limitations, we introduce hyperbolic dense retrieval, developing two model variants in the Lorentz model of hyperbolic space: HyTE-FH, a fully hyperbolic transformer, and HyTE-H, a hybrid architecture projecting pre-trained Euclidean embeddings into hyperbolic space. To prevent representational collapse during sequence aggregation, we introduce the Outward Einstein Midpoint, a geometry-aware pooling operator that provably preserves hierarchical structure. On MTEB, HyTE-FH outperforms equivalent Euclidean baselines, while on RAGBench, HyTE-H achieves up to 29% gains over Euclidean baselines in context relevance and answer relevance using substantially smaller models than current state-of-the-art retrievers. Our analysis also reveals that hyperbolic representations encode document specificity through norm-based separation, with over 20% radial increase from general to specific concepts, a property absent in Euclidean embeddings, underscoring the critical role of geometric inductive bias in faithful RAG systems.

</details>


### [13] [Generative Reasoning Re-ranker](https://arxiv.org/abs/2602.07774)
*Mingfu Liang,Yufei Li,Jay Xu,Kavosh Asadi,Xi Liu,Shuo Gu,Kaushik Rangadurai,Frank Shyu,Shuaiwen Wang,Song Yang,Zhijing Li,Jiang Liu,Mengying Sun,Fei Tian,Xiaohan Wei,Chonglin Sun,Jacob Tao,Shike Mei,Hamed Firooz,Wenlin Chen,Luke Simon*

Main category: cs.IR

TL;DR: GR2是一个用于推荐系统重排序的生成式推理框架，通过语义ID编码、高质量推理轨迹生成和强化学习优化，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统存在三个关键局限：1) 忽视重排序阶段；2) 未充分利用LLM的推理能力；3) 使用非语义ID导致可扩展性问题。需要解决这些缺陷来提升推荐系统性能。

Method: GR2采用三阶段训练流程：1) 使用语义ID编码器对LLM进行中间训练；2) 通过精心设计的提示和拒绝采样生成高质量推理轨迹，用于监督微调；3) 应用DAPO（解耦剪辑和动态采样策略优化）进行可扩展的强化学习监督。

Result: 在两个真实世界数据集上，GR2在Recall@5和NDCG@5指标上分别超过当前最佳方法OneRec-Think 2.4%和1.3%。消融实验证实高级推理轨迹带来显著提升，并发现RL奖励设计对重排序至关重要。

Conclusion: GR2成功解决了LLM推荐系统中的关键局限，通过语义ID、高质量推理和强化学习的结合，显著提升了重排序性能，并为推荐系统的RL奖励设计提供了重要见解。

Abstract: Recent studies increasingly explore Large Language Models (LLMs) as a new paradigm for recommendation systems due to their scalability and world knowledge. However, existing work has three key limitations: (1) most efforts focus on retrieval and ranking, while the reranking phase, critical for refining final recommendations, is largely overlooked; (2) LLMs are typically used in zero-shot or supervised fine-tuning settings, leaving their reasoning abilities, especially those enhanced through reinforcement learning (RL) and high-quality reasoning data, underexploited; (3) items are commonly represented by non-semantic IDs, creating major scalability challenges in industrial systems with billions of identifiers. To address these gaps, we propose the Generative Reasoning Reranker (GR2), an end-to-end framework with a three-stage training pipeline tailored for reranking. First, a pretrained LLM is mid-trained on semantic IDs encoded from non-semantic IDs via a tokenizer achieving $\ge$99% uniqueness. Next, a stronger larger-scale LLM generates high-quality reasoning traces through carefully designed prompting and rejection sampling, which are used for supervised fine-tuning to impart foundational reasoning skills. Finally, we apply Decoupled Clip and Dynamic sAmpling Policy Optimization (DAPO), enabling scalable RL supervision with verifiable rewards designed specifically for reranking. Experiments on two real-world datasets demonstrate GR2's effectiveness: it surpasses the state-of-the-art OneRec-Think by 2.4% in Recall@5 and 1.3% in NDCG@5. Ablations confirm that advanced reasoning traces yield substantial gains across metrics. We further find that RL reward design is crucial in reranking: LLMs tend to exploit reward hacking by preserving item order, motivating conditional verifiable rewards to mitigate this behavior and optimize reranking performance.

</details>


### [14] [SAGE: Scalable AI Governance & Evaluation](https://arxiv.org/abs/2602.07840)
*Benjamin Le,Xueying Lu,Nick Stern,Wenqiong Liu,Igor Lapchuk,Xiang Li,Baofen Zheng,Kevin Rosenberg,Jiewen Huang,Zhe Zhang,Abraham Cabangbang,Satej Milind Wagle,Jianqiang Shen,Raghavan Muthuregunathan,Abhinav Gupta,Mathew Teoh,Andrew Kirk,Thomas Kwan,Jingwei Wu,Wenjing Zhang*

Main category: cs.IR

TL;DR: SAGE框架通过双向校准循环将人类产品判断转化为可扩展的评估信号，利用LLM代理法官、政策和先例共同演化，通过师生蒸馏降低92倍成本，在LinkedIn搜索中提升0.25%日活用户。


<details>
  <summary>Details</summary>
Motivation: 大规模搜索系统的相关性评估面临治理鸿沟：精细但资源有限的人工监督与高吞吐量生产需求之间的矛盾。传统方法依赖参与度代理或稀疏人工评审，无法全面捕捉高影响的相关性失败。

Method: 提出SAGE框架，核心是双向校准循环：自然语言政策、精选先例和LLM代理法官共同演化，系统解决语义模糊和错位问题。通过师生蒸馏将高保真判断转移到紧凑的学生代理模型，成本降低92倍。

Result: 在LinkedIn搜索生态中部署SAGE，通过模拟驱动开发指导模型迭代，为在线服务提炼政策对齐模型，实现快速离线评估。生产中的政策监督测量了模型变体并检测到参与度指标无法发现的回归问题。

Conclusion: SAGE成功将主观相关性判断转化为可执行的多维度评估标准，达到接近人类水平的共识，最终驱动LinkedIn日活用户提升0.25%，证明其在大规模搜索系统中实现可扩展AI治理的有效性。

Abstract: Evaluating relevance in large-scale search systems is fundamentally constrained by the governance gap between nuanced, resource-constrained human oversight and the high-throughput requirements of production systems. While traditional approaches rely on engagement proxies or sparse manual review, these methods often fail to capture the full scope of high-impact relevance failures. We present \textbf{SAGE} (Scalable AI Governance \& Evaluation), a framework that operationalizes high-quality human product judgment as a scalable evaluation signal. At the core of SAGE is a bidirectional calibration loop where natural-language \emph{Policy}, curated \emph{Precedent}, and an \emph{LLM Surrogate Judge} co-evolve. SAGE systematically resolves semantic ambiguities and misalignments, transforming subjective relevance judgment into an executable, multi-dimensional rubric with near human-level agreement. To bridge the gap between frontier model reasoning and industrial-scale inference, we apply teacher-student distillation to transfer high-fidelity judgments into compact student surrogates at \textbf{92$\times$} lower cost. Deployed within LinkedIn Search ecosystems, SAGE guided model iteration through simulation-driven development, distilling policy-aligned models for online serving and enabling rapid offline evaluation. In production, it powered policy oversight that measured ramped model variants and detected regressions invisible to engagement metrics. Collectively, these drove a \textbf{0.25\%} lift in LinkedIn daily active users.

</details>


### [15] [SimGR: Escaping the Pitfalls of Generative Decoding in LLM-based Recommendation](https://arxiv.org/abs/2602.07847)
*Yuanbo Zhao,Ruochen Liu,Senzhang Wang,Jun Yin,Yuxin Dong,Huan Gong,Hao Chen,Shirui Pan,Chengqi Zhang*

Main category: cs.IR

TL;DR: SimGR框架通过直接在共享潜在空间中建模物品级偏好分布，解决了基于LLM的生成推荐中存在的系统性偏差问题，避免了通过token级生成近似物品分布带来的误差。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的生成推荐方法在估计物品级偏好分布时存在系统性偏差：自回归生成因beam search剪枝导致覆盖不全，并行生成因假设token独立而扭曲概率。这些方法通过token级生成近似物品级分布，存在根本性的建模不匹配问题。

Method: 提出SimGR框架，直接在共享潜在空间中建模物品级偏好分布，通过相似度对物品进行排序，使建模目标与推荐任务对齐，避免分布扭曲。该方法不依赖token级生成来近似物品分布。

Result: 在多个数据集和LLM骨干网络上的广泛实验表明，SimGR始终优于现有的生成推荐方法，证明了直接建模物品级分布的有效性。

Conclusion: 通过理论分析和实证验证，token级生成无法忠实替代物品级生成。SimGR通过直接在潜在空间中建模物品级偏好分布，解决了这一根本问题，为基于LLM的推荐系统提供了更准确的分布估计方法。

Abstract: A core objective in recommender systems is to accurately model the distribution of user preferences over items to enable personalized recommendations. Recently, driven by the strong generative capabilities of large language models (LLMs), LLM-based generative recommendation has become increasingly popular. However, we observe that existing methods inevitably introduce systematic bias when estimating item-level preference distributions. Specifically, autoregressive generation suffers from incomplete coverage due to beam search pruning, while parallel generation distorts probabilities by assuming token independence. We attribute this issue to a fundamental modeling mismatch: these methods approximate item-level distributions via token-level generation, which inherently induces approximation errors. Through both theoretical analysis and empirical validation, we demonstrate that token-level generation cannot faithfully substitute item-level generation, leading to biased item distributions. To address this, we propose \textbf{Sim}ply \textbf{G}enerative \textbf{R}ecommendation (\textbf{SimGR}), a framework that directly models item-level preference distributions in a shared latent space and ranks items by similarity, thereby aligning the modeling objective with recommendation and mitigating distributional distortion. Extensive experiments across multiple datasets and LLM backbones show that SimGR consistently outperforms existing generative recommenders. Our code is available at https://anonymous.4open.science/r/SimGR-C408/

</details>


### [16] [Learning to Alleviate Familiarity Bias in Video Recommendation](https://arxiv.org/abs/2602.07987)
*Zheng Ren,Yi Wu,Jianan Lu,Acar Ary,Yiqu Liu,Li Wei,Lukasz Heldt*

Main category: cs.IR

TL;DR: LAFB是一个轻量级、模型无关的框架，用于缓解推荐系统中的熟悉度偏差，已在YouTube推荐系统的后排序阶段部署。


<details>
  <summary>Details</summary>
Motivation: 现代视频推荐系统面临结构性曝光不平衡问题，主要由行为偏差（特别是熟悉度偏差）引起，导致熟悉内容过度主导推荐结果，影响内容多样性和新兴创作者曝光。

Method: LAFB通过离散和连续交互特征建模用户-内容熟悉度，估计个性化去偏因子来调整用户评分预测分数，从而在最终排序中减少熟悉内容的支配地位。

Result: 大规模离线评估和在线A/B测试表明，LAFB增加了新颖观看时间份额，改善了新兴创作者的曝光和整体内容多样性，同时保持了稳定的总体观看时间和短期满意度。

Conclusion: LAFB已成功部署在YouTube推荐系统的后排序阶段，证明其在实际应用中的有效性，能够缓解熟悉度偏差并提升推荐系统的多样性和公平性。

Abstract: Modern video recommendation systems aim to optimize user engagement and platform objectives, yet often face structural exposure imbalances caused by behavioral biases. In this work, we focus on the post-ranking stage and present LAFB (Learning to Alleviate Familiarity Bias), a lightweight and model-agnostic framework designed to mitigate familiarity bias in recommendation outputs. LAFB models user-content familiarity using discrete and continuous interaction features, and estimates personalized debiasing factors to adjust user rating prediction scores, thereby reducing the dominance of familiar content in the final ranking. We conduct large-scale offline evaluations and online A/B testing in a real-world recommendation system, under a unified serving stack that also compares LAFB with deployable popularity-oriented remedies. Results show that LAFB increases novel watch-time share and improves exposure for emerging creators and overall content diversity, while maintaining stable overall watch time and short-term satisfaction. LAFB has already been launched in the post-ranking stage of YouTube's recommendation system, demonstrating its effectiveness in real-world applications.

</details>


### [17] [IRB: Automated Generation of Robust Factuality Benchmarks](https://arxiv.org/abs/2602.08070)
*Lam Thanh Do,Bhagyashree Taleka,Hozaifa Ammar Bhutta,Vikram Sharma Mailthody,Kevin Chen-Chuan Chang,Wen-mei Hwu*

Main category: cs.IR

TL;DR: IRB是一个自动生成RAG系统事实性评估基准的框架，通过结构化生成流程挑战前沿LLM，发现推理型LLM更可靠，改进检索组件比扩展生成器更具成本效益


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统静态基准存在快速饱和问题，需要大量人工维护才能保持鲁棒性，因此需要自动化的基准生成方法来评估RAG系统的事实性

Method: 提出IRB框架，采用结构化生成流程，利用"事实支架"和"算法支架"自动生成评估基准，用于评估前沿LLM和检索器

Result: IRB对前沿LLM在闭卷设置下构成显著挑战；推理型LLM更可靠；改进检索组件比扩展生成器在提高RAG系统正确性方面更具成本效益

Conclusion: IRB为RAG系统提供了有效的自动化评估基准，揭示了推理能力的重要性以及检索组件优化的优先级

Abstract: Static benchmarks for RAG systems often suffer from rapid saturation and require significant manual effort to maintain robustness. To address this, we present IRB, a framework for automatically generating benchmarks to evaluate the factuality of RAG systems. IRB employs a structured generation pipeline utilizing \textit{factual scaffold} and \textit{algorithmic scaffold}. We utilize IRB to construct a benchmark and evaluate frontier LLMs and retrievers. Our results demonstrate that IRB poses a significant challenge for frontier LLMs in the closed-book setting. Furthermore, our evaluation suggests that reasoning LLMs are more reliable, and that improving the retrieval component may yield more cost-effective gains in RAG system correctness than scaling the generator.

</details>


### [18] [A Sketch+Text Composed Image Retrieval Dataset for Thangka](https://arxiv.org/abs/2602.08411)
*Jinyu Xu,Yi Sun,Jiangling Zhang,Qing Xie,Daomin Ji,Zhifeng Bao,Jiachen Li,Yanchun Ma,Yongjian Liu*

Main category: cs.IR

TL;DR: 提出了CIRThan数据集，这是一个针对唐卡图像的草图+文本组合图像检索数据集，包含2,287张高质量唐卡图像，每张图像都配有手绘草图和三层语义层次的文本描述。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索基准主要关注通用领域图像，且依赖带有简短文本修改的参考图像，无法支持需要细粒度语义推理、结构化视觉理解和领域特定知识的检索场景。

Method: 构建了CIRThan数据集，包含2,287张高质量唐卡图像，每张图像都配有手绘草图和三层语义层次的文本描述（结构、元素、符号）。提供了标准化数据划分、全面数据集分析和代表性监督与零样本CIR方法的基准评估。

Result: 实验结果表明，现有的CIR方法（主要为通用领域图像开发）难以有效对齐基于草图的抽象和层次化文本语义与细粒度唐卡图像，特别是在没有领域内监督的情况下。

Conclusion: CIRThan为推进草图+文本组合图像检索、层次化语义建模以及文化遗产和其他知识特定视觉领域的多模态检索提供了有价值的基准。

Abstract: Composed Image Retrieval (CIR) enables image retrieval by combining multiple query modalities, but existing benchmarks predominantly focus on general-domain imagery and rely on reference images with short textual modifications. As a result, they provide limited support for retrieval scenarios that require fine-grained semantic reasoning, structured visual understanding, and domain-specific knowledge. In this work, we introduce CIRThan, a sketch+text Composed Image Retrieval dataset for Thangka imagery, a culturally grounded and knowledge-specific visual domain characterized by complex structures, dense symbolic elements, and domain-dependent semantic conventions. CIRThan contains 2,287 high-quality Thangka images, each paired with a human-drawn sketch and hierarchical textual descriptions at three semantic levels, enabling composed queries that jointly express structural intent and multi-level semantic specification. We provide standardized data splits, comprehensive dataset analysis, and benchmark evaluations of representative supervised and zero-shot CIR methods. Experimental results reveal that existing CIR approaches, largely developed for general-domain imagery, struggle to effectively align sketch-based abstractions and hierarchical textual semantics with fine-grained Thangka images, particularly without in-domain supervision. We believe CIRThan offers a valuable benchmark for advancing sketch+text CIR, hierarchical semantic modeling, and multimodal retrieval in cultural heritage and other knowledge-specific visual domains. The dataset is publicly available at https://github.com/jinyuxu-whut/CIRThan.

</details>


### [19] [Hybrid Pooling with LLMs via Relevance Context Learning](https://arxiv.org/abs/2602.08457)
*David Otero,Javier Parapar*

Main category: cs.IR

TL;DR: 提出Relevance Context Learning (RCL)框架，通过LLM分析相关判断样本来生成主题特定的相关性标准叙述，从而提升自动相关性评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统信息检索系统评估需要大量人工相关性标注，成本高昂。现有LLM自动评估方法（零样本提示或少量示例的上下文学习）未能显式捕捉主题相关性标准，泛化能力有限。

Method: 提出RCL框架：1) 使用Instructor LLM分析已标注的查询-文档对，生成描述主题相关性标准的明确叙述；2) 使用这些相关性叙述作为结构化提示，指导Assessor LLM进行相关性判断；3) 采用混合池化策略，浅层文档由人工标注，其余由LLM标注。

Result: 实验结果显示RCL显著优于零样本提示方法，并持续改进标准上下文学习。表明将相关性示例转化为明确的、上下文感知的相关性叙述是利用人工判断进行LLM驱动的IR数据集构建的更有效方式。

Conclusion: RCL通过显式建模主题特定相关性标准，有效提升了LLM作为自动相关性评估器的可靠性，为大规模IR数据集构建提供了更高效的方法。

Abstract: High-quality relevance judgements over large query sets are essential for evaluating Information Retrieval (IR) systems, yet manual annotation remains costly and time-consuming. Large Language Models (LLMs) have recently shown promise as automatic relevance assessors, but their reliability is still limited. Most existing approaches rely on zero-shot prompting or In-Context Learning (ICL) with a small number of labeled examples. However, standard ICL treats examples as independent instances and fails to explicitly capture the underlying relevance criteria of a topic, restricting its ability to generalize to unseen query-document pairs. To address this limitation, we introduce Relevance Context Learning (RCL), a novel framework that leverages human relevance judgements to explicitly model topic-specific relevance criteria. Rather than directly using labeled examples for in-context prediction, RCL first prompts an LLM (Instructor LLM) to analyze sets of judged query-document pairs and generate explicit narratives that describe what constitutes relevance for a given topic. These relevance narratives are then used as structured prompts to guide a second LLM (Assessor LLM) in producing relevance judgements. To evaluate RCL in a realistic data collection setting, we propose a hybrid pooling strategy in which a shallow depth-\textit{k} pool from participating systems is judged by human assessors, while the remaining documents are labeled by LLMs. Experimental results demonstrate that RCL substantially outperforms zero-shot prompting and consistently improves over standard ICL. Overall, our findings indicate that transforming relevance examples into explicit, context-aware relevance narratives is a more effective way of exploiting human judgements for LLM-based IR dataset construction.

</details>


### [20] [PIT: A Dynamic Personalized Item Tokenizer for End-to-End Generative Recommendation](https://arxiv.org/abs/2602.08530)
*Huanjie Wang,Xinchen Luo,Honghui Bao,Zhang Zixing,Lejian Ren,Yunfan Wu,Hongwei Zhang,Liwei Guan,Guang Chen*

Main category: cs.IR

TL;DR: PIT提出了一种动态个性化项目标记器框架，通过协同生成架构实现索引构建和推荐的端到端联合演化，解决了现有生成推荐方法中协同信号不稳定和训练阶段分离的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐方法通常使用静态解耦的标记化，忽略了协同信号。虽然近期方法尝试在索引构建或端到端建模中整合协同信号，但在实际生产环境中面临挑战：协同信号波动导致标记化不稳定，当前端到端策略往往退化为次优的两阶段训练而非真正的协同演化。

Method: 提出PIT框架，采用协同生成架构，通过协同信号对齐协调协同模式，并通过协同演化学习同步项目标记器和生成推荐器。使用一对多波束索引确保可扩展性和鲁棒性，便于大规模工业部署。

Result: 在真实数据集上的广泛实验表明，PIT始终优于竞争基线。在快手的大规模部署中，在线A/B测试实现了0.402%的App停留时间提升，验证了框架在动态工业环境中的有效性。

Conclusion: PIT框架通过动态个性化项目标记器和协同演化学习，实现了索引构建和推荐的端到端联合演化，解决了生成推荐中协同信号整合的挑战，并在工业环境中证明了其有效性和可扩展性。

Abstract: Generative Recommendation has revolutionized recommender systems by reformulating retrieval as a sequence generation task over discrete item identifiers. Despite the progress, existing approaches typically rely on static, decoupled tokenization that ignores collaborative signals. While recent methods attempt to integrate collaborative signals into item identifiers either during index construction or through end-to-end modeling, they encounter significant challenges in real-world production environments. Specifically, the volatility of collaborative signals leads to unstable tokenization, and current end-to-end strategies often devolve into suboptimal two-stage training rather than achieving true co-evolution. To bridge this gap, we propose PIT, a dynamic Personalized Item Tokenizer framework for end-to-end generative recommendation, which employs a co-generative architecture that harmonizes collaborative patterns through collaborative signal alignment and synchronizes item tokenizer with generative recommender via a co-evolution learning. This enables the dynamic, joint, end-to-end evolution of both index construction and recommendation. Furthermore, a one-to-many beam index ensures scalability and robustness, facilitating seamless integration into large-scale industrial deployments. Extensive experiments on real-world datasets demonstrate that PIT consistently outperforms competitive baselines. In a large-scale deployment at Kuaishou, an online A/B test yielded a substantial 0.402% uplift in App Stay Time, validating the framework's effectiveness in dynamic industrial environments.

</details>


### [21] [DA-RAG: Dynamic Attributed Community Search for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.08545)
*Xingyuan Zeng,Zuohan Wu,Yue Wang,Chen Zhang,Quanming Yao,Libin Zheng,Jian Yin*

Main category: cs.IR

TL;DR: DA-RAG是一种基于属性社区搜索的动态图增强检索生成方法，相比现有G-RAG方法能更好地利用图拓扑结构，在多项指标上提升达40%，同时显著降低计算和token成本。


<details>
  <summary>Details</summary>
Motivation: 当前图增强检索生成方法主要关注低阶结构或预计算静态社区，未能充分利用图拓扑结构，导致处理动态复杂查询时效果受限。

Method: 提出DA-RAG方法，利用属性社区搜索根据查询问题动态提取相关子图，捕捉高阶图结构，并采用分块层导向的图索引实现高效多粒度检索。

Result: 在多个数据集上评估显示，DA-RAG在四项指标上比现有RAG方法提升达40%，同时将索引构建时间和token开销分别降低37%和41%。

Conclusion: DA-RAG通过动态社区搜索有效利用图拓扑结构，显著提升了检索生成性能并降低了成本，为图增强检索生成提供了更优解决方案。

Abstract: Owing to their unprecedented comprehension capabilities, large language models (LLMs) have become indispensable components of modern web search engines. From a technical perspective, this integration represents retrieval-augmented generation (RAG), which enhances LLMs by grounding them in external knowledge bases. A prevalent technical approach in this context is graph-based RAG (G-RAG). However, current G-RAG methodologies frequently underutilize graph topology, predominantly focusing on low-order structures or pre-computed static communities. This limitation affects their effectiveness in addressing dynamic and complex queries. Thus, we propose DA-RAG, which leverages attributed community search (ACS) to extract relevant subgraphs based on the queried question dynamically. DA-RAG captures high-order graph structures, allowing for the retrieval of self-complementary knowledge. Furthermore, DA-RAG is equipped with a chunk-layer oriented graph index, which facilitates efficient multi-granularity retrieval while significantly reducing both computational and economic costs. We evaluate DA-RAG on multiple datasets, demonstrating that it outperforms existing RAG methods by up to 40% in head-to-head comparisons across four metrics while reducing index construction time and token overhead by up to 37% and 41%, respectively.

</details>


### [22] [QARM V2: Quantitative Alignment Multi-Modal Recommendation for Reasoning User Sequence Modeling](https://arxiv.org/abs/2602.08559)
*Tian Xia,Jiaqi Zhang,Yueyang Liu,Hongjian Dou,Tingya Yin,Jiangxia Cao,Xulei Liang,Tianlu Xie,Lihao Liu,Xiang Chen,Shen Wang,Changxin Lao,Haixiang Gan,Jinkai Yu,Keting Cen,Lu Hao,Xu Zhang,Qiqiang Zhong,Zhongbo Sun,Yiyu Wang,Shuang Yang,Mingxin Wen,Xiangyu Wu,Shaoguo Liu,Tingting Gao,Zhaojie Liu,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: QARM V2是一个统一框架，通过将LLM的语义理解与推荐系统的业务需求相结合，解决传统ID嵌入方法的信息密度低、知识隔离和泛化能力弱的问题。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖ID嵌入进行用户序列建模，存在信息密度低、知识隔离和泛化能力弱的问题。虽然LLM具有密集语义表示和强泛化能力的优势，但直接将LLM嵌入应用于推荐系统面临两大挑战：表示与业务目标不匹配，以及表示无法与下游任务端到端学习。

Method: 提出了QARM V2统一框架，旨在桥接LLM语义理解与推荐系统业务需求，用于用户序列建模。该框架解决了LLM嵌入与推荐系统之间的表示匹配和端到端学习问题。

Result: 论文提出了QARM V2框架，但没有在摘要中提供具体的实验结果或性能指标。

Conclusion: QARM V2框架成功地将LLM的语义理解能力与推荐系统的业务需求相结合，为解决传统推荐系统的局限性提供了新的解决方案。

Abstract: With the evolution of large language models (LLMs), there is growing interest in leveraging their rich semantic understanding to enhance industrial recommendation systems (RecSys). Traditional RecSys relies on ID-based embeddings for user sequence modeling in the General Search Unit (GSU) and Exact Search Unit (ESU) paradigm, which suffers from low information density, knowledge isolation, and weak generalization ability. While LLMs offer complementary strengths with dense semantic representations and strong generalization, directly applying LLM embeddings to RecSys faces critical challenges: representation unmatch with business objectives and representation unlearning end-to-end with downstream tasks. In this paper, we present QARM V2, a unified framework that bridges LLM semantic understanding with RecSys business requirements for user sequence modeling.

</details>


### [23] [RankGR: Rank-Enhanced Generative Retrieval with Listwise Direct Preference Optimization in Recommendation](https://arxiv.org/abs/2602.08575)
*Kairui Fu,Changfa Wu,Kun Yuan,Binbin Cao,Dunxian Huang,Yuliang Yan,Junjun Zheng,Jianning Zhang,Silu Zhou,Jian Wu,Kun Kuang*

Main category: cs.IR

TL;DR: RankGR：一种基于排序增强的生成式检索推荐方法，通过两阶段分解检索过程，结合列表式直接偏好优化，提升用户偏好建模精度和推荐效果。


<details>
  <summary>Details</summary>
Motivation: 当前生成式检索方法主要依赖下一词预测范式，存在两个主要问题：1) 难以捕捉用户偏好的细微结构；2) 忽视了已解码标识符与用户行为序列之间的深层交互。需要一种能够更全面理解用户层次化偏好并进行有效偏序建模的方法。

Method: 提出RankGR方法，将检索过程分解为两个互补阶段：初始评估阶段(IAP)和精化评分阶段(RSP)。IAP阶段将新颖的列表式直接偏好优化策略融入生成式检索，实现更全面的用户层次化偏好理解和偏序建模。RSP阶段使用轻量级评分模块对IAP生成的top-λ候选进行精化评分。两个阶段在统一的生成式检索模型下联合优化。

Result: 在研究和工业数据集上的广泛离线实验以及在淘宝"猜你喜欢"模块的在线部署均验证了RankGR的有效性和可扩展性。系统能够实时处理近万个请求/秒，在实际应用中取得了显著效果提升。

Conclusion: RankGR通过两阶段分解和列表式直接偏好优化，解决了传统生成式检索方法的局限性，实现了更精确的用户偏好建模和候选评估，为推荐系统的生成式检索提供了有效且可扩展的解决方案。

Abstract: Generative retrieval (GR) has emerged as a promising paradigm in recommendation systems by autoregressively decoding identifiers of target items. Despite its potential, current approaches typically rely on the next-token prediction schema, which treats each token of the next interacted items as the sole target. This narrow focus 1) limits their ability to capture the nuanced structure of user preferences, and 2) overlooks the deep interaction between decoded identifiers and user behavior sequences. In response to these challenges, we propose RankGR, a Rank-enhanced Generative Retrieval method that incorporates listwise direct preference optimization for recommendation. RankGR decomposes the retrieval process into two complementary stages: the Initial Assessment Phase (IAP) and the Refined Scoring Phase (RSP). In IAP, we incorporate a novel listwise direct preference optimization strategy into GR, thus facilitating a more comprehensive understanding of the hierarchical user preferences and more effective partial-order modeling. The RSP then refines the top-λ candidates generated by IAP with interactions towards input sequences using a lightweight scoring module, leading to more precise candidate evaluation. Both phases are jointly optimized under a unified GR model, ensuring consistency and efficiency. Additionally, we implement several practical improvements in training and deployment, ultimately achieving a real-time system capable of handling nearly ten thousand requests per second. Extensive offline performance on both research and industrial datasets, as well as the online gains on the "Guess You Like" section of Taobao, validate the effectiveness and scalability of RankGR.

</details>


### [24] [OneLive: Dynamically Unified Generative Framework for Live-Streaming Recommendation](https://arxiv.org/abs/2602.08612)
*Shen Wang,Yusheng Huang,Ruochen Yang,Shuang Wen,Pengbo Xu,Jiangxia Cao,Yueyang Liu,Kuo Cai,Chengcheng Guo,Shiyao Wang,Xinchen Luo,Qiang Luo,Ruiming Tang,Shuang Yang,Zhaojie Liu,Guorui Zhou,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: OneLive是一个为直播场景定制的动态统一生成式推荐框架，解决了传统生成式推荐方法无法直接应用于直播场景的问题，通过动态token化、时间感知注意力、高效解码器和多目标对齐等组件来处理直播的实时性、内容演化和多目标挑战。


<details>
  <summary>Details</summary>
Motivation: 直播推荐系统面临独特挑战：内容持续演化、生命周期有限、严格实时约束和异构多目标，这些使得传统的静态token化和生成式推荐框架无法直接应用。需要专门针对直播场景设计新的推荐框架。

Method: 提出OneLive框架，包含四个核心组件：1) 动态tokenizer通过残差量化融合实时直播内容和行为信号；2) 时间感知门控注意力机制显式建模时间动态性；3) 高效解码器架构采用Sequential MTP和QK Norm实现稳定训练和加速推理；4) 统一多目标对齐框架强化策略优化以适应个性化偏好。

Result: 论文提出了专门针对直播场景的生成式推荐框架OneLive，能够处理直播的实时性、内容演化和多目标挑战，但具体实验结果未在摘要中提供。

Conclusion: OneLive是一个为直播推荐场景量身定制的动态统一生成式推荐框架，通过创新的动态token化、时间建模、高效架构和多目标对齐机制，有效解决了直播场景特有的挑战，为直播推荐系统提供了新的解决方案。

Abstract: Live-streaming recommender system serves as critical infrastructure that bridges the patterns of real-time interactions between users and authors. Similar to traditional industrial recommender systems, live-streaming recommendation also relies on cascade architectures to support large-scale concurrency. Recent advances in generative recommendation unify the multi-stage recommendation process with Transformer-based architectures, offering improved scalability and higher computational efficiency. However, the inherent complexity of live-streaming prevents the direct transfer of these methods to live-streaming scenario, where continuously evolving content, limited lifecycles, strict real-time constraints, and heterogeneous multi-objectives introduce unique challenges that invalidate static tokenization and conventional model framework. To address these issues, we propose OneLive, a dynamically unified generative recommendation framework tailored for live-streaming scenario. OneLive integrates four key components: (i) A Dynamic Tokenizer that continuously encodes evolving real-time live content fused with behavior signal through residual quantization; (ii) A Time-Aware Gated Attention mechanism that explicitly models temporal dynamics for timely decision making; (iii) An efficient decoder-only generative architecture enhanced with Sequential MTP and QK Norm for stable training and accelerated inference; (iv) A Unified Multi-Objective Alignment Framework reinforces policy optimization for personalized preferences.

</details>


### [25] [SRSUPM: Sequential Recommender System Based on User Psychological Motivation](https://arxiv.org/abs/2602.08667)
*Yicheng Di,Yuan Liu,Zhi Chen,Jingcai Guo*

Main category: cs.IR

TL;DR: 提出SRSUPM框架，通过心理动机转移建模增强序列推荐系统，解决现有方法缺乏显式心理动机转移建模的问题


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法将近期行为压缩为单个向量并优化到单个目标物品，但缺乏对用户心理动机转移的显式建模，导致难以捕捉不同转移程度下的分布模式和协作知识

Method: 提出SRSUPM框架：1) 心理动机转移评估定量测量转移程度；2) 转移信息构建动态演化多级转移状态；3) 心理动机转移驱动信息分解分解和正则化不同转移级别的表示；4) 心理动机转移信息匹配强化与转移相关的协作模式

Result: 在三个公共基准测试上的广泛实验表明，SRSUPM在多种序列推荐任务上持续优于代表性基线方法

Conclusion: SRSUPM框架通过显式建模用户心理动机转移，能够学习更具区分性的用户表示，有效提升序列推荐性能

Abstract: Sequential recommender infers users' evolving psychological motivations from historical interactions to recommend the next preferred items. Most existing methods compress recent behaviors into a single vector and optimize it toward a single observed target item, but lack explicit modeling of psychological motivation shift. As a result, they struggle to uncover the distributional patterns across different shift degrees and to capture collaborative knowledge that is sensitive to psychological motivation shift. We propose a general framework, the Sequential Recommender System Based on User Psychological Motivation, to enhance sequential recommenders with psychological motivation shift-aware user modeling. Specifically, the Psychological Motivation Shift Assessment quantitatively measures psychological motivation shift; guided by PMSA, the Shift Information Construction models dynamically evolving multi-level shift states, and the Psychological Motivation Shift-driven Information Decomposition decomposes and regularizes representations across shift levels. Moreover, the Psychological Motivation Shift Information Matching strengthens collaborative patterns related to psychological motivation shift to learn more discriminative user representations. Extensive experiments on three public benchmarks show that SRSUPM consistently outperforms representative baselines on diverse sequential recommender tasks.

</details>


### [26] [SA-CAISR: Stage-Adaptive and Conflict-Aware Incremental Sequential Recommendation](https://arxiv.org/abs/2602.08678)
*Xiaomeng Song,Xinru Wang,Hanbing Wang,Hongyu Lu,Yu Chen,Zhaochun Ren,Zhumin Chen*

Main category: cs.IR

TL;DR: SA-CAISR：一种无需缓冲区的增量序列推荐框架，通过Fisher加权知识筛选机制动态识别过时知识，在减少97.5%内存使用和46.9%训练时间的同时，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有增量学习方法面临两大挑战：基于回放的方法内存和计算成本高；基于正则化的方法难以有效丢弃过时或冲突知识。需要一种既能高效更新又能动态平衡稳定性和适应性的增量序列推荐框架。

Method: 提出SA-CAISR框架，采用无缓冲区设计，仅使用旧模型和新数据。核心创新是Fisher加权知识筛选机制，通过估计旧模型与新数据之间的参数级冲突，动态识别过时知识，选择性移除过时知识同时保留兼容的历史模式。

Result: 在增量序列推荐任务中达到新的SOTA性能：Recall@20平均提升2.0%，MRR@20提升1.2%，NDCG@20提升1.4%。同时内存使用减少97.5%，训练时间减少46.9%。

Conclusion: SA-CAISR通过动态平衡稳定性和适应性，在显著降低计算开销的同时提升推荐性能，使现实系统能够以最小计算开销快速更新用户画像，提供更及时准确的推荐。

Abstract: Sequential recommendation (SR) aims to predict a user's next action by learning from their historical interaction sequences. In real-world applications, these models require periodic updates to adapt to new interactions and evolving user preferences. While incremental learning methods facilitate these updates, they face significant challenges. Replay-based approaches incur high memory and computational costs, and regularization-based methods often struggle to discard outdated or conflicting knowledge. To overcome these challenges, we propose SA-CAISR, a Stage-Adaptive and Conflict-Aware Incremental Sequential Recommendation framework. As a buffer-free framework, SA-CAISR operates using only the old model and new data, directly addressing the high costs of replay-based techniques. SA-CAISR introduces a novel Fisher-weighted knowledge-screening mechanism that dynamically identifies outdated knowledge by estimating parameter-level conflicts between the old model and new data, allowing our approach to selectively remove obsolete knowledge while preserving compatible historical patterns. This dynamic balance between stability and adaptability allows our method to achieve a new state-of-the-art performance in incremental SR. Specifically, SA-CAISR improves Recall@20 by 2.0%, MRR@20 by 1.2%, and NDCG@20 by 1.4% on average across datasets, while reducing memory usage by 97.5% and training time by 46.9% compared to the best baselines. This efficiency allows real-world systems to rapidly update user profiles with minimal computational overhead, ensuring more timely and accurate recommendations.

</details>


### [27] [AMEM4Rec: Leveraging Cross-User Similarity for Memory Evolution in Agentic LLM Recommenders](https://arxiv.org/abs/2602.08837)
*Minh-Duc Nguyen,Hai-Dang Kieu,Dung D. Le*

Main category: cs.IR

TL;DR: AMEM4Rec：通过跨用户记忆演化的智能LLM推荐系统，在端到端学习中捕获协同过滤信号，无需预训练CF模型


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能推荐系统面临参数效率低、提示推理受上下文长度限制和幻觉风险等问题，且现有系统主要依赖语义知识而忽略了协同过滤信号这一隐式偏好建模的关键要素

Method: 提出AMEM4Rec框架，通过全局记忆池存储抽象用户行为模式，在池中记忆与相似现有记忆链接并迭代演化以强化跨用户共享模式，从而在端到端学习中捕获协同过滤信号

Result: 在Amazon和MIND数据集上的广泛实验表明，AMEM4Rec持续优于最先进的基于LLM的推荐系统，证明了演化记忆引导的协同过滤的有效性

Conclusion: AMEM4Rec通过跨用户记忆演化机制成功地将协同过滤信号整合到智能LLM推荐系统中，解决了现有方法的局限性，为LLM在推荐系统中的应用提供了新思路

Abstract: Agentic systems powered by Large Language Models (LLMs) have shown strong potential in recommender systems but remain hindered by several challenges. Fine-tuning LLMs is parameter-inefficient, and prompt-based agentic reasoning is limited by context length and hallucination risk. Moreover, existing agentic recommendation systems predominantly leverages semantic knowledge while neglecting the collaborative filtering (CF) signals essential for implicit preference modeling. To address these limitations, we propose AMEM4Rec, an agentic LLM-based recommender that learns collaborative signals in an end-to-end manner through cross-user memory evolution. AMEM4Rec stores abstract user behavior patterns from user histories in a global memory pool. Within this pool, memories are linked to similar existing ones and iteratively evolved to reinforce shared cross-user patterns, enabling the system to become aware of CF signals without relying on a pre-trained CF model. Extensive experiments on Amazon and MIND datasets show that AMEM4Rec consistently outperforms state-of-the-art LLM-based recommenders, demonstrating the effectiveness of evolving memory-guided collaborative filtering.

</details>


### [28] [Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation](https://arxiv.org/abs/2602.08873)
*Lisette Espin-Noboa,Gonzalo Gabriel Mendez*

Main category: cs.IR

TL;DR: LLMScholarBench是一个用于审计基于LLM的学者推荐系统的基准测试，它同时评估模型基础设施和终端用户干预措施，发现这些干预措施并不能普遍改善性能，而是重新分配了不同维度上的错误。


<details>
  <summary>Details</summary>
Motivation: 现有审计通常孤立评估模型输出，忽略了终端用户在推理时的干预，因此不清楚推荐失败（如拒绝、幻觉、覆盖不均）是源于模型选择还是部署决策。需要一个新的基准来联合评估模型基础设施和终端用户干预。

Method: 引入LLMScholarBench基准，使用9个指标衡量技术质量和社会代表性。在物理学专家推荐中实例化该基准，审计22个LLM在温度变化、代表性约束提示和通过网络搜索的检索增强生成（RAG）下的表现。

Result: 终端用户干预不能带来普遍改进，而是重新分配了不同维度上的错误：更高温度会降低有效性、一致性和事实性；代表性约束提示提高了多样性但牺牲了事实性；RAG主要改善技术质量但降低了多样性和公平性。

Conclusion: 终端用户干预重塑了权衡取舍，而不是提供通用解决方案。研究发布了代码和数据，可通过替换领域特定的真实数据和指标来适应其他学科。

Abstract: Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.

</details>


### [29] [Contrastive Learning for Diversity-Aware Product Recommendations in Retail](https://arxiv.org/abs/2602.08886)
*Vasileios Karlis,Ezgi Yıldırım,David Vos,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该论文提出了一种通过负采样和对比学习来提升推荐系统目录覆盖率的方法，在保持推荐质量的同时增加长尾商品的曝光


<details>
  <summary>Details</summary>
Motivation: 推荐系统通常面临长尾分布和有限商品目录曝光的问题，少数热门商品主导推荐结果。这在大型在线零售环境中尤为关键，因为商品种类繁多且多样

Method: 受负采样解决流行度偏差的启发，将对比学习与精心选择的负样本相结合，在IKEA现有的数字推荐流程中集成该方法

Result: 通过离线和在线评估，该方法提高了目录覆盖率，确保推荐更加多样化，同时保持了强大的推荐性能

Conclusion: 该方法能够在保持推荐质量的同时，有效提升推荐系统的目录覆盖率，为大规模在线零售环境中的推荐多样性问题提供了解决方案

Abstract: Recommender systems often struggle with long-tail distributions and limited item catalog exposure, where a small subset of popular items dominates recommendations. This challenge is especially critical in large-scale online retail settings with extensive and diverse product assortments. This paper introduces an approach to enhance catalog coverage without compromising recommendation quality in the existing digital recommendation pipeline at IKEA Retail. Drawing inspiration from recent advances in negative sampling to address popularity bias, we integrate contrastive learning with carefully selected negative samples. Through offline and online evaluations, we demonstrate that our method improves catalog coverage, ensuring a more diverse set of recommendations yet preserving strong recommendation performance.

</details>


### [30] [OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation](https://arxiv.org/abs/2602.08896)
*Yehua Huang,Penglei Sun,Zebin Chen,Zhenheng Tang,Xiaowen Chu*

Main category: cs.IR

TL;DR: OmniReview数据集与Pro-MMoE框架：通过整合多源学术平台构建大规模验证评审数据集，并提出结合LLM语义档案与多门混合专家的评审推荐新方法，在多项指标上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 学术同行评审面临数据和方法双重挑战：数据方面缺乏大规模验证基准和反映真实编辑流程的评估指标；方法方面现有嵌入方法存在语义压缩信息瓶颈和有限可解释性。

Method: 1) 构建OmniReview数据集：整合多源学术平台，通过消歧流程获得202,756条验证评审记录；2) 提出三层分层评估框架；3) 开发Pro-MMoE框架：结合LLM生成语义档案保留细粒度专业细节，采用任务自适应多门混合专家架构动态平衡冲突评估目标。

Result: Pro-MMoE在7个评估指标中的6个上达到最先进性能，为现实评审推荐建立了新基准，验证了该方法在保留专业细节和可解释性方面的优势。

Conclusion: OmniReview数据集和Pro-MMoE框架有效解决了学术评审推荐中的数据和方法限制，通过大规模验证数据和LLM与多任务学习的协同，为现实评审推荐提供了更准确、可解释的解决方案。

Abstract: Academic peer review remains the cornerstone of scholarly validation, yet the field faces some challenges in data and methods. From the data perspective, existing research is hindered by the scarcity of large-scale, verified benchmarks and oversimplified evaluation metrics that fail to reflect real-world editorial workflows. To bridge this gap, we present OmniReview, a comprehensive dataset constructed by integrating multi-source academic platforms encompassing comprehensive scholarly profiles through the disambiguation pipeline, yielding 202, 756 verified review records. Based on this data, we introduce a three-tier hierarchical evaluaion framework to assess recommendations from recall to precise expert identification. From the method perspective, existing embedding-based approaches suffer from the information bottleneck of semantic compression and limited interpretability. To resolve these method limitations, we propose Profiling Scholars with Multi-gate Mixture-of-Experts (Pro-MMoE), a novel framework that synergizes Large Language Models (LLMs) with Multi-task Learning. Specifically, it utilizes LLM-generated semantic profiles to preserve fine-grained expertise nuances and interpretability, while employing a Task-Adaptive MMoE architecture to dynamically balance conflicting evaluation goals. Comprehensive experiments demonstrate that Pro-MMoE achieves state-of-the-art performance across six of seven metrics, establishing a new benchmark for realistic reviewer recommendation.

</details>


### [31] [Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion](https://arxiv.org/abs/2602.08917)
*Minghan Li,Ercong Nie,Siqi Zhao,Tongna Chen,Huiping Huang,Guodong Zhou*

Main category: cs.IR

TL;DR: 提出自动化、领域自适应的查询扩展框架，通过BM25-MonoT5构建领域内示例池，使用无监督聚类选择多样化示例，并引入两LLM集成方法提升扩展质量


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的查询扩展方法依赖手工提示、手动选择示例或单一LLM，导致可扩展性差且对领域迁移敏感，需要自动化、领域自适应的解决方案

Method: 1) 使用BM25-MonoT5管道从伪相关段落构建领域内示例池；2) 采用无训练聚类策略选择多样化演示示例；3) 提出两LLM集成方法：两个异构LLM独立生成扩展，再由第三个LLM整合为一致扩展

Result: 在TREC DL20、DBPedia和SciFact数据集上，精炼集成方法相比BM25、Rocchio、零样本和固定少样本基线获得一致且统计显著的性能提升

Conclusion: 该框架为示例选择和多LLM生成提供了可复现的测试平台，并为实际应用中的查询扩展提供了无需标注的实用解决方案

Abstract: Query expansion with large language models is promising but often relies on hand-crafted prompts, manually chosen exemplars, or a single LLM, making it non-scalable and sensitive to domain shift. We present an automated, domain-adaptive QE framework that builds in-domain exemplar pools by harvesting pseudo-relevant passages using a BM25-MonoT5 pipeline. A training-free cluster-based strategy selects diverse demonstrations, yielding strong and stable in-context QE without supervision. To further exploit model complementarity, we introduce a two-LLM ensemble in which two heterogeneous LLMs independently generate expansions and a refinement LLM consolidates them into one coherent expansion. Across TREC DL20, DBPedia, and SciFact, the refined ensemble delivers consistent and statistically significant gains over BM25, Rocchio, zero-shot, and fixed few-shot baselines. The framework offers a reproducible testbed for exemplar selection and multi-LLM generation, and a practical, label-free solution for real-world QE.

</details>
