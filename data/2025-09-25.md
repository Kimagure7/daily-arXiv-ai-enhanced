<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [AIRwaves at CheckThat! 2025: Retrieving Scientific Sources for Implicit Claims on Social Media with Dual Encoders and Neural Re-Ranking](https://arxiv.org/abs/2509.19509)
*Cem Ashbaugh,Leon Baumgärtner,Tim Gress,Nikita Sidorov,Daniel Werner*

Main category: cs.IR

TL;DR: 该论文提出了一个两阶段检索管道，用于将社交媒体上的隐式科学声明链接到原始出版物，在CLEF-2025 CheckThat! Lab的Subtask 4b中排名第二。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的科学声明与原始出版物链接对于基于证据的事实核查和学术讨论至关重要，但受到词汇稀疏性、极短查询和领域特定语言的阻碍。

Method: 采用两阶段检索管道：第一阶段使用基于E5-large的双编码器，通过批内和挖掘的困难负样本进行微调，并增强分块标记化和丰富文档元数据；第二阶段使用SciBERT交叉编码器进行神经重排序。

Result: 优化后的稀疏检索基线(BM25)在黄金标签盲测集上达到MRR@5 = 0.5025。神经表示将性能提升至MRR@5 = 0.6174，完整管道进一步改进至MRR@5 = 0.6828，显著优于竞争基线。

Conclusion: 将密集检索与神经重排序器结合为推文到研究匹配提供了强大高效的解决方案，并为未来证据检索管道提供了实用蓝图。

Abstract: Linking implicit scientific claims made on social media to their original
publications is crucial for evidence-based fact-checking and scholarly
discourse, yet it is hindered by lexical sparsity, very short queries, and
domain-specific language. Team AIRwaves ranked second in Subtask 4b of the
CLEF-2025 CheckThat! Lab with an evidence-retrieval approach that markedly
outperforms the competition baseline. The optimized sparse-retrieval
baseline(BM25) achieves MRR@5 = 0.5025 on the gold label blind test set. To
surpass this baseline, a two-stage retrieval pipeline is introduced: (i) a
first stage that uses a dual encoder based on E5-large, fine-tuned using
in-batch and mined hard negatives and enhanced through chunked tokenization and
rich document metadata; and (ii) a neural re-ranking stage using a SciBERT
cross-encoder. Replacing purely lexical matching with neural representations
lifts performance to MRR@5 = 0.6174, and the complete pipeline further improves
to MRR@5 = 0.6828. The findings demonstrate that coupling dense retrieval with
neural re-rankers delivers a powerful and efficient solution for tweet-to-study
matching and provides a practical blueprint for future evidence-retrieval
pipelines.

</details>


### [2] [Learning Contextual Retrieval for Robust Conversational Search](https://arxiv.org/abs/2509.19700)
*Seunghan Yang,Juntae Lee,Jihwan Bang,Kyuhong Shim,Minsoo Kim,Simyung Chang*

Main category: cs.IR

TL;DR: 提出ContextualRetriever，一种直接整合对话上下文的LLM检索器，解决多轮对话中用户意图跟踪问题，在保持性能的同时不增加推理开销


<details>
  <summary>Details</summary>
Motivation: 传统检索器难以处理多轮对话中的缩写和话题转换，查询重写技术计算成本高，现有LLM检索器未针对多轮意图跟踪优化，容易在话题漂移或上下文模糊时失败

Method: 引入上下文感知嵌入机制突出当前查询，基于高质量重写查询的意图引导监督，以及保持基础LLM生成能力的训练策略

Result: 在多个对话搜索基准测试中，ContextualRetriever显著优于现有方法，且不产生额外推理开销

Conclusion: ContextualRetriever有效解决了多轮对话检索中的意图跟踪问题，在性能和效率方面都表现出色

Abstract: Effective conversational search demands a deep understanding of user intent
across multiple dialogue turns. Users frequently use abbreviations and shift
topics in the middle of conversations, posing challenges for conventional
retrievers. While query rewriting techniques improve clarity, they often incur
significant computational cost due to additional autoregressive steps.
Moreover, although LLM-based retrievers demonstrate strong performance, they
are not explicitly optimized to track user intent in multi-turn settings, often
failing under topic drift or contextual ambiguity. To address these
limitations, we propose ContextualRetriever, a novel LLM-based retriever that
directly incorporates conversational context into the retrieval process. Our
approach introduces: (1) a context-aware embedding mechanism that highlights
the current query within the dialogue history; (2) intent-guided supervision
based on high-quality rewritten queries; and (3) a training strategy that
preserves the generative capabilities of the base LLM. Extensive evaluations
across multiple conversational search benchmarks demonstrate that
ContextualRetriever significantly outperforms existing methods while incurring
no additional inference overhead.

</details>


### [3] [FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion](https://arxiv.org/abs/2509.19767)
*Alireza Heidari,Wei Zhang,Ying Xiong*

Main category: cs.IR

TL;DR: FusedANN是一个几何框架，通过将属性过滤提升为ANN优化约束，引入拉格朗日松弛的凸融合空间，将硬过滤器转化为连续的加权惩罚，实现高效的混合查询搜索。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的向量搜索需要结合向量相似性和属性过滤的混合查询，但现有解决方案在召回率、速度和灵活性之间存在权衡，依赖脆弱的索引技巧且无法扩展。

Method: 通过基于变换器的凸化方法联合嵌入属性和向量，将硬过滤器转化为连续加权惩罚，保留top-k语义的同时实现高效近似搜索。

Result: FusedANN在标准混合基准测试中消除了脆弱的过滤阶段，实现了优越的召回率-延迟权衡，比最先进的混合和图基系统吞吐量提高3倍且召回率更好。

Conclusion: FusedANN在符号约束和向量相似性之间建立了原则性、可扩展且可验证的桥梁，为大规模、混合和动态的NLP/ML工作负载解锁了新一代过滤检索系统。

Abstract: Vector search powers transformers technology, but real-world use demands
hybrid queries that combine vector similarity with attribute filters (e.g.,
"top document in category X, from 2023"). Current solutions trade off recall,
speed, and flexibility, relying on fragile index hacks that don't scale. We
introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric
framework that elevates filtering to ANN optimization constraints and
introduces a convex fused space via a Lagrangian-like relaxation. Our method
jointly embeds attributes and vectors through transformer-based
convexification, turning hard filters into continuous, weighted penalties that
preserve top-k semantics while enabling efficient approximate search. We prove
that FusedANN reduces to exact filtering under high selectivity, gracefully
relaxes to semantically nearest attributes when exact matches are insufficient,
and preserves downstream ANN alpha-approximation guarantees. Empirically,
FusedANN improves query throughput by eliminating brittle filtering stages,
achieving superior recall-latency tradeoffs on standard hybrid benchmarks
without specialized index hacks, delivering up to 3 times higher throughput and
better recall than state-of-the-art hybrid and graph-based systems.
Theoretically, we provide explicit error bounds and parameter selection rules
that make FusedANN practical for production. This establishes a principled,
scalable, and verifiable bridge between symbolic constraints and vector
similarity, unlocking a new generation of filtered retrieval systems for large,
hybrid, and dynamic NLP/ML workloads.

</details>


### [4] [Adaptive User Interest Modeling via Conditioned Denoising Diffusion For Click-Through Rate Prediction](https://arxiv.org/abs/2509.19876)
*Qihang Zhao,Xiaoyang Zheng,Ben Chen,Zhongbo Sun,Chenyi Lei*

Main category: cs.IR

TL;DR: 本文提出Contextual Diffusion Purifier (CDP)方法，通过前向加噪和条件反向去噪过程，从受污染的用户行为序列中生成纯净、上下文感知的兴趣表示，解决搜索系统中用户行为序列的噪声污染和静态表示问题。


<details>
  <summary>Details</summary>
Motivation: 搜索系统中的用户行为序列存在曝光偏差、类别漂移和上下文噪声等问题，现有方法假设序列不变地反映用户偏好，忽略了噪声与真实兴趣的有机纠缠，且输出静态、上下文无关的表示，无法适应动态意图变化。

Method: CDP将类别过滤后的行为视为受污染观测，采用前向加噪和条件反向去噪过程，通过跨交互特征（查询×用户×物品×上下文）引导，可控地生成纯净、上下文感知的兴趣表示。

Result: 离线和在线实验表明，CDP在性能上优于现有最先进方法。

Conclusion: CDP有效解决了用户行为序列中的噪声污染问题，能够生成动态适应不同场景的上下文感知兴趣表示，在搜索系统中具有显著优势。

Abstract: User behavior sequences in search systems resemble "interest fossils",
capturing genuine intent yet eroded by exposure bias, category drift, and
contextual noise. Current methods predominantly follow an "identify-aggregate"
paradigm, assuming sequences immutably reflect user preferences while
overlooking the organic entanglement of noise and genuine interest. Moreover,
they output static, context-agnostic representations, failing to adapt to
dynamic intent shifts under varying Query-User-Item-Context conditions.
  To resolve this dual challenge, we propose the Contextual Diffusion Purifier
(CDP). By treating category-filtered behaviors as "contaminated observations",
CDP employs a forward noising and conditional reverse denoising process guided
by cross-interaction features (Query x User x Item x Context), controllably
generating pure, context-aware interest representations that dynamically evolve
with scenarios. Extensive offline/online experiments demonstrate the
superiority of CDP over state-of-the-art methods.

</details>


### [5] [Documentation Retrieval Improves Planning Language Generation](https://arxiv.org/abs/2509.19931)
*Renxiang Wang,Li Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种轻量级管道方法，通过文档检索、模块化代码生成和错误精炼，显著提升了中小型开源LLM在零样本形式化规划任务中的性能，将计划正确率从0%提升至80%以上，但语义错误在复杂领域仍然存在。


<details>
  <summary>Details</summary>
Motivation: 当前大多数参数小于50B的开源LLM在零样本形式化规划任务中表现接近零，主要原因是PDDL等规划语言的资源稀缺性。

Method: 采用轻量级管道方法，整合文档检索、模块化代码生成和错误精炼三个模块来提升模型性能。

Result: 在BlocksWorld领域，最佳管道将计划正确率从0%提升至超过80%，但语法错误大幅减少的同时，语义错误在更具挑战性的领域仍然存在。

Conclusion: 虽然提出的方法显著提升了性能，但当前模型在复杂领域的推理能力仍存在根本性限制，语义错误问题尚未完全解决。

Abstract: Certain strong LLMs have shown promise for zero-shot formal planning by
generating planning languages like PDDL. Yet, performance of most open-source
models under 50B parameters has been reported to be close to zero due to the
low-resource nature of these languages. We significantly improve their
performance via a series of lightweight pipelines that integrates documentation
retrieval with modular code generation and error refinement. With models like
Llama-4-Maverick, our best pipeline improves plan correctness from 0\% to over
80\% on the common BlocksWorld domain. However, while syntactic errors are
substantially reduced, semantic errors persist in more challenging domains,
revealing fundamental limitations in current models' reasoning
capabilities.\footnote{Our code and data can be found at
https://github.com/Nangxxxxx/PDDL-RAG

</details>


### [6] [Multimodal-enhanced Federated Recommendation: A Group-wise Fusion Approach](https://arxiv.org/abs/2509.19955)
*Chunxu Zhang,Weipeng Zhang,Guodong Long,Zhiheng Xue,Riting Xia,Bo Yang*

Main category: cs.IR

TL;DR: 本文提出了一种新的多模态联邦推荐框架GFMFR，通过服务器端处理多模态特征来提升推荐性能，同时解决效率、分布异质性和细粒度对齐等挑战。


<details>
  <summary>Details</summary>
Motivation: 联邦推荐在保护隐私的同时面临多模态特征整合的挑战，包括效率问题、分布异质性和细粒度对齐困难。

Method: GFMFR将多模态表示学习卸载到服务器端，采用分组感知的物品表示融合方法，并设计了可插拔的融合损失函数。

Result: 在五个公共基准数据集上的实验表明，GFMFR持续优于现有的多模态联邦推荐基线方法。

Conclusion: GFMFR为联邦推荐系统提供了一种有效整合多模态特征的方法，在保持隐私保护的同时显著提升了推荐性能。

Abstract: Federated Recommendation (FR) is a new learning paradigm to tackle the
learn-to-rank problem in a privacy-preservation manner. How to integrate
multi-modality features into federated recommendation is still an open
challenge in terms of efficiency, distribution heterogeneity, and fine-grained
alignment. To address these challenges, we propose a novel multimodal fusion
mechanism in federated recommendation settings (GFMFR). Specifically, it
offloads multimodal representation learning to the server, which stores item
content and employs a high-capacity encoder to generate expressive
representations, alleviating client-side overhead. Moreover, a group-aware item
representation fusion approach enables fine-grained knowledge sharing among
similar users while retaining individual preferences. The proposed fusion loss
could be simply plugged into any existing federated recommender systems
empowering their capability by adding multi-modality features. Extensive
experiments on five public benchmark datasets demonstrate that GFMFR
consistently outperforms state-of-the-art multimodal FR baselines.

</details>


### [7] [Cascade! Human in the loop shortcomings can increase the risk of failures in recommender systems](https://arxiv.org/abs/2509.20099)
*Wm. Matthew Kennedy,Nishanshi Shukla,Cigdem Patlak,Blake Chambers,Theodora Skeadas,Tuesday,Kingsley Owadara,Aayush Dhanotiya*

Main category: cs.IR

TL;DR: 本文探讨了推荐系统中"人在回路"监督模式的新风险，指出这种监督方式在特定信息环境下可能增加级联失败的风险，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统广泛采用"人在回路"模式来确保问责制，但作者认为这种人类监督方式存在尚未充分描述的新风险，特别是在不同的部署环境下可能无法实现社会责任的推荐。

Method: 通过分析人类监督的局限性如何增加特定类型的失败（级联或复合失败）的可能性，并探讨三种常见部署环境下人类监督失效的独特动态机制。

Result: 研究发现"人在回路"实践在提供有意义的AI系统监督方面存在不足，特别是在推荐系统领域可能无法实现社会责任目标。

Conclusion: 作者提出了两个建议来改进推荐系统中的人类监督机制，以降低级联失败的风险并提高系统的社会责任性。

Abstract: Recommender systems are among the most commonly deployed systems today.
Systems design approaches to AI-powered recommender systems have done well to
urge recommender system developers to follow more intentional data collection,
curation, and management procedures. So too has the "human-in-the-loop"
paradigm been widely adopted, primarily to address the issue of accountability.
However, in this paper, we take the position that human oversight in
recommender system design also entails novel risks that have yet to be fully
described. These risks are "codetermined" by the information context in which
such systems are often deployed. Furthermore, new knowledge of the shortcomings
of "human-in-the-loop" practices to deliver meaningful oversight of other AI
systems suggest that they may also be inadequate for achieving socially
responsible recommendations. We review how the limitations of human oversight
may increase the chances of a specific kind of failure: a "cascade" or
"compound" failure. We then briefly explore how the unique dynamics of three
common deployment contexts can make humans in the loop more likely to fail in
their oversight duties. We then conclude with two recommendations.

</details>


### [8] [Intelligent Algorithm Selection for Recommender Systems: Meta-Learning via in-depth algorithm feature engineering](https://arxiv.org/abs/2509.20134)
*Jarne Mathi Decker*

Main category: cs.IR

TL;DR: 该论文研究了在推荐系统中通过为算法本身构建特征集来改进算法选择问题，发现虽然算法特征提高了Top-1选择准确率，但用户特征在整体性能中仍占主导地位。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中的算法选择问题，传统元学习方法将算法视为黑盒选择，本研究旨在通过为算法本身构建特征来克服这一局限。

Method: 构建了包含静态代码指标、抽象语法树属性、行为性能基准和高层概念特征的算法特征集，在五个数据集上评估了仅使用用户特征的基线模型和同时使用用户与算法特征的模型。

Result: 使用算法特征的元学习器平均NDCG@10为0.143，比单一最佳算法基线提高11.7%，但与仅使用用户特征的元学习器(0.144)相比没有改善。算法特征提高了Top-1选择准确率16.1%，但降低了Top-3准确率10.7%。

Conclusion: 在推荐系统的个性化算法选择任务中，用户特征的预测能力占主导地位。虽然算法特征能提高选择精度，但要利用其潜力提升整体性能仍是一个挑战。

Abstract: The "No Free Lunch" theorem dictates that no single recommender algorithm is
optimal for all users, creating a significant Algorithm Selection Problem.
Standard meta-learning approaches aim to solve this by selecting an algorithm
based on user features, but treat the fundamentally diverse algorithms
themselves as equivalent, "black-box" choices. This thesis investigates the
impact of overcoming this limitation by engineering a comprehensive feature set
to explicitly characterize the algorithms themselves. We combine static code
metrics, Abstract Syntax Tree properties, behavioral performance landmarks, and
high-level conceptual features. We evaluate two meta-learners across five
datasets: a baseline using only user features and our proposed model using both
user and algorithm features. Our results show that the meta-learner augmented
with algorithm features achieves an average NDCG@10 of 0.143, a statistically
significant improvement of 11.7% over the Single Best Algorithm baseline
(0.128). However, we found that the inclusion of algorithm features did not
lead to an improvement in overall NDCG@10 over the meta learner using only user
features (0.144). While adding algorithm features to the meta-learner did
improve its Top-1 selection accuracy (+16.1%), this was counterbalanced by
leading to a lower Top-3 accuracy (-10.7%). We conclude that for the per-user
algorithm selection task in recommender systems, the predictive power of user
features is overwhelmingly dominant. While algorithm features improve selection
precision, unlocking their potential to boost overall performance remains a
non-trivial challenge.

</details>


### [9] [Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation](https://arxiv.org/abs/2509.20225)
*Hui Wang,Jinghui Qin,Wushao Wen,Qingling Li,Shanshan Zhong,Zhongzhan Huang*

Main category: cs.IR

TL;DR: 本文提出了一种多模态表示解缠信息瓶颈（MRdIB）框架，通过信息瓶颈压缩输入表示来过滤任务无关噪声，并将信息分解为独特、冗余和协同三个组件，以提升多模态推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推荐系统在处理冗余和无关信息方面存在不足，直接融合多模态信息或使用刚性架构分离的方法无法有效过滤噪声和建模模态间复杂交互。

Method: 首先使用多模态信息瓶颈压缩输入表示以过滤噪声，然后将信息基于与推荐目标的关系分解为独特、冗余和协同三个组件，并通过三个学习目标（独特信息学习、冗余信息最小化和协同信息捕获）来实现解缠表示学习。

Result: 在多个竞争性模型和三个基准数据集上的广泛实验证明了MRdIB在增强多模态推荐方面的有效性和通用性。

Conclusion: MRdIB框架能够指导模型学习更强大和解缠的表示，有效解决了多模态推荐系统中的信息冗余和噪声问题。

Abstract: Multimodal data has significantly advanced recommendation systems by
integrating diverse information sources to model user preferences and item
characteristics. However, these systems often struggle with redundant and
irrelevant information, which can degrade performance. Most existing methods
either fuse multimodal information directly or use rigid architectural
separation for disentanglement, failing to adequately filter noise and model
the complex interplay between modalities. To address these challenges, we
propose a novel framework, the Multimodal Representation-disentangled
Information Bottleneck (MRdIB). Concretely, we first employ a Multimodal
Information Bottleneck to compress the input representations, effectively
filtering out task-irrelevant noise while preserving rich semantic information.
Then, we decompose the information based on its relationship with the
recommendation target into unique, redundant, and synergistic components. We
achieve this decomposition with a series of constraints: a unique information
learning objective to preserve modality-unique signals, a redundant information
learning objective to minimize overlap, and a synergistic information learning
objective to capture emergent information. By optimizing these objectives,
MRdIB guides a model to learn more powerful and disentangled representations.
Extensive experiments on several competitive models and three benchmark
datasets demonstrate the effectiveness and versatility of our MRdIB in
enhancing multimodal recommendation.

</details>


### [10] [Muse-it: A Tool for Analyzing Music Discourse on Reddit](https://arxiv.org/abs/2509.20228)
*Jatin Agarwala,George Paul,Nemani Harsha Vardhan,Vinoo Alluri*

Main category: cs.IR

TL;DR: Muse-it是一个用于分析Reddit上音乐相关讨论的平台，通过自然语言处理和大数据分析技术，帮助研究者大规模研究音乐参与行为。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台提供了观察自然音乐参与行为的空间，但大规模数据的提取和分析需要专门工具。Reddit的匿名性鼓励多样化参与，产生了丰富的音乐讨论数据。

Method: 开发Muse-it平台，从Reddit检索用户定义查询的全面数据，支持主题建模、时间趋势分析和聚类，识别音乐相关超链接并获取曲目级元数据。

Result: 平台能够聚合跨子版块的帖子，提供动态可视化界面，有效支持大规模音乐讨论研究。

Conclusion: Muse-it为音乐研究者提供了收集和分析大数据的便捷途径，为理解在线自然发生的音乐参与行为开辟了新途径。

Abstract: Music engagement spans diverse interactions with music, from selection and
emotional response to its impact on behavior, identity, and social connections.
Social media platforms provide spaces where such engagement can be observed in
natural, unprompted conversations. Advances in natural language processing
(NLP) and big data analytics make it possible to analyze these discussions at
scale, extending music research to broader contexts. Reddit, in particular,
offers anonymity that encourages diverse participation and yields rich
discourse on music in ecological settings. Yet the scale of this data requires
tools to extract, process, and analyze it effectively. We present Muse-it, a
platform that retrieves comprehensive Reddit data centered on user-defined
queries. It aggregates posts from across subreddits, supports topic modeling,
temporal trend analysis, and clustering, and enables efficient study of
large-scale discourse. Muse-it also identifies music-related hyperlinks (e.g.,
Spotify), retrieves track-level metadata such as artist, album, release date,
genre, popularity, and lyrics, and links these to the discussions. An
interactive interface provides dynamic visualizations of the collected data.
Muse-it thus offers an accessible way for music researchers to gather and
analyze big data, opening new avenues for understanding music engagement as it
naturally unfolds online.

</details>
