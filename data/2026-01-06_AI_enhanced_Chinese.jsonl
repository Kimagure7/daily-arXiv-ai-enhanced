{"id": "2601.00833", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00833", "abs": "https://arxiv.org/abs/2601.00833", "authors": ["Tangtang Wang", "Kaijie Zhang", "Kuangcong Liu"], "title": "A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization", "comment": null, "summary": "In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u8bed\u4e49\u63a8\u8350\u6570\u636e\u5e93\u7cfb\u7edf(KGSR-ADS)\uff0c\u7528\u4e8e\u5e7f\u544a\u68c0\u7d22\u548c\u4e2a\u6027\u5316\u63a8\u8350", "motivation": "\u73b0\u4ee3\u6570\u5b57\u8425\u9500\u4e2d\u5e7f\u544a\u6570\u636e\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u80fd\u591f\u7406\u89e3\u4ea7\u54c1\u3001\u53d7\u4f17\u548c\u5e7f\u544a\u5185\u5bb9\u4e4b\u95f4\u8bed\u4e49\u5173\u7cfb\u7684\u667a\u80fd\u7cfb\u7edf", "method": "\u96c6\u6210\u5f02\u6784\u5e7f\u544a\u77e5\u8bc6\u56fe\u8c31(Ad-KG)\u3001\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u5d4c\u5165\u5c42\u3001GNN+\u6ce8\u610f\u529b\u6a21\u578b\u4ee5\u53ca\u57fa\u4e8e\u5411\u91cf\u7d22\u5f15\u7684\u6570\u636e\u5e93\u4f18\u5316\u68c0\u7d22\u5c42", "result": "\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u8bed\u4e49\u5339\u914d\u548c\u53ef\u6269\u5c55\u7684\u68c0\u7d22\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u4e2a\u6027\u5316\u5e7f\u544a\u63a8\u8350", "conclusion": "\u63d0\u51fa\u7684KGSR-ADS\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5e7f\u544a\u6570\u636e\u8bed\u4e49\u7406\u89e3\u6311\u6218\uff0c\u5b9e\u73b0\u667a\u80fd\u5316\u7684\u5e7f\u544a\u68c0\u7d22\u548c\u4e2a\u6027\u5316\u63a8\u8350"}}
{"id": "2601.00891", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00891", "abs": "https://arxiv.org/abs/2601.00891", "authors": ["Rodrigo Kataishi"], "title": "Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u9898\u589e\u5f3a\u5d4c\u5165\u65b9\u6cd5\uff0c\u7ed3\u5408TF-IDF\u3001\u4e3b\u9898\u5efa\u6a21\u548c\u964d\u7ef4\u6280\u672f\uff0c\u5c06\u672f\u8bed\u4fe1\u53f7\u548c\u4e3b\u9898\u7ed3\u6784\u6574\u5408\u5230\u4e0a\u4e0b\u6587\u53e5\u5b50\u5d4c\u5165\u4e2d\uff0c\u4ee5\u63d0\u9ad8RAG\u7cfb\u7edf\u7684\u68c0\u7d22\u8d28\u91cf\u3002", "motivation": "\u5728\u4e3b\u9898\u91cd\u53e0\u548c\u4e3b\u9898\u53d8\u5316\u9ad8\u7684\u8bed\u6599\u5e93\u4e2d\uff0cRAG\u7cfb\u7edf\u7684\u68c0\u7d22\u8d28\u91cf\u4f1a\u4e0b\u964d\u3002\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u7c7b\u590d\u6742\u8bed\u4e49\u7ed3\u6784\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u6355\u6349\u672f\u8bed\u7ea7\u548c\u4e3b\u9898\u7ea7\u8bed\u4e49\u3002", "method": "\u7ed3\u5408TF-IDF\u4e0e\u4e3b\u9898\u5efa\u6a21\uff08LSA\u548cLDA\uff09\u548c\u964d\u7ef4\u6280\u672f\uff0c\u5c06\u6f5c\u5728\u4e3b\u9898\u7ec4\u7ec7\u7f16\u7801\u5230\u5d4c\u5165\u8868\u793a\u4e2d\uff0c\u7136\u540e\u4e0e\u7d27\u51d1\u7684\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\uff08all-MiniLM\uff09\u878d\u5408\uff0c\u521b\u5efa\u4e3b\u9898\u589e\u5f3a\u5d4c\u5165\u3002", "result": "\u5728\u6cd5\u5f8b\u6587\u672c\u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u4e3b\u9898\u589e\u5f3a\u5d4c\u5165\u5728\u805a\u7c7b\u4e00\u81f4\u6027\u548c\u68c0\u7d22\u6307\u6807\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u63d0\u5347\uff0c\u63d0\u9ad8\u4e86\u8bed\u4e49\u805a\u7c7b\u8d28\u91cf\u3001\u68c0\u7d22\u7cbe\u5ea6\uff0c\u540c\u65f6\u76f8\u5bf9\u4e8e\u7eaf\u4e0a\u4e0b\u6587\u57fa\u7ebf\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002", "conclusion": "\u4e3b\u9898\u589e\u5f3a\u5d4c\u5165\u80fd\u591f\u6709\u6548\u6355\u6349\u672f\u8bed\u7ea7\u548c\u4e3b\u9898\u7ea7\u8bed\u4e49\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u77e5\u8bc6\u5bc6\u96c6\u578bRAG\u7ba1\u9053\u4e2d\u66f4\u53ef\u9760\u7684\u5b9e\u7528\u7ec4\u4ef6\uff0c\u63d0\u9ad8\u68c0\u7d22\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.00912", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00912", "abs": "https://arxiv.org/abs/2601.00912", "authors": ["Amit Prakash Sharma"], "title": "The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries", "comment": "20 pages, 7 figures. Based on M.Tech thesis research, Indian Institute of Technology Patna, 2025", "summary": "When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.\n  I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).\n  The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like \"What are the best AI tools launched this year?\" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.\n  Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.\n  What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).\n  The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5112\u4e2aProduct Hunt\u70ed\u95e8\u4ea7\u54c1\u5728ChatGPT\u548cPerplexity\u4e2d\u7684\u53ef\u89c1\u6027\uff0c\u53d1\u73b0AI\u80fd\u51c6\u786e\u8bc6\u522b\u5177\u4f53\u4ea7\u54c1\u540d\u79f0\uff0899.4%/94.3%\uff09\uff0c\u4f46\u5728\u53d1\u73b0\u5f0f\u67e5\u8be2\u4e2d\u6210\u529f\u7387\u66b4\u8dcc\u81f33.32%/8.29%\u3002\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316(GEO)\u65e0\u6548\uff0c\u4f20\u7edfSEO\u548c\u793e\u533a\u5f71\u54cd\u529b\u624d\u662f\u5173\u952e\u3002", "motivation": "\u63a2\u7a76AI\u52a9\u624b\uff08\u5982ChatGPT\uff09\u5728\u63a8\u8350\u4ea7\u54c1\u65f6\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u521d\u521b\u516c\u53f8\u7684\u65b0\u4ea7\u54c1\u80fd\u5426\u88abAI\u53d1\u73b0\u3002\u5173\u6ce8\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316(GEO)\u662f\u5426\u771f\u7684\u80fd\u63d0\u5347\u4ea7\u54c1\u5728AI\u641c\u7d22\u7ed3\u679c\u4e2d\u7684\u53ef\u89c1\u6027\u3002", "method": "\u4ece2025\u5e74Product Hunt\u6392\u884c\u699c\u524d500\u540d\u4e2d\u968f\u673a\u9009\u62e9112\u4e2a\u521d\u521b\u4ea7\u54c1\uff0c\u5bf9\u6bcf\u4e2a\u4ea7\u54c1\u8fdb\u884c2,240\u6b21\u67e5\u8be2\u6d4b\u8bd5\uff0c\u4f7f\u7528ChatGPT(gpt-4o-mini)\u548cPerplexity(sonar with web search)\u4e24\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u3002\u5206\u6790GEO\u8bc4\u5206\u3001SEO\u4fe1\u53f7\uff08\u5916\u94fe\u57df\u540d\uff09\u3001Product Hunt\u6392\u540d\u3001Reddit\u793e\u533a\u5b58\u5728\u7b49\u6307\u6807\u4e0eAI\u53ef\u89c1\u6027\u7684\u76f8\u5173\u6027\u3002", "result": "1. \u5177\u4f53\u540d\u79f0\u67e5\u8be2\uff1aChatGPT\u8bc6\u522b\u738799.4%\uff0cPerplexity 94.3%\uff1b2. \u53d1\u73b0\u5f0f\u67e5\u8be2\u6210\u529f\u7387\u66b4\u8dcc\uff1aChatGPT 3.32%\uff0cPerplexity 8.29%\uff08\u76f8\u5dee30\u500d\uff09\uff1b3. GEO\u4f18\u5316\u4e0eAI\u53d1\u73b0\u7387\u65e0\u76f8\u5173\u6027\uff1b4. Perplexity\u4e2d\u4f20\u7edfSEO\u4fe1\u53f7\uff08\u5916\u94fe\u57df\u540dr=+0.319\uff09\u548cProduct Hunt\u6392\u540d(r=-0.286)\u9884\u6d4b\u53ef\u89c1\u6027\uff1b5. Reddit\u793e\u533a\u5b58\u5728\u663e\u8457\u76f8\u5173(r=+0.395)\u3002", "conclusion": "\u4e0d\u8981\u76f4\u63a5\u4e3aAI\u53d1\u73b0\u8fdb\u884c\u4f18\u5316\uff0c\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316(GEO)\u65e0\u6548\u3002\u5e94\u4f18\u5148\u5efa\u7acb\u4f20\u7edfSEO\u57fa\u7840\uff08\u5916\u94fe\u5efa\u8bbe\u3001\u793e\u533a\u53c2\u4e0e\u3001\u5e73\u53f0\u6392\u540d\uff09\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89c1\u6027\u81ea\u7136\u4f1a\u968f\u4e4b\u63d0\u5347\u3002\u5bf9\u521d\u521b\u516c\u53f8\u7684\u5b9e\u9645\u5efa\u8bae\uff1a\u4e13\u6ce8\u4e8eSEO\u548c\u793e\u533a\u5efa\u8bbe\uff0c\u800c\u975e\u4e13\u95e8\u7684AI\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2601.00926", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00926", "abs": "https://arxiv.org/abs/2601.00926", "authors": ["Satya Swaroop Gudipudi", "Sahil Girhepuje", "Ponnurangam Kumaraguru", "Kristine Ma"], "title": "MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers", "comment": null, "summary": "Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.", "AI": {"tldr": "MACA\u662f\u4e00\u79cd\u5143\u6570\u636e\u611f\u77e5\u7684\u8de8\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5c06\u6821\u51c6\u7684LLM\u91cd\u6392\u5668\u84b8\u998f\u5230\u7d27\u51d1\u7684\u5b66\u751f\u68c0\u7d22\u5668\u4e2d\uff0c\u907f\u514d\u5728\u7ebfLLM\u8c03\u7528\uff0c\u63d0\u5347\u4f01\u4e1a\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4f01\u4e1a\u68c0\u7d22\u7cfb\u7edf\u9700\u8981\u5904\u7406\u7b80\u77ed\u3001\u4e0d\u660e\u786e\u7684\u67e5\u8be2\uff0c\u8bed\u4e49\u7ec6\u5fae\u5dee\u522b\u548c\u5143\u6570\u636e\u5f88\u91cd\u8981\uff0c\u4f46\u6bcf\u4e2a\u67e5\u8be2\u4f7f\u7528LLM\u91cd\u6392\u548c\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51fa\u5143\u6570\u636e\u611f\u77e5\u8de8\u6a21\u578b\u5bf9\u9f50(MACA)\uff1a1) \u4f7f\u7528\u5143\u6570\u636e\u611f\u77e5\u63d0\u793a\u9a8c\u8bc1\u6559\u5e08LLM\u7684\u53ef\u9760\u6027\uff1b2) \u63d0\u4f9b\u5217\u8868\u8bc4\u5206\u3001\u56f0\u96be\u8d1f\u6837\u672c\u548c\u6821\u51c6\u76f8\u5173\u6027\u8fb9\u754c\uff1b3) \u5b66\u751f\u901a\u8fc7MetaFusion\u76ee\u6807\u8bad\u7ec3\uff0c\u7ed3\u5408\u5143\u6570\u636e\u6761\u4ef6\u6392\u5e8f\u635f\u5931\u548c\u8de8\u6a21\u578b\u8fb9\u754c\u635f\u5931\u3002", "result": "\u5728\u4e13\u6709\u6d88\u8d39\u8005\u94f6\u884cFAQ\u8bed\u6599\u5e93\u548cBankFAQs\u4e0a\uff0cMACA\u6559\u5e08\u6bd4MAFA\u57fa\u7ebf\u5728Accuracy@1\u4e0a\u5206\u522b\u63d0\u53475\u70b9\u548c3\u70b9\u3002MACA\u5b66\u751f\u663e\u8457\u4f18\u4e8e\u9884\u8bad\u7ec3\u7f16\u7801\u5668\uff0c\u5982MiniLM\u7684Accuracy@1\u4ece0.23\u63d0\u5347\u52300.48\uff0c\u540c\u65f6\u907f\u514dLLM\u8c03\u7528\u5e76\u652f\u6301\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002", "conclusion": "MACA\u901a\u8fc7\u5c06\u6821\u51c6\u7684\u5143\u6570\u636e\u611f\u77e5LLM\u91cd\u6392\u5668\u84b8\u998f\u5230\u7d27\u51d1\u68c0\u7d22\u5668\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f01\u4e1a\u68c0\u7d22\u4e2d\u67e5\u8be2\u7b80\u77ed\u3001\u5143\u6570\u636e\u91cd\u8981\u4f46LLM\u8c03\u7528\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2601.00930", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00930", "abs": "https://arxiv.org/abs/2601.00930", "authors": ["Nicolas Bougie", "Gian Maria Marconi", "Tony Yip", "Narimasa Watanabe"], "title": "AlignUSER: Human-Aligned LLM Agents via World Models for Recommender System Evaluation", "comment": null, "summary": "Evaluating recommender systems remains challenging due to the gap between offline metrics and real user behavior, as well as the scarcity of interaction data. Recent work explores large language model (LLM) agents as synthetic users, yet they typically rely on few-shot prompting, which yields a shallow understanding of the environment and limits their ability to faithfully reproduce user actions. We introduce AlignUSER, a framework that learns world-model-driven agents from human interactions. Given rollout sequences of actions and states, we formalize world modeling as a next state prediction task that helps the agent internalize the environment. To align actions with human personas, we generate counterfactual trajectories around demonstrations and prompt the LLM to compare its decisions with human choices, identify suboptimal actions, and extract lessons. The learned policy is then used to drive agent interactions with the recommender system. We evaluate AlignUSER across multiple datasets and demonstrate closer alignment with genuine humans than prior work, both at the micro and macro levels.", "AI": {"tldr": "AlignUSER\uff1a\u4e00\u4e2a\u4ece\u4eba\u7c7b\u4ea4\u4e92\u4e2d\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u6a21\u62df\u7528\u6237\u884c\u4e3a\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf", "motivation": "\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff1a\u79bb\u7ebf\u6307\u6807\u4e0e\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff0c\u4ea4\u4e92\u6570\u636e\u7a00\u7f3a\u3002\u73b0\u6709LLM\u667a\u80fd\u4f53\u65b9\u6cd5\u4f9d\u8d56\u5c11\u6837\u672c\u63d0\u793a\uff0c\u5bf9\u73af\u5883\u7406\u89e3\u6d45\u5c42\uff0c\u96be\u4ee5\u5fe0\u5b9e\u590d\u73b0\u7528\u6237\u884c\u4e3a\u3002", "method": "1) \u5c06\u4e16\u754c\u5efa\u6a21\u5f62\u5f0f\u5316\u4e3a\u4e0b\u4e00\u72b6\u6001\u9884\u6d4b\u4efb\u52a1\uff0c\u5e2e\u52a9\u667a\u80fd\u4f53\u5185\u5316\u73af\u5883\u7406\u89e3\uff1b2) \u56f4\u7ed5\u6f14\u793a\u751f\u6210\u53cd\u4e8b\u5b9e\u8f68\u8ff9\uff0c\u63d0\u793aLLM\u6bd4\u8f83\u5176\u51b3\u7b56\u4e0e\u4eba\u7c7b\u9009\u62e9\uff0c\u8bc6\u522b\u6b21\u4f18\u884c\u52a8\u5e76\u63d0\u53d6\u7ecf\u9a8c\uff1b3) \u5b66\u4e60\u7b56\u7565\u9a71\u52a8\u667a\u80fd\u4f53\u4e0e\u63a8\u8350\u7cfb\u7edf\u4ea4\u4e92\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cAlignUSER\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u63a5\u8fd1\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\uff0c\u5728\u5fae\u89c2\u548c\u5b8f\u89c2\u5c42\u9762\u90fd\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "AlignUSER\u6846\u67b6\u901a\u8fc7\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6a21\u62df\u7528\u6237\u884c\u4e3a\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u5408\u6210\u7528\u6237\u65b9\u6cd5\u3002"}}
{"id": "2601.01118", "categories": ["cs.IR", "cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2601.01118", "abs": "https://arxiv.org/abs/2601.01118", "authors": ["Qingqing Long", "Haotian Chen", "Chenyang Zhao", "Xiaolei Du", "Xuezhi Wang", "Pengyao Wang", "Chengzan Li", "Yuanchun Zhou", "Hengshu Zhu"], "title": "ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services", "comment": "12 pages, 9 figures", "summary": "The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.", "AI": {"tldr": "ScienceDB AI\u662f\u9996\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u5f0f\u63a8\u8350\u7cfb\u7edf\uff0c\u4e13\u95e8\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u5171\u4eab\u670d\u52a1\u8bbe\u8ba1\uff0c\u901a\u8fc7\u6df1\u5ea6\u8bed\u4e49\u7406\u89e3\u548c\u4e2a\u6027\u5316\u63a8\u8350\u89e3\u51b3\u79d1\u5b66\u6570\u636e\u96c6\u5171\u4eab\u96be\u9898\u3002", "motivation": "\u79d1\u5b66\u6570\u636e\u96c6\u5305\u542b\u590d\u6742\u7684\u9886\u57df\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\uff0c\u4f20\u7edf\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u3002\u968f\u7740AI4S\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u7cfb\u7edf\u6765\u4fc3\u8fdb\u79d1\u5b66\u6570\u636e\u96c6\u7684\u5171\u4eab\u548c\u5229\u7528\u3002", "method": "\u7cfb\u7edf\u91c7\u7528LLM\u9a71\u52a8\u7684\u667a\u80fd\u63a8\u8350\u67b6\u6784\uff0c\u5305\u542b\uff1a\u79d1\u5b66\u610f\u56fe\u611f\u77e5\u5668\u63d0\u53d6\u7ed3\u6784\u5316\u5b9e\u9a8c\u5143\u7d20\uff0c\u7ed3\u6784\u5316\u8bb0\u5fc6\u538b\u7f29\u5668\u7ba1\u7406\u591a\u8f6e\u5bf9\u8bdd\uff0c\u53ef\u4fe1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u673a\u5236\u5e76\u63d0\u4f9b\u53ef\u5f15\u7528\u7684\u6570\u636e\u96c6\u53c2\u8003\u3002", "result": "\u901a\u8fc7\u5bf9\u8d85\u8fc71000\u4e07\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8fdb\u884c\u7ebf\u4e0b\u548c\u7ebf\u4e0a\u5b9e\u9a8c\uff0cScienceDB AI\u8868\u73b0\u51fa\u663e\u8457\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u51c6\u786e\u63a8\u8350\u7b26\u5408\u7814\u7a76\u4eba\u5458\u79d1\u5b66\u610f\u56fe\u548c\u9700\u6c42\u7684\u6570\u636e\u96c6\u3002", "conclusion": "ScienceDB AI\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u5171\u4eab\u670d\u52a1\u8bbe\u8ba1\u7684LLM\u9a71\u52a8\u5bf9\u8bdd\u5f0f\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u548c\u6df1\u5ea6\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u6570\u636e\u96c6\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.01448", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.01448", "abs": "https://arxiv.org/abs/2601.01448", "authors": ["Na Li", "Fanghui Sun", "Yan Zou", "Yangfu Zhu", "Xiatian Zhu", "Ying Ma"], "title": "Adaptive Diffusion-based Augmentation for Recommendation", "comment": null, "summary": "Recommendation systems often rely on implicit feedback, where only positive user-item interactions can be observed. Negative sampling is therefore crucial to provide proper negative training signals. However, existing methods tend to mislabel potentially positive but unobserved items as negatives and lack precise control over negative sample selection. We aim to address these by generating controllable negative samples, rather than sampling from the existing item pool. In this context, we propose Adaptive Diffusion-based Augmentation for Recommendation (ADAR), a novel and model-agnostic module that leverages diffusion to synthesize informative negatives. Inspired by the progressive corruption process in diffusion, ADAR simulates a continuous transition from positive to negative, allowing for fine-grained control over sample hardness. To mine suitable negative samples, we theoretically identify the transition point at which a positive sample turns negative and derive a score-aware function to adaptively determine the optimal sampling timestep. By identifying this transition point, ADAR generates challenging negative samples that effectively refine the model's decision boundary. Experiments confirm that ADAR is broadly compatible and boosts the performance of existing recommendation models substantially, including collaborative filtering and sequential recommendation, without architectural modifications.", "AI": {"tldr": "ADAR\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8d1f\u6837\u672c\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u6269\u6563\u8fc7\u7a0b\u7684\u91c7\u6837\u65f6\u95f4\u6b65\u6765\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u8d1f\u6837\u672c\uff0c\u63d0\u5347\u63a8\u8350\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u57fa\u4e8e\u9690\u5f0f\u53cd\u9988\uff0c\u53ea\u80fd\u89c2\u5bdf\u5230\u6b63\u6837\u672c\uff0c\u8d1f\u91c7\u6837\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u53ef\u80fd\u5c06\u6f5c\u5728\u7684\u6b63\u6837\u672c\u8bef\u6807\u4e3a\u8d1f\u6837\u672c\uff1b2) \u7f3a\u4e4f\u5bf9\u8d1f\u6837\u672c\u9009\u62e9\u7684\u7cbe\u786e\u63a7\u5236\u3002\u9700\u8981\u751f\u6210\u53ef\u63a7\u7684\u8d1f\u6837\u672c\u800c\u975e\u4ece\u73b0\u6709\u7269\u54c1\u6c60\u4e2d\u91c7\u6837\u3002", "method": "ADAR\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u6e10\u8fdb\u5f0f\u7834\u574f\u8fc7\u7a0b\uff0c\u6a21\u62df\u4ece\u6b63\u6837\u672c\u5230\u8d1f\u6837\u672c\u7684\u8fde\u7eed\u8fc7\u6e21\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u6837\u672c\u96be\u5ea6\u63a7\u5236\u3002\u901a\u8fc7\u7406\u8bba\u8bc6\u522b\u6b63\u6837\u672c\u8f6c\u53d8\u4e3a\u8d1f\u6837\u672c\u7684\u8fc7\u6e21\u70b9\uff0c\u5e76\u63a8\u5bfc\u51fa\u57fa\u4e8e\u5206\u6570\u7684\u81ea\u9002\u5e94\u51fd\u6570\u6765\u786e\u5b9a\u6700\u4f18\u91c7\u6837\u65f6\u95f4\u6b65\uff0c\u4ece\u800c\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u8d1f\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eADAR\u5177\u6709\u5e7f\u6cdb\u7684\u517c\u5bb9\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u73b0\u6709\u63a8\u8350\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5305\u62ec\u534f\u540c\u8fc7\u6ee4\u548c\u5e8f\u5217\u63a8\u8350\u6a21\u578b\uff0c\u4e14\u65e0\u9700\u4fee\u6539\u6a21\u578b\u67b6\u6784\u3002", "conclusion": "ADAR\u901a\u8fc7\u6269\u6563\u6a21\u578b\u751f\u6210\u53ef\u63a7\u7684\u8d1f\u6837\u672c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8d1f\u91c7\u6837\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8d1f\u6837\u672c\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2601.01492", "categories": ["cs.IR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.01492", "abs": "https://arxiv.org/abs/2601.01492", "authors": ["Annelies de Jong", "Giuseppe Cascavilla", "Jessica De Pascale"], "title": "Breadcrumbs in the Digital Forest: Tracing Criminals through Torrent Metadata with OSINT", "comment": null, "summary": "This work investigates the potential of torrent metadata as a source for open-source intelligence (OSINT), with a focus on user profiling and behavioral analysis. While peer-to-peer (P2P) networks such as BitTorrent are well studied with respect to privacy and performance, their metadata is rarely used for investigative purposes. This work presents a proof of concept demonstrating how tracker responses, torrent index data, and enriched IP metadata can reveal patterns associated with high-risk behavior.\n  The research follows a five-step OSINT process: source identification, data collection, enrichment, behavioral analysis, and presentation of the results. Data were collected from The Pirate Bay and UDP trackers, yielding a dataset of more than 60,000 unique IP addresses across 206 popular torrents. The data were enriched with geolocation, anonymization status, and flags of involvement in child exploitation material (CEM). A case study on sensitive e-books shows how such data can help detect possible interest in illicit content.\n  Network analysis highlights peer clustering, co-download patterns, and the use of privacy tools by suspicious users. The study shows that publicly available torrent metadata can support scalable and automated OSINT profiling.\n  This work adds to digital forensics by proposing a new method to extract useful signals from noisy data, with applications in law enforcement, cybersecurity, and threat analysis.", "AI": {"tldr": "\u5229\u7528BitTorrent\u5143\u6570\u636e\u8fdb\u884c\u5f00\u6e90\u60c5\u62a5\u5206\u6790\uff0c\u901a\u8fc7\u7528\u6237\u753b\u50cf\u548c\u884c\u4e3a\u5206\u6790\u68c0\u6d4b\u9ad8\u98ce\u9669\u884c\u4e3a\uff0c\u5305\u62ec\u513f\u7ae5\u5265\u524a\u6750\u6599\u7b49\u975e\u6cd5\u5185\u5bb9\u3002", "motivation": "\u867d\u7136P2P\u7f51\u7edc\u5728\u9690\u79c1\u548c\u6027\u80fd\u65b9\u9762\u5df2\u6709\u6df1\u5165\u7814\u7a76\uff0c\u4f46\u5176\u5143\u6570\u636e\u5f88\u5c11\u7528\u4e8e\u8c03\u67e5\u76ee\u7684\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u516c\u5f00\u7684\u79cd\u5b50\u5143\u6570\u636e\u8fdb\u884c\u5f00\u6e90\u60c5\u62a5\u5206\u6790\uff0c\u4ee5\u652f\u6301\u6267\u6cd5\u548c\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u3002", "method": "\u91c7\u7528\u4e94\u6b65OSINT\u6d41\u7a0b\uff1a\u6e90\u8bc6\u522b\u3001\u6570\u636e\u6536\u96c6\u3001\u6570\u636e\u4e30\u5bcc\u3001\u884c\u4e3a\u5206\u6790\u548c\u7ed3\u679c\u5448\u73b0\u3002\u4eceThe Pirate Bay\u548cUDP\u8ddf\u8e2a\u5668\u6536\u96c6\u4e86206\u4e2a\u70ed\u95e8\u79cd\u5b50\u768460,000\u591a\u4e2a\u552f\u4e00IP\u5730\u5740\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u5730\u7406\u4f4d\u7f6e\u3001\u533f\u540d\u5316\u72b6\u6001\u548c\u513f\u7ae5\u5265\u524a\u6750\u6599\u53c2\u4e0e\u6807\u5fd7\u8fdb\u884c\u6570\u636e\u4e30\u5bcc\u3002", "result": "\u7f51\u7edc\u5206\u6790\u63ed\u793a\u4e86\u8282\u70b9\u805a\u7c7b\u3001\u5171\u540c\u4e0b\u8f7d\u6a21\u5f0f\u4ee5\u53ca\u53ef\u7591\u7528\u6237\u4f7f\u7528\u9690\u79c1\u5de5\u5177\u7684\u884c\u4e3a\u3002\u654f\u611f\u7535\u5b50\u4e66\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u6b64\u7c7b\u6570\u636e\u6709\u52a9\u4e8e\u68c0\u6d4b\u5bf9\u975e\u6cd5\u5185\u5bb9\u7684\u53ef\u80fd\u5174\u8da3\u3002\u7814\u7a76\u8bc1\u660e\u516c\u5f00\u7684\u79cd\u5b50\u5143\u6570\u636e\u53ef\u4ee5\u652f\u6301\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316OSINT\u753b\u50cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6570\u5b57\u53d6\u8bc1\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u566a\u58f0\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u7528\u4fe1\u53f7\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u6267\u6cd5\u3001\u7f51\u7edc\u5b89\u5168\u548c\u5a01\u80c1\u5206\u6790\u65b9\u9762\u5177\u6709\u5e94\u7528\u4ef7\u503c\uff0c\u6269\u5c55\u4e86\u5f00\u6e90\u60c5\u62a5\u5206\u6790\u7684\u6570\u636e\u6e90\u3002"}}
{"id": "2601.01576", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.01576", "abs": "https://arxiv.org/abs/2601.01576", "authors": ["Ming Zhang", "Kexin Tan", "Yueyuan Huang", "Yujiong Shen", "Chunchun Ma", "Li Ju", "Xinran Zhang", "Yuhui Wang", "Wenqing Jing", "Jingyi Deng", "Huayu Sha", "Binze Hu", "Jingqi Tong", "Changhao Jiang", "Yage Geng", "Yuankai Ying", "Yue Zhang", "Zhangyue Yin", "Zhiheng Xi", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment", "comment": null, "summary": "Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \\textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.", "AI": {"tldr": "OpenNovelty\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u56db\u9636\u6bb5\u6d41\u7a0b\uff08\u63d0\u53d6\u8d21\u732e\u3001\u68c0\u7d22\u76f8\u5173\u6587\u732e\u3001\u6784\u5efa\u5206\u7c7b\u4f53\u7cfb\u3001\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\uff09\u4e3a\u5b66\u672f\u8bba\u6587\u63d0\u4f9b\u900f\u660e\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u65b0\u9896\u6027\u5206\u6790\uff0c\u5df2\u5728500+ ICLR 2026\u6295\u7a3f\u4e0a\u90e8\u7f72\u3002", "motivation": "\u540c\u884c\u8bc4\u5ba1\u4e2d\u8bc4\u4f30\u65b0\u9896\u6027\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u8bc4\u5ba1\u8005\u9700\u8981\u5728\u5e9e\u5927\u4e14\u5feb\u901f\u53d1\u5c55\u7684\u6587\u732e\u4e2d\u8bc4\u4f30\u6295\u7a3f\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u8bc1\u636e\u57fa\u7840\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u5224\u65ad\u7684\u7cfb\u7edf\u5316\u5de5\u5177\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u56db\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u63d0\u53d6\u6838\u5fc3\u4efb\u52a1\u548c\u8d21\u732e\u58f0\u660e\u751f\u6210\u68c0\u7d22\u67e5\u8be2\uff1b2) \u901a\u8fc7\u8bed\u4e49\u641c\u7d22\u5f15\u64ce\u68c0\u7d22\u76f8\u5173\u5148\u524d\u5de5\u4f5c\uff1b3) \u6784\u5efa\u6838\u5fc3\u4efb\u52a1\u76f8\u5173\u5de5\u4f5c\u7684\u5c42\u6b21\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u8fdb\u884c\u8d21\u732e\u7ea7\u522b\u7684\u5168\u6587\u6bd4\u8f83\uff1b4) \u5c06\u6240\u6709\u5206\u6790\u7efc\u5408\u6210\u5305\u542b\u660e\u786e\u5f15\u7528\u548c\u8bc1\u636e\u7247\u6bb5\u7684\u7ed3\u6784\u5316\u65b0\u9896\u6027\u62a5\u544a\u3002", "result": "\u7cfb\u7edf\u5df2\u5728500+ ICLR 2026\u6295\u7a3f\u4e0a\u90e8\u7f72\uff0c\u6240\u6709\u62a5\u544a\u516c\u5f00\u53ef\u7528\u3002\u521d\u6b65\u5206\u6790\u8868\u660e\u7cfb\u7edf\u80fd\u591f\u8bc6\u522b\u76f8\u5173\u5148\u524d\u5de5\u4f5c\uff0c\u5305\u62ec\u4f5c\u8005\u53ef\u80fd\u5ffd\u7565\u7684\u5bc6\u5207\u76f8\u5173\u7684\u8bba\u6587\uff0c\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u5224\u65ad\u57fa\u7840\u3002", "conclusion": "OpenNovelty\u65e8\u5728\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u4fc3\u8fdb\u516c\u5e73\u3001\u4e00\u81f4\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u540c\u884c\u8bc4\u5ba1\uff0c\u901a\u8fc7\u5c06\u8bc4\u4f30\u57fa\u4e8e\u771f\u5b9e\u68c0\u7d22\u7684\u8bba\u6587\u6765\u786e\u4fdd\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2601.01684", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.01684", "abs": "https://arxiv.org/abs/2601.01684", "authors": ["Zhichao Xu", "Shengyao Zhuang", "Crystina Zhang", "Xueguang Ma", "Yijun Tian", "Maitrey Mehta", "Jimmy Lin", "Vivek Srikumar"], "title": "LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum", "comment": null, "summary": "While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.", "AI": {"tldr": "LACONIC\u662f\u4e00\u4e2a\u57fa\u4e8eLlama-3\u67b6\u6784\u7684\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\uff0c\u5728\u6027\u80fd\u63a5\u8fd1\u5bc6\u96c6\u6a21\u578b\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u90e8\u7f72\u65f6\u9762\u4e34\u9ad8\u5185\u5b58\u9700\u6c42\u548cGPU\u4f9d\u8d56\u7684\u9650\u5236\u3002\u7a00\u758f\u68c0\u7d22\u867d\u7136\u80fd\u901a\u8fc7\u5012\u6392\u7d22\u5f15\u5b9e\u73b0\u9ad8\u6548\u641c\u7d22\uff0c\u4f46\u5386\u53f2\u4e0a\u5173\u6ce8\u5ea6\u8f83\u4f4e\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u53c8\u80fd\u5728CPU\u786c\u4ef6\u4e0a\u9ad8\u6548\u8fd0\u884c\u7684\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eLlama-3\u67b6\u6784\uff081B\u30013B\u30018B\uff09\u6784\u5efa\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5bb6\u65cf\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a1\uff09\u5f31\u76d1\u7763\u9884\u5fae\u8c03\uff0c\u4f7f\u56e0\u679cLLM\u9002\u5e94\u53cc\u5411\u4e0a\u4e0b\u6587\u5904\u7406\uff1b2\uff09\u4f7f\u7528\u7cbe\u5fc3\u7b5b\u9009\u7684\u56f0\u96be\u8d1f\u4f8b\u8fdb\u884c\u9ad8\u8d28\u91cf\u5fae\u8c03\u3002", "result": "LACONIC-8B\u5728MTEB\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523060.2 nDCG\uff0c\u57282026\u5e741\u67081\u65e5\u7684\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c15\u4f4d\uff0c\u540c\u65f6\u6bd4\u7b49\u6548\u5bc6\u96c6\u6a21\u578b\u51cf\u5c1171%\u7684\u7d22\u5f15\u5185\u5b58\u4f7f\u7528\u3002\u80fd\u591f\u5728\u5546\u7528CPU\u786c\u4ef6\u4e0a\u9ad8\u6548\u8fd0\u884c\uff0c\u8ba1\u7b97\u9884\u7b97\u8fdc\u4f4e\u4e8e\u7ade\u4e89\u6a21\u578b\u3002", "conclusion": "LACONIC\u901a\u8fc7\u7a00\u758f\u68c0\u7d22\u65b9\u6cd5\u6709\u6548\u5f25\u5408\u4e86\u4e0e\u5bc6\u96c6\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u5b9e\u9645\u641c\u7d22\u5e94\u7528\u573a\u666f\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2601.01750", "categories": ["cs.IR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.01750", "abs": "https://arxiv.org/abs/2601.01750", "authors": ["Shayan Alipour", "Mehdi Kargar", "Morteza Zihayat"], "title": "When Attention Becomes Exposure in Generative Search", "comment": "8 pages, 2 figures", "summary": "Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.", "AI": {"tldr": "\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u7684\u5f15\u7528\u5b58\u5728\u66dd\u5149\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u5df2\u6709\u77e5\u540d\u5ea6\u7684\u58f0\u97f3\uff0c\u8fd9\u53ef\u80fd\u4f1a\u56fa\u5316\u73b0\u6709\u4f18\u52bf\u5e76\u7f29\u5c0f\u89c2\u70b9\u591a\u6837\u6027\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u5728Web3\u4f01\u4e1a\u67e5\u8be2\u4e2d\u7684\u5f15\u7528\u66dd\u5149\u662f\u5426\u53d7\u5230\u5916\u90e8\u6ce8\u610f\u529b\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5f71\u54cd\u5982\u4f55\u5851\u9020\u4fe1\u606f\u83b7\u53d6\u3002", "method": "\u5bf944\u5bb6Web3\u4f01\u4e1a\u8fdb\u884c\u5ba1\u8ba1\uff1a1) \u5206\u6790\u4f01\u4e1a\u521b\u4f5c\u8005\u793e\u533a\u7684\u6301\u7eed\u6027\uff1b2) \u901a\u8fc7\u4f01\u4e1a\u7279\u5b9a\u67e5\u8be2\u68c0\u67e5\u5f15\u7528\u66dd\u5149\u6a21\u5f0f\uff1b3) \u5206\u6790\u7c89\u4e1d\u57fa\u7840\u548c\u521b\u4f5c\u8005\u6838\u5fc3\u96c6\u4e2d\u5ea6\u4e0e\u66dd\u5149\u6392\u540d\u7684\u5173\u7cfb\u3002", "result": "1) \u4f01\u4e1a\u521b\u4f5c\u8005\u793e\u533a\u5177\u6709\u65f6\u95f4\u6301\u7eed\u6027\uff1b2) \u66f4\u53d7\u6b22\u8fce\u7684\u58f0\u97f3\u7cfb\u7edf\u6027\u83b7\u5f97\u66f4\u591a\u5f15\u7528\u66dd\u5149\uff1b3) \u66f4\u5927\u7c89\u4e1d\u57fa\u7840\u548c\u66f4\u96c6\u4e2d\u7684\u521b\u4f5c\u8005\u6838\u5fc3\u4e0e\u66f4\u9ad8\u6392\u540d\u66dd\u5149\u76f8\u5173\u3002", "conclusion": "\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u5f15\u7528\u5b58\u5728\u5411\u5df2\u6709\u77e5\u540d\u58f0\u97f3\u503e\u659c\u7684\u66dd\u5149\u504f\u5dee\uff0c\u8fd9\u53ef\u80fd\u56fa\u5316\u73b0\u6709\u4f18\u52bf\u5e76\u51cf\u5c11\u89c2\u70b9\u591a\u6837\u6027\u3002"}}
{"id": "2601.01751", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.01751", "abs": "https://arxiv.org/abs/2601.01751", "authors": ["Samaneh Mohtadi", "Gianluca Demartini"], "title": "Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis", "comment": "Accepted for presentation at the ECIR 2026 Full Papers track", "summary": "Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6846\u67b6\u6765\u5206\u6790LLM\u4f5c\u4e3a\u76f8\u5173\u6027\u8bc4\u4f30\u8005\u65f6\u7684\u7cfb\u7edf\u6027\u9519\u8bef\u6a21\u5f0f\uff0c\u53d1\u73b0LLM\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u8005\u7684\u5206\u6b67\u96c6\u4e2d\u5728\u7279\u5b9a\u8bed\u4e49\u96c6\u7fa4\u800c\u975e\u968f\u673a\u5206\u5e03\u3002", "motivation": "\u867d\u7136LLM\u5df2\u88ab\u7528\u4f5c\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u4e2d\u7684\u76f8\u5173\u6027\u8bc4\u4f30\u8005\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLM\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u8005\u7684\u5e73\u5747\u8868\u73b0\u5dee\u5f02\uff0c\u800c\u7f3a\u4e4f\u5bf9LLM\u7cfb\u7edf\u6027\u9519\u8bef\u6a21\u5f0f\u7684\u7406\u89e3\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc6\u522bLLM\u5728\u5224\u65ad\u76f8\u5173\u6027\u65f6\u662f\u5426\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8bc4\u4f30\u5176\u5e73\u5747\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8868\u793a\u65b9\u6cd5\uff0c\u5c06\u67e5\u8be2-\u6587\u6863\u5bf9\u5d4c\u5165\u5230\u8054\u5408\u8bed\u4e49\u7a7a\u95f4\u4e2d\uff0c\u5c06\u76f8\u5173\u6027\u89c6\u4e3a\u5173\u7cfb\u5c5e\u6027\u3002\u5f15\u5165\u57fa\u4e8e\u805a\u7c7b\u7684\u6846\u67b6\u6765\u5206\u6790\u76f8\u5173\u6027\u6807\u7b7e\u5206\u5e03\uff0c\u6bd4\u8f83LLM\u548c\u4eba\u7c7b\u6807\u7b7e\u4ee5\u8bc6\u522b\u5206\u6b67\u6a21\u5f0f\u5e76\u5b9a\u4f4d\u7cfb\u7edf\u6027\u5206\u6b67\u533a\u57df\u3002", "result": "\u5728TREC Deep Learning 2019\u548c2020\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4eba\u7c7b\u4e0eLLM\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u5206\u6b67\u96c6\u4e2d\u5728\u7279\u5b9a\u8bed\u4e49\u96c6\u7fa4\u4e2d\uff0c\u800c\u975e\u968f\u673a\u5206\u5e03\u3002\u67e5\u8be2\u7ea7\u5206\u6790\u63ed\u793a\u4e86\u5728\u5b9a\u4e49\u5bfb\u6c42\u3001\u653f\u7b56\u76f8\u5173\u6216\u6a21\u7cca\u4e0a\u4e0b\u6587\u4e2d\u7684\u91cd\u590d\u6027\u5931\u8d25\u3002\u5177\u6709\u8de8\u96c6\u7fa4\u5927\u53d8\u5f02\u6027\u7684\u67e5\u8be2\u6210\u4e3a\u5206\u6b67\u70ed\u70b9\uff0cLLM\u503e\u5411\u4e8e\u4f4e\u4f30\u76f8\u5173\u5185\u5bb9\u6216\u8fc7\u5ea6\u5305\u542b\u65e0\u5173\u6750\u6599\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u5168\u5c40\u8bca\u65ad\u4e0e\u5c40\u90e8\u805a\u7c7b\u76f8\u7ed3\u5408\uff0c\u63ed\u793a\u4e86LLM\u5224\u65ad\u4e2d\u7684\u9690\u85cf\u5f31\u70b9\uff0c\u4e3a\u5b9e\u73b0\u504f\u5dee\u611f\u77e5\u548c\u66f4\u53ef\u9760\u7684\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b9\u6cd5\u3002"}}
{"id": "2601.01753", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01753", "abs": "https://arxiv.org/abs/2601.01753", "authors": ["Hyunsoo Kim", "Jaewan Moon", "Seongmin Park", "Jongwuk Lee"], "title": "MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation", "comment": "Accepted by KDD 2026", "summary": "Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.", "AI": {"tldr": "MergeRec\uff1a\u57fa\u4e8e\u6a21\u578b\u878d\u5408\u7684\u6570\u636e\u9694\u79bb\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u65b0\u6846\u67b6\uff0c\u65e0\u9700\u5171\u4eab\u539f\u59cb\u7528\u6237\u6570\u636e\uff0c\u901a\u8fc7\u4f2a\u7528\u6237\u6570\u636e\u6784\u5efa\u548c\u534f\u540c\u878d\u5408\u4f18\u5316\u63d0\u5347\u8de8\u57df\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u8de8\u57df\u63a8\u8350\u65b9\u6cd5\u4f9d\u8d56\u57df\u95f4\u91cd\u53e0\u7528\u6237/\u7269\u54c1\u6216\u5ffd\u7565\u9690\u79c1\u7ea6\u675f\uff0c\u65e0\u6cd5\u5904\u7406\u6570\u636e\u9694\u79bb\u7684\u5b9e\u9645\u573a\u666f\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u5171\u4eab\u539f\u59cb\u6570\u636e\u7684\u8de8\u57df\u63a8\u8350\u89e3\u51b3\u65b9\u6848", "method": "\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u878d\u5408\u521d\u59cb\u5316\u4f7f\u7528\u65e0\u8bad\u7ec3\u878d\u5408\u6280\u672f\uff1b2) \u4f2a\u7528\u6237\u6570\u636e\u6784\u5efa\uff0c\u5c06\u6bcf\u4e2a\u7269\u54c1\u89c6\u4e3a\u865a\u62df\u5e8f\u5217\uff1b3) \u534f\u540c\u878d\u5408\u4f18\u5316\uff0c\u7ed3\u5408\u63a8\u8350\u635f\u5931\u548c\u84b8\u998f\u635f\u5931\u8054\u5408\u4f18\u5316\u57df\u7279\u5b9a\u878d\u5408\u6743\u91cd", "result": "MergeRec\u5728\u4fdd\u6301\u539f\u59cb\u6a21\u578b\u4f18\u52bf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5bf9\u672a\u89c1\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u5e73\u5747Recall@10\u63d0\u5347\u8fbe17.21%", "conclusion": "\u6a21\u578b\u878d\u5408\u662f\u6784\u5efa\u901a\u7528\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6709\u6548\u65b9\u6cd5\uff0cMergeRec\u4e3a\u6570\u636e\u9694\u79bb\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.01785", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01785", "abs": "https://arxiv.org/abs/2601.01785", "authors": ["Rajiv Chaitanya Muttur"], "title": "SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines", "comment": "Presented at ICEdge 2025; nominated for Best Paper Award", "summary": "Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.", "AI": {"tldr": "SRAS\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8f7b\u91cf\u7ea7\u6587\u6863\u9009\u62e9\u5668\uff0c\u4e13\u4e3a\u8fb9\u7f18\u8bbe\u5907RAG\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5728\u4e25\u683c\u7684\u8ba1\u7b97\u548c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u6587\u6863\u9009\u62e9\u3002", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u4f7f\u7528\u56fa\u5b9a\u7684top-k\u6587\u6863\u9009\u62e9\u673a\u5236\uff0c\u5ffd\u7565\u4e86\u751f\u6210\u8d28\u91cf\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u65e0\u6cd5\u6ee1\u8db3\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u7684\u4e25\u683c\u5ef6\u8fdf\u548c\u8ba1\u7b97\u9650\u5236\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u7b56\u7565\uff0c\u91c7\u7528PPO\u7b97\u6cd5\u548c\u6df7\u5408\u5956\u52b1\u4fe1\u53f7\uff08Relaxed F1 + BERTScore\uff09\uff0c\u5728\u4e25\u683ctoken\u548c\u8ba1\u7b97\u7ea6\u675f\u4e0b\u5b66\u4e60\u7d27\u51d1\u7684\u6587\u6863\u9009\u62e9\u7b56\u7565\u3002", "result": "SRAS\u4ec5\u5360\u7528\u7ea60.76MB\u5185\u5b58\uff0cCPU\u4e0a\u5ef6\u8fdf<1\u79d2\uff0c\u5728\u5408\u6210QA\u57fa\u51c6\u4e0a\u4f18\u4e8e\u76d1\u7763\u548c\u968f\u673a\u9009\u62e9\u5668\uff0c\u5728SQuAD v2\u4e0a\u8fbe\u52300.8546 BERTScore F1\uff0c\u65e0\u9700\u9886\u57df\u7279\u5b9a\u8c03\u4f18\u3002", "conclusion": "\u9996\u6b21\u8bc1\u660e\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6587\u6863\u9009\u62e9\u53ef\u4ee5\u5b9e\u73b0\u8d85\u8f7b\u91cf\u3001\u5ef6\u8fdf\u611f\u77e5\u4e14\u6709\u6548\u7684\u8fb9\u7f18\u8bbe\u5907RAG\u90e8\u7f72\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01897", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.01897", "abs": "https://arxiv.org/abs/2601.01897", "authors": ["Lilu Cheng", "Jingjun Lu", "Yi Xuan Chan", "Quoc Khai Nguyen", "John Bi", "Sean Ho"], "title": "A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing", "comment": "19 pages, 3 figures, 3 tables", "summary": "Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.\n  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u9636\u6bb5\u7ba1\u9053\uff0c\u7528\u4e8e\u4ece\u5f02\u6784\u533b\u7597\u7406\u8d54\u6587\u6863\u4e2d\u9ad8\u6548\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u5b9e\u73b095%\u6587\u6863\u5206\u7c7b\u51c6\u786e\u7387\u548c87%\u5b57\u6bb5\u63d0\u53d6\u51c6\u786e\u7387\uff0c\u5904\u7406\u901f\u5ea6\u6bd4\u4eba\u5de5\u5feb300\u500d\u3002", "motivation": "\u533b\u7597\u7406\u8d54\u6587\u6863\u901a\u5e38\u4ee5\u626b\u63cfPDF\u6216\u7167\u7247\u5f62\u5f0f\u5b58\u5728\uff0c\u5177\u6709\u5185\u5bb9\u5f02\u6784\u6027\uff08\u6253\u5b57\u53d1\u7968\u5230\u624b\u5199\u533b\u7597\u62a5\u544a\uff09\u3001\u8bed\u8a00\u591a\u6837\u6027\u3001\u56fe\u50cf\u8d28\u91cf\u4e0d\u4e00\u81f4\u548c\u5e03\u5c40\u591a\u6837\u7b49\u95ee\u9898\uff0c\u7ed9\u81ea\u52a8\u5316\u89e3\u6790\u548c\u4fe1\u606f\u63d0\u53d6\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002Fullerton Health\u6bcf\u5e74\u5904\u7406\u6570\u5343\u4e07\u4efd\u8de8\u4e5d\u56fd\u5e02\u573a\u7684\u7406\u8d54\uff0c\u6025\u9700\u9ad8\u6548\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u7ba1\u9053\uff1a1) \u4f7f\u7528\u591a\u8bed\u8a00OCR\u5f15\u64cePaddleOCR\u8fdb\u884c\u6587\u672c\u8bc6\u522b\uff1b2) \u4f20\u7edf\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\u8fdb\u884c\u6587\u6863\u7c7b\u578b\u5206\u7c7b\uff1b3) \u7d27\u51d1\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578bQwen 2.5-VL-7B\u8fdb\u884c\u5b57\u6bb5\u63d0\u53d6\u3002\u7ed3\u5408\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u73b0\u4ee3VLM\u6280\u672f\u3002", "result": "\u6587\u6863\u7c7b\u578b\u5206\u7c7b\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u5b57\u6bb5\u7ea7\u63d0\u53d6\u51c6\u786e\u7387\u7ea687%\uff0c\u5e73\u5747\u5904\u7406\u5ef6\u8fdf\u4f4e\u4e8e2\u79d2/\u6587\u6863\u3002\u76f8\u6bd4\u4eba\u5de5\u5904\u7406\u6bcf\u4efd\u7406\u8d54\u7ea610\u5206\u949f\uff0c\u6548\u7387\u63d0\u5347300\u500d\u3002\u7cfb\u7edf\u5df2\u5728\u79fb\u52a8\u5e94\u7528\u4e2d\u90e8\u7f72\uff0c\u6bcf\u5468\u5904\u7406\u8d8a\u5357\u548c\u65b0\u52a0\u5761\u6570\u4e07\u4efd\u7406\u8d54\u3002", "conclusion": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0e\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u80fd\u591f\u5b9e\u73b0\u751f\u4ea7\u7ea7\u51c6\u786e\u7387\u548c\u901f\u5ea6\uff0c\u6ee1\u8db3\u73b0\u5b9e\u4e16\u754c\u81ea\u52a8\u5316\u9700\u6c42\u3002\u8be5\u89e3\u51b3\u65b9\u6848\u5df2\u6210\u529f\u90e8\u7f72\u5e76\u5904\u7406\u5927\u89c4\u6a21\u7406\u8d54\u6570\u636e\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.01930", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01930", "abs": "https://arxiv.org/abs/2601.01930", "authors": ["Dongfang Zhao"], "title": "MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search", "comment": null, "summary": "Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.", "AI": {"tldr": "MCGI\u662f\u4e00\u79cd\u57fa\u4e8e\u6d41\u5f62\u4e00\u81f4\u6027\u7684\u56fe\u7d22\u5f15\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u672c\u5f81\u7ef4\u5ea6\u52a8\u6001\u8c03\u6574\u641c\u7d22\u7b56\u7565\uff0c\u89e3\u51b3\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u6b27\u51e0\u91cc\u5f97-\u6d4b\u5730\u7ebf\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u9ad8\u7ef4ANN\u641c\u7d22\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u56fe\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5b58\u5728\"\u6b27\u51e0\u91cc\u5f97-\u6d4b\u5730\u7ebf\u4e0d\u5339\u914d\"\u95ee\u9898\uff0c\u8d2a\u5a6a\u8def\u7531\u4f1a\u504f\u79bb\u5e95\u5c42\u6570\u636e\u6d41\u5f62\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u6570\u636e\u5185\u5728\u51e0\u4f55\u7ed3\u6784\u7684\u7d22\u5f15\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6d41\u5f62\u4e00\u81f4\u56fe\u7d22\u5f15(MCGI)\uff0c\u8fd9\u662f\u4e00\u79cd\u51e0\u4f55\u611f\u77e5\u7684\u78c1\u76d8\u9a7b\u7559\u7d22\u5f15\u65b9\u6cd5\u3002\u5229\u7528\u5c40\u90e8\u672c\u5f81\u7ef4\u5ea6(LID)\u8fdb\u884c\u539f\u4f4d\u51e0\u4f55\u5206\u6790\uff0c\u52a8\u6001\u8c03\u6574\u6ce2\u675f\u641c\u7d22\u9884\u7b97\uff0c\u6d88\u9664\u5bf9\u9759\u6001\u8d85\u53c2\u6570\u7684\u4f9d\u8d56\uff0c\u4fdd\u6301\u6d41\u5f62\u4e00\u81f4\u7684\u62d3\u6251\u8fde\u63a5\u6027\u3002", "result": "\u5728\u9ad8\u7ef4GIST1M\u6570\u636e\u96c6\u4e0a\uff0cMCGI\u572895%\u53ec\u56de\u7387\u4e0b\u5b9e\u73b0\u4e865.8\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff1b\u5728\u5341\u4ebf\u7ea7SIFT1B\u6570\u636e\u96c6\u4e0a\uff0c\u9ad8\u53ec\u56de\u67e5\u8be2\u5ef6\u8fdf\u964d\u4f4e\u4e863\u500d\uff0c\u540c\u65f6\u5728\u6807\u51c6\u4f4e\u7ef4\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "MCGI\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u7684\u7d22\u5f15\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4ANN\u641c\u7d22\u4e2d\u7684\u6d41\u5f62\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7406\u8bba\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u7684\u641c\u7d22\u6027\u80fd\u3002"}}
{"id": "2601.01997", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.01997", "abs": "https://arxiv.org/abs/2601.01997", "authors": ["Dario Di Palma", "Giovanni Maria Biancofiore", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations", "comment": null, "summary": "ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.\n  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86ChatGPT-3.5\u548cChatGPT-4\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u6d41\u884c\u5ea6\u504f\u5dee\u8868\u73b0\uff0c\u53d1\u73b0\u5728Top-N\u63a8\u8350\u548c\u51b7\u542f\u52a8\u573a\u666f\u4e2d\uff0cChatGPT-4\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\uff0c\u7279\u522b\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c3d\u7ba1ChatGPT\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5176\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u6f5c\u5728\u504f\u5dee\uff08\u5982\u6d41\u884c\u5ea6\u504f\u5dee\uff09\u7684\u5168\u9762\u5206\u6790\u3002\u968f\u7740\u8fd9\u4e9b\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7406\u89e3\u8fd9\u4e9b\u65b9\u9762\u5bf9\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u5b9e\u73b0\u957f\u671f\u4e2a\u6027\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86ChatGPT-3.5\u548cChatGPT-4\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u7ef4\u5ea6\u5305\u62ec\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u6d41\u884c\u5ea6\u504f\u5dee\uff0c\u5e76\u6d4b\u8bd5\u4e86Top-N\u63a8\u8350\u548c\u51b7\u542f\u52a8\u4e24\u79cd\u573a\u666f\u3002", "result": "ChatGPT-4\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\uff0c\u5728\u63a8\u8350\u7684\u65b0\u9896\u6027\u548c\u591a\u6837\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\uff0cChatGPT\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u65b0\u9896\u6027\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u9002\u5408\u65b0\u7528\u6237\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86ChatGPT\u63a8\u8350\u7684\u4f18\u52bf\u548c\u5c40\u9650\uff0c\u4e3a\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u5728\u51c6\u786e\u6027\u4e4b\u5916\u63d0\u4f9b\u63a8\u8350\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u8868\u660eChatGPT\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u3002"}}
{"id": "2601.02002", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.02002", "abs": "https://arxiv.org/abs/2601.02002", "authors": ["Antonio Colacicco", "Vito Guida", "Dario Di Palma", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u4eceLLM\u4e2d\u63d0\u53d6\u8bb0\u5fc6\u5316\u63a8\u8350\u6570\u636e\u7684\u65b9\u6cd5\uff1a\u8d8a\u72f1\u63d0\u793a\u5de5\u7a0b\u3001\u65e0\u76d1\u7763\u6f5c\u5728\u77e5\u8bc6\u53d1\u73b0\u548c\u81ea\u52a8\u63d0\u793a\u5de5\u7a0b\uff0c\u53d1\u73b0\u81ea\u52a8\u63d0\u793a\u5de5\u7a0b\u662f\u6700\u6709\u524d\u666f\u7684\u7b56\u7565\u3002", "motivation": "LLM\u5728\u63a8\u8350\u573a\u666f\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u8bad\u7ec3\u6570\u636e\u4e0d\u516c\u5f00\u5f15\u53d1\u6570\u636e\u6cc4\u9732\u62c5\u5fe7\u3002\u5df2\u6709\u7814\u7a76\u8868\u660eMovieLens-1M\u6570\u636e\u96c6\u88abLLaMA\u548cOpenAI\u6a21\u578b\u8bb0\u5fc6\uff0c\u4f46\u73b0\u6709\u63d0\u53d6\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u548c\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30\u4e09\u79cd\u65b9\u6cd5\uff1a1) \u8d8a\u72f1\u63d0\u793a\u5de5\u7a0b\uff1b2) \u65e0\u76d1\u7763\u6f5c\u5728\u77e5\u8bc6\u53d1\u73b0\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4e00\u81f4\u641c\u7d22(CCS)\u548c\u805a\u7c7b\u8303\u6570\u63a2\u6d4b\u5185\u90e8\u6fc0\u6d3b\uff1b3) \u81ea\u52a8\u63d0\u793a\u5de5\u7a0b(APE)\uff0c\u5c06\u63d0\u793a\u53d1\u73b0\u4f5c\u4e3a\u5143\u5b66\u4e60\u8fc7\u7a0b\u8fed\u4ee3\u4f18\u5316\u5019\u9009\u6307\u4ee4\u3002", "result": "\u5728MovieLens-1M\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u53d1\u73b0\uff1a\u8d8a\u72f1\u63d0\u793a\u65e0\u6cd5\u6539\u5584\u8bb0\u5fc6\u9879\u68c0\u7d22\u4e14\u7ed3\u679c\u4e0d\u4e00\u81f4\uff1bCCS\u80fd\u53ef\u9760\u533a\u5206\u771f\u5b9e\u4e0e\u4f2a\u9020\u7535\u5f71\u6807\u9898\u4f46\u65e0\u6cd5\u5904\u7406\u6570\u503c\u7528\u6237\u548c\u8bc4\u5206\u6570\u636e\uff1bAPE\u80fd\u4e2d\u7b49\u7a0b\u5ea6\u6210\u529f\u68c0\u7d22\u9879\u76ee\u7ea7\u4fe1\u606f\u4f46\u96be\u4ee5\u6062\u590d\u6570\u503c\u4ea4\u4e92\u3002", "conclusion": "\u81ea\u52a8\u4f18\u5316\u63d0\u793a\u662f\u4eceLLM\u4e2d\u63d0\u53d6\u8bb0\u5fc6\u5316\u6837\u672c\u7684\u6700\u6709\u524d\u666f\u7b56\u7565\uff0c\u4f46\u5f53\u524d\u65b9\u6cd5\u5728\u6570\u503c\u6570\u636e\u63d0\u53d6\u65b9\u9762\u4ecd\u6709\u5c40\u9650\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.02306", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02306", "abs": "https://arxiv.org/abs/2601.02306", "authors": ["Shivam Verma", "Hannes Karlbom", "Yu Zhao", "Nick Topping", "Vivian Chen", "Kieran Stanley", "Bharath Rengarajan"], "title": "Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify", "comment": "Accepted at WSDM 2026", "summary": "We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.", "AI": {"tldr": "Spotify\u63d0\u51fa\u7edf\u4e00\u591a\u76ee\u6807\u6a21\u578b\uff0c\u540c\u65f6\u4f18\u5316\u5e7f\u544a\u548c\u63a8\u5e7f\u6d3b\u52a8\u7684\u4e2a\u6027\u5316\u63a8\u8350\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\u548c\u63d0\u5347\u6d41\u5a92\u4f53\u7387\u3002", "motivation": "\u89e3\u51b3\u64ad\u5ba2\u751f\u6001\u7cfb\u7edf\u4e2d\u5e7f\u544a\u548c\u63a8\u5e7f\u6d3b\u52a8\u7684\u4e2a\u6027\u5316\u63a8\u8350\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u65b0\u5e7f\u544a\u76ee\u6807\u548c\u51b7\u542f\u52a8\u95ee\u9898\u3002\u4f20\u7edf\u7cfb\u7edf\u5b58\u5728\u5b64\u7acb\u7684\u63a8\u8350\u7ba1\u9053\uff0c\u7ef4\u62a4\u56f0\u96be\u4e14\u51b7\u542f\u52a8\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u5927\u89c4\u6a21\u5e7f\u544a\u548c\u5185\u5bb9\u4ea4\u4e92\u6570\u636e\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u3002\u6a21\u578b\u5171\u4eab\u7528\u6237\u3001\u5185\u5bb9\u3001\u4e0a\u4e0b\u6587\u548c\u521b\u610f\u7279\u5f81\u7684\u8868\u793a\uff0c\u8054\u5408\u4f18\u5316\u5e7f\u544a\u548c\u63a8\u5e7f\u7684\u591a\u4e2a\u76ee\u6807\uff08\u5982\u6d41\u5a92\u4f53\u3001\u70b9\u51fb\u3001\u5173\u6ce8\uff09\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff1a\u6709\u6548\u6bcf\u6d41\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe22%\uff08\u7279\u522b\u662f\u8f83\u5c11\u64ad\u653e\u7684\u64ad\u5ba2\uff09\uff0c\u64ad\u5ba2\u6d41\u5a92\u4f53\u7387\u63d0\u534718-24%\u3002\u79bb\u7ebf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8f85\u52a9\u76ee\u6807\u548c\u7279\u5f81\u7ec4\u5bf9\u51b7\u542f\u52a8\u6027\u80fd\u7684\u8d21\u732e\u3002", "conclusion": "\u7edf\u4e00\u5efa\u6a21\u7b56\u7565\u63d0\u9ad8\u4e86\u53ef\u7ef4\u62a4\u6027\u3001\u51b7\u542f\u52a8\u6027\u80fd\u548c\u8986\u76d6\u7387\uff0c\u6253\u7834\u4e86\u5386\u53f2\u4e0a\u5b64\u7acb\u7684\u63a8\u8350\u7ba1\u9053\u3002\u8ba8\u8bba\u4e86\u5b9e\u9645\u5e7f\u544a\u7cfb\u7edf\u4e2d\u8054\u5408\u6a21\u578b\u7684\u6743\u8861\u53d6\u820d\u3002"}}
