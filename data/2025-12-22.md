<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [A Reproducible and Fair Evaluation of Partition-aware Collaborative Filtering](https://arxiv.org/abs/2512.17015)
*Domenico De Gioia,Claudio Pomo,Ludovico Boratto,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 本文对FPSR和FPSR+分区感知协同过滤模型进行了可复现的基准测试，发现该模型系列虽然整体保持竞争力，但并非始终表现最佳，在长尾场景中优势明显。


<details>
  <summary>Details</summary>
Motivation: 基于相似度的协同过滤模型虽然离线性能强且概念简单，但维护稠密项目-项目相似度矩阵的二次成本限制了其可扩展性。分区感知方法在效果和效率间取得了平衡，但先前FPSR/FPSR+的评估存在可复现性问题，包括使用来源不明的数据分割和遗漏相似度基线，难以进行公平比较。

Method: 提出了透明、完全可复现的FPSR和FPSR+基准测试框架，系统评估了这些分区感知协同过滤模型。通过可复现的实验协议，对比分析了分区、全局组件和枢纽设计带来的准确率-覆盖率权衡。

Result: FPSR模型系列并未始终达到最高性能水平，但整体保持竞争力，验证了其设计选择，并在长尾场景中显示出显著优势。研究阐明了分区感知相似度建模何时最有益，并揭示了分区、全局组件和枢纽设计带来的准确率-覆盖率权衡。

Conclusion: 分区感知相似度建模在可扩展推荐系统设计中具有价值，特别是在长尾场景中。研究提供了在可复现协议下设计可扩展推荐系统的实用指导，强调了准确评估和公平比较的重要性。

Abstract: Similarity-based collaborative filtering (CF) models have long demonstrated strong offline performance and conceptual simplicity. However, their scalability is limited by the quadratic cost of maintaining dense item-item similarity matrices. Partitioning-based paradigms have recently emerged as an effective strategy for balancing effectiveness and efficiency, enabling models to learn local similarities within coherent subgraphs while maintaining a limited global context. In this work, we focus on the Fine-tuning Partition-aware Similarity Refinement (FPSR) framework, a prominent representative of this family, as well as its extension, FPSR+. Reproducible evaluation of partition-aware collaborative filtering remains challenging, as prior FPSR/FPSR+ reports often rely on splits of unclear provenance and omit some similarity-based baselines, thereby complicating fair comparison. We present a transparent, fully reproducible benchmark of FPSR and FPSR+. Based on our results, the family of FPSR models does not consistently perform at the highest level. Overall, it remains competitive, validates its design choices, and shows significant advantages in long-tail scenarios. This highlights the accuracy-coverage trade-offs resulting from partitioning, global components, and hub design. Our investigation clarifies when partition-aware similarity modeling is most beneficial and offers actionable guidance for scalable recommender system design under reproducible protocols.

</details>


### [2] [Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations](https://arxiv.org/abs/2512.17027)
*Erica Coppolillo,Simone Mungari*

Main category: cs.IR

TL;DR: 对维基百科和Grokipedia两大百科平台的搜索引擎进行首次比较分析，发现两者都会产生与查询弱相关的结果，但推荐内容存在显著差异，且都存在从无害查询引发意外内容的风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成的百科全书Grokipedia的出现，搜索引擎在不同百科系统中的行为尚未得到充分研究。本研究旨在填补这一空白，首次比较分析维基百科和Grokipedia的搜索引擎机制。

Method: 使用近10,000个中性英文单词及其子字符串作为查询，收集超过70,000个搜索结果，分析语义对齐、重叠度和主题结构。通过主题标注和轨迹分析，研究内容类别呈现方式和搜索结果在多阶段探索中的演变。

Result: 两个平台都经常产生与原始查询弱相关的结果，甚至从无害查询中浮现意外内容。尽管有这些共同特性，两个系统对相同查询产生的推荐集存在显著差异。在主题分布和查询建议方面存在系统性差异。

Conclusion: 意外搜索结果在两大平台中都是常见现象，尽管它们在主题分布和查询建议方面存在差异。这揭示了AI生成和传统百科平台搜索引擎行为的共性和差异。

Abstract: Encyclopedic knowledge platforms are key gateways through which users explore information online. The recent release of Grokipedia, a fully AI-generated encyclopedia, introduces a new alternative to traditional, well-established platforms like Wikipedia. In this context, search engine mechanisms play an important role in guiding users exploratory paths, yet their behavior across different encyclopedic systems remains underexplored. In this work, we address this gap by providing the first comparative analysis of search engine in Wikipedia and Grokipedia.
  Using nearly 10,000 neutral English words and their substrings as queries, we collect over 70,000 search engine results and examine their semantic alignment, overlap, and topical structure. We find that both platforms frequently generate results that are weakly related to the original query and, in many cases, surface unexpected content starting from innocuous queries. Despite these shared properties, the two systems often produce substantially different recommendation sets for the same query. Through topical annotation and trajectory analysis, we further identify systematic differences in how content categories are surfaced and how search engine results evolve over multiple stages of exploration.
  Overall, our findings show that unexpected search engine outcomes are a common feature of both the platforms, even though they exhibit discrepancies in terms of topical distribution and query suggestions.

</details>


### [3] [TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval](https://arxiv.org/abs/2512.17164)
*Yu Yang,Feng Tian,Ping Chen*

Main category: cs.IR

TL;DR: TCDE提出了一种基于大语言模型的主题中心化双扩展策略，同时在查询和文档两侧进行扩展，通过建立语义桥梁来解决传统单独扩展导致的语义不对齐问题。


<details>
  <summary>Details</summary>
Motivation: 传统的查询扩展和文档扩展通常单独应用，这可能导致扩展后的查询（或文档）与其相关文档（或查询）之间的语义不对齐。为了解决这个严重问题，需要一种能够同时处理查询和文档扩展的方法。

Method: TCDE使用大语言模型进行主题中心化的双扩展：1）在查询侧，LLM识别查询中的不同子主题并为每个子主题生成聚焦的伪文档；2）在文档侧，LLM将文档提炼为一组核心主题句。这些输出用于扩展原始查询和文档，建立查询与相关文档之间的语义桥梁。

Result: 在TREC Deep Learning和BEIR两个具有挑战性的基准测试中，TCDE相比现有的强扩展基线取得了显著改进。特别是在密集检索任务中，它在SciFact数据集上的NDCG@10指标相对提升了2.8%，优于多个最先进方法。

Conclusion: TCDE通过主题中心化的双扩展策略，有效解决了查询和文档扩展中的语义不对齐问题，实验结果表明该方法在检索任务中具有显著优势，验证了双扩展策略的有效性。

Abstract: Query Expansion (QE) enriches queries and Document Expansion (DE) enriches documents, and these two techniques are often applied separately. However, such separate application may lead to semantic misalignment between the expanded queries (or documents) and their relevant documents (or queries). To address this serious issue, we propose TCDE, a dual expansion strategy that leverages large language models (LLMs) for topic-centric enrichment on both queries and documents. In TCDE, we design two distinct prompt templates for processing each query and document. On the query side, an LLM is guided to identify distinct sub-topics within each query and generate a focused pseudo-document for each sub-topic. On the document side, an LLM is guided to distill each document into a set of core topic sentences. The resulting outputs are used to expand the original query and document. This topic-centric dual expansion process establishes semantic bridges between queries and their relevant documents, enabling better alignment for downstream retrieval models. Experiments on two challenging benchmarks, TREC Deep Learning and BEIR, demonstrate that TCDE achieves substantial improvements over strong state-of-the-art expansion baselines. In particular, on dense retrieval tasks, it outperforms several state-of-the-art methods, with a relative improvement of 2.8\% in NDCG@10 on the SciFact dataset. Experimental results validate the effectiveness of our topic-centric and dual expansion strategy.

</details>


### [4] [Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest](https://arxiv.org/abs/2512.17277)
*Saeed Ebrahimi,Weijie Jiang,Jaewon Yang,Olafur Gudmundsson,Yucheng Tu,Huizhong Duan*

Main category: cs.IR

TL;DR: 论文提出针对Pinterest冷启动物品推荐问题的四项轻量级解决方案，包括残差连接、分数正则化、流形混合等技术，仅增加5%参数，提升新鲜内容参与度10%


<details>
  <summary>Details</summary>
Motivation: Pinterest作为视觉发现平台，推荐系统对用户体验至关重要。冷启动物品在训练数据中出现频率低，导致预测质量差，影响新鲜内容推荐效果。虽然学术界对此问题有研究，但工业级平台规模下的实际挑战尚未有效解决

Method: 1. 设计轻量级方案，总参数仅增加5%；2. 为非历史特征引入残差连接，提升其重要性；3. 加入分数正则化项，缓解冷启动物品分数偏低问题；4. 应用流形混合技术，解决标签稀疏性

Result: 方法组合实施后，Pinterest新鲜内容参与度提升10%，整体参与度和成本未受影响，已部署服务超过5.7亿用户

Conclusion: 针对工业级推荐系统中的冷启动问题，提出了四项高效、轻量级的解决方案，有效提升了新鲜内容推荐效果，为大规模平台提供了实用的冷启动处理框架

Abstract: Pinterest is a leading visual discovery platform where recommender systems (RecSys) are key to delivering relevant, engaging, and fresh content to our users. In this paper, we study the problem of improving RecSys model predictions for cold-start (CS) items, which appear infrequently in the training data. Although this problem is well-studied in academia, few studies have addressed its root causes effectively at the scale of a platform like Pinterest. By investigating live traffic data, we identified several challenges of the CS problem and developed a corresponding solution for each: First, industrial-scale RecSys models must operate under tight computational constraints. Since CS items are a minority, any related improvements must be highly cost-efficient. To address this, our solutions were designed to be lightweight, collectively increasing the total parameters by only 5%. Second, CS items are represented only by non-historical (e.g., content or attribute) features, which models often treat as less important. To elevate their significance, we introduce a residual connection for the non-historical features. Third, CS items tend to receive lower prediction scores compared to non-CS items, reducing their likelihood of being surfaced. We mitigate this by incorporating a score regularization term into the model. Fourth, the labels associated with CS items are sparse, making it difficult for the model to learn from them. We apply the manifold mixup technique to address this data sparsity. Implemented together, our methods increased fresh content engagement at Pinterest by 10% without negatively impacting overall engagement and cost, and have been deployed to serve over 570 million users on Pinterest.

</details>


### [5] [The Mental World of Large Language Models in Recommendation: A Benchmark on Association, Personalization, and Knowledgeability](https://arxiv.org/abs/2512.17389)
*Guangneng Hu*

Main category: cs.IR

TL;DR: LRWorld基准测试评估LLMs在推荐系统中的能力，发现LLMs在深度个性化嵌入方面表现不佳，但在浅层记忆相似度、实体关系推理和多模态知识方面表现良好，且没有模型在所有十个因素上都表现一致优秀。


<details>
  <summary>Details</summary>
Motivation: LLMs在推荐系统中作为知识增强器或零样本排序器显示出潜力，但LLMs（语言世界知识）与推荐系统（个性化行为世界）之间存在巨大语义鸿沟。研究社区缺乏一个全面的基准来评估LLMs在推荐系统中的局限性和边界，以便得出可靠结论。

Method: 提出LRWorld基准，包含从广泛使用的公共推荐数据集中精心编译和生成的超过38K高质量样本和23M令牌。将LLMs在推荐系统中的心智世界分为三个主要尺度（关联性、个性化、知识性），涵盖十个因素和31个测量（任务）。在数十个LLMs上进行全面实验。

Result: LLMs仍然不能很好地捕捉深度神经个性化嵌入，但在浅层记忆基础的物品相似度上能取得良好结果。在推断用户兴趣时，LLMs擅长感知物品实体关系、实体层次分类和物品关联规则。此外，LLMs在多模态知识推理（电影海报和产品图像）和对噪声用户画像的鲁棒性方面显示出有前景的能力。没有模型在十个因素上都表现一致优秀。

Conclusion: LLMs在推荐系统中表现出混合能力：在浅层相似度和知识推理方面表现良好，但在深度个性化方面仍有局限。需要进一步研究来弥合LLMs与推荐系统之间的语义鸿沟，并开发更全面的评估基准。

Abstract: Large language models (LLMs) have shown potential in recommendation systems (RecSys) by using them as either knowledge enhancer or zero-shot ranker. A key challenge lies in the large semantic gap between LLMs and RecSys where the former internalizes language world knowledge while the latter captures personalized world of behaviors. Unfortunately, the research community lacks a comprehensive benchmark that evaluates the LLMs over their limitations and boundaries in RecSys so that we can draw a confident conclusion. To investigate this, we propose a benchmark named LRWorld containing over 38K high-quality samples and 23M tokens carefully compiled and generated from widely used public recommendation datasets. LRWorld categorizes the mental world of LLMs in RecSys as three main scales (association, personalization, and knowledgeability) spanned by ten factors with 31 measures (tasks). Based on LRWorld, comprehensive experiments on dozens of LLMs show that they are still not well capturing the deep neural personalized embeddings but can achieve good results on shallow memory-based item-item similarity. They are also good at perceiving item entity relations, entity hierarchical taxonomies, and item-item association rules when inferring user interests. Furthermore, LLMs show a promising ability in multimodal knowledge reasoning (movie poster and product image) and robustness to noisy profiles. None of them show consistently good performance over the ten factors. Model sizes, position bias, and more are ablated.

</details>


### [6] [A Systematic Reproducibility Study of BSARec for Sequential Recommendation](https://arxiv.org/abs/2512.17442)
*Jan Hutter,Hua Chang Bakker,Stan Fris,Madelon Bernardy,Yuanna Liu*

Main category: cs.IR

TL;DR: BSARec通过傅里叶变换增强Transformer的高频信号捕获能力，但研究发现DSP方法相比简单残差连接优势有限，非恒定填充策略对性能提升更关键。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在序列推荐中作为低通滤波器，难以捕捉反映短期用户兴趣的高频信号，需要验证BSARec方法的有效性及其组件作用。

Method: 复现BSARec并评估其性能；提出量化用户历史频率的指标；比较不同数字信号处理技术（傅里叶变换vs小波变换）；探索不同填充策略对性能的影响。

Result: BSARec在某些数据集上优于其他方法；小波变换相比傅里叶变换改进有限；DSP方法相比简单残差连接无明显优势；非恒定填充显著提升推荐性能，而恒定填充会阻碍高频信号捕获。

Conclusion: BSARec的高频增强机制有效，但数字信号处理方法的优势有限，填充策略对性能影响比信号处理技术本身更重要，需要重新评估DSP在序列推荐中的价值。

Abstract: In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.

</details>


### [7] [Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application](https://arxiv.org/abs/2512.17462)
*Olivier Jeunen,Schaun Wheeler*

Main category: cs.IR

TL;DR: 代理驱动的个性化消息在金融服务应用中减少了21%的退订行为，并促进了提前报税行为


<details>
  <summary>Details</summary>
Motivation: 评估代理驱动的个性化方法在金融服务客户沟通系统中的行为和留存效果，特别是在税务申报期间

Method: 通过为期两个月的随机对照试验，比较代理消息方法与基于规则的常规业务系统，重点关注退订行为和转化时机

Result: 代理消息使退订事件相对常规系统减少21%（±0.01），并在国家截止日期前几周增加了提前申报行为

Conclusion: 自适应、用户级别的决策系统可以调节参与强度，同时改善长期留存指标

Abstract: Marketing and product personalisation provide a prominent and visible use-case for the application of Information Retrieval methods across several business domains. Recently, agentic approaches to these problems have been gaining traction. This work evaluates the behavioural and retention effects of agentic personalisation on a financial service application's customer communication system during a 2025 national tax filing period. Through a two month-long randomised controlled trial, we compare an agentic messaging approach against a business-as-usual (BAU) rule-based campaign system, focusing on two primary outcomes: unsubscribe behaviour and conversion timing. Empirical results show that agent-led messaging reduced unsubscribe events by 21\% ($\pm 0.01$) relative to BAU and increased early filing behaviour in the weeks preceding the national deadline. These findings demonstrate how adaptive, user-level decision-making systems can modulate engagement intensity whilst improving long-term retention indicators.

</details>


### [8] [Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure](https://arxiv.org/abs/2512.17733)
*Jingmao Zhang,Zhiting Zhao,Yunqi Lin,Jianghong Ma,Tianjun Wei,Haijun Zhang,Xiaofeng Zhang*

Main category: cs.IR

TL;DR: Cadence是一个基于因果去混杂的多样性推荐框架，通过构建无偏非对称共购关系图，结合反事实曝光模拟，在保持准确性的同时显著提升推荐多样性。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统主要依赖共现关系，容易受到商品流行度和用户属性偏差的影响，导致嵌入质量下降。同时，多样性作为推荐质量的重要方面，现有研究缺乏因果视角和理论基础。

Method: 1. 计算无偏非对称共购关系(UACR)，排除商品流行度和用户属性影响，构建去混杂的有向商品图，通过聚合机制优化嵌入表示。2. 利用UACR识别与用户交互商品有强因果相关性但尚未接触的多样化商品类别，在高曝光场景下模拟用户行为。

Result: 在真实数据集上的实验表明，该方法在多样性和准确性方面均优于现有最先进的多样性模型，验证了其有效性、可迁移性和效率。

Conclusion: Cadence框架通过因果去混杂和反事实曝光模拟，成功解决了推荐系统中多样性提升与准确性保持的平衡问题，为多样性推荐提供了新的理论和方法基础。

Abstract: Beyond user-item modeling, item-to-item relationships are increasingly used to enhance recommendation. However, common methods largely rely on co-occurrence, making them prone to item popularity bias and user attributes, which degrades embedding quality and performance. Meanwhile, although diversity is acknowledged as a key aspect of recommendation quality, existing research offers limited attention to it, with a notable lack of causal perspectives and theoretical grounding. To address these challenges, we propose Cadence: Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure - a plug-and-play framework built upon LightGCN as the backbone, primarily designed to enhance recommendation diversity while preserving accuracy. First, we compute the Unbiased Asymmetric Co-purchase Relationship (UACR) between items - excluding item popularity and user attributes - to construct a deconfounded directed item graph, with an aggregation mechanism to refine embeddings. Second, we leverage UACR to identify diverse categories of items that exhibit strong causal relevance to a user's interacted items but have not yet been engaged with. We then simulate their behavior under high-exposure scenarios, thereby significantly enhancing recommendation diversity while preserving relevance. Extensive experiments on real-world datasets demonstrate that our method consistently outperforms state-of-the-art diversity models in both diversity and accuracy, and further validates its effectiveness, transferability, and efficiency over baselines.

</details>
