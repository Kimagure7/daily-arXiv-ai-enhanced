<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [STCRank: Spatio-temporal Collaborative Ranking for Interactive Recommender System at Kuaishou E-shop](https://arxiv.org/abs/2601.10027)
*Boyang Xia,Ruilin Bao,Hanjun Jiang,Jun Wang,Wenwu Ou*

Main category: cs.IR

TL;DR: 快手电商提出STCRank框架，通过时空协同排序解决全屏UI下的多目标冲突和时序贪婪陷阱问题，实现购买和日活双增长。


<details>
  <summary>Details</summary>
Motivation: 快手电商作为流行的电商平台，需要处理实时用户反馈。全屏UI和沉浸式下滑功能带来了两个主要挑战：1）转化率、浏览和下滑等多目标之间存在显性干扰（重叠或冲突）；2）排序系统在序列推荐槽位转换中容易陷入时序贪婪陷阱。

Method: 提出时空协同排序（STCRank）框架，包含两个模块：1）多目标协同（MOC）模块，通过缓解目标重叠和冲突来推进帕累托前沿；2）多槽位协同（MSC）模块，通过双阶段前瞻排序机制实现整体序列槽位的全局最优。

Result: 大量实验表明该方法带来了购买和日活用户的双重增长。该系统已于2025年6月在快手电商部署上线。

Conclusion: STCRank框架有效解决了全屏UI电商推荐系统中的多目标冲突和时序贪婪问题，实现了多目标协同和跨槽位优化，在实际部署中取得了显著效果。

Abstract: As a popular e-commerce platform, Kuaishou E-shop provides precise personalized product recommendations to tens of millions of users every day. To better respond real-time user feedback, we have deployed an interactive recommender system (IRS) alongside our core homepage recommender system. This IRS is triggered by user click on homepage, and generates a series of highly relevant recommendations based on the clicked item to meet focused browsing demands. Different from traditional e-commerce RecSys, the full-screen UI and immersive swiping down functionality present two distinct challenges for regular ranking system. First, there exists explicit interference (overlap or conflicts) between ranking objectives, i.e., conversion, view and swipe down. This is because there are intrinsic behavioral co-occurrences under the premise of immersive browsing and swiping down functionality. Second, the ranking system is prone to temporal greedy traps in sequential recommendation slot transitions, which is caused by full-screen UI design. To alleviate these challenges, we propose a novel Spatio-temporal collaborative ranking (STCRank) framework to achieve collaboration between multi-objectives within one slot (spatial) and between multiple sequential recommondation slots. In multi-objective collaboration (MOC) module, we push Pareto frontier by mitigating the objective overlaps and conflicts. In multi-slot collaboration (MSC) module, we achieve global optima on overall sequential slots by dual-stage look-ahead ranking mechanism. Extensive experiments demonstrate our proposed method brings about purchase and DAU co-growth. The proposed system has been already deployed at Kuaishou E-shop since 2025.6.

</details>


### [2] [Development of Ontological Knowledge Bases by Leveraging Large Language Models](https://arxiv.org/abs/2601.10436)
*Le Ngoc Luyen,Marie-Hélène Abel,Philippe Gouspillou*

Main category: cs.IR

TL;DR: 本文提出了一种利用大语言模型（LLMs）优化本体知识库（OKBs）开发的迭代方法，通过车辆销售领域的用户上下文配置文件本体案例研究，展示了该方法能显著加速本体构建、提高一致性、缓解偏见并增强透明度。


<details>
  <summary>Details</summary>
Motivation: 传统手动开发本体知识库面临可扩展性、一致性和适应性方面的挑战，而生成式AI特别是大语言模型为自动化和增强OKB开发提供了有前景的解决方案。

Method: 提出了一种结构化、迭代的方法论，利用LLMs优化知识获取、自动化本体工件生成，并支持持续精炼循环。通过车辆销售领域的用户上下文配置文件本体案例研究来演示该方法。

Result: 该方法显著加速了本体构建过程，提高了本体一致性，有效缓解了偏见，并增强了本体工程过程的透明度。

Conclusion: 研究结果表明，将LLMs集成到本体开发中具有变革性潜力，能显著提高知识管理系统的可扩展性、集成能力和整体效率。

Abstract: Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.

</details>


### [3] [iTIMO: An LLM-empowered Synthesis Dataset for Travel Itinerary Modification](https://arxiv.org/abs/2601.10609)
*Zhuoxuan Huang,Yunshan Ma,Hongyu Zhang,Hua Ma,Zhu Sun*

Main category: cs.IR

TL;DR: iTIMO是一个专门用于行程修改任务的数据集，通过意图驱动的扰动方法生成需要修改的行程数据，以解决该领域数据匮乏的问题。


<details>
  <summary>Details</summary>
Motivation: 行程修改是旅行中的常见需求，但现有研究主要关注固定行程规划，行程修改任务缺乏系统研究和专门数据集，阻碍了该领域的发展。

Method: 提出一个通用数据生成流程，将需要修改的行程数据生成视为意图驱动的扰动任务，使用大语言模型通过REPLACE、ADD、DELETE三种原子编辑操作对真实行程进行扰动，扰动基于流行度、空间距离和类别多样性三种意图。

Result: 创建了iTIMO数据集，通过综合实验揭示了当前大语言模型在行程修改任务上的局限性，为未来研究提供了有价值的方向。

Conclusion: iTIMO数据集填补了行程修改研究的数据空白，提出的数据生成方法有效，实验结果为未来行程修改研究提供了重要基础。

Abstract: Addressing itinerary modification is crucial for enhancing the travel experience as it is a frequent requirement during traveling. However, existing research mainly focuses on fixed itinerary planning, leaving modification underexplored. To bridge this gap, we formally define the itinerary modification task and introduce iTIMO, a dataset specifically tailored for this purpose. We identify the lack of {\itshape need-to-modify} itinerary data as the critical bottleneck hindering research on this task and propose a general pipeline to overcome it. This pipeline frames the generation of such data as an intent-driven perturbation task. It instructs large language models to perturb real world itineraries using three atomic editing operations: REPLACE, ADD, and DELETE. Each perturbation is grounded in three intents, including disruptions of popularity, spatial distance, and category diversity. Furthermore, a hybrid evaluation metric is designed to ensure perturbation effectiveness. We conduct comprehensive experiments on iTIMO, revealing the limitations of current LLMs and lead to several valuable directions for future research. Dataset and corresponding code are available at https://github.com/zelo2/iTIMO.

</details>


### [4] [RoutIR: Fast Serving of Retrieval Pipelines for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.10644)
*Eugene Yang,Andrew Yates,Dawn Lawrie,James Mayfield,Trevor Adriaanse*

Main category: cs.IR

TL;DR: RoutIR是一个Python包，为检索模型提供HTTP API，支持动态RAG系统中的在线检索服务


<details>
  <summary>Details</summary>
Motivation: 当前学术IR平台主要针对Cranfield范式设计，支持批量离线处理，但无法满足动态RAG系统所需的在线服务需求，如多轮检索、循环、反馈等

Method: 开发RoutIR Python包，通过HTTP API包装任意检索方法（包括第一阶段检索、重排序、查询扩展、结果融合），支持JSON配置文件和异步查询批处理

Result: RoutIR提供了灵活的检索管道构建能力，支持任意模型组合，自动进行异步批处理和缓存，已支持多种先进检索方法且易于扩展

Conclusion: RoutIR填补了学术检索模型与动态RAG应用之间的鸿沟，为构建在线检索服务提供了简单高效的解决方案

Abstract: Retrieval models are key components of Retrieval-Augmented Generation (RAG) systems, which generate search queries, process the documents returned, and generate a response. RAG systems are often dynamic and may involve multiple rounds of retrieval. While many state-of-the-art retrieval methods are available through academic IR platforms, these platforms are typically designed for the Cranfield paradigm in which all queries are known up front and can be batch processed offline. This simplification accelerates research but leaves state-of-the-art retrieval models unable to support downstream applications that require online services, such as arbitrary dynamic RAG pipelines that involve looping, feedback, or even self-organizing agents. In this work, we introduce RoutIR, a Python package that provides a simple and efficient HTTP API that wraps arbitrary retrieval methods, including first stage retrieval, reranking, query expansion, and result fusion. By providing a minimal JSON configuration file specifying the retrieval models to serve, RoutIR can be used to construct and query retrieval pipelines on-the-fly using any permutation of available models (e.g., fusing the results of several first-stage retrieval methods followed by reranking). The API automatically performs asynchronous query batching and caches results by default. While many state-of-the-art retrieval methods are already supported by the package, RoutIR is also easily expandable by implementing the Engine abstract class. The package is open-sourced and publicly available on GitHub: http://github.com/hltcoe/routir.

</details>
