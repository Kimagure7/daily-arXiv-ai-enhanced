<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 17]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [AgenticShop: Benchmarking Agentic Product Curation for Personalized Web Shopping](https://arxiv.org/abs/2602.12315)
*Sunghwan Kim,Ryang Heo,Yongsik Seo,Jinyoung Yeo,Dongha Lee*

Main category: cs.IR

TL;DR: 提出了AgenticShop基准，用于评估开放网络环境中个性化产品推荐的智能代理系统，填补了现有基准在真实购物场景和个性化评估方面的不足。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速发展导致信息环境嘈杂且碎片化，增加了用户的认知负担。虽然智能代理系统在自动化用户端任务方面显示出潜力，但现有基准无法全面评估代理在开放网络环境中进行产品推荐的能力，特别是缺乏真实购物场景覆盖和个性化评估。

Method: 提出了AgenticShop基准，包含三个关键特征：1）真实购物场景；2）多样化用户画像；3）可验证的、基于清单驱动的个性化评估框架。该基准旨在全面评估代理系统在开放网络环境中的个性化产品推荐能力。

Result: 通过大量实验证明，当前的智能代理系统在个性化产品推荐方面仍然存在显著不足，强调了需要开发能够有效在现代网络中为用户量身定制产品的用户端系统。

Conclusion: AgenticShop是首个用于评估开放网络环境中个性化产品推荐智能代理系统的基准，揭示了当前系统的局限性，并为未来开发更有效的用户端推荐系统提供了评估框架。

Abstract: The proliferation of e-commerce has made web shopping platforms key gateways for customers navigating the vast digital marketplace. Yet this rapid expansion has led to a noisy and fragmented information environment, increasing cognitive burden as shoppers explore and purchase products online. With promising potential to alleviate this challenge, agentic systems have garnered growing attention for automating user-side tasks in web shopping. Despite significant advancements, existing benchmarks fail to comprehensively evaluate how well agentic systems can curate products in open-web settings. Specifically, they have limited coverage of shopping scenarios, focusing only on simplified single-platform lookups rather than exploratory search. Moreover, they overlook personalization in evaluation, leaving unclear whether agents can adapt to diverse user preferences in realistic shopping contexts. To address this gap, we present AgenticShop, the first benchmark for evaluating agentic systems on personalized product curation in open-web environment. Crucially, our approach features realistic shopping scenarios, diverse user profiles, and a verifiable, checklist-driven personalization evaluation framework. Through extensive experiments, we demonstrate that current agentic systems remain largely insufficient, emphasizing the need for user-side systems that effectively curate tailored products across the modern web.

</details>


### [2] [An Industrial-Scale Sequential Recommender for LinkedIn Feed Ranking](https://arxiv.org/abs/2602.12354)
*Lars Hertel,Gaurav Srivastava,Syed Ali Naqvi,Satyam Kumar,Yue Zhang,Borja Ocejo,Benjamin Zelditch,Adrian Englhardt,Hailing Cheng,Andy Hu,Antonio Alonso,Daming Li,Siddharth Dangi,Chen Zhu,Mingzhou Zhou,Wanning Li,Tao Huang,Fedor Borisyuk,Ganesh Parameswaran,Birjodh Singh Tiwana,Sriram Sankar,Qing Lan,Julie Choi,Souvik Ghosh*

Main category: cs.IR

TL;DR: LinkedIn开发了基于Transformer的Feed-SR序列推荐模型，替代原有DCNv2排序器，在严格生产约束下显著提升用户参与度


<details>
  <summary>Details</summary>
Motivation: LinkedIn Feed需要为全球专业人士提供相关内容发现、建立连接和知识分享，现有DCNv2模型需要更先进的序列推荐方法来提升用户体验和参与度

Method: 采用基于Transformer的序列排序模型Feed-SR，详细设计了建模选择、训练技术和服务优化，以满足LinkedIn规模的生产部署要求

Result: Feed-SR成为LinkedIn Feed的主要体验，在线A/B测试显示相比现有生产模型，用户参与度显著提升（时间花费+2.10%）

Conclusion: Feed-SR在在线指标和生产效率方面提供了最佳组合，成功部署为LinkedIn Feed的主要推荐系统，展示了序列推荐模型在工业规模应用中的有效性

Abstract: LinkedIn Feed enables professionals worldwide to discover relevant content, build connections, and share knowledge at scale. We present Feed Sequential Recommender (Feed-SR), a transformer-based sequential ranking model for LinkedIn Feed that replaces a DCNv2-based ranker and meets strict production constraints. We detail the modeling choices, training techniques, and serving optimizations that enable deployment at LinkedIn scale. Feed-SR is currently the primary member experience on LinkedIn's Feed and shows significant improvements in member engagement (+2.10% time spent) in online A/B tests compared to the existing production model. We also describe our deployment experience with alternative sequential and LLM-based ranking architectures and why Feed-SR provided the best combination of online metrics and production efficiency.

</details>


### [3] [Latent Customer Segmentation and Value-Based Recommendation Leveraging a Two-Stage Model with Missing Labels](https://arxiv.org/abs/2602.12485)
*Keerthi Gopalakrishnan,Tianning Dong,Chia-Yen Ho,Yokila Arora,Topojoy Biswas,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.IR

TL;DR: 提出两阶段多模型架构，使用自步损失改进客户分类，区分活动影响、有机参与和低参与客户，提高营销活动精准度和转化效率


<details>
  <summary>Details</summary>
Motivation: 传统营销活动可能侵蚀品牌价值且投资回报率低，现有经济算法常误判高参与客户为理想目标，导致参与和转化效率低下

Method: 两阶段多模型架构：第一阶段使用多类神经网络区分活动影响客户、有机参与客户和低参与客户；第二阶段应用二元标签校正模型，在缺失标签框架下识别真正的活动驱动意图

Result: A/B测试显示关键成功指标提升超过100个基点，系统能更精准定位活动目标，降低曝光成本，提高转化效率

Conclusion: 通过分离活动驱动参与和有机行为，意图感知的客户细分方法能实现更精准的活动定位，为价值驱动营销策略提供有效解决方案

Abstract: The success of businesses depends on their ability to convert consumers into loyal customers. A customer's value proposition is a primary determinant in this process, requiring a balance between affordability and long-term brand equity. Broad marketing campaigns can erode perceived brand value and reduce return on investment, while existing economic algorithms often misidentify highly engaged customers as ideal targets, leading to inefficient engagement and conversion outcomes.
  This work introduces a two-stage multi-model architecture employing Self-Paced Loss to improve customer categorization. The first stage uses a multi-class neural network to distinguish customers influenced by campaigns, organically engaged customers, and low-engagement customers. The second stage applies a binary label correction model to identify true campaign-driven intent using a missing-label framework, refining customer segmentation during training.
  By separating prompted engagement from organic behavior, the system enables more precise campaign targeting, reduces exposure costs, and improves conversion efficiency. A/B testing demonstrates over 100 basis points improvement in key success metrics, highlighting the effectiveness of intent-aware segmentation for value-driven marketing strategies.

</details>


### [4] [Visual RAG Toolkit: Scaling Multi-Vector Visual Retrieval with Training-Free Pooling and Multi-Stage Search](https://arxiv.org/abs/2602.12510)
*Ara Yeroyan*

Main category: cs.IR

TL;DR: Visual RAG Toolkit通过训练无关的池化和多阶段检索，将视觉多向量检索的存储向量从数千个减少到数十个，实现二次方级的计算量减少，在保持检索质量的同时显著提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 多向量视觉检索器（如ColPali风格的后期交互模型）虽然准确率高，但每个页面产生数千个向量，导致索引和搜索成本高昂，扩展性差。

Method: 提出Visual RAG Toolkit系统，采用训练无关的模型感知池化和多阶段检索。基于Matryoshka Embeddings思想，通过静态空间池化（包括轻量级滑动窗口平均变体）对补丁嵌入进行压缩，生成紧凑的瓦片级和全局表示用于快速候选生成，然后使用完整多向量嵌入进行精确MaxSim重排序。

Result: 在ViDoRe v2基准测试中，两阶段检索通常能保持NDCG和Recall@5/10指标，仅有轻微下降，同时显著提升吞吐量（约4倍QPS）。存储向量从每页数千个减少到数十个，实现二次方级的向量比较减少。

Conclusion: 该工具包通过强调常见截断点（k≤10）的效率，降低了硬件门槛，使最先进的视觉检索在实际应用中更加可访问。提供了完整的预处理和可复现评估流程，支持快速探索不同检索变体。

Abstract: Multi-vector visual retrievers (e.g., ColPali-style late interaction models) deliver strong accuracy, but scale poorly because each page yields thousands of vectors, making indexing and search increasingly expensive. We present Visual RAG Toolkit, a practical system for scaling visual multi-vector retrieval with training-free, model-aware pooling and multi-stage retrieval. Motivated by Matryoshka Embeddings, our method performs static spatial pooling - including a lightweight sliding-window averaging variant - over patch embeddings to produce compact tile-level and global representations for fast candidate generation, followed by exact MaxSim reranking using full multi-vector embeddings.
  Our design yields a quadratic reduction in vector-to-vector comparisons by reducing stored vectors per page from thousands to dozens, notably without requiring post-training, adapters, or distillation. Across experiments with interaction-style models such as ColPali and ColSmol-500M, we observe that over the limited ViDoRe v2 benchmark corpus 2-stage retrieval typically preserves NDCG and Recall @ 5/10 with minimal degradation, while substantially improving throughput (approximately 4x QPS); with sensitivity mainly at very large k. The toolkit additionally provides robust preprocessing - high resolution PDF to image conversion, optional margin/empty-region cropping and token hygiene (indexing only visual tokens) - and a reproducible evaluation pipeline, enabling rapid exploration of two-, three-, and cascaded retrieval variants. By emphasizing efficiency at common cutoffs (e.g., k <= 10), the toolkit lowers hardware barriers and makes state-of-the-art visual retrieval more accessible in practice.

</details>


### [5] [DiffuRank: Effective Document Reranking with Diffusion Language Models](https://arxiv.org/abs/2602.12528)
*Qi Liu,Kun Ai,Jiaxin Mao,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Fengbin Zhu,Ji-Rong Wen*

Main category: cs.IR

TL;DR: DiffuRank：基于扩散语言模型的文档重排框架，通过并行解码和灵活生成顺序解决自回归模型效率低、错误传播的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的文档重排方法主要依赖自回归生成，存在token-by-token解码延迟高、固定从左到右生成顺序导致早期错误传播且难以修正的问题，需要更高效灵活的重排方案

Method: 提出DiffuRank框架，基于扩散语言模型(dLLMs)探索三种重排策略：1)点式方法评估单个查询-文档对相关性；2)基于logit的列表方法联合评估多个文档相关性；3)基于排列的列表方法适配dLLMs标准解码过程到重排任务，并为每种方法设计相应训练方法

Result: 在多个基准测试中，dLLMs在零样本和微调重排性能上达到与相似规模自回归LLMs相当甚至更好的表现，证明了扩散语言模型作为自回归架构替代方案的潜力

Conclusion: 扩散语言模型为文档重排提供了有前景的替代方案，支持更灵活的生成顺序和并行解码，在效率和可控性方面具有优势，未来可进一步探索其在信息检索任务中的应用

Abstract: Recent advances in large language models (LLMs) have inspired new paradigms for document reranking. While this paradigm better exploits the reasoning and contextual understanding capabilities of LLMs, most existing LLM-based rerankers rely on autoregressive generation, which limits their efficiency and flexibility. In particular, token-by-token decoding incurs high latency, while the fixed left-to-right generation order causes early prediction errors to propagate and is difficult to revise. To address these limitations, we explore the use of diffusion language models (dLLMs) for document reranking and propose DiffuRank, a reranking framework built upon dLLMs. Unlike autoregressive models, dLLMs support more flexible decoding and generation processes that are not constrained to a left-to-right order, and enable parallel decoding, which may lead to improved efficiency and controllability. Specifically, we investigate three reranking strategies based on dLLMs: (1) a pointwise approach that uses dLLMs to estimate the relevance of each query-document pair; (2) a logit-based listwise approach that prompts dLLMs to jointly assess the relevance of multiple documents and derives ranking lists directly from model logits; and (3) a permutation-based listwise approach that adapts the canonical decoding process of dLLMs to the reranking tasks. For each approach, we design corresponding training methods to fully exploit the advantages of dLLMs. We evaluate both zero-shot and fine-tuned reranking performance on multiple benchmarks. Experimental results show that dLLMs achieve performance comparable to, and in some cases exceeding, that of autoregressive LLMs with similar model sizes. These findings demonstrate the promise of diffusion-based language models as a compelling alternative to autoregressive architectures for document reranking.

</details>


### [6] [Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation](https://arxiv.org/abs/2602.12530)
*Kehan Zheng,Deyao Hong,Qian Li,Jun Zhang,Huan Yu,Jie Jiang,Hongning Wang*

Main category: cs.IR

TL;DR: 提出Reasoning to Rank框架，通过强化学习端到端训练LLM，将推荐效用优化内化到逐步推理过程中，提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统需要深入推理用户偏好，而不仅仅是模式匹配。虽然已有研究开始利用LLM进行推荐，但如何有效优化模型以提升推荐效用仍待探索

Method: 提出Reasoning to Rank端到端训练框架，在用户-物品级别进行推理，使用强化学习端到端训练LLM，将推荐效用优化内化到逐步推理学习中

Result: 在三个Amazon数据集和一个大规模工业数据集上实验，相比传统方法和基于LLM的解决方案均取得一致提升

Conclusion: 通过深入分析验证了框架关键组件的必要性，为这一研究方向未来发展提供了启示

Abstract: Recommender systems are tasked to infer users' evolving preferences and rank items aligned with their intents, which calls for in-depth reasoning beyond pattern-based scoring. Recent efforts start to leverage large language models (LLMs) for recommendation, but how to effectively optimize the model for improved recommendation utility is still under explored. In this work, we propose Reasoning to Rank, an end-to-end training framework that internalizes recommendation utility optimization into the learning of step-by-step reasoning in LLMs. To avoid position bias in LLM reasoning and enable direct optimization of the reasoning process, our framework performs reasoning at the user-item level and employs reinforcement learning for end-to-end training of the LLM. Experiments on three Amazon datasets and a large-scale industrial dataset showed consistent gains over strong conventional and LLM-based solutions. Extensive in-depth analyses validate the necessity of the key components in the proposed framework and shed lights on the future developments of this line of work.

</details>


### [7] [CAPTS: Channel-Aware, Preference-Aligned Trigger Selection for Multi-Channel Item-to-Item Retrieval](https://arxiv.org/abs/2602.12564)
*Xiaoyou Zhou,Yuqi Liu,Zhao Liu,Xiao Lv,Bo Chen,Ruiming Tang,Guorui Zhou*

Main category: cs.IR

TL;DR: 提出CAPTS框架解决多通道检索中的触发选择问题，通过价值归因模块和通道自适应触发路由模块，协调多通道触发分配，提升推荐系统性能。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统中多通道检索存在两个主要问题：1）价值归因偏差，仅基于触发本身的反馈而非其作为检索种子的下游效用来评估触发；2）多通道路由不协调，各通道在共享配额下独立选择触发，导致跨通道重叠。

Method: 提出CAPTS框架，包含两个核心模块：价值归因模块（VAM）通过前瞻性监督，将每个触发与后续在I2I通道上检索到的项目产生的参与度关联；通道自适应触发路由（CATR）模块协调触发到通道的分配，最大化多通道检索的整体价值。

Result: 在快手国际短视频平台Kwai上进行的大规模离线实验和在线A/B测试表明，CAPTS持续提升多通道召回率，在线测试中平均每设备使用时间提升+0.351%。

Conclusion: CAPTS框架有效解决了多通道触发选择中的价值归因偏差和路由协调问题，通过统一的学习路由方法显著提升了工业推荐系统的性能。

Abstract: Large-scale industrial recommender systems commonly adopt multi-channel retrieval for candidate generation, combining direct user-to-item (U2I) retrieval with two-hop user-to-item-to-item (U2I2I) pipelines. In U2I2I, the system selects a small set of historical interactions as triggers to seed downstream item-to-item (I2I) retrieval across multiple channels. In production, triggers are often selected using rule-based policies or learned scorers and tuned in a channel-by-channel manner. However, these practices face two persistent challenges: biased value attribution that values triggers by on-trigger feedback rather than their downstream utility as retrieval seeds, and uncoordinated multi-channel routing where channels select triggers independently under a shared quota, increasing cross-channel overlap. To address these challenges, we propose Channel-Aware, Preference-Aligned Trigger Selection (CAPTS), a unified and flexible framework that treats multi-channel trigger selection as a learnable routing problem. CAPTS introduces a Value Attribution Module (VAM) that provides look-ahead supervision by crediting each trigger with the subsequent engagement generated by items retrieved from it on each I2I channel, and a Channel-Adaptive Trigger Routing (CATR) module that coordinates trigger-to-channel assignment to maximize the overall value of multi-channel retrieval. Extensive offline experiments and large-scale online A/B tests on Kwai, Kuaishou's international short-video platform, show that CAPTS consistently improves multi-channel recall offline and delivers a +0.351% lift in average time spent per device online.

</details>


### [8] [RQ-GMM: Residual Quantized Gaussian Mixture Model for Multimodal Semantic Discretization in CTR Prediction](https://arxiv.org/abs/2602.12593)
*Ziye Tong,Jiahao Liu,Weimin Zhang,Hongji Ruan,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: 提出RQ-GMM方法，通过高斯混合模型与残差量化，将多模态嵌入离散化为语义ID，用于CTR预测，显著提升广告价值


<details>
  <summary>Details</summary>
Motivation: 多模态内容对CTR预测至关重要，但直接将预训练模型的连续嵌入用于CTR模型效果不佳，因为优化目标和收敛速度不一致。现有离散化方法存在码本利用率低、重建精度差、语义区分度不足等问题

Method: 提出RQ-GMM（残差量化高斯混合模型），引入概率建模来更好地捕捉多模态嵌入空间的统计结构。通过高斯混合模型结合残差量化，实现更优的码本利用率和重建精度

Result: 在公开数据集和大型短视频平台的在线A/B测试中，RQ-GMM相比强基线带来1.502%的广告价值提升。该方法已全面部署，为数亿用户提供每日推荐服务

Conclusion: RQ-GMM通过概率建模和残差量化有效解决了多模态嵌入离散化问题，显著提升了CTR预测性能，已在实际大规模系统中成功应用

Abstract: Multimodal content is crucial for click-through rate (CTR) prediction. However, directly incorporating continuous embeddings from pre-trained models into CTR models yields suboptimal results due to misaligned optimization objectives and convergence speed inconsistency during joint training. Discretizing embeddings into semantic IDs before feeding them into CTR models offers a more effective solution, yet existing methods suffer from limited codebook utilization, reconstruction accuracy, and semantic discriminability. We propose RQ-GMM (Residual Quantized Gaussian Mixture Model), which introduces probabilistic modeling to better capture the statistical structure of multimodal embedding spaces. Through Gaussian Mixture Models combined with residual quantization, RQ-GMM achieves superior codebook utilization and reconstruction accuracy. Experiments on public datasets and online A/B tests on a large-scale short-video platform serving hundreds of millions of users demonstrate substantial improvements: RQ-GMM yields a 1.502% gain in Advertiser Value over strong baselines. The method has been fully deployed, serving daily recommendations for hundreds of millions of users.

</details>


### [9] [Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback](https://arxiv.org/abs/2602.12612)
*Sein Kim,Sangwu Park,Hongseok Kang,Wonjoong Kim,Jimin Seo,Yeonjun In,Kanghoon Yoon,Chanyoung Park*

Main category: cs.IR

TL;DR: Self-EvolveRec：一个通过用户模拟器和模型诊断工具建立定向反馈循环的推荐系统自动设计框架，解决了传统方法依赖固定搜索空间和标量指标的问题。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统自动化设计方法（如NAS）受限于人工先验定义的固定搜索空间，而最近的LLM驱动代码演化框架虽然转向开放式程序空间，但主要依赖NDCG、Hit Ratio等标量指标，这些指标无法提供模型失败的定性洞察或改进的方向性指导。

Method: 提出Self-EvolveRec框架，通过集成用户模拟器（提供定性批评）和模型诊断工具（进行定量内部验证）建立定向反馈循环。同时引入诊断工具-模型协同演化策略，确保评估标准随着推荐架构的演化而动态适应。

Result: 大量实验表明，Self-EvolveRec在推荐性能和用户满意度方面显著优于最先进的NAS和LLM驱动代码演化基线方法。

Conclusion: Self-EvolveRec通过建立定向反馈循环和动态适应的评估标准，有效解决了传统推荐系统自动化设计方法的局限性，在性能和用户满意度方面取得了显著提升。

Abstract: Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec.

</details>


### [10] [Training Dense Retrievers with Multiple Positive Passages](https://arxiv.org/abs/2602.12727)
*Benben Wang,Minghao Tang,Hengran Zhang,Jiafeng Guo,Keping Bi*

Main category: cs.IR

TL;DR: 本文系统研究了检索器训练中的多正样本优化目标，发现Log-Sum-Exp Pairwise (LSEPair)损失在不同设置下表现最稳健，而JointLH和SumMargLH对正样本质量敏感。


<details>
  <summary>Details</summary>
Motivation: 知识密集型系统（如RAG）依赖检索器性能，但传统训练受限于稀疏的单正样本标注，导致假阴性噪声和次优监督。LLMs使得大规模收集密集多正样本标注成为可能，但如何有效利用这些密集信号进行训练尚不明确。

Method: 将代表性优化目标（JointLH、SumMargLH、LSEPair）统一到对比学习框架下，进行理论分析揭示其梯度行为差异，并在Natural Questions、MS MARCO和BEIR基准上进行实证评估，涵盖同质LLM标注数据和异质混合标注两种现实场景。

Result: LSEPair在不同设置下始终表现出优越的稳健性和性能，而JointLH和SumMargLH对正样本质量高度敏感。随机采样策略(Rand1LH)可作为可靠基线。研究为利用密集LLM增强监督提升检索器效果提供了实用设计原则。

Conclusion: 通过理论洞察与实证发现的对齐，本文为利用密集、LLM增强的监督来提升检索器效果提供了实用的设计原则，特别推荐LSEPair作为稳健的多正样本优化目标。

Abstract: Modern knowledge-intensive systems, such as retrieval-augmented generation (RAG), rely on effective retrievers to establish the performance ceiling for downstream modules. However, retriever training has been bottlenecked by sparse, single-positive annotations, which lead to false-negative noise and suboptimal supervision. While the advent of large language models (LLMs) makes it feasible to collect comprehensive multi-positive relevance labels at scale, the optimal strategy for incorporating these dense signals into training remains poorly understood. In this paper, we present a systematic study of multi-positive optimization objectives for retriever training. We unify representative objectives, including Joint Likelihood (JointLH), Summed Marginal Likelihood (SumMargLH), and Log-Sum-Exp Pairwise (LSEPair) loss, under a shared contrastive learning framework. Our theoretical analysis characterizes their distinct gradient behaviors, revealing how each allocates probability mass across positive document sets. Empirically, we conduct extensive evaluations on Natural Questions, MS MARCO, and the BEIR benchmark across two realistic regimes: homogeneous LLM-annotated data and heterogeneous mixtures of human and LLM labels. Our results show that LSEPair consistently achieves superior robustness and performance across settings, while JointLH and SumMargLH exhibit high sensitivity to the quality of positives. Furthermore, we find that the simple strategy of random sampling (Rand1LH) serves as a reliable baseline. By aligning theoretical insights with empirical findings, we provide practical design principles for leveraging dense, LLM-augmented supervision to enhance retriever effectiveness.

</details>


### [11] [SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise](https://arxiv.org/abs/2602.12783)
*Yuejie Li,Ke Yang,Yueying Hua,Berlin Chen,Jianhao Nie,Yueping He,Caixin Kang*

Main category: cs.IR

TL;DR: SQuTR是一个用于口语查询检索的鲁棒性基准测试，包含大规模数据集和统一评估协议，用于评估系统在复杂声学扰动下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有口语查询检索评估数据集通常局限于简单查询和受限噪声条件，无法充分评估系统在复杂声学扰动下的鲁棒性。

Method: 从六个常用英文和中文文本检索数据集中聚合37,317个独特查询，使用200个真实说话者的语音配置文件合成语音，并在可控信噪比下混合17类真实环境噪声。

Result: 检索性能随噪声增加而下降，不同系统下降幅度差异显著，即使大规模检索模型在极端噪声下也表现不佳，表明鲁棒性仍是关键瓶颈。

Conclusion: SQuTR为口语查询到文本检索的鲁棒性研究提供了可复现的测试平台和诊断分析工具，有助于推动该领域的未来发展。

Abstract: Spoken query retrieval is an important interaction mode in modern information retrieval. However, existing evaluation datasets are often limited to simple queries under constrained noise conditions, making them inadequate for assessing the robustness of spoken query retrieval systems under complex acoustic perturbations. To address this limitation, we present SQuTR, a robustness benchmark for spoken query retrieval that includes a large-scale dataset and a unified evaluation protocol. SQuTR aggregates 37,317 unique queries from six commonly used English and Chinese text retrieval datasets, spanning multiple domains and diverse query types. We synthesize speech using voice profiles from 200 real speakers and mix 17 categories of real-world environmental noise under controlled SNR levels, enabling reproducible robustness evaluation from quiet to highly noisy conditions. Under the unified protocol, we conduct large-scale evaluations on representative cascaded and end-to-end retrieval systems. Experimental results show that retrieval performance decreases as noise increases, with substantially different drops across systems. Even large-scale retrieval models struggle under extreme noise, indicating that robustness remains a critical bottleneck. Overall, SQuTR provides a reproducible testbed for benchmarking and diagnostic analysis, and facilitates future research on robustness in spoken query to text retrieval.

</details>


### [12] [WISE: A Multimodal Search Engine for Visual Scenes, Audio, Objects, Faces, Speech, and Metadata](https://arxiv.org/abs/2602.12819)
*Prasanna Sridhar,Horace Lee,David M. S. Pinto,Andrew Zisserman,Abhishek Dutta*

Main category: cs.IR

TL;DR: WISE是一个开源的多模态视听搜索引擎，集成了多种检索功能，支持自然语言、图像、人脸、音频等多种查询方式，采用向量搜索技术，可扩展至百万级图像和千小时视频的检索。


<details>
  <summary>Details</summary>
Motivation: 当前需要一种实用的多模态检索工具，能够整合多种检索能力（图像、视频、音频、人脸、语音转录等），同时让非机器学习专家也能使用，并支持本地部署以处理敏感数据。

Method: 采用向量搜索技术实现高效检索，支持场景级和对象级的自然语言和反向图像查询、人脸识别搜索、音频事件检索、语音转录搜索以及元数据过滤。采用模块化架构便于集成新模型。

Result: WISE能够扩展到支持数百万图像或数千小时视频的高效检索，已应用于多个实际用例，支持本地部署处理私有或敏感数据集合。

Conclusion: WISE提供了一个功能全面、实用且可扩展的开源多模态搜索引擎，使非专家用户也能进行复杂的跨模态检索，填补了现有工具的空白。

Abstract: In this paper, we present WISE, an open-source audiovisual search engine which integrates a range of multimodal retrieval capabilities into a single, practical tool accessible to users without machine learning expertise. WISE supports natural-language and reverse-image queries at both the scene level (e.g. empty street) and object level (e.g. horse) across images and videos; face-based search for specific individuals; audio retrieval of acoustic events using text (e.g. wood creak) or an audio file; search over automatically transcribed speech; and filtering by user-provided metadata. Rich insights can be obtained by combining queries across modalities -- for example, retrieving German trains from a historical archive by applying the object query "train" and the metadata query "Germany", or searching for a face in a place. By employing vector search techniques, WISE can scale to support efficient retrieval over millions of images or thousands of hours of video. Its modular architecture facilitates the integration of new models. WISE can be deployed locally for private or sensitive collections, and has been applied to various real-world use cases. Our code is open-source and available at https://gitlab.com/vgg/wise/wise.

</details>


### [13] [JARVIS: An Evidence-Grounded Retrieval System for Interpretable Deceptive Reviews Adjudication](https://arxiv.org/abs/2602.12941)
*Nan Lu,Leyang Li,Yurong Hu,Rui Lin,Shaoyi Xu*

Main category: cs.IR

TL;DR: JARVIS是一个用于检测欺骗性评论的框架，通过增强检索和证据图结构进行判断，提高检测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有欺骗性评论检测方法存在两个关键限制：泛化能力不足和缺乏可解释性。在电商生态系统中，欺骗性评论仍然是重要的治理挑战。

Method: 提出JARVIS框架：1) 从待评估评论出发，通过混合稠密-稀疏多模态检索获取语义相似证据；2) 通过共享实体扩展关系信号，构建异构证据图；3) 使用大语言模型进行基于证据的裁决，生成可解释的风险评估。

Result: 离线实验中，在构建的评论数据集上，精确率从0.953提升到0.988，召回率从0.830提升到0.901。生产环境中，召回量增加27%，人工检查时间减少75%，模型生成分析的采纳率达到96.4%。

Conclusion: JARVIS框架通过增强检索和证据图结构，有效解决了欺骗性评论检测中的泛化能力和可解释性问题，在实际应用中表现出显著效果。

Abstract: Deceptive reviews, refer to fabricated feedback designed to artificially manipulate the perceived quality of products. Within modern e-commerce ecosystems, these reviews remain a critical governance challenge. Despite advances in review-level and graph-based detection methods, two pivotal limitations remain: inadequate generalization and lack of interpretability. To address these challenges, we propose JARVIS, a framework providing Judgment via Augmented Retrieval and eVIdence graph Structures. Starting from the review to be evaluated, it retrieves semantically similar evidence via hybrid dense-sparse multimodal retrieval, expands relational signals through shared entities, and constructs a heterogeneous evidence graph. Large language model then performs evidence-grounded adjudication to produce interpretable risk assessments. Offline experiments demonstrate that JARVIS enhances performance on our constructed review dataset, achieving a precision increase from 0.953 to 0.988 and a recall boost from 0.830 to 0.901. In the production environment, our framework achieves a 27% increase in the recall volume and reduces manual inspection time by 75%. Furthermore, the adoption rate of the model-generated analysis reaches 96.4%.

</details>


### [14] [RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems](https://arxiv.org/abs/2602.12968)
*Junhua Liu,Yang Jihao,Cheng Chang,Kunrong LI,Bin Fu,Kwan Hui Lim*

Main category: cs.IR

TL;DR: RGAlign-Rec：一个用于电商聊天机器人主动意图预测的闭环对齐框架，通过LLM语义推理器与查询增强排序模型的集成，以及基于排序信号的多阶段训练，解决了语义鸿沟和目标错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有工业系统面临两个基本挑战：1）离散用户特征与聊天机器人知识库中语义意图之间的语义鸿沟；2）通用LLM输出与任务特定排序效用之间的目标错位。需要一种方法将语义推理与排序目标对齐。

Method: 提出RGAlign-Rec框架，包含LLM语义推理器和查询增强排序模型。引入排序引导对齐（RGA）多阶段训练范式，利用下游排序信号作为反馈来优化LLM的潜在推理。

Result: 在Shopee大规模工业数据集上，RGAlign-Rec实现了0.12%的GAUC增益，错误率相对降低3.52%，Recall@3提高0.56%。在线A/B测试显示查询增强模型带来0.98%的CTR提升，排序引导对齐阶段额外贡献0.13%增益。

Conclusion: 排序感知对齐有效同步了语义推理与排序目标，显著提升了现实世界主动推荐系统的预测准确性和服务质量。该框架为解决工业推荐系统中的语义鸿沟和目标错位问题提供了有效方案。

Abstract: Proactive intent prediction is a critical capability in modern e-commerce chatbots, enabling "zero-query" recommendations by anticipating user needs from behavioral and contextual signals. However, existing industrial systems face two fundamental challenges: (1) the semantic gap between discrete user features and the semantic intents within the chatbot's Knowledge Base, and (2) the objective misalignment between general-purpose LLM outputs and task-specific ranking utilities. To address these issues, we propose RGAlign-Rec, a closed-loop alignment framework that integrates an LLM-based semantic reasoner with a Query-Enhanced (QE) ranking model. We also introduce Ranking-Guided Alignment (RGA), a multi-stage training paradigm that utilizes downstream ranking signals as feedback to refine the LLM's latent reasoning. Extensive experiments on a large-scale industrial dataset from Shopee demonstrate that RGAlign-Rec achieves a 0.12% gain in GAUC, leading to a significant 3.52% relative reduction in error rate, and a 0.56% improvement in Recall@3. Online A/B testing further validates the cumulative effectiveness of our framework: the Query-Enhanced model (QE-Rec) initially yields a 0.98% improvement in CTR, while the subsequent Ranking-Guided Alignment stage contributes an additional 0.13% gain. These results indicate that ranking-aware alignment effectively synchronizes semantic reasoning with ranking objectives, significantly enhancing both prediction accuracy and service quality in real-world proactive recommendation systems.

</details>


### [15] [Awakening Dormant Users: Generative Recommendation with Counterfactual Functional Role Reasoning](https://arxiv.org/abs/2602.13134)
*Huishi Luo,Shuokai Li,Hanchen Yang,Zhongbo Sun,Haojie Ding,Boheng Zhang,Zijia Cai,Renliang Qian,Fan Yang,Tingting Gao,Chenyi Lei,Wenwu Ou,Fuzhen Zhuang*

Main category: cs.IR

TL;DR: RoleGen是一个唤醒电商平台休眠用户的框架，通过建模商品在转化路径中的功能性角色，结合LLM推理器和生成式行为骨干网络，显著提升召回率和订单量。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只估计商品的固有价值（如即时点击概率），忽略了商品的工具性效应——特定交互可以触发潜在意图并推动后续转化决策。对于保持参与但转化率低的休眠用户，这种单步估计方法效果不佳。

Method: 提出RoleGen框架：1) 基于LLM的转化轨迹推理器，显式建模商品的情境依赖性功能角色，重构意图演化，并使用反事实推理模拟多样化转化路径；2) 生成式行为骨干网络，通过"推理-执行-反馈-反思"闭环策略优化执行。

Result: 在快手电商平台的离线实验和在线A/B测试中，RoleGen实现了Recall@1提升6.2%，在线订单量增加7.3%，有效激活了休眠用户群体。

Conclusion: RoleGen通过建模商品在转化轨迹中的功能性角色，结合LLM推理和生成式学习，能够有效唤醒电商平台的休眠用户，显著提升转化效果。

Abstract: Awakening dormant users, who remain engaged but exhibit low conversion, is a pivotal driver for incremental GMV growth in large-scale e-commerce platforms. However, existing approaches often yield suboptimal results since they typically rely on single-step estimation of an item's intrinsic value (e.g., immediate click probability). This mechanism overlooks the instrumental effect of items, where specific interactions act as triggers to shape latent intent and drive subsequent decisions along a conversion trajectory. To bridge this gap, we propose RoleGen, a novel framework that synergizes a Conversion Trajectory Reasoner with a Generative Behavioral Backbone. Specifically, the LLM-based Reasoner explicitly models the context-dependent Functional Role of items to reconstruct intent evolution. It further employs counterfactual inference to simulate diverse conversion paths, effectively mitigating interest collapse. These reasoned candidate items are integrated into the generative backbone, which is optimized via a collaborative "Reasoning-Execution-Feedback-Reflection" closed-loop strategy to ensure grounded execution. Extensive offline experiments and online A/B testing on the Kuaishou e-commerce platform demonstrate that RoleGen achieves a 6.2% gain in Recall@1 and a 7.3% increase in online order volume, confirming its effectiveness in activating the dormant user base.

</details>


### [16] [Asynchronous Verified Semantic Caching for Tiered LLM Architectures](https://arxiv.org/abs/2602.13165)
*Asmit Kumar Singh,Haozhe Wang,Laxmi Naga Santosh Attaluri,Tak Chiam,Weihua Zhu*

Main category: cs.IR

TL;DR: Krites是一种异步LLM判断的语义缓存策略，通过LLM验证低于静态阈值的缓存匹配，将验证通过的响应提升到动态缓存中，在不改变关键路径延迟的情况下显著提高静态缓存的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 当前生产部署中的语义缓存采用静态-动态分层设计，但通常使用单一的嵌入相似度阈值，导致保守阈值会错过安全重用机会，而激进阈值则可能提供语义错误的响应。

Method: Krites在关键路径上保持标准静态阈值策略。当提示的最邻近静态邻居略低于静态阈值时，异步调用LLM判断器来验证静态响应是否适用于新提示。验证通过的匹配会被提升到动态缓存中。

Result: 在对话和搜索工作负载的跟踪驱动模拟中，Krites将使用精选静态答案（直接静态命中加验证提升）服务的请求比例提高了最多3.9倍，同时关键路径延迟保持不变。

Conclusion: Krites通过LLM判断的异步验证机制，在不影响服务延迟的情况下显著扩展了静态缓存的覆盖范围，解决了传统单一阈值策略的权衡问题。

Abstract: Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.

</details>


### [17] [Fix Before Search: Benchmarking Agentic Query Visual Pre-processing in Multimodal Retrieval-augmented Generation](https://arxiv.org/abs/2602.13179)
*Jiankun Zhang,Shenglai Zeng,Kai Guo,Xinnan Dai,Hui Liu,Jiliang Tang,Yi Chang*

Main category: cs.IR

TL;DR: 提出了首个视觉查询预处理基准V-QPP-Bench，用于评估多模态检索增强生成系统中视觉查询缺陷的修复效果，发现视觉缺陷会严重降低检索性能，而经过专门训练的紧凑模型可以达到与大型专有模型相当的效果。


<details>
  <summary>Details</summary>
Motivation: 现有MRAG系统大多将视觉输入视为静态且无噪声的，但现实中的视觉查询常存在几何扭曲、质量下降或语义模糊等缺陷，导致检索失败。目前缺乏专门评估视觉查询预处理效果的基准。

Method: 将V-QPP定义为智能体决策任务，让MLLMs自主诊断视觉缺陷并部署感知工具来优化查询。构建包含46,700个有缺陷查询的基准，涵盖多种MRAG范式，评估不同预处理方法的效果。

Result: 发现三个关键结论：1）视觉缺陷会严重降低检索召回率和端到端MRAG性能；2）理想预处理可恢复接近完美的性能，但现成MLLMs在工具选择和参数预测方面表现不佳；3）监督微调可使紧凑模型达到与大型专有模型相当或更好的性能。

Conclusion: V-QPP-Bench是首个全面的视觉查询预处理基准，揭示了视觉缺陷对MRAG系统的严重影响，并证明了专门训练可以显著提升预处理效果，为开发鲁棒的MRAG系统提供了重要参考。

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a key paradigm for grounding MLLMs with external knowledge. While query pre-processing (e.g., rewriting) is standard in text-based RAG, existing MRAG pipelines predominantly treat visual inputs as static and immutable, implicitly assuming they are noise-free. However, real-world visual queries are often ``imperfect'' -- suffering from geometric distortions, quality degradation, or semantic ambiguity -- leading to catastrophic retrieval failures. To address this gap, we propose V-QPP-Bench, the first comprehensive benchmark dedicated to Visual Query Pre-processing (V-QPP). We formulate V-QPP as an agentic decision-making task where MLLMs must autonomously diagnose imperfections and deploy perceptual tools to refine queries. Our extensive evaluation across 46,700 imperfect queries and diverse MRAG paradigms reveals three critical insights: (1) Vulnerability -- visual imperfections severely degrade both retrieval recall and end-to-end MRAG performance; (2) Restoration Potential \& Bottleneck -- while oracle preprocessing recovers near-perfect performance, off-the-shelf MLLMs struggle with tool selection and parameter prediction without specialized training; and (3) Training Enhancement -- supervised fine-tuning enables compact models to achieve comparable or superior performance to larger proprietary models, demonstrating the benchmark's value for developing robust MRAG systems The code is available at https://github.com/phycholosogy/VQQP_Bench

</details>
