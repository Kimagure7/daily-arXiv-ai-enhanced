<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 3]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [STARS: Semantic Tokens with Augmented Representations for Recommendation at Scale](https://arxiv.org/abs/2512.10149)
*Han Chen,Steven Zhu,Yingrui Li*

Main category: cs.IR

TL;DR: STARS是一个为大规模、低延迟电商场景设计的Transformer序列推荐框架，通过双记忆用户嵌入、语义物品标记、上下文感知评分和延迟敏感的两阶段检索管道，在保持毫秒级响应时间的同时显著提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 解决电商推荐系统在冷启动产品、快速变化的用户意图、动态上下文（季节性、节假日、促销）等挑战下，仍需满足严格的毫秒级延迟约束的现实需求。

Method: 1. 双记忆用户嵌入：分离长期偏好和短期会话意图；2. 语义物品标记：融合预训练文本嵌入、可学习增量、LLM生成的属性标签；3. 上下文感知评分：学习日历和事件偏移；4. 延迟敏感的两阶段检索管道：离线嵌入生成和在线最大内积搜索。

Result: 离线评估中，STARS相比现有LambdaMART系统提升Hit@5超过75%；大规模A/B测试（600万次访问）显示显著提升：总订单+0.8%，首页加购+2.0%，用户访问次数+0.5%。

Conclusion: 结合语义增强、多意图建模和面向部署的设计，可以在不牺牲服务效率的情况下，在现实环境中实现最先进的推荐质量。

Abstract: Real-world ecommerce recommender systems must deliver relevant items under strict tens-of-milliseconds latency constraints despite challenges such as cold-start products, rapidly shifting user intent, and dynamic context including seasonality, holidays, and promotions. We introduce STARS, a transformer-based sequential recommendation framework built for large-scale, low-latency ecommerce settings. STARS combines several innovations: dual-memory user embeddings that separate long-term preferences from short-term session intent; semantic item tokens that fuse pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, strengthening content-based matching, long-tail coverage, and cold-start performance; context-aware scoring with learned calendar and event offsets; and a latency-conscious two-stage retrieval pipeline that performs offline embedding generation and online maximum inner-product search with filtering, enabling tens-of-milliseconds response times. In offline evaluations on production-scale data, STARS improves Hit@5 by more than 75 percent relative to our existing LambdaMART system. A large-scale A/B test on 6 million visits shows statistically significant lifts, including Total Orders +0.8%, Add-to-Cart on Home +2.0%, and Visits per User +0.5%. These results demonstrate that combining semantic enrichment, multi-intent modeling, and deployment-oriented design can yield state-of-the-art recommendation quality in real-world environments without sacrificing serving efficiency.

</details>


### [2] [The Best of the Two Worlds: Harmonizing Semantic and Hash IDs for Sequential Recommendation](https://arxiv.org/abs/2512.10388)
*Ziwei Liu,Yejing Wang,Qidong Liu,Zijian Zhang,Chong Chen,Wei Huang,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 提出H2Rec框架，通过协调语义ID和哈希ID来解决序列推荐中头部和尾部物品的性能权衡问题


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐系统使用哈希ID存在长尾问题，而基于语义ID的方法又面临协作压倒现象，导致头部和尾部物品性能权衡

Method: 设计双分支建模架构，同时捕捉语义ID的多粒度语义和哈希ID的独特协作身份；引入双级对齐策略桥接两种表示

Result: 在三个真实数据集上的实验表明，H2Rec能有效平衡头部和尾部物品的推荐质量，并超越现有基线方法

Conclusion: H2Rec框架成功协调了语义ID和哈希ID，解决了序列推荐中头部和尾部物品的性能权衡问题

Abstract: Conventional Sequential Recommender Systems (SRS) typically assign unique Hash IDs (HID) to construct item embeddings. These HID embeddings effectively learn collaborative information from historical user-item interactions, making them vulnerable to situations where most items are rarely consumed (the long-tail problem). Recent methods that incorporate auxiliary information often suffer from noisy collaborative sharing caused by co-occurrence signals or semantic homogeneity caused by flat dense embeddings. Semantic IDs (SIDs), with their capability of code sharing and multi-granular semantic modeling, provide a promising alternative. However, the collaborative overwhelming phenomenon hinders the further development of SID-based methods. The quantization mechanisms commonly compromise the uniqueness of identifiers required for modeling head items, creating a performance seesaw between head and tail items. To address this dilemma, we propose \textbf{\name}, a novel framework that harmonizes the SID and HID. Specifically, we devise a dual-branch modeling architecture that enables the model to capture both the multi-granular semantics within SID while preserving the unique collaborative identity of HID. Furthermore, we introduce a dual-level alignment strategy that bridges the two representations, facilitating knowledge transfer and supporting robust preference modeling. Extensive experiments on three real-world datasets show that \name~ effectively balances recommendation quality for both head and tail items while surpassing the existing baselines. The implementation code can be found online\footnote{https://github.com/ziwliu8/H2Rec}.

</details>


### [3] [Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition](https://arxiv.org/abs/2512.10688)
*Lingfeng Liu,Yixin Song,Dazhong Shen,Bing Yin,Hao Li,Yanyong Zhang,Chao Wang*

Main category: cs.IR

TL;DR: 论文揭示了贝叶斯成对排序优化中的流行度偏差是几何结构问题，提出了方向分解与校正框架来从几何根源解耦偏好与流行度


<details>
  <summary>Details</summary>
Motivation: 流行度偏差严重损害了协同过滤模型的个性化能力，导致过度推荐热门项目而忽视用户对利基内容的真实偏好。现有方法将其视为外部混杂因素，但本文发现这是BPR优化中的内在几何伪影

Method: 提出方向分解与校正框架，通过非对称方向更新来纠正嵌入几何。该框架引导正向交互沿个性化偏好方向，同时使负向交互远离全局流行度方向，从几何源头解耦偏好与流行度

Result: 在多个基于BPR的架构上进行广泛实验，DDC显著优于最先进的去偏方法，将训练损失降低到强基线方法的5%以下，同时实现更好的推荐质量和公平性

Conclusion: 流行度偏差是BPR优化中的内在几何问题，通过方向分解与校正框架可以从几何根源有效解决这一问题，显著提升推荐系统的去偏效果

Abstract: Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant "popularity direction" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.

</details>
