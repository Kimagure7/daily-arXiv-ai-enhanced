{"id": "2601.17057", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17057", "abs": "https://arxiv.org/abs/2601.17057", "authors": ["Zhikai Wang", "Weihua Zhang"], "title": "Frequency-aware Adaptive Contrastive Learning for Sequential Recommendation", "comment": "10 pages, 6 figures", "summary": "In this paper, we revisited the role of data augmentation in contrastive learning for sequential recommendation, revealing its inherent bias against low-frequency items and sparse user behaviors. To address this limitation, we proposed FACL, a frequency-aware adaptive contrastive learning framework that introduces micro-level adaptive perturbation to protect the integrity of rare items, as well as macro-level reweighting to amplify the influence of sparse and rare-interaction sequences during training. Comprehensive experiments on five public benchmark datasets demonstrated that FACL consistently outperforms state-of-the-art data augmentation and model augmentation-based methods, achieving up to 3.8% improvement in recommendation accuracy. Moreover, fine-grained analyses confirm that FACL significantly alleviates the performance drop on low-frequency items and users, highlighting its robust intent-preserving ability and its superior applicability to real-world, long-tail recommendation scenarios.", "AI": {"tldr": "FACL\u6846\u67b6\u901a\u8fc7\u9891\u7387\u611f\u77e5\u7684\u81ea\u9002\u5e94\u5bf9\u6bd4\u5b66\u4e60\uff0c\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u6570\u636e\u589e\u5f3a\u5bf9\u4f4e\u9891\u7269\u54c1\u548c\u7a00\u758f\u7528\u6237\u884c\u4e3a\u7684\u504f\u89c1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u548c\u957f\u5c3e\u573a\u666f\u9002\u7528\u6027\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u5bf9\u6bd4\u5b66\u4e60\u6570\u636e\u589e\u5f3a\u5b58\u5728\u56fa\u6709\u504f\u89c1\uff0c\u4f1a\u635f\u5bb3\u4f4e\u9891\u7269\u54c1\u548c\u7a00\u758f\u7528\u6237\u884c\u4e3a\u7684\u5b8c\u6574\u6027\uff0c\u5bfc\u81f4\u63a8\u8350\u7cfb\u7edf\u5728\u957f\u5c3e\u573a\u666f\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faFACL\u6846\u67b6\uff1a1\uff09\u5fae\u89c2\u5c42\u9762\u7684\u81ea\u9002\u5e94\u6270\u52a8\u4fdd\u62a4\u7a00\u6709\u7269\u54c1\u5b8c\u6574\u6027\uff1b2\uff09\u5b8f\u89c2\u5c42\u9762\u7684\u91cd\u52a0\u6743\u653e\u5927\u7a00\u758f\u548c\u7a00\u6709\u4ea4\u4e92\u5e8f\u5217\u5728\u8bad\u7ec3\u4e2d\u7684\u5f71\u54cd\u529b\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cFACL\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6570\u636e\u589e\u5f3a\u548c\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\uff0c\u63a8\u8350\u51c6\u786e\u6027\u63d0\u5347\u6700\u9ad8\u8fbe3.8%\uff0c\u663e\u8457\u7f13\u89e3\u4f4e\u9891\u7269\u54c1\u548c\u7528\u6237\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "FACL\u6846\u67b6\u5177\u6709\u5f3a\u5927\u7684\u610f\u56fe\u4fdd\u6301\u80fd\u529b\u548c\u5bf9\u73b0\u5b9e\u4e16\u754c\u957f\u5c3e\u63a8\u8350\u573a\u666f\u7684\u4f18\u8d8a\u9002\u7528\u6027\uff0c\u4e3a\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u9891\u7387\u504f\u89c1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.17218", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17218", "abs": "https://arxiv.org/abs/2601.17218", "authors": ["Zihan Huang", "Rohan Surana", "Zhouhang Xie", "Junda Wu", "Yu Xia", "Julian McAuley"], "title": "Evaluation on Entity Matching in Recommender Systems", "comment": null, "summary": "Entity matching is a crucial component in various recommender systems, including conversational recommender systems (CRS) and knowledge-based recommender systems. However, the lack of rigorous evaluation frameworks for cross-dataset entity matching impedes progress in areas such as LLM-driven conversational recommendations and knowledge-grounded dataset construction.\n  In this paper, we introduce Reddit-Amazon-EM, a novel dataset comprising naturally occurring items from Reddit and the Amazon '23 dataset. Through careful manual annotation, we identify corresponding movies across Reddit-Movies and Amazon'23, two existing recommender system datasets with inherently overlapping catalogs. Leveraging Reddit-Amazon-EM, we conduct a comprehensive evaluation of state-of-the-art entity matching methods, including rule-based, graph-based, lexical-based, embedding-based, and LLM-based approaches.\n  For reproducible research, we release our manually annotated entity matching gold set and provide the mapping between the two datasets using the best-performing method from our experiments. This serves as a valuable resource for advancing future work on entity matching in recommender systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Reddit-Amazon-EM\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8de8\u6570\u636e\u96c6\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u4e25\u683c\u8bc4\u4f30\u6846\u67b6\u7684\u7a7a\u767d\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7528\u4e8e\u8de8\u6570\u636e\u96c6\u5b9e\u4f53\u5339\u914d\u7684\u4e25\u683c\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd9\u963b\u788d\u4e86LLM\u9a71\u52a8\u7684\u5bf9\u8bdd\u63a8\u8350\u548c\u77e5\u8bc6\u57fa\u7840\u6570\u636e\u96c6\u6784\u5efa\u7b49\u9886\u57df\u7684\u8fdb\u5c55\u3002\u7279\u522b\u662f\u5728\u63a8\u8350\u7cfb\u7edf\uff08\u5982\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u548c\u57fa\u4e8e\u77e5\u8bc6\u7684\u63a8\u8350\u7cfb\u7edf\uff09\u4e2d\uff0c\u5b9e\u4f53\u5339\u914d\u662f\u91cd\u8981\u7ec4\u4ef6\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "1. \u6784\u5efaReddit-Amazon-EM\u6570\u636e\u96c6\uff1a\u5305\u542b\u6765\u81eaReddit\u548cAmazon'23\u6570\u636e\u96c6\u7684\u81ea\u7136\u51fa\u73b0\u9879\u76ee\uff1b2. \u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u8bc6\u522bReddit-Movies\u548cAmazon'23\u4e2d\u5bf9\u5e94\u7684\u7535\u5f71\u5b9e\u4f53\uff1b3. \u4f7f\u7528\u8be5\u6570\u636e\u96c6\u5168\u9762\u8bc4\u4f30\u591a\u79cd\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\uff1a\u57fa\u4e8e\u89c4\u5219\u3001\u57fa\u4e8e\u56fe\u3001\u57fa\u4e8e\u8bcd\u6cd5\u3001\u57fa\u4e8e\u5d4c\u5165\u548c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002", "result": "1. \u521b\u5efa\u4e86\u5305\u542b\u4eba\u5de5\u6807\u6ce8\u5b9e\u4f53\u5339\u914d\u9ec4\u91d1\u6807\u51c6\u7684\u6570\u636e\u96c6\uff1b2. \u901a\u8fc7\u5b9e\u9a8c\u786e\u5b9a\u4e86\u6700\u4f73\u6027\u80fd\u7684\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\uff1b3. \u63d0\u4f9b\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u7684\u5b9d\u8d35\u8d44\u6e90\u3002", "conclusion": "Reddit-Amazon-EM\u6570\u636e\u96c6\u586b\u8865\u4e86\u63a8\u8350\u7cfb\u7edf\u5b9e\u4f53\u5339\u914d\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\u3002\u901a\u8fc7\u53d1\u5e03\u4eba\u5de5\u6807\u6ce8\u7684\u9ec4\u91d1\u6807\u51c6\u548c\u6570\u636e\u96c6\u6620\u5c04\uff0c\u8be5\u5de5\u4f5c\u5c06\u4fc3\u8fdb\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2601.17333", "categories": ["cs.IR", "cs.AI", "cs.CE", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.17333", "abs": "https://arxiv.org/abs/2601.17333", "authors": ["Lalit Pant", "Shivang Nagar"], "title": "FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search", "comment": "8 pages, 8 figures, Information Retrieval, Natural Language Query, Vector Search, Embeddings, Named Entity Recognition, Large Language Models", "summary": "Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u7684\u73b0\u4ee3\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7cfb\u7edf\u6280\u672f\u84dd\u56fe\uff0c\u901a\u8fc7\u7ed3\u5408NLP\u3001\u641c\u7d22\u5de5\u7a0b\u548c\u5411\u91cf\u6570\u636e\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u91d1\u878d\u6570\u636e\u68c0\u7d22\u4e2d\u7684\u53d1\u73b0\u3001\u76f8\u5173\u6027\u6392\u5e8f\u3001\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u5b9e\u4f53\u8bc6\u522b\u7b49\u5173\u952e\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e14\u96be\u4ee5\u6709\u6548\u8fde\u63a5\u5206\u6563\u7684\u91d1\u878d\u5bf9\u8c61\u3001\u4e8b\u4ef6\u548c\u5173\u7cfb\u3002\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u80fd\u591f\u4f7f\u7528\u4eba\u7c7b\u81ea\u7136\u8bed\u8a00\u4e0e\u4fe1\u606f\u7cfb\u7edf\u4ea4\u4e92\uff0c\u6709\u671b\u663e\u8457\u63d0\u5347\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u7684\u6548\u679c\u548c\u6df1\u5ea6\u6d1e\u5bdf\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u641c\u7d22\u5de5\u7a0b\u548c\u5411\u91cf\u6570\u636e\u6a21\u578b\u7684\u6838\u5fc3\u6784\u5efa\u6a21\u5757\uff0c\u8bbe\u8ba1\u4e86\u5305\u542b\u79bb\u7ebf\u7d22\u5f15\u548c\u5728\u7ebf\u68c0\u7d22\u7684\u67b6\u6784\u7ec4\u4ef6\u3002\u8be6\u7ec6\u9610\u8ff0\u4e86\u91d1\u878d\u6570\u636e\u96c6\u548c\u6587\u6863\u7684\u72ec\u7279\u9700\u6c42\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u65b9\u6cd5\u8bba\u3001\u6570\u636e\u4f7f\u7528\u548c\u7ed3\u679c\u5206\u6790\u3002", "result": "\u63d0\u51fa\u7684NLQ\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u4e2d\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8fde\u63a5\u4e0d\u540c\u7684\u91d1\u878d\u5bf9\u8c61\u3001\u4e8b\u4ef6\u548c\u5173\u7cfb\uff0c\u4e3a\u91d1\u878d\u670d\u52a1\u4e2d\u7684\u589e\u5f3a\u77e5\u8bc6\u641c\u7d22\u63d0\u4f9b\u4e86\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91d1\u878d\u9886\u57df\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6280\u672f\u84dd\u56fe\u548c\u7406\u8bba\u652f\u6301\uff0c\u5c55\u793a\u4e86NLQ\u5728\u63d0\u5347\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u6548\u679c\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u4f18\u5316\u7684\u65b9\u5411\u3002"}}
{"id": "2601.17339", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17339", "abs": "https://arxiv.org/abs/2601.17339", "authors": ["Payel Santra", "Partha Basuchowdhuri", "Debasis Ganguly"], "title": "Beyond Correlations: A Downstream Evaluation Framework for Query Performance Prediction", "comment": null, "summary": "The standard practice of query performance prediction (QPP) evaluation is to measure a set-level correlation between the estimated retrieval qualities and the true ones. However, neither this correlation-based evaluation measure quantifies QPP effectiveness at the level of individual queries, nor does this connect to a downstream application, meaning that QPP methods yielding high correlation values may not find a practical application in query-specific decisions in an IR pipeline. In this paper, we propose a downstream-focussed evaluation framework where a distribution of QPP estimates across a list of top-documents retrieved with several rankers is used as priors for IR fusion. While on the one hand, a distribution of these estimates closely matching that of the true retrieval qualities indicates the quality of the predictor, their usage as priors on the other hand indicates a predictor's ability to make informed choices in an IR pipeline. Our experiments firstly establish the importance of QPP estimates in weighted IR fusion, yielding substantial improvements of over 4.5% over unweighted CombSUM and RRF fusion strategies, and secondly, reveal new insights that the downstream effectiveness of QPP does not correlate well with the standard correlation-based QPP evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u9762\u5411\u4e0b\u6e38\u5e94\u7528\u7684QPP\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5c06QPP\u4f30\u8ba1\u5206\u5e03\u4f5c\u4e3aIR\u878d\u5408\u7684\u5148\u9a8c\u6765\u8bc4\u4f30\u9884\u6d4b\u5668\u8d28\u91cf\uff0c\u53d1\u73b0\u4e0b\u6e38\u6548\u679c\u4e0e\u6807\u51c6\u76f8\u5173\u6027\u8bc4\u4f30\u4e0d\u5339\u914d\u3002", "motivation": "\u4f20\u7edfQPP\u8bc4\u4f30\u4ec5\u6d4b\u91cf\u96c6\u5408\u5c42\u9762\u7684\u76f8\u5173\u6027\uff0c\u65e0\u6cd5\u91cf\u5316\u5355\u4e2a\u67e5\u8be2\u7684\u9884\u6d4b\u6548\u679c\uff0c\u4e5f\u65e0\u6cd5\u8fde\u63a5\u5230\u4e0b\u6e38\u5e94\u7528\u3002\u9ad8\u76f8\u5173\u6027\u7684QPP\u65b9\u6cd5\u5728\u5b9e\u9645IR\u7ba1\u9053\u4e2d\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u652f\u6301\u67e5\u8be2\u7279\u5b9a\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e0b\u6e38\u805a\u7126\u7684\u8bc4\u4f30\u6846\u67b6\uff1a\u5c06\u591a\u4e2a\u6392\u5e8f\u5668\u68c0\u7d22\u5230\u7684top\u6587\u6863\u5217\u8868\u4e2d\u7684QPP\u4f30\u8ba1\u5206\u5e03\u4f5c\u4e3aIR\u878d\u5408\u7684\u5148\u9a8c\u3002\u4e00\u65b9\u9762\uff0c\u8fd9\u4e9b\u4f30\u8ba1\u5206\u5e03\u4e0e\u771f\u5b9e\u68c0\u7d22\u8d28\u91cf\u5206\u5e03\u7684\u5339\u914d\u5ea6\u53cd\u6620\u9884\u6d4b\u5668\u8d28\u91cf\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u4f5c\u4e3a\u5148\u9a8c\u4f7f\u7528\u8868\u660e\u9884\u6d4b\u5668\u5728IR\u7ba1\u9053\u4e2d\u505a\u51fa\u660e\u667a\u51b3\u7b56\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09QPP\u4f30\u8ba1\u5728\u52a0\u6743IR\u878d\u5408\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u76f8\u6bd4\u672a\u52a0\u6743\u7684CombSUM\u548cRRF\u878d\u5408\u7b56\u7565\u6709\u8d85\u8fc74.5%\u7684\u663e\u8457\u6539\u8fdb\uff1b2\uff09QPP\u7684\u4e0b\u6e38\u6548\u679c\u4e0e\u6807\u51c6\u76f8\u5173\u6027\u8bc4\u4f30\u4e0d\u76f8\u5173\uff0c\u63ed\u793a\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003QPP\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e0b\u6e38\u5e94\u7528\u5bfc\u5411\u7684\u8bc4\u4f30\u6846\u67b6\u80fd\u66f4\u597d\u5730\u53cd\u6620QPP\u65b9\u6cd5\u5728\u5b9e\u9645IR\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\uff0c\u800c\u4f20\u7edf\u76f8\u5173\u6027\u8bc4\u4f30\u53ef\u80fd\u8bef\u5bfc\u65b9\u6cd5\u9009\u62e9\u3002"}}
{"id": "2601.17359", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17359", "abs": "https://arxiv.org/abs/2601.17359", "authors": ["Payel Santra", "Partha Basuchowdhuri", "Debasis Ganguly"], "title": "Breaking Flat: A Generalised Query Performance Prediction Evaluation Framework", "comment": null, "summary": "The traditional use-case of query performance prediction (QPP) is to identify which queries perform well and which perform poorly for a given ranking model. A more fine-grained and arguably more challenging extension of this task is to determine which ranking models are most effective for a given query. In this work, we generalize the QPP task and its evaluation into three settings: (i) SingleRanker MultiQuery (SRMQ-PP), corresponding to the standard use case; (ii) MultiRanker SingleQuery (MRSQ-PP), which evaluates a QPP model's ability to select the most effective ranker for a query; and (iii) MultiRanker MultiQuery (MRMQ-PP), which considers predictions jointly across all query ranker pairs. Our results show that (a) the relative effectiveness of QPP models varies substantially across tasks (SRMQ-PP vs. MRSQ-PP), and (b) predicting the best ranker for a query is considerably more difficult than predicting the relative difficulty of queries for a given ranker.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u67e5\u8be2\u6027\u80fd\u9884\u6d4b(QPP)\u7684\u4e09\u4e2a\u4efb\u52a1\u8bbe\u7f6e\uff1a\u5355\u6392\u5e8f\u5668\u591a\u67e5\u8be2(SRMQ-PP)\u3001\u591a\u6392\u5e8f\u5668\u5355\u67e5\u8be2(MRSQ-PP)\u548c\u591a\u6392\u5e8f\u5668\u591a\u67e5\u8be2(MRMQ-PP)\uff0c\u53d1\u73b0\u4e0d\u540c\u4efb\u52a1\u4e2dQPP\u6a21\u578b\u6548\u679c\u5dee\u5f02\u663e\u8457\uff0c\u4e14\u9884\u6d4b\u6700\u4f73\u6392\u5e8f\u5668\u6bd4\u9884\u6d4b\u67e5\u8be2\u96be\u5ea6\u66f4\u5177\u6311\u6218\u6027\u3002", "motivation": "\u4f20\u7edfQPP\u4e3b\u8981\u7528\u4e8e\u8bc4\u4f30\u5355\u4e2a\u6392\u5e8f\u6a21\u578b\u5728\u4e0d\u540c\u67e5\u8be2\u4e0a\u7684\u8868\u73b0\uff0c\u4f46\u66f4\u7ec6\u7c92\u5ea6\u7684\u6269\u5c55\u4efb\u52a1\u2014\u2014\u4e3a\u7ed9\u5b9a\u67e5\u8be2\u9009\u62e9\u6700\u6709\u6548\u7684\u6392\u5e8f\u6a21\u578b\u2014\u2014\u66f4\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u65e8\u5728\u5c06QPP\u4efb\u52a1\u53ca\u5176\u8bc4\u4f30\u63a8\u5e7f\u5230\u66f4\u5168\u9762\u7684\u8bbe\u7f6e\u3002", "method": "\u5c06QPP\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u4e09\u4e2a\u8bbe\u7f6e\uff1a(1) SRMQ-PP\uff1a\u6807\u51c6\u7528\u4f8b\uff0c\u8bc4\u4f30\u5355\u4e2a\u6392\u5e8f\u5668\u5728\u591a\u4e2a\u67e5\u8be2\u4e0a\u7684\u6027\u80fd\u9884\u6d4b\uff1b(2) MRSQ-PP\uff1a\u8bc4\u4f30QPP\u6a21\u578b\u4e3a\u5355\u4e2a\u67e5\u8be2\u9009\u62e9\u6700\u6709\u6548\u6392\u5e8f\u5668\u7684\u80fd\u529b\uff1b(3) MRMQ-PP\uff1a\u540c\u65f6\u8003\u8651\u6240\u6709\u67e5\u8be2-\u6392\u5e8f\u5668\u5bf9\u7684\u8054\u5408\u9884\u6d4b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(a) QPP\u6a21\u578b\u7684\u76f8\u5bf9\u6709\u6548\u6027\u5728\u4e0d\u540c\u4efb\u52a1(SRMQ-PP vs MRSQ-PP)\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b(b) \u4e3a\u67e5\u8be2\u9884\u6d4b\u6700\u4f73\u6392\u5e8f\u5668\u6bd4\u9884\u6d4b\u7ed9\u5b9a\u6392\u5e8f\u5668\u4e0b\u67e5\u8be2\u7684\u76f8\u5bf9\u96be\u5ea6\u8981\u56f0\u96be\u5f97\u591a\u3002", "conclusion": "QPP\u4efb\u52a1\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u8fdb\u884c\u533a\u5206\uff0c\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u6a21\u578b\u6027\u80fd\u4e0d\u53ef\u76f4\u63a5\u6bd4\u8f83\u3002\u4e3a\u67e5\u8be2\u9009\u62e9\u6700\u4f73\u6392\u5e8f\u5668\u662f\u4e00\u4e2a\u66f4\u5177\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u7814\u7a76\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.17438", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17438", "abs": "https://arxiv.org/abs/2601.17438", "authors": ["Jialei Li", "Yang Zhang", "Yimeng Bai", "Shuai Zhu", "Ziqi Xue", "Xiaoyan Zhao", "Dingxian Wang", "Frank Yang", "Andrew Rabinovich", "Xiangnan He"], "title": "UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization", "comment": "11 pages, 6 figures", "summary": "Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics.\n  To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at https://github.com/Jialei-03/UniGRec.", "AI": {"tldr": "UniGRec\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5fae\u8f6f\u9879\u76ee\u6807\u8bc6\u7b26\u5c06\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u7edf\u4e00\u5728\u6700\u7ec8\u63a8\u8350\u76ee\u6807\u4e0b\uff0c\u89e3\u51b3\u4e86\u8bad\u7ec3-\u63a8\u7406\u5dee\u5f02\u3001\u6807\u8bc6\u7b26\u5d29\u6e83\u548c\u534f\u540c\u4fe1\u53f7\u4e0d\u8db3\u4e09\u5927\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u5c06\u5206\u8bcd\u5668\u4e0e\u63a8\u8350\u5668\u89e3\u8026\u6216\u4f9d\u8d56\u5f02\u6b65\u4ea4\u66ff\u4f18\u5316\uff0c\u9650\u5236\u4e86\u7aef\u5230\u7aef\u5bf9\u9f50\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u5c06\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u7edf\u4e00\u5728\u6700\u7ec8\u63a8\u8350\u76ee\u6807\u4e0b\u8fdb\u884c\u8054\u5408\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "method": "\u63d0\u51faUniGRec\u6846\u67b6\uff1a1) \u4f7f\u7528\u9000\u706b\u63a8\u7406\u5bf9\u9f50\u5e73\u6ed1\u8fde\u63a5\u8f6f\u8bad\u7ec3\u548c\u786c\u63a8\u7406\uff1b2) \u91c7\u7528\u7801\u5b57\u5747\u5300\u6b63\u5219\u5316\u9632\u6b62\u6807\u8bc6\u7b26\u5d29\u6e83\u5e76\u4fc3\u8fdb\u7801\u672c\u591a\u6837\u6027\uff1b3) \u8bbe\u8ba1\u53cc\u91cd\u534f\u540c\u84b8\u998f\u673a\u5236\uff0c\u4ece\u8f7b\u91cf\u7ea7\u6559\u5e08\u6a21\u578b\u4e2d\u63d0\u53d6\u534f\u540c\u5148\u9a8c\u6765\u5171\u540c\u6307\u5bfc\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cUniGRec\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "UniGRec\u901a\u8fc7\u7edf\u4e00\u7684\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2601.17472", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17472", "abs": "https://arxiv.org/abs/2601.17472", "authors": ["Junyou He", "Lixi Deng", "Huichao Guo", "Ye Tang", "Yong Li", "Sulong Xu"], "title": "Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features", "comment": "Accepted to ICDM 2025", "summary": "Cross-domain recommendation (CDR) has been increasingly explored to address data sparsity and cold-start issues. However, recent approaches typically disentangle domain-invariant features shared between source and target domains, as well as domain-specific features for each domain. However, they often rely solely on domain-invariant features combined with target domain-specific features, which can lead to suboptimal performance. To overcome the limitations, this paper presents the Adversarial Alignment and Disentanglement Cross-Domain Recommendation ($A^2DCDR$ ) model, an innovative approach designed to capture a comprehensive range of cross-domain information, including both domain-invariant and valuable non-aligned features. The $A^2DCDR$ model enhances cross-domain recommendation through three key components: refining MMD with adversarial training for better generalization, employing a feature disentangler and reconstruction mechanism for intra-domain disentanglement, and introducing a novel fused representation combining domain-invariant, non-aligned features with original contextual data. Experiments on real-world datasets and online A/B testing show that $A^2DCDR$ outperforms existing methods, confirming its effectiveness and practical applicability. The code is provided at https://github.com/youzi0925/A-2DCDR/tree/main.", "AI": {"tldr": "\u63d0\u51faA\u00b2DCDR\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u6297\u5bf9\u9f50\u548c\u7279\u5f81\u89e3\u8026\u6539\u8fdb\u8de8\u57df\u63a8\u8350\uff0c\u7ed3\u5408\u57df\u4e0d\u53d8\u7279\u5f81\u3001\u975e\u5bf9\u9f50\u7279\u5f81\u548c\u539f\u59cb\u4e0a\u4e0b\u6587\u6570\u636e\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u73b0\u6709\u8de8\u57df\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u57df\u4e0d\u53d8\u7279\u5f81\u7ed3\u5408\u76ee\u6807\u57df\u7279\u5b9a\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u6709\u4ef7\u503c\u7684\u975e\u5bf9\u9f50\u7279\u5f81\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650", "method": "1) \u4f7f\u7528\u5bf9\u6297\u8bad\u7ec3\u6539\u8fdbMMD\u4ee5\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b2) \u7279\u5f81\u89e3\u8026\u5668\u548c\u91cd\u5efa\u673a\u5236\u5b9e\u73b0\u57df\u5185\u89e3\u8026\uff1b3) \u878d\u5408\u57df\u4e0d\u53d8\u7279\u5f81\u3001\u975e\u5bf9\u9f50\u7279\u5f81\u548c\u539f\u59cb\u4e0a\u4e0b\u6587\u6570\u636e\u7684\u65b0\u8868\u793a\u65b9\u6cd5", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0cA\u00b2DCDR\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c", "conclusion": "A\u00b2DCDR\u6a21\u578b\u901a\u8fc7\u5168\u9762\u6355\u6349\u8de8\u57df\u4fe1\u606f\uff08\u5305\u62ec\u57df\u4e0d\u53d8\u548c\u6709\u4ef7\u503c\u7684\u975e\u5bf9\u9f50\u7279\u5f81\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u57df\u63a8\u8350\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.17492", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17492", "abs": "https://arxiv.org/abs/2601.17492", "authors": ["Jin Li", "Huilin Gu", "Shoujin Wang", "Qi Zhang", "Shui Yu", "Chen Wang", "Xiwei Xu", "Fang Chen"], "title": "Towards Fair Large Language Model-based Recommender Systems without Costly Retraining", "comment": "Accepted by WWW 2026", "summary": "Large Language Models (LLMs) have revolutionized Recommender Systems (RS) through advanced generative user modeling. However, LLM-based RS (LLM-RS) often inadvertently perpetuates bias present in the training data, leading to severe fairness issues. Addressing these fairness problems in LLM-RS faces two significant challenges. 1) Existing debiasing methods, designed for specific bias types, lack the generality to handle diverse or emerging biases in real-world applications. 2) Debiasing methods relying on retraining are computationally infeasible given the massive parameter scale of LLMs. To overcome these challenges, we propose FUDLR (Fast Unified Debiasing for LLM-RS). The core idea is to reformulate the debiasing problem as an efficient machine unlearning task with two stages. First, FUDLR identifies bias-inducing samples to unlearn through a novel bias-agnostic mask, optimized to balance fairness improvement with accuracy preservation. Its bias-agnostic design allows adaptability to various or co-existing biases simply by incorporating different fairness metrics. Second, FUDLR performs efficient debiasing by estimating and removing the influence of identified samples on model parameters. Extensive experiments demonstrate that FUDLR effectively and efficiently improves fairness while preserving recommendation accuracy, offering a practical path toward socially responsible LLM-RS. The code and data are available at https://github.com/JinLi-i/FUDLR.", "AI": {"tldr": "FUDLR\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u7edf\u4e00\u7684LLM\u63a8\u8350\u7cfb\u7edf\u53bb\u504f\u65b9\u6cd5\uff0c\u5c06\u53bb\u504f\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9ad8\u6548\u7684\u673a\u5668\u9057\u5fd8\u4efb\u52a1\uff0c\u901a\u8fc7\u504f\u7f6e\u65e0\u5173\u63a9\u7801\u8bc6\u522b\u9700\u8981\u9057\u5fd8\u7684\u6837\u672c\uff0c\u5e76\u9ad8\u6548\u79fb\u9664\u5176\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u5f71\u54cd\u3002", "motivation": "LLM\u63a8\u8350\u7cfb\u7edf\u5bb9\u6613\u5ef6\u7eed\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u504f\u7f6e\uff0c\u5bfc\u81f4\u4e25\u91cd\u516c\u5e73\u6027\u95ee\u9898\u3002\u73b0\u6709\u53bb\u504f\u65b9\u6cd5\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u9488\u5bf9\u7279\u5b9a\u504f\u7f6e\u7c7b\u578b\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u5904\u7406\u591a\u6837\u6216\u65b0\u5174\u504f\u7f6e\u7684\u901a\u7528\u6027\uff1b2) \u4f9d\u8d56\u91cd\u8bad\u7ec3\uff0c\u5bf9\u5927\u89c4\u6a21LLM\u8ba1\u7b97\u4e0d\u53ef\u884c\u3002", "method": "FUDLR\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u504f\u7f6e\u65e0\u5173\u63a9\u7801\u8bc6\u522b\u9700\u8981\u9057\u5fd8\u7684\u504f\u7f6e\u8bf1\u5bfc\u6837\u672c\uff0c\u5e73\u8861\u516c\u5e73\u6027\u63d0\u5347\u4e0e\u51c6\u786e\u6027\u4fdd\u6301\uff1b2) \u9ad8\u6548\u4f30\u8ba1\u5e76\u79fb\u9664\u8fd9\u4e9b\u6837\u672c\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u53bb\u504f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFUDLR\u80fd\u6709\u6548\u4e14\u9ad8\u6548\u5730\u63d0\u5347\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u51c6\u786e\u6027\uff0c\u4e3a\u6784\u5efa\u793e\u4f1a\u8d23\u4efb\u7684LLM\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002", "conclusion": "FUDLR\u901a\u8fc7\u5c06\u53bb\u504f\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u673a\u5668\u9057\u5fd8\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u9ad8\u6548\u7684\u53bb\u504f\u65b9\u6cd5\uff0c\u9002\u5e94\u5404\u79cd\u6216\u5171\u5b58\u7684\u504f\u7f6e\u7c7b\u578b\u3002"}}
{"id": "2601.17500", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17500", "abs": "https://arxiv.org/abs/2601.17500", "authors": ["Emmanouil Georgios Lionis", "Jia-Huei Ju", "Angelos Nalmpantis", "Casper Thuis", "Sean MacAvaney", "Andrew Yates"], "title": "To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval", "comment": "This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this contribution is published in ECIR2026 (Part I) Advances in Information Retrieval", "summary": "Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5728LSR\u4e2d\u4f7f\u7528cased\u6a21\u578b\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4f46\u901a\u8fc7\u6587\u672c\u5c0f\u5199\u5316\u9884\u5904\u7406\u53ef\u4ee5\u6d88\u9664\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f7fcased\u6a21\u578b\u8868\u73b0\u5f97\u50cfuncased\u6a21\u578b", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LSR\u65b9\u6cd5\u51e0\u4e4e\u5b8c\u5168\u4f9d\u8d56uncased\u9aa8\u5e72\u6a21\u578b\uff0c\u4f46\u6700\u65b0\u7684SOTA\u8bed\u8a00\u6a21\u578b\u53ea\u6709cased\u7248\u672c\u3002\u9aa8\u5e72\u6a21\u578b\u7684\u5927\u5c0f\u5199\u5bf9LSR\u7684\u5f71\u54cd\u5c1a\u672a\u7814\u7a76\uff0c\u8fd9\u53ef\u80fd\u5a01\u80c1\u5230\u8be5\u65b9\u6cd5\u7684\u672a\u6765\u53d1\u5c55", "method": "\u7cfb\u7edf\u8bc4\u4f30\u914d\u5bf9\u7684cased\u548cuncased\u7248\u672c\u7684\u76f8\u540c\u9aa8\u5e72\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6587\u672c\u5c0f\u5199\u5316\u9884\u5904\u7406\uff0c\u5e76\u8fdb\u884ctoken\u7ea7\u522b\u7684\u5206\u6790", "result": "\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528cased\u9aa8\u5e72\u6a21\u578b\u7684LSR\u6a21\u578b\u6027\u80fd\u663e\u8457\u4f4e\u4e8euncased\u7248\u672c\uff1b\u4f46\u901a\u8fc7\u5c0f\u5199\u5316\u9884\u5904\u7406\u53ef\u4ee5\u5b8c\u5168\u6d88\u9664\u8fd9\u4e00\u6027\u80fd\u5dee\u8ddd\uff1btoken\u5206\u6790\u663e\u793a\u5c0f\u5199\u5316\u540ecased\u6a21\u578b\u51e0\u4e4e\u5b8c\u5168\u6291\u5236\u4e86\u5927\u5c0f\u5199\u654f\u611f\u7684\u8bcd\u6c47\u9879\uff0c\u8868\u73b0\u5f97\u50cfuncased\u6a21\u578b", "conclusion": "\u8fd9\u4e00\u7ed3\u679c\u6269\u5c55\u4e86\u6700\u65b0cased\u6a21\u578b\u5728LSR\u8bbe\u7f6e\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e76\u4fc3\u8fdb\u4e86\u66f4\u5f3a\u9aa8\u5e72\u67b6\u6784\u4e0e\u7a00\u758f\u68c0\u7d22\u7684\u96c6\u6210\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u5c0f\u5199\u5316\u9884\u5904\u7406\u5373\u53ef\u5b9e\u73b0"}}
{"id": "2601.17502", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17502", "abs": "https://arxiv.org/abs/2601.17502", "authors": ["Emmanouil Georgios Lionis", "Craig Macdonald", "Sean MacAvaney"], "title": "Pipeline Inspection, Visualization, and Interoperability in PyTerrier", "comment": "This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this contribution is published in ECIR2026 (Part IV) Advances in Information Retrieval", "summary": "PyTerrier provides a declarative framework for building and experimenting with Information Retrieval (IR) pipelines. In this demonstration, we highlight several recent pipeline operations that improve their ability to be programmatically inspected, visualized, and integrated with other tools (via the Model Context Protocol, MCP). These capabilities aim to make it easier for researchers, students, and AI agents to understand and use a wide array of IR pipelines.", "AI": {"tldr": "PyTerrier\u662f\u4e00\u4e2a\u58f0\u660e\u5f0f\u4fe1\u606f\u68c0\u7d22\u6846\u67b6\uff0c\u65b0\u589e\u4e86\u53ef\u7f16\u7a0b\u68c0\u67e5\u3001\u53ef\u89c6\u5316\u548c\u5de5\u5177\u96c6\u6210\u529f\u80fd\uff0c\u65e8\u5728\u8ba9\u7814\u7a76\u4eba\u5458\u3001\u5b66\u751f\u548cAI\u4ee3\u7406\u66f4\u5bb9\u6613\u7406\u89e3\u548c\u4f7f\u7528\u5404\u79cdIR\u7ba1\u9053\u3002", "motivation": "\u5f53\u524d\u4fe1\u606f\u68c0\u7d22\u7ba1\u9053\u901a\u5e38\u96be\u4ee5\u7406\u89e3\u548c\u8c03\u8bd5\uff0c\u7814\u7a76\u4eba\u5458\u3001\u5b66\u751f\u548cAI\u4ee3\u7406\u5728\u7406\u89e3\u548c\u4f7f\u7528\u5404\u79cdIR\u7ba1\u9053\u65f6\u9762\u4e34\u6311\u6218\u3002\u9700\u8981\u63d0\u9ad8IR\u7ba1\u9053\u7684\u53ef\u68c0\u67e5\u6027\u3001\u53ef\u89c6\u5316\u80fd\u529b\u548c\u5de5\u5177\u96c6\u6210\u6027\u3002", "method": "\u901a\u8fc7PyTerrier\u58f0\u660e\u5f0f\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u7684\u7ba1\u9053\u64cd\u4f5c\uff0c\u652f\u6301\u7a0b\u5e8f\u5316\u68c0\u67e5\u3001\u53ef\u89c6\u5316\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4e0e\u5176\u4ed6\u5de5\u5177\u96c6\u6210\u3002", "result": "\u5f00\u53d1\u4e86\u6539\u8fdb\u7684\u7ba1\u9053\u64cd\u4f5c\u529f\u80fd\uff0c\u4f7fIR\u7ba1\u9053\u80fd\u591f\u88ab\u7a0b\u5e8f\u5316\u68c0\u67e5\u3001\u53ef\u89c6\u5316\uff0c\u5e76\u66f4\u597d\u5730\u4e0e\u5176\u4ed6\u5de5\u5177\u96c6\u6210\uff0c\u589e\u5f3a\u4e86\u6846\u67b6\u7684\u53ef\u7528\u6027\u548c\u53ef\u7406\u89e3\u6027\u3002", "conclusion": "PyTerrier\u7684\u65b0\u529f\u80fd\u663e\u8457\u63d0\u9ad8\u4e86IR\u7ba1\u9053\u7684\u53ef\u7406\u89e3\u6027\u548c\u53ef\u7528\u6027\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u3001\u5b66\u751f\u548cAI\u4ee3\u7406\u80fd\u591f\u66f4\u8f7b\u677e\u5730\u6784\u5efa\u3001\u5b9e\u9a8c\u548c\u4f7f\u7528\u5404\u79cd\u4fe1\u606f\u68c0\u7d22\u7ba1\u9053\u3002"}}
{"id": "2601.17567", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17567", "abs": "https://arxiv.org/abs/2601.17567", "authors": ["Zijing Hui", "Wenhan Lyu", "Shusen Wang", "Li Chen", "Chu Wang"], "title": "Real-Time Trend Prediction via Continually-Aligned LLM Query Generation", "comment": null, "summary": "Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.", "AI": {"tldr": "RTTP\u662f\u4e00\u4e2a\u5b9e\u65f6\u8d8b\u52bf\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7LLM\u76f4\u63a5\u4ece\u65b0\u95fb\u5185\u5bb9\u751f\u6210\u641c\u7d22\u67e5\u8be2\uff0c\u89e3\u51b3\u4e86\u4f4e\u6d41\u91cf\u641c\u7d22\u73af\u5883\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5728Facebook\u548cMeta AI\u4ea7\u54c1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f4e\u6d41\u91cf\u641c\u7d22\u73af\u5883\u4e2d\u7684\u8d8b\u52bf\u68c0\u6d4b\u9762\u4e34\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u73b0\u6709\u57fa\u4e8e\u5173\u952e\u8bcd\u9891\u7387\u6216\u67e5\u8be2\u5cf0\u503c\u7684\u65b9\u6cd5\u5728\u7a00\u758f\u8bbe\u7f6e\u4e2d\u53cd\u5e94\u7f13\u6162\u4e14\u6548\u679c\u4e0d\u4f73\uff0c\u65e0\u6cd5\u53ca\u65f6\u8bc6\u522b\u65b0\u5174\u6216\u957f\u5c3e\u8d8b\u52bf\u3002", "method": "RTTP\u91c7\u7528\u6301\u7eed\u5b66\u4e60LLM\u5c06\u65b0\u95fb\u5e16\u5b50\u8f6c\u6362\u4e3a\u641c\u7d22\u5f0f\u67e5\u8be2\uff0c\u5e76\u4f7f\u7528\u53c2\u4e0e\u5ea6\u5f3a\u5ea6\u548c\u521b\u4f5c\u8005\u6743\u5a01\u6027\u8fdb\u884c\u8bc4\u5206\uff1b\u63d0\u51faMix-Policy DPO\u65b9\u6cd5\uff0c\u7ed3\u5408on-policy\u7a33\u5b9a\u6027\u548coff-policy\u65b0\u9896\u6027\uff0c\u7f13\u89e3\u6a21\u578b\u5347\u7ea7\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728Facebook\u548cMeta AI\u4ea7\u54c1\u4e2d\u90e8\u7f72\uff0cRTTP\u5728\u5c3e\u90e8\u8d8b\u52bf\u68c0\u6d4b\u7cbe\u5ea6@500\u4e0a\u63d0\u5347\u4e8691.4%\uff0c\u67e5\u8be2\u751f\u6210\u51c6\u786e\u7387\u6bd4\u884c\u4e1a\u57fa\u7ebf\u63d0\u9ad8\u4e8619%\uff0c\u5e76\u5728\u591a\u5468\u5728\u7ebf\u8bad\u7ec3\u540e\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5f53LLM\u751f\u6210\u7684\u5408\u6210\u641c\u7d22\u4fe1\u53f7\u7ecf\u8fc7\u5bf9\u9f50\u548c\u6301\u7eed\u66f4\u65b0\u65f6\uff0c\u80fd\u591f\u5728\u4f4e\u6d41\u91cf\u641c\u7d22\u73af\u5883\u4e2d\u5b9e\u73b0\u53ca\u65f6\u7684\u8d8b\u52bf\u7406\u89e3\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5ef6\u8fdf\u95ee\u9898\u3002"}}
{"id": "2601.17601", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.17601", "abs": "https://arxiv.org/abs/2601.17601", "authors": ["Fangping Lan", "Abdullah Aljebreen", "Eduard C. Dragut"], "title": "Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts", "comment": "10 pages including references, 5 figures,", "summary": "URLs serve as bridges between social media platforms and the broader web, linking user-generated content to external information resources. On Twitter (X), approximately one in five tweets contains at least one URL, underscoring their central role in information dissemination. While prior studies have examined the motivations of authors who share URLs, such author-centered intentions are difficult to observe in practice. To enable broader downstream use, this work investigates reader-centered interpretations, i.e., how users perceive the intentions behind hyperlinks included in posts. We develop an intent taxonomy for including hyperlinks in social posts through a hybrid approach that begins with a bottom-up, data-driven process using large-scale crowdsourced annotations, and is then refined using large language model assistance to generate descriptive category names and precise definitions. The final taxonomy comprises 6 top-level categories and 26 fine-grained intention classes, capturing diverse communicative purposes. Applying this taxonomy, we annotate and analyze 1000 user posts, revealing that advertising, arguing, and sharing are the most prevalent intentions. This resulting taxonomy provides a foundation for intent-aware information retrieval and NLP applications, enabling more accurate retrieval, recommendation, and understanding of social media content.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u793e\u4ea4\u5a92\u4f53\u4e2dURL\u610f\u56fe\u5206\u7c7b\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f17\u5305\u6807\u6ce8\u548cLLM\u8f85\u52a9\u6784\u5efa\u4e86\u5305\u542b6\u4e2a\u9876\u5c42\u7c7b\u522b\u548c26\u4e2a\u7ec6\u7c92\u5ea6\u610f\u56fe\u7684\u5b8c\u6574\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u5e94\u7528\u4e8e1000\u6761\u63a8\u6587\u5206\u6790\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e2dURL\u94fe\u63a5\u666e\u904d\u5b58\u5728\uff08\u7ea620%\u63a8\u6587\u5305\u542bURL\uff09\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u53d1\u5e03\u8005\u610f\u56fe\uff0c\u96be\u4ee5\u5b9e\u9645\u89c2\u5bdf\u3002\u4e3a\u652f\u6301\u4e0b\u6e38\u5e94\u7528\uff0c\u672c\u7814\u7a76\u8f6c\u5411\u8bfb\u8005\u89c6\u89d2\uff0c\u63a2\u7d22\u7528\u6237\u5982\u4f55\u7406\u89e3\u5e16\u5b50\u4e2d\u94fe\u63a5\u7684\u610f\u56fe\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u5927\u89c4\u6a21\u4f17\u5305\u6807\u6ce8\u8fdb\u884c\u81ea\u4e0b\u800c\u4e0a\u7684\u6570\u636e\u9a71\u52a8\u8fc7\u7a0b\uff0c\u7136\u540e\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u751f\u6210\u63cf\u8ff0\u6027\u7c7b\u522b\u540d\u79f0\u548c\u7cbe\u786e\u5b9a\u4e49\uff0c\u6700\u7ec8\u6784\u5efa\u5305\u542b6\u4e2a\u9876\u5c42\u7c7b\u522b\u548c26\u4e2a\u7ec6\u7c92\u5ea6\u610f\u56fe\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u6784\u5efa\u4e86\u5b8c\u6574\u7684URL\u610f\u56fe\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e94\u7528\u4e8e1000\u6761\u7528\u6237\u5e16\u5b50\u6807\u6ce8\u5206\u6790\uff0c\u53d1\u73b0\u5e7f\u544a\u3001\u4e89\u8bba\u548c\u5206\u4eab\u662f\u6700\u666e\u904d\u7684\u610f\u56fe\u3002\u5e7f\u544a\u610f\u56fe\u5360\u6bd4\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e89\u8bba\u548c\u5206\u4eab\u3002", "conclusion": "\u8be5\u5206\u7c7b\u4f53\u7cfb\u4e3a\u610f\u56fe\u611f\u77e5\u7684\u4fe1\u606f\u68c0\u7d22\u548cNLP\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u68c0\u7d22\u3001\u63a8\u8350\u548c\u7406\u89e3\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\uff0c\u652f\u6301\u4e0b\u6e38\u5e94\u7528\u5f00\u53d1\u3002"}}
{"id": "2601.17617", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17617", "abs": "https://arxiv.org/abs/2601.17617", "authors": ["Jingjie Ning", "Jo\u00e3o Coelho", "Yibo Kong", "Yunfan Long", "Bruno Martins", "Jo\u00e3o Magalh\u00e3es", "Jamie Callan", "Chenyan Xiong"], "title": "Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests", "comment": null, "summary": "LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.", "AI": {"tldr": "\u5927\u89c4\u6a21\u65e5\u5fd7\u5206\u6790\u63ed\u793aLLM\u641c\u7d22\u4ee3\u7406\u7684\u884c\u4e3a\u6a21\u5f0f\uff1a90%\u591a\u8f6e\u4f1a\u8bdd\u4e0d\u8d85\u8fc710\u6b65\uff0c89%\u6b65\u9aa4\u95f4\u9694\u5c0f\u4e8e1\u5206\u949f\uff1b\u4e0d\u540c\u610f\u56fe\u884c\u4e3a\u5dee\u5f02\u5927\uff0c\u4e8b\u5b9e\u67e5\u8be2\u91cd\u590d\u7387\u9ad8\uff0c\u63a8\u7406\u4efb\u52a1\u63a2\u7d22\u66f4\u5e7f\uff1b54%\u65b0\u67e5\u8be2\u8bcd\u53ef\u8ffd\u6eaf\u5230\u5148\u524d\u8bc1\u636e\uff0c\u652f\u6301\u8de8\u6b65\u9aa4\u4e0a\u4e0b\u6587\u8ffd\u8e2a\u3002", "motivation": "\u968f\u7740LLM\u9a71\u52a8\u7684\u641c\u7d22\u4ee3\u7406\u5728\u591a\u6b65\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0cIR\u793e\u533a\u7f3a\u4e4f\u5bf9\u4ee3\u7406\u641c\u7d22\u4f1a\u8bdd\u5982\u4f55\u5c55\u5f00\u4ee5\u53ca\u68c0\u7d22\u8bc1\u636e\u5982\u4f55\u4f7f\u7528\u7684\u5b9e\u8bc1\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5927\u89c4\u6a21\u65e5\u5fd7\u5206\u6790\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u57fa\u4e8eDeepResearchGym\u5f00\u6e90\u641c\u7d22API\u6536\u96c6\u76841444\u4e07\u641c\u7d22\u8bf7\u6c42\uff08397\u4e07\u4f1a\u8bdd\uff09\u8fdb\u884c\u5927\u89c4\u6a21\u65e5\u5fd7\u5206\u6790\u3002\u4f7f\u7528\u4f1a\u8bdd\u5316\u5904\u7406\u3001\u57fa\u4e8eLLM\u7684\u4f1a\u8bdd\u7ea7\u610f\u56fe\u6807\u6ce8\u548c\u6b65\u9aa4\u7ea7\u67e5\u8be2\u91cd\u6784\u6807\u7b7e\uff0c\u5e76\u63d0\u51fa\u4e0a\u4e0b\u6587\u9a71\u52a8\u7684\u672f\u8bed\u91c7\u7eb3\u7387\uff08CTAR\uff09\u6765\u91cf\u5316\u65b0\u67e5\u8be2\u8bcd\u662f\u5426\u53ef\u8ffd\u6eaf\u5230\u5148\u524d\u68c0\u7d22\u8bc1\u636e\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u4e3b\u8981\u884c\u4e3a\u6a21\u5f0f\uff1a1\uff0990%\u591a\u8f6e\u4f1a\u8bdd\u4e0d\u8d85\u8fc710\u6b65\uff0c89%\u6b65\u9aa4\u95f4\u9694\u5c0f\u4e8e1\u5206\u949f\uff1b2\uff09\u4e0d\u540c\u610f\u56fe\u884c\u4e3a\u5dee\u5f02\u663e\u8457\uff0c\u4e8b\u5b9e\u67e5\u8be2\u4f1a\u8bdd\u91cd\u590d\u7387\u9ad8\u4e14\u968f\u65f6\u95f4\u589e\u52a0\uff0c\u63a8\u7406\u4efb\u52a1\u4f1a\u8bdd\u7ef4\u6301\u66f4\u5e7f\u6cdb\u63a2\u7d22\uff1b3\uff09\u4ee3\u7406\u8de8\u6b65\u9aa4\u91cd\u7528\u8bc1\u636e\uff0c\u5e73\u574754%\u65b0\u67e5\u8be2\u8bcd\u51fa\u73b0\u5728\u7d2f\u79ef\u8bc1\u636e\u4e0a\u4e0b\u6587\u4e2d\uff0c\u65e9\u671f\u6b65\u9aa4\u8d21\u732e\u8d85\u51fa\u6700\u8fd1\u68c0\u7d22\u3002", "conclusion": "\u4ee3\u7406\u641c\u7d22\u53ef\u80fd\u53d7\u76ca\u4e8e\u91cd\u590d\u611f\u77e5\u7684\u65e9\u671f\u505c\u6b62\u3001\u610f\u56fe\u81ea\u9002\u5e94\u7684\u68c0\u7d22\u9884\u7b97\u548c\u663e\u5f0f\u7684\u8de8\u6b65\u9aa4\u4e0a\u4e0b\u6587\u8ffd\u8e2a\u3002\u7814\u7a76\u8ba1\u5212\u53d1\u5e03\u533f\u540d\u5316\u65e5\u5fd7\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.17692", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17692", "abs": "https://arxiv.org/abs/2601.17692", "authors": ["Yunhan Li", "Mingjie Xie", "Gaoli Kang", "Zihan Gong", "Gengshen Wu", "Min Yang"], "title": "LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval", "comment": "31pages, 4 figures", "summary": "Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.", "AI": {"tldr": "LegalMALR\uff1a\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u67e5\u8be2\u7406\u89e3\u7cfb\u7edf\u4e0e\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u7684\u6cd5\u5f8b\u6cd5\u89c4\u68c0\u7d22\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u9690\u5f0f\u3001\u591a\u95ee\u9898\u3001\u53e3\u8bed\u5316\u6cd5\u5f8b\u67e5\u8be2\u7684\u68c0\u7d22\u6548\u679c", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6cd5\u5f8b\u67e5\u8be2\u5f80\u5f80\u662f\u9690\u5f0f\u3001\u591a\u95ee\u9898\u3001\u53e3\u8bed\u5316\u6216\u672a\u5145\u5206\u6307\u5b9a\u7684\uff0c\u8fd9\u4f7f\u5f97\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\u96be\u4ee5\u51c6\u786e\u6062\u590d\u6240\u9700\u7684\u6cd5\u5f8b\u8981\u7d20\u3002\u5bc6\u96c6\u68c0\u7d22\u5668\u4e3b\u8981\u5173\u6ce8\u67e5\u8be2\u7684\u5b57\u9762\u5f62\u5f0f\uff0c\u800c\u8f7b\u91cf\u7ea7\u91cd\u6392\u5e8f\u5668\u7f3a\u4e4f\u8bc4\u4f30\u6cd5\u5f8b\u9002\u7528\u6027\u6240\u9700\u7684\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faLegalMALR\u6846\u67b6\uff1a1\uff09\u591a\u667a\u80fd\u4f53\u67e5\u8be2\u7406\u89e3\u7cfb\u7edf\uff08MAS\uff09\u751f\u6210\u591a\u6837\u5316\u7684\u6cd5\u5f8b\u57fa\u7840\u91cd\u5199\u5e76\u8fdb\u884c\u8fed\u4ee3\u5bc6\u96c6\u68c0\u7d22\u4ee5\u6269\u5927\u5019\u9009\u8986\u76d6\uff1b2\uff09\u4f7f\u7528\u5e7f\u4e49\u5f3a\u5316\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u7edf\u4e00\u4f18\u5316MAS\u7b56\u7565\u4ee5\u7a33\u5b9aLLM\u751f\u6210\u91cd\u5199\u7684\u968f\u673a\u884c\u4e3a\uff1b3\uff09LLM\u91cd\u6392\u5e8f\u6a21\u5757\u6267\u884c\u81ea\u7136\u8bed\u8a00\u6cd5\u5f8b\u63a8\u7406\u751f\u6210\u6700\u7ec8\u6392\u5e8f\u3002\u6784\u5efa\u4e86\u5305\u542b118\u4e2a\u56f0\u96be\u4e2d\u6587\u6cd5\u5f8b\u67e5\u8be2\u7684CSAID\u6570\u636e\u96c6\u3002", "result": "\u5728CSAID\u6570\u636e\u96c6\u548c\u516c\u5f00STARD\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLegalMALR\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u5f3a\u5927\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u591a\u89c6\u89d2\u67e5\u8be2\u89e3\u91ca\u3001\u57fa\u4e8e\u5f3a\u5316\u7684\u7b56\u7565\u4f18\u5316\u548c\u5927\u6a21\u578b\u91cd\u6392\u5e8f\u7684\u6709\u6548\u6027\u3002", "conclusion": "LegalMALR\u901a\u8fc7\u6574\u5408\u591a\u667a\u80fd\u4f53\u67e5\u8be2\u7406\u89e3\u3001\u5f3a\u5316\u7b56\u7565\u4f18\u5316\u548cLLM\u91cd\u6392\u5e8f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6cd5\u5f8b\u68c0\u7d22\u4e2d\u67e5\u8be2\u8868\u8fbe\u4e0d\u660e\u786e\u7684\u95ee\u9898\uff0c\u4e3a\u6cd5\u5f8b\u8f85\u52a9\u548c\u53f8\u6cd5\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u6cd5\u6761\u68c0\u7d22\u65b9\u6848\u3002"}}
{"id": "2601.17787", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17787", "abs": "https://arxiv.org/abs/2601.17787", "authors": ["Wei-Ning Chiu", "Chuan-Ju Wang", "Pu-Jen Cheng"], "title": "Token-Weighted Multi-Target Learning for Generative Recommenders with Curriculum Learning", "comment": "11 pages, 5 figures", "summary": "Generative recommender systems have recently attracted attention by formulating next-item prediction as an autoregressive sequence generation task. However, most existing methods optimize standard next-token likelihood and implicitly treat all tokens as equally informative, which is misaligned with semantic-ID-based generation. Accordingly, we propose two complementary information-gain-based token-weighting strategies tailored to generative recommendation with semantic IDs. Front-Greater Weighting captures conditional semantic information gain by prioritizing early tokens that most effectively reduce candidate-item uncertainty given their prefixes and encode coarse semantics. Frequency Weighting models marginal information gain under long-tailed item and token distributions, upweighting rare tokens to counteract popularity bias. Beyond individual strategies, we introduce a multi-target learning framework with curriculum learning that jointly optimizes the two token-weighted objectives alongside standard likelihood, enabling stable optimization and adaptive emphasis across training stages. Extensive experiments on benchmark datasets show that our method consistently outperforms strong baselines and existing token-weighting approaches, with improved robustness, strong generalization across different semantic-ID constructions, and substantial gains on both head and tail items. Code is available at https://github.com/CHIUWEINING/Token-Weighted-Multi-Target-Learning-for-Generative-Recommenders-with-Curriculum-Learning.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684token\u52a0\u6743\u7b56\u7565\uff08Front-Greater Weighting\u548cFrequency Weighting\uff09\u548c\u8bfe\u7a0b\u5b66\u4e60\u591a\u76ee\u6807\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u57fa\u4e8e\u8bed\u4e49ID\u7684\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4f7f\u7528\u6807\u51c6\u7684\u4e0b\u4e00\u4e2atoken\u4f3c\u7136\u4f18\u5316\uff0c\u5c06\u6240\u6709token\u89c6\u4e3a\u540c\u7b49\u91cd\u8981\uff0c\u8fd9\u4e0e\u57fa\u4e8e\u8bed\u4e49ID\u7684\u751f\u6210\u4efb\u52a1\u4e0d\u5339\u914d\u3002\u9700\u8981\u9488\u5bf9\u8bed\u4e49ID\u63a8\u8350\u7684\u7279\u70b9\u8bbe\u8ba1\u4e13\u95e8\u7684token\u52a0\u6743\u7b56\u7565\u3002", "method": "1. Front-Greater Weighting\uff1a\u57fa\u4e8e\u6761\u4ef6\u8bed\u4e49\u4fe1\u606f\u589e\u76ca\uff0c\u4f18\u5148\u52a0\u6743\u65e9\u671ftoken\uff08\u80fd\u6709\u6548\u51cf\u5c11\u5019\u9009\u9879\u76ee\u4e0d\u786e\u5b9a\u6027\uff0c\u7f16\u7801\u7c97\u7c92\u5ea6\u8bed\u4e49\uff09\u30022. Frequency Weighting\uff1a\u57fa\u4e8e\u8fb9\u9645\u4fe1\u606f\u589e\u76ca\uff0c\u5bf9\u7a00\u6709token\u8fdb\u884c\u52a0\u6743\u4ee5\u62b5\u6d88\u6d41\u884c\u5ea6\u504f\u5dee\u30023. \u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u7684\u591a\u76ee\u6807\u5b66\u4e60\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u4e24\u4e2atoken\u52a0\u6743\u76ee\u6807\u548c\u6807\u51c6\u4f3c\u7136\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e00\u81f4\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u548c\u73b0\u6709token\u52a0\u6743\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u5728\u4e0d\u540c\u8bed\u4e49ID\u6784\u5efa\u65b9\u5f0f\u4e0a\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u5934\u90e8\u548c\u5c3e\u90e8\u9879\u76ee\u4e0a\u90fd\u83b7\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684token\u52a0\u6743\u7b56\u7565\u548c\u591a\u76ee\u6807\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u4e49ID\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684token\u91cd\u8981\u6027\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2601.17836", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17836", "abs": "https://arxiv.org/abs/2601.17836", "authors": ["Weijiang Lai", "Beihong Jin", "Di Zhang", "Siru Chen", "Jiongyan Zhang", "Yuhang Gou", "Jian Dong", "Xingxing Wang"], "title": "Unleashing the Potential of Sparse Attention on Long-term Behaviors for CTR Prediction", "comment": null, "summary": "In recent years, the success of large language models (LLMs) has driven the exploration of scaling laws in recommender systems. However, models that demonstrate scaling laws are actually challenging to deploy in industrial settings for modeling long sequences of user behaviors, due to the high computational complexity of the standard self-attention mechanism. Despite various sparse self-attention mechanisms proposed in other fields, they are not fully suited for recommendation scenarios. This is because user behaviors exhibit personalization and temporal characteristics: different users have distinct behavior patterns, and these patterns change over time, with data from these users differing significantly from data in other fields in terms of distribution. To address these challenges, we propose SparseCTR, an efficient and effective model specifically designed for long-term behaviors of users. To be precise, we first segment behavior sequences into chunks in a personalized manner to avoid separating continuous behaviors and enable parallel processing of sequences. Based on these chunks, we propose a three-branch sparse self-attention mechanism to jointly identify users' global interests, interest transitions, and short-term interests. Furthermore, we design a composite relative temporal encoding via learnable, head-specific bias coefficients, better capturing sequential and periodic relationships among user behaviors. Extensive experimental results show that SparseCTR not only improves efficiency but also outperforms state-of-the-art methods. More importantly, it exhibits an obvious scaling law phenomenon, maintaining performance improvements across three orders of magnitude in FLOPs. In online A/B testing, SparseCTR increased CTR by 1.72\\% and CPM by 1.41\\%. Our source code is available at https://github.com/laiweijiang/SparseCTR.", "AI": {"tldr": "SparseCTR\uff1a\u9488\u5bf9\u7528\u6237\u957f\u884c\u4e3a\u5e8f\u5217\u7684\u9ad8\u6548\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u5206\u5757\u548c\u4e09\u5206\u652f\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u63d0\u5347\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u6027\u80fd\u6539\u8fdb\u5e76\u5c55\u73b0\u7f29\u653e\u5b9a\u5f8b\u73b0\u8c61\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u5b9a\u5f8b\u96be\u4ee5\u5728\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u90e8\u7f72\uff0c\u56e0\u4e3a\u6807\u51c6\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u800c\u73b0\u6709\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u4e0d\u9002\u5408\u63a8\u8350\u573a\u666f\u3002\u7528\u6237\u884c\u4e3a\u5177\u6709\u4e2a\u6027\u5316\u548c\u65f6\u5e8f\u7279\u6027\uff0c\u4e0d\u540c\u7528\u6237\u884c\u4e3a\u6a21\u5f0f\u5dee\u5f02\u5927\u4e14\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u6570\u636e\u5206\u5e03\u4e0e\u5176\u4ed6\u9886\u57df\u663e\u8457\u4e0d\u540c\u3002", "method": "1. \u4e2a\u6027\u5316\u5206\u5757\uff1a\u5c06\u884c\u4e3a\u5e8f\u5217\u6309\u4e2a\u6027\u5316\u65b9\u5f0f\u5206\u5757\uff0c\u907f\u514d\u5206\u79bb\u8fde\u7eed\u884c\u4e3a\u5e76\u652f\u6301\u5e76\u884c\u5904\u7406\uff1b2. \u4e09\u5206\u652f\u7a00\u758f\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff1a\u8054\u5408\u8bc6\u522b\u7528\u6237\u7684\u5168\u5c40\u5174\u8da3\u3001\u5174\u8da3\u8f6c\u79fb\u548c\u77ed\u671f\u5174\u8da3\uff1b3. \u590d\u5408\u76f8\u5bf9\u65f6\u5e8f\u7f16\u7801\uff1a\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5934\u7279\u5b9a\u504f\u7f6e\u7cfb\u6570\uff0c\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u884c\u4e3a\u7684\u5e8f\u5217\u548c\u5468\u671f\u6027\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aSparseCTR\u4e0d\u4ec5\u63d0\u9ad8\u6548\u7387\uff0c\u800c\u4e14\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u5c55\u73b0\u51fa\u660e\u663e\u7684\u7f29\u653e\u5b9a\u5f8b\u73b0\u8c61\uff0c\u5728\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684FLOPs\u8303\u56f4\u5185\u4fdd\u6301\u6027\u80fd\u6539\u8fdb\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0cCTR\u63d0\u53471.72%\uff0cCPM\u63d0\u53471.41%\u3002", "conclusion": "SparseCTR\u662f\u9488\u5bf9\u7528\u6237\u957f\u884c\u4e3a\u5e8f\u5217\u7684\u9ad8\u6548\u6709\u6548\u6a21\u578b\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u5206\u5757\u548c\u4e09\u5206\u652f\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u4e86\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u4e2a\u6027\u5316\u65f6\u5e8f\u7279\u6027\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u5e76\u5c55\u73b0\u51fa\u7f29\u653e\u5b9a\u5f8b\u7279\u6027\u3002"}}
{"id": "2601.18009", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18009", "abs": "https://arxiv.org/abs/2601.18009", "authors": ["Ervin Dervishaj", "Maria Maistro", "Tuukka Ruotsalo", "Christina Lioma"], "title": "Post-Training Denoising of User Profiles with LLMs in Collaborative Filtering Recommendation", "comment": "Accepted at the 48th European Conference on Information Retrieval (ECIR 2026)", "summary": "Implicit feedback -- the main data source for training Recommender Systems (RSs) -- is inherently noisy and has been shown to negatively affect recommendation effectiveness. Denoising has been proposed as a method for removing noisy implicit feedback and improving recommendations. Prior work has focused on in-training denoising, however this requires additional data, changes to the model architecture and training procedure or fine-tuning, all of which can be costly and data hungry. In this work, we focus on post-training denoising. Different from in-training denoising, post-training denoising does not involve changing the architecture of the model nor its training procedure, and does not require additional data. Specifically, we present a method for post-training denoising user profiles using Large Language Models (LLMs) for Collaborative Filtering (CF) recommendations. Our approach prompts LLMs with (i) a user profile (user interactions), (ii) a candidate item, and (iii) its rank as given by the CF recommender, and asks the LLM to remove items from the user profile to improve the rank of the candidate item. Experiments with a state-of-the-art CF recommender and 4 open and closed source LLMs in 3 datasets show that our denoising yields improvements up to 13% in effectiveness over the original user profiles. Our code is available at https://github.com/edervishaj/denoising-user-profiles-LLM.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u793aLLM\u4ece\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u4e2d\u79fb\u9664\u566a\u58f0\u4ea4\u4e92\uff0c\u63d0\u5347\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u6548\u679c\uff0c\u65e0\u9700\u6539\u53d8\u6a21\u578b\u67b6\u6784\u6216\u989d\u5916\u6570\u636e\u3002", "motivation": "\u9690\u5f0f\u53cd\u9988\u6570\u636e\u5b58\u5728\u566a\u58f0\uff0c\u4f20\u7edf\u53bb\u566a\u65b9\u6cd5\u9700\u8981\u989d\u5916\u6570\u636e\u3001\u6539\u53d8\u6a21\u578b\u67b6\u6784\u6216\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u6210\u672c\u9ad8\u4e14\u6570\u636e\u9700\u6c42\u5927\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u6539\u53d8\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u67b6\u6784\u7684\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\uff1a\u4f7f\u7528LLM\u5904\u7406\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u3001\u5019\u9009\u7269\u54c1\u53ca\u5176CF\u6392\u540d\uff0c\u901a\u8fc7\u63d0\u793aLLM\u79fb\u9664\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u566a\u58f0\u7269\u54c1\u6765\u63d0\u5347\u5019\u9009\u7269\u54c1\u6392\u540d\u3002\u65e0\u9700\u6539\u53d8CF\u6a21\u578b\u67b6\u6784\u6216\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u57283\u4e2a\u6570\u636e\u96c6\u4e0a\u4f7f\u75284\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90LLM\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4e0e\u6700\u5148\u8fdb\u7684CF\u63a8\u8350\u5668\u7ed3\u5408\uff0c\u53bb\u566a\u540e\u7684\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u4f7f\u63a8\u8350\u6548\u679c\u63d0\u5347\u9ad8\u8fbe13%\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u9690\u5f0f\u53cd\u9988\u566a\u58f0\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6548\u679c\uff0c\u4e14\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u6a21\u578b\u67b6\u6784\u4fee\u6539\uff0c\u5177\u6709\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.18096", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18096", "abs": "https://arxiv.org/abs/2601.18096", "authors": ["Yuting Zhang", "Ziliang Pei", "Chao Wang", "Ying Sun", "Fuzhen Zhuang"], "title": "Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph", "comment": null, "summary": "LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4ea4\u4e92\u77e5\u8bc6\u56fe\u8c31\u7684\u504f\u597d\u63d0\u793a\u53d1\u73b0\u6a21\u578b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u63d0\u53d6\u5173\u952e\u5c5e\u6027\u4f5c\u4e3a\u63d0\u793a\u6765\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf", "motivation": "LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u96be\u4ee5\u6355\u6349\u590d\u6742\u504f\u597d\u6a21\u5f0f\uff0c\u4f20\u7edf\u63a8\u8350\u5d4c\u5165\u4e0eLLM\u79bb\u6563\u8bed\u4e49\u7a7a\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u627e\u5230\u6709\u6548\u65b9\u6cd5\u5c06\u5c5e\u6027\u77e5\u8bc6\u8f6c\u5316\u4e3aLLM\u53ef\u7406\u89e3\u7684\u504f\u597d\u63d0\u793a", "method": "1) \u534f\u4f5c\u504f\u597d\u63d0\u793a\u63d0\u53d6\u65b9\u6848\uff1a\u5229\u7528\u76f8\u4f3c\u7528\u6237\u663e\u5f0f\u4ea4\u4e92\u7684\u8bed\u4e49\u77e5\u8bc6\u4f5c\u4e3a\u672a\u89c1\u7269\u54c1\u7684\u63d0\u793a\uff1b2) \u5b9e\u4f8b\u7ea7\u53cc\u91cd\u6ce8\u610f\u529b\u673a\u5236\uff1a\u91cf\u5316\u5019\u9009\u5c5e\u6027\u7684\u504f\u597d\u53ef\u4fe1\u5ea6\uff1b3) \u6241\u5e73\u5316\u63d0\u793a\u7ec4\u7ec7\u65b9\u6cd5\u7f29\u77ed\u8f93\u5165\u957f\u5ea6", "result": "\u5728\u6210\u5bf9\u548c\u5217\u8868\u63a8\u8350\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u5e73\u5747\u76f8\u5bf9\u6539\u8fdb\u8d85\u8fc73.02%", "conclusion": "\u901a\u8fc7\u504f\u597d\u63d0\u793a\u53d1\u73b0\u6a21\u578b\u6709\u6548\u5f25\u5408\u4e86\u4f20\u7edf\u63a8\u8350\u5d4c\u5165\u4e0eLLM\u8bed\u4e49\u7a7a\u95f4\u7684\u5dee\u8ddd\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u6027\u80fd"}}
{"id": "2601.18146", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18146", "abs": "https://arxiv.org/abs/2601.18146", "authors": ["Huizhong Guo", "Tianjun Wei", "Dongxia Wang", "Yingpeng Du", "Ziyan Wang", "Jie Zhang", "Zhu Sun"], "title": "Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking", "comment": null, "summary": "Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\\% NDCG@10 with -49.5\\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off.", "AI": {"tldr": "\u63d0\u51fa\u63a8\u7406\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u63a8\u7406\u6a21\u5f0f\uff0c\u5728\u63d0\u5347\u6392\u5e8f\u6548\u679c\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "motivation": "LLM\u5728\u6392\u5e8f\u4efb\u52a1\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u63a8\u7406\u63d0\u793a\u80fd\u63d0\u5347\u6548\u679c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6548\u679c\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u667a\u80fd\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u63a8\u7406", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u53ef\u63d2\u62d4\u8def\u7531\u5668\u5934\uff0c\u57fa\u4e8e\u9884\u751f\u6210\u4fe1\u53f7\uff08\u6392\u5e8f\u611f\u77e5\u7279\u5f81\u548c\u6a21\u578b\u611f\u77e5\u96be\u5ea6\u4fe1\u53f7\uff09\u51b3\u5b9a\u4f7f\u7528\u76f4\u63a5\u63a8\u7406\u8fd8\u662f\u63a8\u7406\u6a21\u5f0f\uff0c\u8def\u7531\u5668\u53ef\u6cbf\u9a8c\u8bc1Pareto\u524d\u6cbf\u81ea\u9002\u5e94\u9009\u62e9\u7b56\u7565", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6392\u5e8f\u6570\u636e\u96c6\u4e0a\uff0c\u4e0d\u540c\u89c4\u6a21\u7684LLM\u5747\u663e\u793a\u6392\u5e8f\u6548\u679c\u63d0\u5347\u4e14token\u6d88\u8017\u51cf\u5c11\uff08\u5982MovieLens\u4e0aNDCG@10\u63d0\u53476.3%\uff0ctoken\u51cf\u5c1149.5%\uff09", "conclusion": "\u63a8\u7406\u8def\u7531\u6846\u67b6\u662f\u89e3\u51b3\u6392\u5e8f\u4efb\u52a1\u4e2d\u51c6\u786e\u6027\u4e0e\u6548\u7387\u6743\u8861\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u5230\u6700\u9700\u8981\u63a8\u7406\u7684\u5b9e\u4f8b"}}
{"id": "2601.18203", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18203", "abs": "https://arxiv.org/abs/2601.18203", "authors": ["ShunLiang Fu", "Yanxin Zhang", "Yixin Xiang", "Xiaoyu Du", "Jinhui Tang"], "title": "DMAP: Human-Aligned Structural Document Map for Multimodal Document Understanding", "comment": null, "summary": "Existing multimodal document question-answering (QA) systems predominantly rely on flat semantic retrieval, representing documents as a set of disconnected text chunks and largely neglecting their intrinsic hierarchical and relational structures. Such flattening disrupts logical and spatial dependencies - such as section organization, figure-text correspondence, and cross-reference relations, that humans naturally exploit for comprehension. To address this limitation, we introduce a document-level structural Document MAP (DMAP), which explicitly encodes both hierarchical organization and inter-element relationships within multimodal documents. Specifically, we design a Structured-Semantic Understanding Agent to construct DMAP by organizing textual content together with figures, tables, charts, etc. into a human-aligned hierarchical schema that captures both semantic and layout dependencies. Building upon this representation, a Reflective Reasoning Agent performs structure-aware and evidence-driven reasoning, dynamically assessing the sufficiency of retrieved context and iteratively refining answers through targeted interactions with DMAP. Extensive experiments on MMDocQA benchmarks demonstrate that DMAP yields document-specific structural representations aligned with human interpretive patterns, substantially enhancing retrieval precision, reasoning consistency, and multimodal comprehension over conventional RAG-based approaches. Code is available at https://github.com/Forlorin/DMAP", "AI": {"tldr": "DMAP\u63d0\u51fa\u4e86\u4e00\u79cd\u6587\u6863\u7ea7\u7ed3\u6784\u5316\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u7ec4\u7ec7\u548c\u5173\u7cfb\u7f16\u7801\u6765\u63d0\u5347\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u6027\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edf\u6241\u5e73\u5316\u68c0\u7d22\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u6241\u5e73\u5316\u8bed\u4e49\u68c0\u7d22\uff0c\u5c06\u6587\u6863\u8868\u793a\u4e3a\u4e0d\u8fde\u63a5\u7684\u6587\u672c\u5757\uff0c\u5ffd\u7565\u4e86\u6587\u6863\u5185\u5728\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u5173\u7cfb\u7ed3\u6784\uff08\u5982\u7ae0\u8282\u7ec4\u7ec7\u3001\u56fe\u6587\u5bf9\u5e94\u3001\u4ea4\u53c9\u5f15\u7528\u7b49\uff09\uff0c\u8fd9\u79cd\u6241\u5e73\u5316\u7834\u574f\u4e86\u4eba\u7c7b\u81ea\u7136\u7406\u89e3\u6587\u6863\u65f6\u4f9d\u8d56\u7684\u903b\u8f91\u548c\u7a7a\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "1. \u5f15\u5165\u6587\u6863\u7ea7\u7ed3\u6784\u5316\u6587\u6863\u5730\u56fe\uff08DMAP\uff09\uff0c\u663e\u5f0f\u7f16\u7801\u591a\u6a21\u6001\u6587\u6863\u4e2d\u7684\u5c42\u6b21\u7ec4\u7ec7\u548c\u5143\u7d20\u95f4\u5173\u7cfb\uff1b2. \u8bbe\u8ba1\u7ed3\u6784\u5316\u8bed\u4e49\u7406\u89e3\u4ee3\u7406\u6765\u6784\u5efaDMAP\uff0c\u5c06\u6587\u672c\u5185\u5bb9\u4e0e\u56fe\u8868\u7b49\u7ec4\u7ec7\u6210\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684\u5c42\u6b21\u5316\u6a21\u5f0f\uff0c\u6355\u6349\u8bed\u4e49\u548c\u5e03\u5c40\u4f9d\u8d56\uff1b3. \u57fa\u4e8e\u6b64\u8868\u793a\uff0c\u8bbe\u8ba1\u53cd\u601d\u63a8\u7406\u4ee3\u7406\u8fdb\u884c\u7ed3\u6784\u611f\u77e5\u548c\u8bc1\u636e\u9a71\u52a8\u7684\u63a8\u7406\uff0c\u52a8\u6001\u8bc4\u4f30\u68c0\u7d22\u4e0a\u4e0b\u6587\u7684\u5145\u5206\u6027\uff0c\u5e76\u901a\u8fc7\u4e0eDMAP\u7684\u5b9a\u5411\u4ea4\u4e92\u8fed\u4ee3\u4f18\u5316\u7b54\u6848\u3002", "result": "\u5728MMDocQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDMAP\u80fd\u591f\u751f\u6210\u4e0e\u4eba\u7c7b\u89e3\u91ca\u6a21\u5f0f\u5bf9\u9f50\u7684\u6587\u6863\u7279\u5b9a\u7ed3\u6784\u5316\u8868\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u57fa\u4e8eRAG\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u7cbe\u5ea6\u3001\u63a8\u7406\u4e00\u81f4\u6027\u548c\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "DMAP\u901a\u8fc7\u663e\u5f0f\u7f16\u7801\u6587\u6863\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6241\u5e73\u5316\u68c0\u7d22\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u63d0\u4f9b\u4e86\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684\u7ed3\u6784\u5316\u8868\u793a\u548c\u63a8\u7406\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2601.18213", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18213", "abs": "https://arxiv.org/abs/2601.18213", "authors": ["Chengkai Huang", "Xiaodi Chen", "Hongtao Huang", "Quan Z. Sheng", "Lina Yao"], "title": "Generative Chain of Behavior for User Trajectory Prediction", "comment": null, "summary": "Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.", "AI": {"tldr": "GCB\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u884c\u4e3a\u94fe\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u7528\u6237\u591a\u6b65\u672a\u6765\u884c\u4e3a\u8f68\u8ff9\uff0c\u901a\u8fc7\u8bed\u4e49ID\u7f16\u7801\u548c\u81ea\u56de\u5f52\u751f\u6210\u5b9e\u73b0\u957f\u671f\u610f\u56fe\u9884\u6d4b\u3002", "motivation": "\u5927\u591a\u6570\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u53ea\u5173\u6ce8\u4e0b\u4e00\u4e2a\u7269\u54c1\u9884\u6d4b\uff0c\u5ffd\u7565\u4e86\u591a\u4e2a\u672a\u6765\u52a8\u4f5c\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u65e0\u6cd5\u7406\u89e3\u7528\u6237\u504f\u597d\u6f14\u53d8\u548c\u5b9e\u73b0\u4e3b\u52a8\u63a8\u8350\u3002", "method": "\u4f7f\u7528RQ-VAE\u548ck-means\u805a\u7c7b\u5c06\u7269\u54c1\u7f16\u7801\u4e3a\u8bed\u4e49ID\uff0c\u6784\u5efa\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u4fdd\u6301\u8bed\u4e49\u90bb\u8fd1\u6027\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u751f\u6210\u5668\u9884\u6d4b\u591a\u6b65\u672a\u6765\u884c\u4e3a\uff0c\u6355\u6349\u957f\u671f\u610f\u56fe\u8f6c\u6362\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGCB\u5728\u591a\u6b65\u51c6\u786e\u6027\u548c\u8f68\u8ff9\u4e00\u81f4\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u3002", "conclusion": "GCB\u4e0d\u4ec5\u53d6\u5f97\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6210\u5f0f\u6846\u67b6\u6765\u6355\u6349\u7528\u6237\u504f\u597d\u6f14\u53d8\uff0c\u4e3a\u7406\u89e3\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.18251", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18251", "abs": "https://arxiv.org/abs/2601.18251", "authors": ["Kesha Ou", "Zhen Tian", "Wayne Xin Zhao", "Hongyu Lu", "Ji-Rong Wen"], "title": "GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction", "comment": "Accepted by WWW 2026 Research Track", "summary": "Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach.", "AI": {"tldr": "GenCI\uff1a\u57fa\u4e8e\u751f\u6210\u5f0f\u7528\u6237\u610f\u56fe\u6846\u67b6\u7684CTR\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u5174\u8da3\u7fa4\u7ec4\u5efa\u6a21\u52a8\u6001\u7528\u6237\u504f\u597d\uff0c\u89e3\u51b3\u5386\u53f2\u7279\u5f81\u8fc7\u62df\u5408\u548c\u70b9\u5f0f\u6392\u5e8f\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002", "motivation": "\u5f53\u524dCTR\u9884\u6d4b\u5b58\u5728\u4e24\u5927\u6311\u6218\uff1a1\uff09\u5224\u522b\u5f0f\u8303\u5f0f\u8fc7\u5ea6\u62df\u5408\u5386\u53f2\u4e3b\u5bfc\u7279\u5f81\uff0c\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u5174\u8da3\u53d8\u5316\uff1b2\uff09\u70b9\u5f0f\u6392\u5e8f\u8303\u5f0f\u4e22\u5f03\u53ec\u56de\u96c6\u7684\u4e30\u5bcc\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff0c\u5bfc\u81f4\u957f\u671f\u504f\u597d\u538b\u5236\u5373\u65f6\u610f\u56fe\u3002", "method": "\u63d0\u51faGenCI\u751f\u6210\u5f0f\u7528\u6237\u610f\u56fe\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u751f\u6210\u6a21\u578b\uff08NTP\u76ee\u6807\uff09\u4e3b\u52a8\u751f\u6210\u5019\u9009\u5174\u8da3\u7fa4\u7ec4\u4f5c\u4e3a\u7528\u6237\u5373\u65f6\u610f\u56fe\u7684\u663e\u5f0f\u8868\u793a\uff1b2\uff09\u5206\u5c42\u5019\u9009\u611f\u77e5\u7f51\u7edc\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u6ce8\u5165\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff0c\u5bf9\u9f50\u7528\u6237\u5386\u53f2\u548c\u76ee\u6807\u5546\u54c1\uff1b3\uff09\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "GenCI\u901a\u8fc7\u751f\u6210\u5f0f\u5174\u8da3\u7fa4\u7ec4\u5efa\u6a21\u52a8\u6001\u7528\u6237\u610f\u56fe\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfCTR\u9884\u6d4b\u7684\u8fc7\u62df\u5408\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u5bf9\u9f50\u548c\u6709\u6548\u7684CTR\u9884\u6d4b\u6d41\u7a0b\u3002"}}
{"id": "2601.18267", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18267", "abs": "https://arxiv.org/abs/2601.18267", "authors": ["Xincheng You", "Qi Sun", "Neha Bora", "Huayi Li", "Shubham Goel", "Kang Li", "Sean Culatana"], "title": "Orchestrating Specialized Agents for Trustworthy Enterprise RAG", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) shows promise for enterprise knowledge work, yet it often underperforms in high-stakes decision settings that require deep synthesis, strict traceability, and recovery from underspecified prompts. One-pass retrieval-and-write pipelines frequently yield shallow summaries, inconsistent grounding, and weak mechanisms for completeness verification. We introduce ADORE (Adaptive Deep Orchestration for Research in Enterprise), an agentic framework that replaces linear retrieval with iterative, user-steered investigation coordinated by a central orchestrator and a set of specialized agents. ADORE's key insight is that a structured Memory Bank (a curated evidence store with explicit claim-evidence linkage and section-level admissible evidence) enables traceable report generation and systematic checks for evidence completeness. Our contributions are threefold: (1) Memory-locked synthesis - report generation is constrained to a structured Memory Bank (Claim-Evidence Graph) with section-level admissible evidence, enabling traceable claims and grounded citations; (2) Evidence-coverage-guided execution - a retrieval-reflection loop audits section-level evidence coverage to trigger targeted follow-up retrieval and terminates via an evidence-driven stopping criterion; (3) Section-packed long-context grounding - section-level packing, pruning, and citation-preserving compression make long-form synthesis feasible under context limits. Across our evaluation suite, ADORE ranks first on DeepResearch Bench (52.65) and achieves the highest head-to-head preference win rate on DeepConsult (77.2%) against commercial systems.", "AI": {"tldr": "ADORE\u662f\u4e00\u4e2a\u7528\u4e8e\u4f01\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bb0\u5fc6\u5e93\u548c\u8fed\u4ee3\u68c0\u7d22\u673a\u5236\u89e3\u51b3\u4f20\u7edfRAG\u5728\u6df1\u5ea6\u5408\u6210\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u5b8c\u6574\u6027\u9a8c\u8bc1\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u4f01\u4e1a\u9ad8\u4ef7\u503c\u51b3\u7b56\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u6d45\u5c42\u603b\u7ed3\u3001\u4e0d\u4e00\u81f4\u7684\u63a5\u5730\u548c\u5f31\u5b8c\u6574\u6027\u9a8c\u8bc1\u673a\u5236\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u6846\u67b6\u6765\u652f\u6301\u6df1\u5ea6\u5408\u6210\u3001\u4e25\u683c\u53ef\u8ffd\u6eaf\u6027\u548c\u5bf9\u4e0d\u660e\u786e\u63d0\u793a\u7684\u6062\u590d\u80fd\u529b\u3002", "method": "ADORE\u91c7\u7528\u4ee3\u7406\u6846\u67b6\uff0c\u6838\u5fc3\u5305\u62ec\uff1a1\uff09\u7ed3\u6784\u5316\u8bb0\u5fc6\u5e93\uff08Claim-Evidence Graph\uff09\u5b9e\u73b0\u8bb0\u5fc6\u9501\u5b9a\u5408\u6210\uff1b2\uff09\u8bc1\u636e\u8986\u76d6\u5f15\u5bfc\u7684\u6267\u884c\u673a\u5236\uff0c\u901a\u8fc7\u68c0\u7d22-\u53cd\u601d\u5faa\u73af\u5ba1\u8ba1\u8bc1\u636e\u5b8c\u6574\u6027\uff1b3\uff09\u7ae0\u8282\u6253\u5305\u957f\u4e0a\u4e0b\u6587\u63a5\u5730\u6280\u672f\uff0c\u5728\u4e0a\u4e0b\u6587\u9650\u5236\u4e0b\u5b9e\u73b0\u957f\u683c\u5f0f\u5408\u6210\u3002", "result": "\u5728DeepResearch Bench\u4e0a\u83b7\u5f9752.65\u5206\u6392\u540d\u7b2c\u4e00\uff0c\u5728DeepConsult\u4e0a\u4e0e\u5546\u4e1a\u7cfb\u7edf\u76f8\u6bd4\u83b7\u5f9777.2%\u7684\u6700\u9ad8\u5934\u5bf9\u5934\u504f\u597d\u80dc\u7387\u3002", "conclusion": "ADORE\u901a\u8fc7\u7ed3\u6784\u5316\u8bb0\u5fc6\u5e93\u548c\u8fed\u4ee3\u4ee3\u7406\u534f\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f01\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u4e2dRAG\u7cfb\u7edf\u7684\u6df1\u5ea6\u5408\u6210\u80fd\u529b\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u5b8c\u6574\u6027\u9a8c\u8bc1\uff0c\u4e3a\u9ad8\u4ef7\u503c\u51b3\u7b56\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18432", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18432", "abs": "https://arxiv.org/abs/2601.18432", "authors": ["Sirui Chen", "Jiawei Chen", "Canghong Jin", "Sheng Zhou", "Jingbang Chen", "Wujie Sun", "Can Wang"], "title": "TopKGAT: A Top-K Objective-Driven Architecture for Recommendation", "comment": "Accepted by WWW2026", "summary": "Recommendation systems (RS) aim to retrieve the top-K items most relevant to users, with metrics such as Precision@K and Recall@K commonly used to assess effectiveness. The architecture of an RS model acts as an inductive bias, shaping the patterns the model is inclined to learn. In recent years, numerous recommendation architectures have emerged, spanning traditional matrix factorization, deep neural networks, and graph neural networks. However, their designs are often not explicitly aligned with the top-K objective, thereby limiting their effectiveness.\n  To address this limitation, we propose TopKGAT, a novel recommendation architecture directly derived from a differentiable approximation of top-K metrics. The forward computation of a single TopKGAT layer is intrinsically aligned with the gradient ascent dynamics of the Precision@K metric, enabling the model to naturally improve top-K recommendation accuracy. Structurally, TopKGAT resembles a graph attention network and can be implemented efficiently. Extensive experiments on four benchmark datasets demonstrate that TopKGAT consistently outperforms state-of-the-art baselines. The code is available at https://github.com/StupidThree/TopKGAT.", "AI": {"tldr": "TopKGAT\u662f\u4e00\u79cd\u76f4\u63a5\u4ecetop-K\u6307\u6807\u7684\u53ef\u5fae\u5206\u8fd1\u4f3c\u63a8\u5bfc\u51fa\u7684\u63a8\u8350\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u524d\u5411\u8ba1\u7b97\u4e0ePrecision@K\u7684\u68af\u5ea6\u4e0a\u5347\u52a8\u6001\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86top-K\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u67b6\u6784\uff08\u5982\u77e9\u9635\u5206\u89e3\u3001\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\uff09\u7684\u8bbe\u8ba1\u901a\u5e38\u6ca1\u6709\u660e\u786e\u4e0etop-K\u76ee\u6807\u5bf9\u9f50\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728top-K\u63a8\u8350\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faTopKGAT\u67b6\u6784\uff0c\u4ecetop-K\u6307\u6807\u7684\u53ef\u5fae\u5206\u8fd1\u4f3c\u76f4\u63a5\u63a8\u5bfc\u800c\u6765\uff0c\u5176\u5355\u5c42\u524d\u5411\u8ba1\u7b97\u4e0ePrecision@K\u6307\u6807\u7684\u68af\u5ea6\u4e0a\u5347\u52a8\u6001\u5185\u5728\u5bf9\u9f50\uff0c\u7ed3\u6784\u7c7b\u4f3c\u4e8e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u4e14\u5b9e\u73b0\u9ad8\u6548\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTopKGAT\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TopKGAT\u901a\u8fc7\u5c06\u67b6\u6784\u8bbe\u8ba1\u4e0etop-K\u76ee\u6807\u76f4\u63a5\u5bf9\u9f50\uff0c\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684top-K\u51c6\u786e\u6027\uff0c\u4e3a\u63a8\u8350\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.18457", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18457", "abs": "https://arxiv.org/abs/2601.18457", "authors": ["Fake Lin", "Binbin Hu", "Zhi Zheng", "Xi Zhu", "Ziqi Liu", "Zhiqiang Zhang", "Jun Zhou", "Tong Xu"], "title": "Token-level Collaborative Alignment for LLM-based Generative Recommendation", "comment": "11 pages, 2 figures, 7 tables, WWW 2026", "summary": "Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems.", "AI": {"tldr": "TCA4Rec\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u4ee4\u724c\u7ea7\u534f\u540c\u5bf9\u9f50\u89e3\u51b3LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u96be\u4ee5\u6709\u6548\u6574\u5408\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6709\u6548\u6574\u5408\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\uff0c\u56e0\u4e3aCF\u7684\u9879\u7ea7\u504f\u597d\u5efa\u6a21\u4e0eLLM\u7684\u4ee4\u724c\u7ea7\u4e0b\u4e00\u4e2a\u4ee4\u724c\u9884\u6d4b\u4f18\u5316\u5b58\u5728\u6839\u672c\u6027\u4e0d\u5339\u914d\u3002\u5148\u524d\u65b9\u6cd5\u901a\u5e38\u5c06CF\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u63d0\u793a\u6216\u8868\u793a\u504f\u5dee\uff0c\u9700\u8981\u591a\u9636\u6bb5\u8bad\u7ec3\u6765\u51cf\u5c11\u884c\u4e3a\u8bed\u4e49\u7a7a\u95f4\u5dee\u5f02\uff0c\u5bfc\u81f4CF\u65e0\u6cd5\u660e\u786e\u8c03\u63a7LLM\u751f\u6210\u3002", "method": "TCA4Rec\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u534f\u540c\u5206\u8bcd\u5668\uff1a\u5c06\u539f\u59cb\u9879\u7ea7CF\u5bf9\u6570\u6295\u5f71\u5230\u4e0eLLM\u4ee4\u724c\u7a7a\u95f4\u5bf9\u9f50\u7684\u4ee4\u724c\u7ea7\u5206\u5e03\uff1b(2) \u8f6f\u6807\u7b7e\u5bf9\u9f50\uff1a\u5c06\u8fd9\u4e9bCF\u4fe1\u606f\u5206\u5e03\u4e0e\u72ec\u70ed\u76d1\u7763\u7ed3\u5408\uff0c\u4f18\u5316\u8f6fNTP\u76ee\u6807\u3002\u8be5\u8bbe\u8ba1\u4fdd\u7559\u4e86LLM\u8bad\u7ec3\u7684\u751f\u6210\u7279\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u4e0eCF\u6a21\u578b\u6838\u5fc3\u7528\u6237\u504f\u597d\u7684\u534f\u540c\u5bf9\u9f50\u3002", "result": "TCA4Rec\u4e0e\u4efb\u610f\u4f20\u7edfCF\u6a21\u578b\u517c\u5bb9\uff0c\u53ef\u6cdb\u5316\u5230\u5e7f\u6cdb\u7684\u57fa\u4e8e\u89e3\u7801\u5668\u7684LLM\u63a8\u8350\u67b6\u6784\u3002\u5b83\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u673a\u5236\u6765\u5e73\u8861\u884c\u4e3a\u5bf9\u9f50\u548c\u8bed\u4e49\u6d41\u7545\u6027\uff0c\u751f\u6210\u65e2\u51c6\u786e\u53c8\u53ef\u63a7\u5236\u7684\u63a8\u8350\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cTCA4Rec\u5728\u5404\u79cdCF\u6a21\u578b\u548c\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u4e2d\u6301\u7eed\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "TCA4Rec\u901a\u8fc7\u5efa\u7acbCF\u76d1\u7763\u4e0eLLM\u751f\u6210\u4e4b\u95f4\u7684\u663e\u5f0f\u4f18\u5316\u7ea7\u63a5\u53e3\uff0c\u89e3\u51b3\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\u6574\u5408\u7684\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u5728\u51c6\u786e\u6027\u548c\u53ef\u63a7\u6027\u65b9\u9762\u7684\u5e73\u8861\u3002"}}
{"id": "2601.18570", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18570", "abs": "https://arxiv.org/abs/2601.18570", "authors": ["Mingzhe Han", "Jiahao Liu", "Dongsheng Li", "Hansu Gu", "Peng Zhang", "Ning Gu", "Tun Lu"], "title": "Feature-Indexed Federated Recommendation with Residual-Quantized Codebooks", "comment": null, "summary": "Federated recommendation provides a privacy-preserving solution for training recommender systems without centralizing user interactions. However, existing methods follow an ID-indexed communication paradigm that transmit whole item embeddings between clients and the server, which has three major limitations: 1) consumes uncontrollable communication resources, 2) the uploaded item information cannot generalize to related non-interacted items, and 3) is sensitive to client noisy feedback. To solve these problems, it is necessary to fundamentally change the existing ID-indexed communication paradigm. Therefore, we propose a feature-indexed communication paradigm that transmits feature code embeddings as codebooks rather than raw item embeddings. Building on this paradigm, we present RQFedRec, which assigns each item a list of discrete code IDs via Residual Quantization (RQ)-Kmeans. Each client generates and trains code embeddings as codebooks based on discrete code IDs provided by the server, and the server collects and aggregates these codebooks rather than item embeddings. This design makes communication controllable since the codebooks could cover all items, enabling updates to propagate across related items in same code ID. In addition, since code embedding represents many items, which is more robust to a single noisy item. To jointly capture semantic and collaborative information, RQFedRec further adopts a collaborative-semantic dual-channel aggregation with a curriculum strategy that emphasizes semantic codes early and gradually increases the contribution of collaborative codes over training. Extensive experiments on real-world datasets demonstrate that RQFedRec consistently outperforms state-of-the-art federated recommendation baselines while significantly reducing communication overhead.", "AI": {"tldr": "RQFedRec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\u7684\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u6b8b\u5dee\u91cf\u5316K-means\u5c06\u7269\u54c1\u8868\u793a\u4e3a\u79bb\u6563\u4ee3\u7801ID\uff0c\u4f20\u8f93\u4ee3\u7801\u5d4c\u5165\u800c\u975e\u539f\u59cb\u7269\u54c1\u5d4c\u5165\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u63a8\u8350\u65b9\u6cd5\u91c7\u7528ID\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\uff0c\u4f20\u8f93\u5b8c\u6574\u7684\u7269\u54c1\u5d4c\u5165\uff0c\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u901a\u4fe1\u8d44\u6e90\u6d88\u8017\u4e0d\u53ef\u63a7\uff1b2) \u4e0a\u4f20\u7684\u7269\u54c1\u4fe1\u606f\u65e0\u6cd5\u6cdb\u5316\u5230\u76f8\u5173\u672a\u4ea4\u4e92\u7269\u54c1\uff1b3) \u5bf9\u5ba2\u6237\u7aef\u566a\u58f0\u53cd\u9988\u654f\u611f\u3002\u9700\u8981\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u73b0\u6709\u901a\u4fe1\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u7279\u5f81\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\uff0c\u4f7f\u7528\u6b8b\u5dee\u91cf\u5316K-means\u4e3a\u6bcf\u4e2a\u7269\u54c1\u5206\u914d\u79bb\u6563\u4ee3\u7801ID\u5217\u8868\u3002\u5ba2\u6237\u7aef\u57fa\u4e8e\u670d\u52a1\u5668\u63d0\u4f9b\u7684\u4ee3\u7801ID\u751f\u6210\u548c\u8bad\u7ec3\u4ee3\u7801\u5d4c\u5165\u4f5c\u4e3a\u7801\u672c\uff0c\u670d\u52a1\u5668\u805a\u5408\u7801\u672c\u800c\u975e\u7269\u54c1\u5d4c\u5165\u3002\u91c7\u7528\u534f\u4f5c-\u8bed\u4e49\u53cc\u901a\u9053\u805a\u5408\u7b56\u7565\uff0c\u65e9\u671f\u5f3a\u8c03\u8bed\u4e49\u4ee3\u7801\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9010\u6b65\u589e\u52a0\u534f\u4f5c\u4ee3\u7801\u8d21\u732e\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRQFedRec\u5728\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\uff0c\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u8054\u90a6\u63a8\u8350\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RQFedRec\u901a\u8fc7\u7279\u5f81\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\u89e3\u51b3\u4e86\u73b0\u6709\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7684\u5173\u952e\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u53ef\u63a7\u901a\u4fe1\u3001\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u8054\u90a6\u63a8\u8350\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18579", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18579", "abs": "https://arxiv.org/abs/2601.18579", "authors": ["Seonho An", "Chaejeong Hyun", "Min-Soo Kim"], "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG", "comment": "under review", "summary": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.", "AI": {"tldr": "FastInsight\uff1a\u4e00\u79cd\u9ad8\u6548\u7684\u56feRAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u56fe\u6a21\u578b\u641c\u7d22\u548c\u5411\u91cf\u56fe\u641c\u7d22\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u6027\u548c\u751f\u6210\u8d28\u91cf", "motivation": "\u73b0\u6709\u56feRAG\u65b9\u6cd5\u4f9d\u8d56\u8017\u65f6\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\uff0c\u65e0\u6cd5\u5b9e\u73b0\u65f6\u95f4\u9ad8\u6548\u7684\u6df1\u5ea6\u68c0\u7d22\u3002\u901a\u8fc7\u56fe\u68c0\u7d22\u5206\u7c7b\u5b66\u5206\u6790\uff0c\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u62d3\u6251\u76f2\u70b9\uff08\u6a21\u578b\u641c\u7d22\uff09\u548c\u8bed\u4e49\u76f2\u70b9\uff08\u56fe\u641c\u7d22\uff09\u4e24\u4e2a\u5173\u952e\u9650\u5236", "method": "\u63d0\u51faFastInsight\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u9896\u7684\u878d\u5408\u7b97\u5b50\uff1a1) Graph-based Reranker (GRanker)\uff1a\u4f5c\u4e3a\u56fe\u6a21\u578b\u641c\u7d22\uff1b2) Semantic-Topological eXpansion (STeX)\uff1a\u4f5c\u4e3a\u5411\u91cf\u56fe\u641c\u7d22\u3002\u901a\u8fc7\u4ea4\u66ff\u4f7f\u7528\u8fd9\u4e24\u4e2a\u7b97\u5b50\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027", "result": "\u5728\u5e7f\u6cdb\u7684\u68c0\u7d22\u548c\u751f\u6210\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cFastInsight\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728\u6548\u679c\u548c\u6548\u7387\u7684\u6743\u8861\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5e15\u7d2f\u6258\u6539\u8fdb", "conclusion": "FastInsight\u901a\u8fc7\u521b\u65b0\u7684\u878d\u5408\u7b97\u5b50\u89e3\u51b3\u4e86\u73b0\u6709\u56feRAG\u65b9\u6cd5\u7684\u62d3\u6251\u76f2\u70b9\u548c\u8bed\u4e49\u76f2\u70b9\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u65f6\u95f4\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6df1\u5ea6\u6d1e\u5bdf\u68c0\u7d22\uff0c\u4e3a\u56fe\u68c0\u7d22\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18664", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18664", "abs": "https://arxiv.org/abs/2601.18664", "authors": ["Zihao Guo", "Jian Wang", "Ruxin Zhou", "Youhua Liu", "Jiawei Guo", "Jun Zhao", "Xiaoxiao Xu", "Yongqi Liu", "Kaiqiao Zhan"], "title": "S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform.", "AI": {"tldr": "\u63d0\u51faS\u00b2GR\u6846\u67b6\uff0c\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u9010\u6b65\u8bed\u4e49\u5f15\u5bfc\u63a8\u7406\u589e\u5f3a\u751f\u6210\u5f0f\u63a8\u8350\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u63a8\u7406\u4e0e\u751f\u6210\u5206\u79bb\u3001\u8ba1\u7b97\u4e0d\u5e73\u8861\u548c\u8bed\u4e49\u4e0d\u53ef\u89e3\u91ca\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4ece\u4ea4\u4e92\u5e8f\u5217\u76f4\u63a5\u751f\u6210\u8bed\u4e49ID\uff0c\u672a\u80fd\u6fc0\u6d3b\u7c7b\u4f3c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\uff0c\u9650\u5236\u4e86\u6027\u80fd\u6f5c\u529b\u3002\u73b0\u6709\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1) \u63a8\u7406\u4e0e\u751f\u6210\u6b65\u9aa4\u4e25\u683c\u5206\u79bb\u5bfc\u81f4\u5c42\u6b21\u5316\u8bed\u4e49ID\u4ee3\u7801\u8ba1\u7b97\u4e0d\u5e73\u8861\uff1b2) \u751f\u6210\u7684\u63a8\u7406\u5411\u91cf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u8bed\u4e49\uff0c\u63a8\u7406\u8def\u5f84\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u76d1\u7763\u3002", "method": "\u63d0\u51faS\u00b2GR\u6846\u67b6\uff1a1) \u901a\u8fc7\u4ee3\u7801\u672c\u4f18\u5316\u5efa\u7acb\u7a33\u5065\u8bed\u4e49\u57fa\u7840\uff0c\u6574\u5408\u7269\u54c1\u5171\u73b0\u5173\u7cfb\u6355\u83b7\u884c\u4e3a\u6a21\u5f0f\uff0c\u4f7f\u7528\u8d1f\u8f7d\u5e73\u8861\u548c\u5747\u5300\u6027\u76ee\u6807\u6700\u5927\u5316\u4ee3\u7801\u672c\u5229\u7528\u7387\u5e76\u5f3a\u5316\u4ece\u7c97\u5230\u7ec6\u7684\u8bed\u4e49\u5c42\u6b21\uff1b2) \u6838\u5fc3\u521b\u65b0\u5f15\u5165\u9010\u6b65\u63a8\u7406\u673a\u5236\uff0c\u5728\u6bcf\u4e2a\u8bed\u4e49ID\u751f\u6210\u6b65\u9aa4\u524d\u63d2\u5165\u601d\u8003\u6807\u8bb0\uff0c\u6bcf\u4e2a\u6807\u8bb0\u660e\u786e\u8868\u793a\u7c97\u7c92\u5ea6\u8bed\u4e49\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u76d1\u7763\u786e\u4fdd\u7269\u7406\u57fa\u7840\u63a8\u7406\u8def\u5f84\u548c\u6240\u6709\u8bed\u4e49ID\u4ee3\u7801\u7684\u5e73\u8861\u8ba1\u7b97\u5173\u6ce8\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eS\u00b2GR\u7684\u4f18\u8d8a\u6027\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u5728\u5927\u578b\u5de5\u4e1a\u77ed\u89c6\u9891\u5e73\u53f0\u4e0a\u786e\u8ba4\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "S\u00b2GR\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u9010\u6b65\u8bed\u4e49\u5f15\u5bfc\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u63a8\u7406\u4e0e\u751f\u6210\u5206\u79bb\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u5e73\u8861\u7684\u8ba1\u7b97\u5173\u6ce8\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2601.18747", "categories": ["cs.IR", "cs.AI", "cs.CC", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.18747", "abs": "https://arxiv.org/abs/2601.18747", "authors": ["Amir Aavani"], "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval", "comment": null, "summary": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.\n  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u68c0\u7d22\u8bed\u8a00\uff0c\u80fd\u9ad8\u6548\u5904\u7406\u590d\u6742\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u903b\u8f91\u548c\u7b97\u672f\u7ea6\u675f\uff0c\u89e3\u51b3\u73b0\u6709\u68c0\u7d22\u67b6\u6784\u7684\u6548\u7387\u56f0\u5883\u3002", "motivation": "\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u6b63\u4ece\u7b80\u5355\u6587\u6863\u8fc7\u6ee4\u8f6c\u5411\u590d\u6742\u7684\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5de5\u4f5c\u6d41\uff0c\u4f46\u73b0\u6709\u68c0\u7d22\u67b6\u6784\u5728\u5904\u7406\u903b\u8f91\u548c\u7b97\u672f\u7ea6\u675f\u65f6\u9762\u4e34\u6548\u7387\u56f0\u5883\uff1a\u57fa\u4e8e\u8fed\u4ee3\u5668\u7684\u5f15\u64ce\u4e0d\u652f\u6301\u590d\u6742\u5d4c\u5957\u903b\u8f91\u56fe\uff0c\u800c\u9012\u5f52\u65b9\u6cd5\u5219\u5b58\u5728\u5185\u5b58\u6d88\u8017\u8fc7\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u5f62\u5f0f\u5316\u68c0\u7d22\u8bed\u8a00\uff08\u2112\u1d63\uff09\uff0c\u8bc1\u660e\u5176\u7cbe\u786e\u6355\u83b7\u590d\u6742\u5ea6\u7c7bP\u3002\u5f15\u5165ComputePN\u7b97\u6cd5\uff0c\u7ed3\u5408\u539f\u751fDAG\u904d\u5386\u548c\u5185\u5b58\u9ad8\u6548\u7684\"\u6b63\u8d1f\"\u54cd\u5e94\u673a\u5236\uff0c\u786e\u4fdd\u2112\u1d63\u4e2d\u4efb\u4f55\u67e5\u8be2\u7684\u9ad8\u6548\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u641c\u7d22\u7d22\u5f15\u8f6c\u53d8\u4e3a\u901a\u7528\u8ba1\u7b97\u5f15\u64ce\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u8bc4\u4f30\u4efb\u4f55\u591a\u9879\u5f0f\u65f6\u95f4\u5c5e\u6027\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u67e5\u8be2\u6267\u884c\u65f6\u7684\u8fd0\u884c\u65f6\u6027\u80fd\u548c\u5185\u5b58\u6d88\u8017\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u68c0\u7d22\u8bed\u8a00\u548c\u9ad8\u6548\u8bc4\u4f30\u7b97\u6cd5\uff0c\u4e3a\u68c0\u7d22\u5f15\u64ce\u5904\u7406\u590d\u6742\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u641c\u7d22\u7d22\u5f15\u80fd\u591f\u4f5c\u4e3a\u901a\u7528\u8ba1\u7b97\u5f15\u64ce\u4f7f\u7528\u3002"}}
