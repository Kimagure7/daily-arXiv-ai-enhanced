<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Where to Explore: A Reach and Cost-Aware Approach for Unbiased Data Collection in Recommender Systems](https://arxiv.org/abs/2512.14733)
*Qiang Chen,Venkatesh Ganapati Hegde*

Main category: cs.IR

TL;DR: 论文提出了一种在流媒体平台中安全高效地引入内容探索的方法，通过优化探索内容的放置位置（基于覆盖范围和机会成本），在保持业务指标的同时收集无偏交互数据。


<details>
  <summary>Details</summary>
Motivation: 探索对于提升长期推荐质量至关重要，但在远程优先的电视环境中，用户被动参与、期望即时相关性且纠正机会少，探索往往会损害短期业务表现。需要一种既能进行内容探索又不显著影响平台观看时间目标的方法。

Method: 识别滚动深度区域中参与度较低的位置，策略性地引入名为"Something Completely Different"的专用容器行，其中包含随机化内容。该方法不强制在UI中统一实施探索，而是根据经验上低成本、高覆盖的位置条件性地显示探索内容，以最小化对平台级观看时间目标的影响。

Result: 在拥有超过1亿月活跃用户的大规模流媒体平台上部署，广泛的A/B测试表明该策略能够保持业务指标，同时收集无偏交互数据。收集的无偏数据集成到下游候选生成中，显著提高了用户参与度。

Conclusion: 该方法通过引入可部署的、基于行为感知的机制，在规模化展示探索性内容方面补充了现有的行内多样化和基于bandit的探索技术。验证了收集的无偏数据对推荐系统的价值，能够在不损害短期业务目标的情况下改善长期推荐质量。

Abstract: Exploration is essential to improve long-term recommendation quality, but it often degrades short-term business performance, especially in remote-first TV environments where users engage passively, expect instant relevance, and offer few chances for correction. This paper introduces an approach for delivering content-level exploration safely and efficiently by optimizing its placement based on reach and opportunity cost. Deployed on a large-scale streaming platform with over 100 million monthly active users, our approach identifies scroll-depth regions with lower engagement and strategically introduces a dedicated container, the "Something Completely Different" row containing randomized content. Rather than enforcing exploration uniformly across the user interface (UI), we condition its appearance on empirically low-cost, high-reach positions to ensure minimal tradeoff against platform-level watch time goals. Extensive A/B testing shows that this strategy preserves business metrics while collecting unbiased interaction data. Our method complements existing intra-row diversification and bandit-based exploration techniques by introducing a deployable, behaviorally informed mechanism for surfacing exploratory content at scale. Moreover, we demonstrate that the collected unbiased data, integrated into downstream candidate generation, significantly improves user engagement, validating its value for recommender systems.

</details>


### [2] [Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models](https://arxiv.org/abs/2512.15372)
*Mikel Williams-Lekuona,Georgina Cosma*

Main category: cs.IR

TL;DR: ICAR提出了一种图像复杂度感知的检索方法，让视觉Transformer根据图像复杂度动态调整计算量，简单图像使用较少计算，复杂图像使用完整网络深度，同时保持跨模态对齐能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型中的视觉Transformer对所有图像都使用相同的计算量（175.33 GFLOPs），无论图像是简单的产品照片还是复杂的街景，这造成了计算资源的浪费。需要一种能根据图像复杂度动态调整计算的方法。

Method: 1. ICAR框架：通过双路径训练，使不同处理深度产生的嵌入保持兼容，确保图像表示和文本嵌入在同一语义空间中；2. ConvNeXt-IC：将图像复杂度评估作为分类任务，使用现代分类器骨干网络而非专门架构，实现复杂度预测。

Result: 1. ConvNeXt-IC达到最先进性能，与人类判断的Pearson相关性为0.959，速度提升4.4倍；2. ICAR在实际基准测试中实现20%的速度提升，保持类别级性能，达到实例级性能的95%。

Conclusion: ICAR通过图像复杂度感知的动态计算分配，在保持视觉语言模型性能的同时显著提升效率，为实现可持续扩展的视觉语言系统提供了有效解决方案。

Abstract: Vision transformers in vision-language models apply uniform computational effort across all images, expending 175.33 GFLOPs (ViT-L/14) whether analysing a straightforward product photograph or a complex street scene. We propose ICAR (Image Complexity-Aware Retrieval), which enables vision transformers to use less compute for simple images whilst processing complex images through their full network depth. The key challenge is maintaining cross-modal alignment: embeddings from different processing depths must remain compatible for text matching. ICAR solves this through dual-path training that produces compatible embeddings from both reduced-compute and full-compute processing. This maintains compatibility between image representations and text embeddings in the same semantic space, whether an image exits early or processes fully. Unlike existing two-stage approaches that require expensive reranking, ICAR enables direct image-text matching without additional overhead. To determine how much compute to use, we develop ConvNeXt-IC, which treats image complexity assessment as a classification task. By applying modern classifier backbones rather than specialised architectures, ConvNeXt-IC achieves state-of-the-art performance with 0.959 correlation with human judgement (Pearson) and 4.4x speedup. Evaluated on standard benchmarks augmented with real-world web data, ICAR achieves 20% practical speedup while maintaining category-level performance and 95% of instance-level performance, enabling sustainable scaling of vision-language systems.

</details>


### [3] [MedNuggetizer: Confidence-Based Information Nugget Extraction from Medical Documents](https://arxiv.org/abs/2512.15384)
*Gregor Donabauer,Samy Ateia,Udo Kruschwitz,Maximilian Burger,Matthias May,Christian Gilfrich,Maximilian Haas,Julio Ruben Rodas Garzaro,Christoph Eckl*

Main category: cs.IR

TL;DR: MedNuggetizer是一个基于LLM的工具，用于从医学文档中提取和聚类信息块，帮助临床医生探索医学证据


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从大量医学文档中快速提取可靠证据，传统方法耗时且效率低，需要自动化工具支持证据探索

Method: 基于大语言模型重复提取信息块，然后进行分组聚类，在单个文档内和跨多个文档中生成可靠证据

Result: 在"前列腺活检前抗生素预防"临床用例中，使用主要泌尿科指南和PubMed研究作为信息来源，领域专家评估显示该工具能高效探索长文档并提取可靠的查询聚焦医学证据

Conclusion: MedNuggetizer为临床医生和研究人员提供了探索长文档和提取可靠医学证据的有效方法，有助于临床决策支持

Abstract: We present MedNuggetizer, https://mednugget-ai.de/; access is available upon request.}, a tool for query-driven extraction and clustering of information nuggets from medical documents to support clinicians in exploring underlying medical evidence. Backed by a large language model (LLM), \textit{MedNuggetizer} performs repeated extractions of information nuggets that are then grouped to generate reliable evidence within and across multiple documents. We demonstrate its utility on the clinical use case of \textit{antibiotic prophylaxis before prostate biopsy} by using major urological guidelines and recent PubMed studies as sources of information. Evaluation by domain experts shows that \textit{MedNuggetizer} provides clinicians and researchers with an efficient way to explore long documents and easily extract reliable, query-focused medical evidence.

</details>


### [4] [BERT and CNN integrated Neural Collaborative Filtering for Recommender Systems](https://arxiv.org/abs/2512.15526)
*Abdullah Al Munem,Sumona Yeasmin,Mohammad Rezwanul Huq*

Main category: cs.IR

TL;DR: 提出结合BERT和CNN的神经协同过滤模型，用于推荐系统，通过处理数值、分类和图像数据提取潜在特征，在MovieLens数据集上优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 网站通过用户与内容的互动获取利润，强大的推荐系统能根据用户偏好推荐项目，增加用户互动。现有推荐系统需要改进以更好地处理多种数据类型。

Method: 提出BERT和CNN集成的神经协同过滤模型，接受用户和项目配置文件输入，提取用户兴趣。模型能处理数值、分类和图像数据，从输入中提取潜在特征。在MovieLens数据集上训练验证25个epoch。

Result: 在MovieLens数据集上，提出的模型优于简单的NCF和基于BERT的NCF模型。获得的结果为：召回率0.72，命中率@10为0.486（799个用户）。

Conclusion: 同时考虑分类数据和图像数据可以提高推荐系统的性能。多模态数据处理对推荐系统有积极影响。

Abstract: Every day, a significant number of users visit the internet for different needs. The owners of a website generate profits from the user interaction with the contents or items of the website. A robust recommendation system can increase user interaction with a website by recommending items according to the user's unique preferences. BERT and CNN-integrated neural collaborative filtering (NCF) have been proposed for the recommendation system in this experiment. The proposed model takes inputs from the user and item profile and finds the user's interest. This model can handle numeric, categorical, and image data to extract the latent features from the inputs. The model is trained and validated on a small sample of the MovieLens dataset for 25 epochs. The same dataset has been used to train and validate a simple NCF and a BERT-based NCF model and compared with the proposed model. The proposed model outperformed those two baseline models. The obtained result for the proposed model is 0.72 recall and 0.486 Hit Ratio @ 10 for 799 users on the MovieLens dataset. This experiment concludes that considering both categorical and image data can improve the performance of a recommendation system.

</details>
