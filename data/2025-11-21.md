<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym是一个轻量级、可扩展的Python工具包，用于支持基于大语言模型的查询重构，提供统一的框架来实施、执行和比较不同的LLM重构方法。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏统一的工具包来实现基于LLM的查询重构方法，这阻碍了公平比较、快速实验、一致性基准测试和可靠部署。

Method: 提供Python API支持多种LLM方法、检索无关的接口、集中式提示管理系统、内置基准测试支持，以及完全开源的实现。

Result: 开发了QueryGym工具包，支持与Pyserini和PyTerrier等后端集成，提供版本控制和元数据跟踪的提示管理。

Conclusion: QueryGym填补了LLM查询重构工具包的空白，为研究人员提供了统一的实验和比较平台。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [2] [Incorporating Token Importance in Multi-Vector Retrieval](https://arxiv.org/abs/2511.16106)
*Archish S,Ankit Garg,Kirankumar Shiragur,Neeraj Kayal*

Main category: cs.IR

TL;DR: 本文提出对ColBERT的Chamfer距离函数的增强，通过计算查询令牌贡献的加权和来改进检索性能，其中权重反映令牌重要性。


<details>
  <summary>Details</summary>
Motivation: ColBERT的晚期交互机制虽然有效，但其Chamfer距离函数对所有查询令牌平等对待，忽略了不同令牌的重要性差异。本文旨在通过引入令牌权重来增强表达力。

Method: 在保持多向量表示固定的情况下，仅训练令牌权重，计算查询令牌贡献的加权和。使用IDF基础权重和少样本微调两种方式。

Result: 在BEIR基准测试中，零样本设置下使用IDF权重平均Recall@10提升1.28%，少样本微调下提升3.66%。

Conclusion: 简单的令牌加权扩展显著增强了晚期交互多向量机制的表达能力，无需改变核心架构即可提升检索性能。

Abstract: ColBERT introduced a late interaction mechanism that independently encodes queries and documents using BERT, and computes similarity via fine-grained interactions over token-level vector representations. This design enables expressive matching while allowing efficient computation of scores, as the multi-vector document representations could be pre-computed offline. ColBERT models distance using a Chamfer-style function: for each query token, it selects the closest document token and sums these distances across all query tokens.
  In our work, we explore enhancements to the Chamfer distance function by computing a weighted sum over query token contributions, where weights reflect the token importance. Empirically, we show that this simple extension, requiring only token-weight training while keeping the multi-vector representations fixed, further enhances the expressiveness of late interaction multi-vector mechanism. In particular, on the BEIR benchmark, our method achieves an average improvement of 1.28\% in Recall@10 in the zero-shot setting using IDF-based weights, and 3.66\% through few-shot fine-tuning.

</details>


### [3] [ARK: Answer-Centric Retriever Tuning via KG-augmented Curriculum Learning](https://arxiv.org/abs/2511.16326)
*Jiawei Zhou,Hang Ding,Haiyun Jiang*

Main category: cs.IR

TL;DR: 提出了一种针对检索增强生成(RAG)的答案对齐微调框架，通过识别高质量正样本和使用课程对比学习来优化检索器在长上下文场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 标准检索器在长上下文场景中难以区分稀疏但关键的证据，且其查询-文档相似性优化与生成精确答案的下游目标不一致。

Method: 首先评估文档块是否足以生成正确答案来识别高质量正样本，然后使用基于LLM构建知识图谱的课程对比学习方案，生成增强查询并挖掘渐进式困难负样本。

Result: 在Ultradomain和LongBench基准的10个数据集上达到最先进性能，相比基础模型提升14.5%，且保持长上下文RAG的高效性。

Conclusion: 该方法为构建真正以答案为中心的检索器提供了稳健有效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for knowledge-intensive tasks, yet its effectiveness in long-context scenarios is often bottlenecked by the retriever's inability to distinguish sparse yet crucial evidence. Standard retrievers, optimized for query-document similarity, frequently fail to align with the downstream goal of generating a precise answer. To bridge this gap, we propose a novel fine-tuning framework that optimizes the retriever for Answer Alignment. Specifically, we first identify high-quality positive chunks by evaluating their sufficiency to generate the correct answer. We then employ a curriculum-based contrastive learning scheme to fine-tune the retriever. This curriculum leverages LLM-constructed Knowledge Graphs (KGs) to generate augmented queries, which in turn mine progressively challenging hard negatives. This process trains the retriever to distinguish the answer-sufficient positive chunks from these nuanced distractors, enhancing its generalization. Extensive experiments on 10 datasets from the Ultradomain and LongBench benchmarks demonstrate that our fine-tuned retriever achieves state-of-the-art performance, improving 14.5% over the base model without substantial architectural modifications and maintaining strong efficiency for long-context RAG. Our work presents a robust and effective methodology for building truly answer-centric retrievers.

</details>


### [4] [An Efficient LLM-based Evolutional Recommendation with Locate-Forget-Update Paradigm](https://arxiv.org/abs/2511.16414)
*Hao Liu,Le Wu,Min Hou,Han Wu,Kun Zhang,Xin Li,Si Wei*

Main category: cs.IR

TL;DR: EvoRec是一个高效的定位-遗忘-更新框架，专门为基于LLM的推荐系统设计，通过识别和更新少量与偏好变化相关的参数来适应用户偏好的演化，同时节省计算资源。


<details>
  <summary>Details</summary>
Motivation: LLM-based推荐系统难以适应不断新增的用户-物品交互数据，传统重训练方法计算成本过高，而仅用新数据微调会导致不活跃用户的偏好遗忘问题。

Method: 提出EvoRec框架，定位与偏好变化相关的少量参数，仅更新这些参数而不引入额外参数，修改的参数仅占LoRA适配器参数的30%。

Result: 在两个真实数据集上的实验表明，EvoRec能高效演化LLMRec以适应活跃用户偏好，同时保护不活跃用户的兴趣不受干扰。

Conclusion: EvoRec通过精确的参数更新策略，在保持推荐性能的同时显著降低了计算成本，解决了LLM推荐系统的演化适应问题。

Abstract: Nowadays, Large Language Models (LLMs) have shown exceptional performance in sequential recommendations, and the adoption of LLM-based recommender systems (LLMRec) is becoming increasingly widespread in existing e-commerce platforms. Despite the impressive performance, the constant high volume of new user-item interactions makes it difficult to adapt to the evolution of user preference over time, especially for LLM-based recommender systems. The challenge arises from the large number of parameters in LLMs, which makes traditional evolution methods (i.e., Re-training or Fine-tuning) impractical. Specifically, Re-training with all interactions results in prohibitively high computational costs. On the other hand, fine-tuning with only new interactions leads to preference forgetting among inactive users, ultimately compromising overall performance. To tackle this problem, we propose EvoRec, an efficient Locate-Forget-Update framework designed for LLM-based recommender systems to model the evolution of user preferences. EvoRec identifies a small set of parameters associated with preference changes and updates them precisely, thereby saving computational resources while maintaining strong recommendation performance. Notably, the modified parameters account for only 30\% of LoRA adapter parameters, with no additional parameters introduced. Extensive experiments on two real-world datasets demonstrate that, compared to existing methods, EvoRec not only efficiently evolves LLMRec to adapt to the preferences of active users, but also preserves the interests of inactive users from being disturbed during evolution.

</details>


### [5] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: 论文认为LLM驱动的音乐推荐系统需要重新思考评估方法，分析了LLM如何重塑用户建模、物品建模和自然语言推荐，并提出了结构化的成功和风险维度评估框架。


<details>
  <summary>Details</summary>
Motivation: 传统音乐推荐系统基于信息检索框架，主要依赖准确性指标，难以回答"什么是好的推荐"这一深层问题。LLM的出现颠覆了这一框架，需要重新思考评估方法。

Method: 首先回顾LLM如何重塑音乐推荐系统的用户建模、物品建模和自然语言推荐，然后借鉴NLP领域的评估实践，最后通过LLM提示技术提出结构化的评估维度。

Result: 提出了一个更新的、教学性的跨学科评估视角，为MRS社区提供了适应LLM时代的评估框架。

Conclusion: LLM驱动的音乐推荐系统需要全新的评估范式，传统基于准确性的指标不再适用，应该采用更全面的成功和风险维度来评估系统性能。

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [6] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: 提出Prism框架，将可解释推荐系统解耦为独立的排序阶段和解释生成阶段，通过知识蒸馏使用大型教师LLM生成高质量解释知识，再由紧凑的学生模型合成个性化解释，实现了性能与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决端到端架构中LLM集成到可解释推荐系统时出现的性能-效率权衡问题，避免排序和解释联合优化导致的次优折衷。

Method: 采用解耦框架，使用FLAN-T5-XXL等大型教师LLM作为Oracle生成高保真解释知识，然后由经过微调的紧凑学生模型（如BART-Base）专门合成个性化解释。

Result: 140M参数的Prism模型在忠实性和个性化的人类评估中显著优于11B参数的教师模型，推理速度提升24倍，内存消耗减少10倍。

Conclusion: 解耦结合定向蒸馏为高质量可解释推荐提供了高效有效的途径，确保每个组件针对其特定目标进行优化。

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>


### [7] [PolyMinHash: Efficient Area-Based MinHashing of Polygons for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2511.16576)
*Alima Subedi,Sankalpa Pokharel,Satish Puri*

Main category: cs.IR

TL;DR: PolyMinHash是一个用于多边形近似相似性搜索的系统，通过将MinHashing适应为新颖的2D多边形哈希方案来生成短且保持相似性的多边形签名。


<details>
  <summary>Details</summary>
Motivation: 随着数据集增大，精确最近邻搜索变得不可行，而现有ANN系统主要针对文本、图像和轨迹数据，多边形数据的ANN系统研究较少。

Method: 通过计算随机采样点落入多边形内部区域所需的点数来生成MinHash值，从而保持基于面积的Jaccard相似性。

Result: 哈希机制在查询细化阶段处理的候选数量比暴力算法减少了高达98%，在搜索准确性和运行时间之间取得了平衡。

Conclusion: PolyMinHash系统为空间数据库系统和地理信息系统中的多边形相似性搜索提供了一种有效的近似解决方案。

Abstract: Similarity searches are a critical task in data mining. As data sets grow larger, exact nearest neighbor searches quickly become unfeasible, leading to the adoption of approximate nearest neighbor (ANN) searches. ANN has been studied for text data, images, and trajectories. However, there has been little effort to develop ANN systems for polygons in spatial database systems and geographic information systems. We present PolyMinHash, a system for approximate polygon similarity search that adapts MinHashing into a novel 2D polygon-hashing scheme to generate short, similarity-preserving signatures of input polygons. Minhash is generated by counting the number of randomly sampled points needed before the sampled point lands within the polygon's interior area, yielding hash values that preserve area-based Jaccard similarity. We present the tradeoff between search accuracy and runtime of our PolyMinHash system. Our hashing mechanism reduces the number of candidates to be processed in the query refinement phase by up to 98% compared to the number of candidates processed by the brute-force algorithm.

</details>
