<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios](https://arxiv.org/abs/2509.15380)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.IR

TL;DR: 本研究利用古兰经多语言语料库的特点，探索开发伊斯兰领域多语言信息检索系统的最佳策略，提出了一种结合跨语言和单语言技术的新混合方法，并在实际部署中展示了单一轻量模型的成本效益。


<details>
  <summary>Details</summary>
Motivation: 当前多语言信息检索研究与实践部署之间存在显著差距，许多研究在孤立环境中评估性能，限制了其在真实场景中的适用性。本研究旨在开发满足用户多语言信息需求的实用检索系统。

Method: 准备了11个检索模型，采用四种训练方法：单语言、跨语言、翻译训练全部，以及结合跨语言和单语言技术的新混合方法。通过领域内数据集评估不同训练配置对嵌入空间的影响。

Result: 评估结果显示混合方法在各种检索场景下都取得了有希望的结果，混合方法在性能上表现优异。

Conclusion: 研究证明了混合训练方法的有效性，并强调了在实际多语言信息检索应用中部署单一多功能轻量模型的成本效率优势。

Abstract: Despite recent advancements in Multilingual Information Retrieval (MLIR), a
significant gap remains between research and practical deployment. Many studies
assess MLIR performance in isolated settings, limiting their applicability to
real-world scenarios. In this work, we leverage the unique characteristics of
the Quranic multilingual corpus to examine the optimal strategies to develop an
ad-hoc IR system for the Islamic domain that is designed to satisfy users'
information needs in multiple languages. We prepared eleven retrieval models
employing four training approaches: monolingual, cross-lingual,
translate-train-all, and a novel mixed method combining cross-lingual and
monolingual techniques. Evaluation on an in-domain dataset demonstrates that
the mixed approach achieves promising results across diverse retrieval
scenarios. Furthermore, we provide a detailed analysis of how different
training configurations affect the embedding space and their implications for
multilingual retrieval effectiveness. Finally, we discuss deployment
considerations, emphasizing the cost-efficiency of deploying a single
versatile, lightweight model for real-world MLIR applications.

</details>


### [2] [SERVAL: Surprisingly Effective Zero-Shot Visual Document Retrieval Powered by Large Vision and Language Models](https://arxiv.org/abs/2509.15432)
*Thong Nguyen,Yibin Lei,Jia-Huei Ju,Andrew Yates*

Main category: cs.IR

TL;DR: 本文提出了一种零样本的生成-编码管道方法，通过视觉语言模型生成文档图像的详细文本描述，然后使用标准文本编码器进行嵌入，在ViDoRe-v2基准测试中取得了63.4%的nDCG@5成绩。


<details>
  <summary>Details</summary>
Motivation: 重新审视零样本方法，避免计算密集型的文本-图像对比训练，利用预训练视觉语言模型作为可重用的语义代理。

Method: 采用生成-编码管道：首先使用视觉语言模型为每个文档图像生成详细文本描述，然后使用标准文本编码器对这些描述进行嵌入。

Result: 在ViDoRe-v2基准测试中达到63.4% nDCG@5，超越了最强的专用多向量视觉文档编码器，同时在大规模集合上扩展性更好，多语言覆盖更广。

Conclusion: 现代视觉语言模型能够以足够细粒度捕捉复杂的文本和视觉线索，通过将模态对齐任务卸载给预训练模型，该方法为未来VDR系统建立了强大的零样本基线。

Abstract: Visual Document Retrieval (VDR) typically operates as text-to-image retrieval
using specialized bi-encoders trained to directly embed document images. We
revisit a zero-shot generate-and-encode pipeline: a vision-language model first
produces a detailed textual description of each document image, which is then
embedded by a standard text encoder. On the ViDoRe-v2 benchmark, the method
reaches 63.4% nDCG@5, surpassing the strongest specialised multi-vector visual
document encoder. It also scales better to large collections and offers broader
multilingual coverage. Analysis shows that modern vision-language models
capture complex textual and visual cues with sufficient granularity to act as a
reusable semantic proxy. By offloading modality alignment to pretrained
vision-language models, our approach removes the need for computationally
intensive text-image contrastive training and establishes a strong zero-shot
baseline for future VDR systems.

</details>


### [3] [Dual-Mode Visual System for Brain-Computer Interfaces: Integrating SSVEP and P300 Responses](https://arxiv.org/abs/2509.15439)
*Ekgari Kasawala,Surej Mouli*

Main category: cs.IR

TL;DR: 本文提出了一种基于LED的双重刺激装置，结合SSVEP和P300范式来提高脑机接口系统的分类精度，实现了86.25%的平均分类准确率和42.08 bpm的信息传输率。


<details>
  <summary>Details</summary>
Motivation: 传统的LCD视觉刺激范式在实际部署中存在局限性，需要开发更有效的刺激装置来提升脑机接口系统的性能。

Method: 开发LED基双重刺激装置，使用7Hz、8Hz、9Hz、10Hz四个频率对应不同方向控制，通过最大FFT幅度和P300峰值检测进行实时特征提取。

Result: 刺激硬件频率偏差仅为0.15%-0.20%，成功区分所有四个刺激频率并与P300事件标记关联，平均分类准确率达86.25%，平均ITR为42.08 bpm。

Conclusion: LED基双重刺激系统在SSVEP分类精度和ITR方面表现出色，为脑机接口系统的实际应用提供了有效解决方案。

Abstract: In brain-computer interface (BCI) systems, steady-state visual evoked
potentials (SSVEP) and P300 responses have achieved widespread implementation
owing to their superior information transfer rates (ITR) and minimal training
requirements. These neurophysiological signals have exhibited robust efficacy
and versatility in external device control, demonstrating enhanced precision
and scalability. However, conventional implementations predominantly utilise
liquid crystal display (LCD)-based visual stimulation paradigms, which present
limitations in practical deployment scenarios. This investigation presents the
development and evaluation of a novel light-emitting diode (LED)-based dual
stimulation apparatus designed to enhance SSVEP classification accuracy through
the integration of both SSVEP and P300 paradigms. The system employs four
distinct frequencies, 7 Hz, 8 Hz, 9 Hz, and 10 Hz, corresponding to forward,
backward, right, and left directional controls, respectively. Oscilloscopic
verification confirmed the precision of these stimulation frequencies.
Real-time feature extraction was accomplished through the concurrent analysis
of maximum Fast Fourier Transform (FFT) amplitude and P300 peak detection to
ascertain user intent. Directional control was determined by the frequency
exhibiting maximal amplitude characteristics. The visual stimulation hardware
demonstrated minimal frequency deviation, with error differentials ranging from
0.15%to 0.20%across all frequencies. The implemented signal processing
algorithm successfully discriminated all four stimulus frequencies whilst
correlating them with their respective P300 event markers. Classification
accuracy was evaluated based on correct task intention recognition. The
proposed hybrid system achieved a mean classification accuracy of 86.25%,
coupled with an average ITR of 42.08 bits per minute (bpm).

</details>


### [4] [CFDA & CLIP at TREC iKAT 2025: Enhancing Personalized Conversational Search via Query Reformulation and Rank Fusion](https://arxiv.org/abs/2509.15588)
*Yu-Cheng Chang,Guan-Wei Yeo,Quah Eugene,Fan-Jie Shih,Yuan-Ching Kuo,Tsung-En Yu,Hung-Chun Hsu,Ming-Feng Tsai,Chuan-Ju Wang*

Main category: cs.IR

TL;DR: 该论文研究了2025年TREC交互式知识辅助赛道(iKAT)的查询重写和检索融合策略，通过Best-of-N选择和互惠排名融合(RRF)方法提升系统在实时交互和离线任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决TREC iKAT赛道中交互式任务面临的实时约束挑战，以及离线任务中需要精确评估段落排序和响应生成的需求。

Method: 采用查询重写和检索融合作为核心策略，构建基于Best-of-N选择和互惠排名融合(RRF)的流水线来处理不同的提交任务。

Result: 结果显示重排序和融合提高了系统的鲁棒性，同时在两个任务中都揭示了有效性和效率之间的权衡关系。

Conclusion: 该方法在提升系统性能的同时，需要平衡有效性和效率的权衡，为交互式知识辅助系统提供了实用的技术方案。

Abstract: The 2025 TREC Interactive Knowledge Assistance Track (iKAT) featured both
interactive and offline submission tasks. The former requires systems to
operate under real-time constraints, making robustness and efficiency as
important as accuracy, while the latter enables controlled evaluation of
passage ranking and response generation with pre-defined datasets. To address
this, we explored query rewriting and retrieval fusion as core strategies. We
built our pipelines around Best-of-$N$ selection and Reciprocal Rank Fusion
(RRF) strategies to handle different submission tasks. Results show that
reranking and fusion improve robustness while revealing trade-offs between
effectiveness and efficiency across both tasks.

</details>


### [5] [Chunk Knowledge Generation Model for Enhanced Information Retrieval: A Multi-task Learning Approach](https://arxiv.org/abs/2509.15658)
*Jisu Kim,Jinhee Park,Changhyun Jeon,Jungwoo Choi,Keonwoo Kim,Minji Hong,Sehyun Kim*

Main category: cs.IR

TL;DR: 本研究提出了一种基于分块的文档扩展方法，通过将文档划分为块单元并生成标题和候选问题，同时从用户查询中提取关键词，以提高检索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统查询扩展技术存在上下文敏感性和性能下降问题，而现有文档扩展方法如Doc2Query存在预处理成本高、索引大小增加和生成内容可靠性等问题。

Method: 提出'分块知识生成模型'，采用基于T5的多任务学习结构，通过单次编码和两次解码过程并行生成三种语义信息（标题、候选问题和关键词）。

Result: 在305个查询-文档对上的GPT评估显示，Top@10准确率达到95.41%，优于文档块级检索方法。

Conclusion: 该方法通过同时从文档块生成标题和候选问题应用于检索流程，并通过定性评估证明了在大规模信息检索系统中提高检索准确性的实证证据。

Abstract: Traditional query expansion techniques for addressing vocabulary mismatch
problems in information retrieval are context-sensitive and may lead to
performance degradation. As an alternative, document expansion research has
gained attention, but existing methods such as Doc2Query have limitations
including excessive preprocessing costs, increased index size, and reliability
issues with generated content. To mitigate these problems and seek more
structured and efficient alternatives, this study proposes a method that
divides documents into chunk units and generates textual data for each chunk to
simultaneously improve retrieval efficiency and accuracy. The proposed "Chunk
Knowledge Generation Model" adopts a T5-based multi-task learning structure
that simultaneously generates titles and candidate questions from each document
chunk while extracting keywords from user queries. This approach maximizes
computational efficiency by generating and extracting three types of semantic
information in parallel through a single encoding and two decoding processes.
The generated data is utilized as additional information in the retrieval
system. GPT-based evaluation on 305 query-document pairs showed that retrieval
using the proposed model achieved 95.41% accuracy at Top@10, demonstrating
superior performance compared to document chunk-level retrieval. This study
contributes by proposing an approach that simultaneously generates titles and
candidate questions from document chunks for application in retrieval
pipelines, and provides empirical evidence applicable to large-scale
information retrieval systems by demonstrating improved retrieval accuracy
through qualitative evaluation.

</details>


### [6] [Understanding Embedding Scaling in Collaborative Filtering](https://arxiv.org/abs/2509.15709)
*Zhuangzhuang He,Zhou Kaiyu,Haoyue Bai,Fengbin Zhu,Yonghui Yang*

Main category: cs.IR

TL;DR: 本文通过大规模实验发现推荐模型嵌入维度缩放中的双峰和对数现象，揭示了嵌入维度对性能的非单调影响，并分析了双峰现象的成因及模型的噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前推荐模型缩放研究中，嵌入维度的缩放被认为可能导致性能下降，但其根本原因尚不明确，且不同模型和数据集中的表现差异未被充分探索。

Method: 在10个不同稀疏度和规模的数据集上，使用4种代表性经典架构进行大规模实验，观察嵌入维度变化对性能的影响。

Result: 发现了双峰现象（性能先升后降再升再降）和对数现象（性能呈完美对数曲线），并分析了双峰现象的成因。

Conclusion: 嵌入维度缩放存在复杂的非线性效应，双峰现象由模型容量和噪声鲁棒性的平衡导致，理论分析与实证观察一致。

Abstract: Scaling recommendation models into large recommendation models has become one
of the most widely discussed topics. Recent efforts focus on components beyond
the scaling embedding dimension, as it is believed that scaling embedding may
lead to performance degradation. Although there have been some initial
observations on embedding, the root cause of their non-scalability remains
unclear. Moreover, whether performance degradation occurs across different
types of models and datasets is still an unexplored area. Regarding the effect
of embedding dimensions on performance, we conduct large-scale experiments
across 10 datasets with varying sparsity levels and scales, using 4
representative classical architectures. We surprisingly observe two novel
phenomenon: double-peak and logarithmic. For the former, as the embedding
dimension increases, performance first improves, then declines, rises again,
and eventually drops. For the latter, it exhibits a perfect logarithmic curve.
Our contributions are threefold. First, we discover two novel phenomena when
scaling collaborative filtering models. Second, we gain an understanding of the
underlying causes of the double-peak phenomenon. Lastly, we theoretically
analyze the noise robustness of collaborative filtering models, with results
matching empirical observations.

</details>


### [7] [Optimizing Product Deduplication in E-Commerce with Multimodal Embeddings](https://arxiv.org/abs/2509.15858)
*Aysenur Kulunk,Berk Taskin,M. Furkan Eseoglu,H. Bahadir Sahin*

Main category: cs.IR

TL;DR: 本文提出了一种针对电商平台的多模态产品去重系统，通过结合领域特定的文本模型和图像表示技术，在超过2亿商品的大规模目录中实现高效重复检测。


<details>
  <summary>Details</summary>
Motivation: 电商平台中重复商品列表导致消费者困惑和运营效率低下，传统基于关键词的方法无法准确识别语义相似的重复产品。

Method: 采用基于BERT架构的领域特定文本模型和MaskedAutoEncoders图像表示，结合降维技术生成128维嵌入向量，并开发了新颖的决策模型整合文本和图像特征，使用Milvus向量数据库进行高效相似性搜索。

Result: 系统在仅消耗100GB内存的情况下，在大规模产品目录中实现了0.90的宏平均F1分数，优于第三方解决方案的0.83分。

Conclusion: 研究表明将领域特定适应与先进机器学习技术相结合，可以有效缓解大规模电商环境中的重复列表问题。

Abstract: In large scale e-commerce marketplaces, duplicate product listings frequently
cause consumer confusion and operational inefficiencies, degrading trust on the
platform and increasing costs. Traditional keyword-based search methodologies
falter in accurately identifying duplicates due to their reliance on exact
textual matches, neglecting semantic similarities inherent in product titles.
To address these challenges, we introduce a scalable, multimodal product
deduplication designed specifically for the e-commerce domain. Our approach
employs a domain-specific text model grounded in BERT architecture in
conjunction with MaskedAutoEncoders for image representations. Both of these
architectures are augmented with dimensionality reduction techniques to produce
compact 128-dimensional embeddings without significant information loss.
Complementing this, we also developed a novel decider model that leverages both
text and image vectors. By integrating these feature extraction mechanisms with
Milvus, an optimized vector database, our system can facilitate efficient and
high-precision similarity searches across extensive product catalogs exceeding
200 million items with just 100GB of system RAM consumption. Empirical
evaluations demonstrate that our matching system achieves a macro-average F1
score of 0.90, outperforming third-party solutions which attain an F1 score of
0.83. Our findings show the potential of combining domain-specific adaptations
with state-of-the-art machine learning techniques to mitigate duplicate
listings in large-scale e-commerce environments.

</details>
