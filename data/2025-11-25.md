<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 19]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Token-Controlled Re-ranking for Sequential Recommendation via LLMs](https://arxiv.org/abs/2511.17913)
*Wenxi Dai,Wujiang Xu,Pinhuan Wang,Dimitris N. Metaxas*

Main category: cs.IR

TL;DR: COREC是一个新颖的token增强重排序框架，通过显式的基于属性的信号让用户能够精确灵活地控制推荐结果，在保持个性化的同时满足用户的具体要求。


<details>
  <summary>Details</summary>
Motivation: 当前LLM重排序器缺乏细粒度用户控制机制，难以平衡用户固有偏好与多属性约束，通常采用简单的硬过滤方法，导致推荐池过度缩小和结果不理想，用户只能被动接受推荐。

Method: 提出COREC框架，通过token增强重排序，将特定用户需求融入推荐结果的共创过程，学习平衡用户指令与潜在偏好。

Result: 实验表明COREC在标准推荐效果上超越最先进基线，在特定属性要求遵循方面表现更优，能够实现细粒度和可预测的排名操控。

Conclusion: COREC框架成功填补了用户控制机制的空白，使用户从被动接受者转变为推荐过程的主动合作者，实现了用户需求与个性化推荐的平衡。

Abstract: The widespread adoption of Large Language Models (LLMs) as re-rankers is shifting recommender systems towards a user-centric paradigm. However, a significant gap remains: current re-rankers often lack mechanisms for fine-grained user control. They struggle to balance inherent user preferences with multiple attribute-based constraints, often resorting to simplistic hard filtering that can excessively narrow the recommendation pool and yield suboptimal results. This limitation leaves users as passive recipients rather than active collaborators in the recommendation process. To bridge this gap, we propose COREC, a novel token-augmented re-ranking framework that incorporates specific user requirements in co-creating the recommendation outcome. COREC empowers users to steer re-ranking results with precise and flexible control via explicit, attribute-based signals. The framework learns to balance these commands against latent preferences, yielding rankings that adhere to user instructions without sacrificing personalization. Experiments show that COREC: (1) exceeds state-of-the-art baselines on standard recommendation effectiveness and (2) demonstrates superior adherence to specific attribute requirements, proving that COREC enables fine-grained and predictable manipulation of the rankings.

</details>


### [2] [Save, Revisit, Retain: A Scalable Framework for Enhancing User Retention in Large-Scale Recommender Systems](https://arxiv.org/abs/2511.18013)
*Weijie Jiang,Armando Ordorica,Jaewon Yang,Olafur Gudmundsson,Yucheng Tu,Huizhong Duan*

Main category: cs.IR

TL;DR: 提出了一种轻量级、可解释的框架来建模用户重新访问行为并优化长期用户留存，通过定义代理归因过程来减少噪声，在Pinterest平台上实现了0.1%的活跃用户提升。


<details>
  <summary>Details</summary>
Motivation: 用户留存是在线平台的关键目标，重新访问是留存的重要指标。但建模和优化重新访问面临归因困难（难以确定哪些具体行为触发重新访问）以及规模和时序复杂性等挑战。

Method: 引入轻量级可解释框架，定义代理归因过程将保存行为与后续重新访问关联，减少因果关系中的噪声；构建可扩展的事件聚合流水线分析用户重新访问模式。

Result: 在Pinterest的Related Pins表面部署，服务5亿+用户，实现了0.1%的活跃用户提升，且没有额外计算成本。

Conclusion: 该框架成功解决了重新访问建模中的归因和扩展性挑战，有效提升了用户留存，证明了其在大型推荐系统中的实用价值。

Abstract: User retention is a critical objective for online platforms like Pinterest, as it strengthens user loyalty and drives growth through repeated engagement. A key indicator of retention is revisitation, i.e., when users return to view previously saved content, a behavior often sparked by personalized recommendations and user satisfaction. However, modeling and optimizing revisitation poses significant challenges. One core difficulty is accurate attribution: it is often unclear which specific user actions or content exposures trigger a revisit, since many confounding factors (e.g., content quality, user interface, notifications, or even changing user intent) can influence return behavior. Additionally, the scale and timing of revisitations introduce further complexity; users may revisit content days or even weeks after their initial interaction, requiring the system to maintain and associate extensive historical records across millions of users and sessions. These complexities render existing methods insufficient for robustly capturing and optimizing long-term revisitation. To address these gaps, we introduce a novel, lightweight, and interpretable framework for modeling revisitation behavior and optimizing long-term user retention in Pinterest's search-based recommendation context. By defining a surrogate attribution process that links saves to subsequent revisitations, we reduce noise in the causal relationship between user actions and return visits. Our scalable event aggregation pipeline enables large-scale analysis of user revisitation patterns and enhances the ranking system's ability to surface items with high retention value. Deployed on Pinterest's Related Pins surface to serve 500+ million users, the framework led to a significant lift of 0.1% in active users without additional computational costs.

</details>


### [3] [Extracting Interaction-Aware Monosemantic Concepts in Recommender Systems](https://arxiv.org/abs/2511.18024)
*Dor Arviv,Yehonatan Elisha,Oren Barkan,Noam Koenigstein*

Main category: cs.IR

TL;DR: 提出一种从推荐系统用户和物品嵌入中提取单语义神经元的方法，使用稀疏自编码器揭示预训练表示中的语义结构，并通过预测感知训练目标保持用户-物品交互关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法在语言模型中提取单语义神经元，但推荐系统中需要保持用户和物品嵌入之间的交互关系，因此需要开发专门的方法来揭示推荐模型中的可解释概念。

Method: 使用稀疏自编码器(SAE)结合预测感知训练目标，通过冻结的推荐器反向传播，使学习到的潜在结构与模型的用户-物品亲和度预测对齐。

Result: 提取的神经元捕获了类型、流行度和时间趋势等属性，支持目标过滤和内容推广等后处理控制操作，无需修改基础模型。

Conclusion: 该方法在不同推荐模型和数据集上具有通用性，为可解释和可控的个性化推荐提供了实用工具。

Abstract: We present a method for extracting \emph{monosemantic} neurons, defined as latent dimensions that align with coherent and interpretable concepts, from user and item embeddings in recommender systems. Our approach employs a Sparse Autoencoder (SAE) to reveal semantic structure within pretrained representations. In contrast to work on language models, monosemanticity in recommendation must preserve the interactions between separate user and item embeddings. To achieve this, we introduce a \emph{prediction aware} training objective that backpropagates through a frozen recommender and aligns the learned latent structure with the model's user-item affinity predictions. The resulting neurons capture properties such as genre, popularity, and temporal trends, and support post hoc control operations including targeted filtering and content promotion without modifying the base model. Our method generalizes across different recommendation models and datasets, providing a practical tool for interpretable and controllable personalization. Code and evaluation resources are available at https://github.com/DeltaLabTLV/Monosemanticity4Rec.

</details>


### [4] [Fidelity-Aware Recommendation Explanations via Stochastic Path Integration](https://arxiv.org/abs/2511.18047)
*Oren Barkan,Yahlly Schein,Yehonatan Elisha,Veronika Bogina,Mikhail Baklanov,Noam Koenigstein*

Main category: cs.IR

TL;DR: SPINRec是一个模型无关的推荐系统解释方法，通过随机基线采样和路径积分技术，从数据分布中采样多个用户画像，选择最忠实的归因路径，提供更稳定和个性化的解释。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中的解释保真度（解释准确反映模型真实推理的程度）严重缺乏研究，现有方法在稀疏和隐式推荐数据上存在局限性。

Method: SPINRec采用随机基线采样：从经验数据分布中采样多个合理的用户画像，选择最忠实的归因路径，而不是从固定或不现实的基线积分。该方法捕捉了观察和未观察交互的影响。

Result: 在三个模型（MF、VAE、NCF）和三个数据集（ML1M、Yahoo! Music、Pinterest）上进行了最全面的保真度评估，SPINRec在所有基线上表现一致优异，为推荐系统中的忠实可解释性建立了新基准。

Conclusion: SPINRec通过随机路径积分方法显著提高了推荐系统解释的保真度，为推荐系统的可信解释提供了有效解决方案。

Abstract: Explanation fidelity, which measures how accurately an explanation reflects a model's true reasoning, remains critically underexplored in recommender systems. We introduce SPINRec (Stochastic Path Integration for Neural Recommender Explanations), a model-agnostic approach that adapts path-integration techniques to the sparse and implicit nature of recommendation data. To overcome the limitations of prior methods, SPINRec employs stochastic baseline sampling: instead of integrating from a fixed or unrealistic baseline, it samples multiple plausible user profiles from the empirical data distribution and selects the most faithful attribution path. This design captures the influence of both observed and unobserved interactions, yielding more stable and personalized explanations. We conduct the most comprehensive fidelity evaluation to date across three models (MF, VAE, NCF), three datasets (ML1M, Yahoo! Music, Pinterest), and a suite of counterfactual metrics, including AUC-based perturbation curves and fixed-length diagnostics. SPINRec consistently outperforms all baselines, establishing a new benchmark for faithful explainability in recommendation. Code and evaluation tools are publicly available at https://github.com/DeltaLabTLV/SPINRec.

</details>


### [5] [ProHD: Projection-Based Hausdorff Distance Approximation](https://arxiv.org/abs/2511.18207)
*Jiuzhou Fu,Luanzheng Guo,Nathan R. Tallent,Dongfang Zhao*

Main category: cs.IR

TL;DR: ProHD是一种投影引导的近似算法，通过将数据投影到少量信息方向上来识别候选极值点，从而显著加速Hausdorff距离计算，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 在大规模高维数据集上精确计算Hausdorff距离计算成本过高，需要一种快速且准确的近似方法。

Method: 通过将数据投影到质心轴和主要主成分等少量信息方向上，识别候选极值点子集，并在该子集上计算Hausdorff距离。

Result: 在图像、物理和合成数据集上的实验表明，ProHD比精确算法快10-100倍，比基于随机采样的近似方法误差低5-20倍，通常能达到与精确值相差几个百分点的结果。

Conclusion: ProHD实现了有界加性误差保证下的HD低估，为大型向量数据库和流数据等场景提供了实用高效的集合距离估计方法。

Abstract: The Hausdorff distance (HD) is a robust measure of set dissimilarity, but computing it exactly on large, high-dimensional datasets is prohibitively expensive. We propose \textbf{ProHD}, a projection-guided approximation algorithm that dramatically accelerates HD computation while maintaining high accuracy. ProHD identifies a small subset of candidate "extreme" points by projecting the data onto a few informative directions (such as the centroid axis and top principal components) and computing the HD on this subset. This approach guarantees an underestimate of the true HD with a bounded additive error and typically achieves results within a few percent of the exact value. In extensive experiments on image, physics, and synthetic datasets (up to two million points in $D=256$), ProHD runs 10--100$\times$ faster than exact algorithms while attaining 5--20$\times$ lower error than random sampling-based approximations. Our method enables practical HD calculations in scenarios like large vector databases and streaming data, where quick and reliable set distance estimation is needed.

</details>


### [6] [LLM Reasoning for Cold-Start Item Recommendation](https://arxiv.org/abs/2511.18261)
*Shijun Li,Yu Wang,Jin Wang,Ying Li,Joydeep Ghosh,Anne Cocos*

Main category: cs.IR

TL;DR: 提出针对Netflix冷启动推荐场景的LLM推理策略，通过监督微调、强化学习微调和混合方法显著提升冷启动推荐性能，在某些情况下比Netflix生产排序模型性能提升8%。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注有丰富用户-物品交互数据的暖启动场景，而交互稀疏的冷启动场景研究不足，传统协同过滤方法在此类场景中表现不佳。

Method: 利用LLM的推理能力推断用户偏好，特别是对新引入或交互稀少的物品；系统评估监督微调、强化学习微调以及两者结合的混合方法。

Result: 在真实数据上的广泛实验表明，在冷启动推荐场景中方法有效性和实际性能均有显著提升；基于推理的微调模型在某些情况下比Netflix生产排序模型性能提升8%。

Conclusion: LLM推理策略能有效解决冷启动推荐问题，特别是通过微调方法可以显著提升推荐性能，为冷启动场景提供了有前景的解决方案。

Abstract: Large Language Models (LLMs) have shown significant potential for improving recommendation systems through their inherent reasoning capabilities and extensive knowledge base. Yet, existing studies predominantly address warm-start scenarios with abundant user-item interaction data, leaving the more challenging cold-start scenarios, where sparse interactions hinder traditional collaborative filtering methods, underexplored. To address this limitation, we propose novel reasoning strategies designed for cold-start item recommendations within the Netflix domain. Our method utilizes the advanced reasoning capabilities of LLMs to effectively infer user preferences, particularly for newly introduced or rarely interacted items. We systematically evaluate supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches that combine both methods to optimize recommendation performance. Extensive experiments on real-world data demonstrate significant improvements in both methodological efficacy and practical performance in cold-start recommendation contexts. Remarkably, our reasoning-based fine-tuned models outperform Netflix's production ranking model by up to 8% in certain cases.

</details>


### [7] [Democratic Recommendation with User and Item Representatives Produced by Graph Condensation](https://arxiv.org/abs/2511.18279)
*Jiahao Liang,Haoran Yang,Xiangyu Zhao,Zhiwen Yu,Guandong Xu,Wanyu Wang,Kaixiang Yang*

Main category: cs.IR

TL;DR: 提出DemoRec框架，利用图压缩技术生成用户和物品代表，通过构建紧凑交互图来减少图规模并提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 解决大规模用户-物品交互图中的计算效率低下和信息传播不足问题，现有方法存在泛化能力差和信息损失等局限性

Method: 基于民主原则，使用图压缩技术生成用户和物品代表，构建紧凑交互图并聚类具有共享特征的节点

Result: 在四个公共数据集上的实验表明，DemoRec在推荐性能、计算效率和鲁棒性方面相比SOTA方法有显著提升

Conclusion: DemoRec框架通过图压缩有效解决了大规模二分图推荐系统的计算挑战，同时保持了推荐性能

Abstract: The challenges associated with large-scale user-item interaction graphs have attracted increasing attention in graph-based recommendation systems, primarily due to computational inefficiencies and inadequate information propagation. Existing methods provide partial solutions but suffer from notable limitations: model-centric approaches, such as sampling and aggregation, often struggle with generalization, while data-centric techniques, including graph sparsification and coarsening, lead to information loss and ineffective handling of bipartite graph structures. Recent advances in graph condensation offer a promising direction by reducing graph size while preserving essential information, presenting a novel approach to mitigating these challenges. Inspired by the principles of democracy, we propose \textbf{DemoRec}, a framework that leverages graph condensation to generate user and item representatives for recommendation tasks. By constructing a compact interaction graph and clustering nodes with shared characteristics from the original graph, DemoRec significantly reduces graph size and computational complexity. Furthermore, it mitigates the over-reliance on high-order information, a critical challenge in large-scale bipartite graphs. Extensive experiments conducted on four public datasets demonstrate the effectiveness of DemoRec, showcasing substantial improvements in recommendation performance, computational efficiency, and robustness compared to SOTA methods.

</details>


### [8] [Large Language Model Enhanced Graph Invariant Contrastive Learning for Out-of-Distribution Recommendation](https://arxiv.org/abs/2511.18282)
*Jiahao Liang,Haoran Yang,Xiangyu Zhao,Zhiwen Yu,Mianjie Li,Chuan Shi,Kaixiang Yang*

Main category: cs.IR

TL;DR: 提出InvGCLLM框架，结合数据驱动模型和知识驱动LLM，通过因果置信度评分指导图结构优化，解决图推荐系统中的分布外泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络算法学习虚假环境相关性而非稳定因果关系，在分布偏移下性能显著下降。LLM具有丰富世界知识和推理能力，但如何将其与特定图的细粒度拓扑结构有效整合以解决OOD问题仍具挑战。

Method: 1) 使用数据驱动不变性学习模型生成用户-物品交互的因果置信度评分；2) 利用LLM进行针对性图优化，基于世界知识剪除虚假连接并增强缺失因果链接；3) 结构纯化后的图提供鲁棒监督信号，用于因果引导的对比学习目标。

Result: 在四个公共数据集上的实验表明，InvGCLLM在分布外推荐任务中取得显著改进，持续优于最先进的基线方法。

Conclusion: InvGCLLM通过协同整合数据驱动模型和知识驱动LLM的优势，有效解决了图推荐系统中的OOD泛化问题，学习了对虚假相关性具有鲁棒性的表示。

Abstract: Out-of-distribution (OOD) generalization has emerged as a significant challenge in graph recommender systems. Traditional graph neural network algorithms often fail because they learn spurious environmental correlations instead of stable causal relationships, leading to substantial performance degradation under distribution shifts. While recent advancements in Large Language Models (LLMs) offer a promising avenue due to their vast world knowledge and reasoning capabilities, effectively integrating this knowledge with the fine-grained topology of specific graphs to solve the OOD problem remains a significant challenge. To address these issues, we propose {$\textbf{Inv}$ariant $\textbf{G}$raph $\textbf{C}$ontrastive Learning with $\textbf{LLM}$s for Out-of-Distribution Recommendation (InvGCLLM)}, an innovative causal learning framework that synergistically integrates the strengths of data-driven models and knowledge-driven LLMs. Our framework first employs a data-driven invariant learning model to generate causal confidence scores for each user-item interaction. These scores then guide an LLM to perform targeted graph refinement, leveraging its world knowledge to prune spurious connections and augment missing causal links. Finally, the structurally purified graphs provide robust supervision for a causality-guided contrastive learning objective, enabling the model to learn representations that are resilient to spurious correlations. Experiments conducted on four public datasets demonstrate that InvGCLLM achieves significant improvements in out-of-distribution recommendation, consistently outperforming state-of-the-art baselines.

</details>


### [9] [UFO: Unfair-to-Fair Evolving Mitigates Unfairness in LLM-based Recommender Systems via Self-Play Fine-tuning](https://arxiv.org/abs/2511.18342)
*Jiaming Zhang,Yuyuan Li,Xiaohua Feng,Zhifei Ren,Li Zhang,Chaochao Chen*

Main category: cs.IR

TL;DR: 本文提出UFO框架，通过自博弈机制解决基于大语言模型的推荐系统中的项目侧不公平问题，同时保持推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注SFT阶段的不公平性，但研究发现预训练阶段也存在偏见，且SFT会放大这些偏见。当前方法无法从根本上解决不公平问题，且难以保持推荐性能。

Method: 提出UFO框架，采用自博弈机制，将不公平缓解建模为双人游戏：评判者识别预训练和SFT中的不公平，修正者调整LRS解决不公平同时保持推荐性能。

Result: 大量实验表明，UFO能有效缓解不公平性，同时提升推荐性能。

Conclusion: UFO框架通过迭代优化完全解决了不公平问题，证明了同时考虑预训练和SFT阶段偏见的重要性。

Abstract: Large language model-based Recommender Systems (LRSs) have demonstrated superior recommendation performance by integrating pre-training with Supervised Fine-Tuning (SFT). However, this approach introduces item-side unfairness. Existing studies primarily attribute this issue to the absence of fairness constraints during SFT and attempt to mitigate unfairness via re-weighting and re-ranking methods. In this paper, we find that unfairness arises not only from SFT but also from pre-training, where inherent biases are further amplified during SFT. This finding underscores the failure of current methods to address the root causes of unfairness. Moreover, current methods struggle to preserve satisfactory recommendation performance. To tackle these issues, we propose an Unfair-to-Fair evOlving (UFO) framework using a self-play mechanism, formulating unfairness mitigation as a two-player game. UFO alternates between two player roles: the \textit{judger}, which identifies unfairness from both pre-training and SFT, and the \textit{corrector}, which adjusts the LRS to address identified unfairness while preserving recommendation performance. Iterative optimization between these roles enables UFO to completely resolve unfairness. Extensive experiments demonstrate that UFO effectively mitigates unfairness while improving recommendation performance.

</details>


### [10] [Time Matters: Enhancing Sequential Recommendations with Time-Guided Graph Neural ODEs](https://arxiv.org/abs/2511.18347)
*Haoyan Fu,Zhida Qin,Shixiao Yang,Haoyao Zhang,Bin Lu,Shuang Li,Tianyu Huang,John C. S. Lui*

Main category: cs.IR

TL;DR: TGODE模型通过构建用户时间图和物品演化图，结合时间引导扩散生成器和用户兴趣截断因子，解决序列推荐中用户兴趣不连续和物品分布不均的问题，在五个数据集上性能提升10%-46%。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法忽视了两个关键因素：用户交互间的不规则兴趣变化和物品随时间的分布不均。前者导致历史交互可能与当前购买行为无关，后者由于季节趋势或促销活动造成的外部驱动分布可能与用户真实兴趣不符。

Method: 1. 构建用户时间图和物品演化图；2. 设计时间引导扩散生成器自动获取增强的时间感知用户图；3. 提出用户兴趣截断因子识别稀疏时间间隔；4. 使用广义图神经ODE对齐用户偏好和物品分布的演化。

Result: 在五个数据集上的实验结果表明，TGODE优于基线方法，性能提升范围在10%到46%之间。

Conclusion: TGODE通过有效处理用户兴趣不连续性和物品分布不均匀性，显著提升了序列推荐的性能，证明了所提出方法在捕捉长期历史交互方面的有效性。

Abstract: Sequential recommendation (SR) is widely deployed in e-commerce platforms, streaming services, etc., revealing significant potential to enhance user experience. However, existing methods often overlook two critical factors: irregular user interests between interactions and highly uneven item distributions over time. The former factor implies that actual user preferences are not always continuous, and long-term historical interactions may not be relevant to current purchasing behavior. Therefore, relying only on these historical interactions for recommendations may result in a lack of user interest at the target time. The latter factor, characterized by peaks and valleys in interaction frequency, may result from seasonal trends, special events, or promotions. These externally driven distributions may not align with individual user interests, leading to inaccurate recommendations. To address these deficiencies, we propose TGODE to both enhance and capture the long-term historical interactions. Specifically, we first construct a user time graph and item evolution graph, which utilize user personalized preferences and global item distribution information, respectively. To tackle the temporal sparsity caused by irregular user interactions, we design a time-guided diffusion generator to automatically obtain an augmented time-aware user graph. Additionally, we devise a user interest truncation factor to efficiently identify sparse time intervals and achieve balanced preference inference. After that, the augmented user graph and item graph are fed into a generalized graph neural ordinary differential equation (ODE) to align with the evolution of user preferences and item distributions. This allows two patterns of information evolution to be matched over time. Experimental results demonstrate that TGODE outperforms baseline methods across five datasets, with improvements ranging from 10% to 46%.

</details>


### [11] [A Recommender System Based on Binary Matrix Representations for Cognitive Disorders](https://arxiv.org/abs/2511.18645)
*Raoul H. Kutil,Georg Zimmermann,Christian Borgelt*

Main category: cs.IR

TL;DR: 开发了一个基于二元矩阵的认知障碍诊断推荐系统，能够根据患者当前症状识别潜在障碍并推荐最有信息量的后续症状进行诊断。


<details>
  <summary>Details</summary>
Motivation: 认知障碍诊断复杂且需要专业知识，症状重叠使得基于症状导航困难，需要工具来帮助识别相关障碍并指导后续调查。

Method: 使用障碍和症状组合的二元矩阵表示，基于患者当前症状过滤行和列来识别潜在障碍，并推荐最有信息量的后续症状。

Result: 原型系统成功从初始症状集中识别出合理的障碍，推荐了进一步诊断的症状，并提供了症状-障碍关系的额外背景信息。

Conclusion: 该推荐系统有潜力作为临床支持工具，帮助心理健康专业人员更有效地识别相关障碍并提高诊断准确性。

Abstract: Diagnosing cognitive (mental health) disorders is a delicate and complex task. Identifying the next most informative symptoms to assess, in order to distinguish between possible disorders, presents an additional challenge. This process requires comprehensive knowledge of diagnostic criteria and symptom overlap across disorders, making it difficult to navigate based on symptoms alone. This research aims to develop a recommender system for cognitive disorder diagnosis using binary matrix representations. The core algorithm utilizes a binary matrix of disorders and their symptom combinations. It filters through the rows and columns based on the patient's current symptoms to identify potential disorders and recommend the most informative next symptoms to examine. A prototype of the recommender system was implemented in Python. Using synthetic test and some real-life data, the system successfully identified plausible disorders from an initial symptom set and recommended further symptoms to refine the diagnosis. It also provided additional context on the symptom-disorder relationships. Although this is a prototype, the recommender system shows potential as a clinical support tool. A fully-developed application of this recommender system may assist mental health professionals in identifying relevant disorders more efficiently and guiding symptom-specific follow-up investigations to improve diagnostic accuracy.

</details>


### [12] [When and What to Recommend: Joint Modeling of Timing and Content for Active Sequential Recommendation](https://arxiv.org/abs/2511.18717)
*Jin Chai,Xiaoxiao Ma,Jian Yang,Jia Wu*

Main category: cs.IR

TL;DR: PASRec是一个基于扩散模型的主动推荐框架，能够预测用户兴趣时间并主动推送相关物品，解决了传统被动推荐在应用关闭后无法触达用户的问题。


<details>
  <summary>Details</summary>
Motivation: 现有顺序推荐系统大多是被动的，只在用户打开应用时响应，错过了应用关闭后的推荐机会。需要研究主动推荐，预测下一次交互时间并主动推送物品。

Method: 提出PASRec框架，使用扩散模型通过联合目标对齐兴趣时间(ToI)和兴趣物品(IoI)，准确预测交互时间并生成相关物品。

Result: 在五个基准数据集上的实验表明，PASRec在留一法和时间分割设置下优于八个最先进的基线方法。

Conclusion: PASRec通过扩散模型有效解决了主动推荐中的时间和物品预测问题，显著提升了推荐性能。

Abstract: Sequential recommendation models user preferences to predict the next target item. Most existing work is passive, where the system responds only when users open the application, missing chances after closure. We investigate active recommendation, which predicts the next interaction time and actively delivers items. Two challenges: accurately estimating the Time of Interest (ToI) and generating Item of Interest (IoI) conditioned on the predicted ToI. We propose PASRec, a diffusion-based framework that aligns ToI and IoI via a joint objective. Experiments on five benchmarks show superiority over eight state-of-the-art baselines under leave-one-out and temporal splits.

</details>


### [13] [Multimodal Large Language Models with Adaptive Preference Optimization for Sequential Recommendation](https://arxiv.org/abs/2511.18740)
*Yu Wang,Yonghui Yang,Le Wu,Yi Zhang,Richang Hong*

Main category: cs.IR

TL;DR: 提出了HaNoRec框架，通过动态调整优化权重和引入高斯扰动分布优化，解决多模态推荐中的样本硬度不平衡和跨模态语义偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用文本模态，忽略了丰富的视觉信号对用户细粒度兴趣的影响，且面临样本硬度不平衡和跨模态语义偏差的挑战。

Method: HaNoRec框架集成硬度感知和噪声正则化的偏好优化，动态调整优化权重，并引入高斯扰动分布优化以增强跨模态语义一致性。

Result: 该框架能够优先处理困难样本，减少模态偏差，提高推荐性能。

Conclusion: HaNoRec通过硬度感知和噪声正则化优化，有效解决了多模态推荐中的关键挑战，提升了模型的推荐准确性和鲁棒性。

Abstract: Recent advances in Large Language Models (LLMs) have opened new avenues for sequential recommendation by enabling natural language reasoning over user behavior sequences. A common approach formulates recommendation as a language modeling task, where interaction histories are transformed into prompts and user preferences are learned via supervised fine-tuning. However, these methods operate solely in the textual modality and often miss users' fine-grained interests, especially when shaped by rich visual signals such as product images or movie posters. Multimodal Large Language Models (MLLMs) offer a promising alternative by aligning text and vision in a shared semantic space. A prevalent training paradigm applies Supervised Fine-Tuning (SFT) followed by Direct Preference Optimization (DPO) to model user preferences. Yet, two core challenges remain: 1) Imbalanced sample hardness, where random negative sampling causes overfitting on easy examples and under-training on hard ones; 2) Cross-modal semantic bias, where the fixed reference model in DPO prevents the policy model from correcting modality misalignments--especially over long sequences. To address these issues, we propose a Multimodal LLM framework that integrates Hardness-aware and Noise-regularized preference optimization for Recommendation (HaNoRec). Specifically, HaNoRec dynamically adjusts optimization weights based on both the estimated hardness of each training sample and the policy model's real-time responsiveness, prioritizing harder examples. It further introduces Gaussian-perturbed distribution optimization on output logits to enhance cross-modal semantic consistency and reduce modality bias inherited from the reference model.

</details>


### [14] [STORE: Semantic Tokenization, Orthogonal Rotation and Efficient Attention for Scaling Up Ranking Models](https://arxiv.org/abs/2511.18805)
*Yi Xu,Chaofan Fan,Jinxin Hu,Yu Zhang,Zeng Xiaoyi,Jing Zhang*

Main category: cs.IR

TL;DR: STORE是一个统一的、可扩展的基于令牌的排序框架，通过语义令牌化、正交旋转变换和高效注意力机制，解决了推荐系统中高基数异构稀疏特征带来的表示瓶颈和计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现代个性化推荐系统中的排序模型在处理高基数、异构和稀疏特征空间时面临模型可扩展性和效率的重大挑战，存在表示瓶颈和计算瓶颈。

Method: 提出STORE框架，包含三个核心创新：(1)语义令牌化将高基数稀疏特征分解为紧凑的稳定语义令牌；(2)正交旋转变换旋转低基数静态特征子空间；(3)高效注意力机制过滤低贡献令牌。

Result: 在广泛的离线和在线A/B测试中，该框架持续提升了预测准确性（在线CTR提升2.71%，AUC提升1.195%）和训练效率（吞吐量提升1.84倍）。

Conclusion: STORE框架成功解决了推荐系统排序模型中的表示和计算瓶颈，显著提升了模型性能和效率。

Abstract: Ranking models have become an important part of modern personalized recommendation systems. However, significant challenges persist in handling high-cardinality, heterogeneous, and sparse feature spaces, particularly regarding model scalability and efficiency. We identify two key bottlenecks: (i) Representation Bottleneck: Driven by the high cardinality and dynamic nature of features, model capacity is forced into sparse-activated embedding layers, leading to low-rank representations. This, in turn, triggers phenomena like "One-Epoch" and "Interaction-Collapse," ultimately hindering model scalability.(ii) Computational Bottleneck: Integrating all heterogeneous features into a unified model triggers an explosion in the number of feature tokens, rendering traditional attention mechanisms computationally demanding and susceptible to attention dispersion. To dismantle these barriers, we introduce STORE, a unified and scalable token-based ranking framework built upon three core innovations: (1) Semantic Tokenization fundamentally tackles feature heterogeneity and sparsity by decomposing high-cardinality sparse features into a compact set of stable semantic tokens; and (2) Orthogonal Rotation Transformation is employed to rotate the subspace spanned by low-cardinality static features, which facilitates more efficient and effective feature interactions; and (3) Efficient attention that filters low-contributing tokens to improve computional efficiency while preserving model accuracy. Across extensive offline experiments and online A/B tests, our framework consistently improves prediction accuracy(online CTR by 2.71%, AUC by 1.195%) and training effeciency (1.84 throughput).

</details>


### [15] [Heterogeneous Multi-treatment Uplift Modeling for Trade-off Optimization in Short-Video Recommendation](https://arxiv.org/abs/2511.18997)
*Chenhao Zhai,Chang Meng,Xueliang Wang,Shuchang Liu,Xiaolong Hu,Shisong Tang,Xiaoqiang Feng,Xiu Li*

Main category: cs.IR

TL;DR: 提出了一个名为HMUM的异构多处理提升建模框架，用于短视频推荐中的权衡优化，包含离线混合提升建模和在线动态决策模块，在快手平台已部署并服务数亿用户。


<details>
  <summary>Details</summary>
Motivation: 现有提升模型在处理短视频推荐的异构多处理场景时存在局限，无法有效捕捉不同策略的协同和个体因果效应，传统固定权重方法缺乏个性化且可能导致决策偏差。

Method: HMUM框架包含离线混合提升建模模块（捕捉多策略的协同和个体效应）和在线动态决策模块（实时估计不同用户响应的价值权重进行个性化决策）。

Result: 在两个公共数据集、一个工业数据集和快手平台在线A/B实验中，模型表现出优越的离线性能，关键指标显著提升。

Conclusion: HMUM框架成功解决了短视频推荐中的异构多处理权衡优化问题，已在快手平台全面部署，服务数亿用户。

Abstract: The rapid proliferation of short videos on social media platforms presents unique challenges and opportunities for recommendation systems. Users exhibit diverse preferences, and the responses resulting from different strategies often conflict with one another, potentially exhibiting inverse correlations between metrics such as watch time and video view counts. Existing uplift models face limitations in handling the heterogeneous multi-treatment scenarios of short-video recommendations, often failing to effectively capture both the synergistic and individual causal effects of different strategies. Furthermore, traditional fixed-weight approaches for balancing these responses lack personalization and can result in biased decision-making. To address these issues, we propose a novel Heterogeneous Multi-treatment Uplift Modeling (HMUM) framework for trade-off optimization in short-video recommendations. HMUM comprises an Offline Hybrid Uplift Modeling (HUM) module, which captures the synergistic and individual effects of multiple strategies, and an Online Dynamic Decision-Making (DDM) module, which estimates the value weights of different user responses in real-time for personalized decision-making. Evaluated on two public datasets, an industrial dataset, and through online A/B experiments on the Kuaishou platform, our model demonstrated superior offline performance and significant improvements in key metrics. It is now fully deployed on the platform, benefiting hundreds of millions of users.

</details>


### [16] [BioArtlas: Computational Clustering of Multi-Dimensional Complexity in Bioart](https://arxiv.org/abs/2511.19162)
*Joonhyung Bae*

Main category: cs.IR

TL;DR: BioArtlas是一个分析81件生物艺术作品的系统，通过13个维度使用轴感知表示方法，结合代码本聚类解决文化术语的多义性问题，发现了四种组织模式，并提供交互式网站和公开数据集。


<details>
  <summary>Details</summary>
Motivation: 生物艺术的混合性质跨越艺术、科学、技术、伦理和政治，难以用传统单轴分类方法进行有效分析。

Method: 使用代码本方法将相关概念分组为统一聚类，解决文化术语的多义性问题；评估了多达800种表示空间-算法组合，确定在4D UMAP上使用k=15的凝聚聚类为最优方法。

Result: 发现了四种组织模式：艺术家特定的方法论一致性、基于技术的分割、时间性艺术演变和跨时间概念亲和性；最优聚类方法的轮廓系数为0.664±0.008，可信度/连续性为0.805/0.812。

Conclusion: 通过将分析优化与公共传播分离，提供了严谨的分析和可访问的探索方式，开发了交互式网站并公开了数据集。

Abstract: Bioart's hybrid nature spanning art, science, technology, ethics, and politics defies traditional single-axis categorization. I present BioArtlas, analyzing 81 bioart works across thirteen curated dimensions using novel axis-aware representations that preserve semantic distinctions while enabling cross-dimensional comparison. Our codebook-based approach groups related concepts into unified clusters, addressing polysemy in cultural terminology. Comprehensive evaluation of up to 800 representation-space-algorithm combinations identifies Agglomerative clustering at k=15 on 4D UMAP as optimal (silhouette 0.664 +/- 0.008, trustworthiness/continuity 0.805/0.812). The approach reveals four organizational patterns: artist-specific methodological cohesion, technique-based segmentation, temporal artistic evolution, and trans-temporal conceptual affinities. By separating analytical optimization from public communication, I provide rigorous analysis and accessible exploration through an interactive web interface (https://www.bioartlas.com) with the dataset publicly available (https://github.com/joonhyungbae/BioArtlas).

</details>


### [17] [What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models](https://arxiv.org/abs/2511.19324)
*Roksana Goworek,Olivia Macmillan-Scott,Eda B. Özyiğit*

Main category: cs.IR

TL;DR: 本文系统评估了跨语言信息检索中的四种干预方法，发现专门为CLIR训练的密集检索模型始终优于词汇匹配方法，且文档翻译带来的收益有限。对比学习能缓解语言偏见，重排序效果取决于训练数据质量。


<details>
  <summary>Details</summary>
Motivation: 跨语言信息检索面临资源差异、文字系统不同以及嵌入模型跨语言语义对齐能力弱等挑战。现有方法依赖翻译和单语检索启发式方法，增加了计算开销和噪声，降低了性能。

Method: 系统评估了四种干预类型：文档翻译、使用预训练编码器的多语言密集检索、在词、短语和查询-文档级别的对比学习，以及交叉编码器重排序。在三个基准数据集上进行测试。

Result: 专门为CLIR训练的密集检索模型始终优于词汇匹配方法，从文档翻译中获益甚微。对比学习显著改善了初始对齐能力弱的编码器，重排序效果取决于交叉编码器训练数据的质量。高资源语言仍主导整体性能，但对低资源和跨文字语言对的改进最为明显。

Conclusion: 跨语言搜索系统应优先考虑语义多语言嵌入和有针对性的基于学习的对齐方法，而不是基于翻译的流程，特别是对于跨文字和资源不足的语言。

Abstract: Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.

</details>


### [18] [Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval](https://arxiv.org/abs/2511.19325)
*Olivia Macmillan-Scott,Roksana Goworek,Eda B. Özyiğit*

Main category: cs.IR

TL;DR: 评估多语言大语言模型在跨语言查询扩展中的表现，发现查询长度决定提示技术效果，语言差异显著影响检索性能，微调仅在训练测试数据格式相似时有效。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型将查询扩展从语义增强转向伪文档生成，这在密集检索中特别有益，需要评估不同生成扩展策略对跨语言检索性能的影响因素。

Method: 评估近期多语言大语言模型及其微调变体在多种生成扩展策略上的表现，分析查询长度、提示技术和语言差异等因素。

Result: 查询长度决定提示技术有效性，复杂提示通常无额外收益；语言差异显著：跨语言查询扩展对基线最弱的语言改进最大，但不同文字系统间检索性能尤其差；微调仅在训练测试数据格式相似时带来性能提升。

Conclusion: 需要更平衡的多语言和跨语言训练与评估资源来解决现有语言差异问题。

Abstract: Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.

</details>


### [19] [Revisiting Feedback Models for HyDE](https://arxiv.org/abs/2511.19349)
*Nour Jedidi,Jimmy Lin*

Main category: cs.IR

TL;DR: 研究发现，在基于LLM的伪相关反馈方法HyDE中，使用传统反馈模型（如Rocchio）比简单的字符串拼接能显著提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 当前利用LLM进行伪相关反馈的方法大多采用简单的字符串拼接方式，而没有充分利用传统反馈模型如Rocchio和RM3的优势。

Method: 系统评估了传统反馈模型在HyDE方法中的应用，HyDE是一种使用LLM生成假设答案文档来丰富查询表示的方法。

Result: 实验表明，使用Rocchio等反馈算法提取和加权扩展词能显著提高HyDE的有效性。

Conclusion: 利用传统反馈算法是进一步提升基于LLM的伪相关反馈方法准确性的简单有效方式。

Abstract: Recent approaches that leverage large language models (LLMs) for pseudo-relevance feedback (PRF) have generally not utilized well-established feedback models like Rocchio and RM3 when expanding queries for sparse retrievers like BM25. Instead, they often opt for a simple string concatenation of the query and LLM-generated expansion content. But is this optimal? To answer this question, we revisit and systematically evaluate traditional feedback models in the context of HyDE, a popular method that enriches query representations with LLM-generated hypothetical answer documents. Our experiments show that HyDE's effectiveness can be substantially improved when leveraging feedback algorithms such as Rocchio to extract and weight expansion terms, providing a simple way to further enhance the accuracy of LLM-based PRF methods.

</details>
