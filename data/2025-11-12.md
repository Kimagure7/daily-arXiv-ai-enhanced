<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [A Hybrid Multimodal Deep Learning Framework for Intelligent Fashion Recommendation](https://arxiv.org/abs/2511.07573)
*Kamand Kalashi,Babak Teimourpour*

Main category: cs.IR

TL;DR: 提出了一种基于CLIP架构的混合多模态深度学习框架，用于时尚推荐，同时处理服装搭配兼容性预测和互补物品检索两个任务。


<details>
  <summary>Details</summary>
Motivation: 在线时尚平台的快速发展对能够理解视觉和文本线索的智能推荐系统提出了日益增长的需求。

Method: 利用CLIP架构的视觉和文本编码器获取时尚物品的联合潜在表示，通过transformer编码器处理统一特征向量。对于兼容性预测引入'搭配标记'建模物品间整体关系；对于互补物品检索使用'目标物品标记'表示所需物品描述。

Result: 在Polyvore数据集上，兼容性预测AUC达到0.95；互补物品检索在FITB指标下准确率达到69.24%。

Conclusion: 该方法在两个任务上都表现出强劲性能，证明了多模态学习在时尚推荐中的有效性。

Abstract: The rapid expansion of online fashion platforms has created an increasing demand for intelligent recommender systems capable of understanding both visual and textual cues. This paper proposes a hybrid multimodal deep learning framework for fashion recommendation that jointly addresses two key tasks: outfit compatibility prediction and complementary item retrieval. The model leverages the visual and textual encoders of the CLIP architecture to obtain joint latent representations of fashion items, which are then integrated into a unified feature vector and processed by a transformer encoder. For compatibility prediction, an "outfit token" is introduced to model the holistic relationships among items, achieving an AUC of 0.95 on the Polyvore dataset. For complementary item retrieval, a "target item token" representing the desired item description is used to retrieve compatible items, reaching an accuracy of 69.24% under the Fill-in-the-Blank (FITB) metric. The proposed approach demonstrates strong performance across both tasks, highlighting the effectiveness of multimodal learning for fashion recommendation.

</details>


### [2] [TurkEmbed4Retrieval: Turkish Embedding Model for Retrieval Task](https://arxiv.org/abs/2511.07595)
*Özay Ezerceli,Gizem Gümüşçekiçci,Tuğba Erkoç,Berke Özenç*

Main category: cs.IR

TL;DR: 提出了TurkEmbed4Retrieval模型，这是专为土耳其语检索任务优化的TurkEmbed变体，在MS MARCO TR数据集上微调后，在Scifact TR数据集上比土耳其colBERT性能提升19.26%。


<details>
  <summary>Details</summary>
Motivation: 原始的TurkEmbed模型主要针对NLI和STS任务设计，需要专门针对土耳其语检索任务进行优化。

Method: 在MS MARCO TR数据集上对基础模型进行微调，采用Matryoshka表示学习和定制的多负例排序损失等先进训练技术。

Result: 在Scifact TR数据集的关键检索指标上，比土耳其colBERT性能提升19.26%，达到SOTA水平。

Conclusion: 为土耳其语信息检索建立了新的基准，证明了专门针对检索任务优化的模型的有效性。

Abstract: In this work, we introduce TurkEmbed4Retrieval, a retrieval specialized variant of the TurkEmbed model originally designed for Natural Language Inference (NLI) and Semantic Textual Similarity (STS) tasks. By fine-tuning the base model on the MS MARCO TR dataset using advanced training techniques, including Matryoshka representation learning and a tailored multiple negatives ranking loss, we achieve SOTA performance for Turkish retrieval tasks. Extensive experiments demonstrate that our model outperforms Turkish colBERT by 19,26% on key retrieval metrics for the Scifact TR dataset, thereby establishing a new benchmark for Turkish information retrieval.

</details>


### [3] [From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization](https://arxiv.org/abs/2511.08006)
*Peiyu Hu,Wayne Lu,Jia Wang*

Main category: cs.IR

TL;DR: GenCDR是一个生成式跨域推荐框架，通过领域自适应分词和跨域自回归推荐解决传统方法依赖共享ID的问题，显著提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 传统跨域推荐方法依赖共享用户/物品ID，但在实际场景中这些ID通常不可用。现有LLM方法面临词汇爆炸和领域特定建模不足的问题。

Method: 提出GenCDR框架，包含领域自适应分词模块（动态路由通用编码器和领域特定适配器）、跨域自回归推荐模块（融合通用和领域特定兴趣）和领域感知前缀树。

Result: 在多个真实数据集上的实验表明，GenCDR显著优于现有最先进的基线方法。

Conclusion: GenCDR有效解决了跨域推荐中的关键挑战，为无共享ID场景提供了有效的解决方案。

Abstract: Cross-domain recommendation (CDR) is crucial for improving recommendation accuracy and generalization, yet traditional methods are often hindered by the reliance on shared user/item IDs, which are unavailable in most real-world scenarios. Consequently, many efforts have focused on learning disentangled representations through multi-domain joint training to bridge the domain gaps. Recent Large Language Model (LLM)-based approaches show promise, they still face critical challenges, including: (1) the \textbf{item ID tokenization dilemma}, which leads to vocabulary explosion and fails to capture high-order collaborative knowledge; and (2) \textbf{insufficient domain-specific modeling} for the complex evolution of user interests and item semantics. To address these limitations, we propose \textbf{GenCDR}, a novel \textbf{Gen}erative \textbf{C}ross-\textbf{D}omain \textbf{R}ecommendation framework. GenCDR first employs a \textbf{Domain-adaptive Tokenization} module, which generates disentangled semantic IDs for items by dynamically routing between a universal encoder and domain-specific adapters. Symmetrically, a \textbf{Cross-domain Autoregressive Recommendation} module models user preferences by fusing universal and domain-specific interests. Finally, a \textbf{Domain-aware Prefix-tree} enables efficient and accurate generation. Extensive experiments on multiple real-world datasets demonstrate that GenCDR significantly outperforms state-of-the-art baselines. Our code is available in the supplementary materials.

</details>


### [4] [BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives](https://arxiv.org/abs/2511.08029)
*Aarush Sinha,Pavan Kumar S,Roshan Balaji,Nirav Pravinbhai Bhatt*

Main category: cs.IR

TL;DR: 提出BiCA方法，利用PubMed文章中的引用链接生成高质量负样本，改进生物医学领域的密集检索模型性能


<details>
  <summary>Details</summary>
Motivation: 生物医学和科学领域中，区分源文档和困难负样本具有挑战性。引用文档与源文档具有上下文相关性但不是重复内容，适合作为困难负样本

Method: 使用20,000篇PubMed文章的引用链接进行困难负样本挖掘，微调GTE_small和GTE_Base模型，利用引用感知的负样本训练

Result: 在BEIR数据集上，零样本密集检索的nDCG@10指标在领域内和领域外任务中均获得持续改进；在LoTTE的长尾主题上使用Success@5指标优于基线方法

Conclusion: 利用文档链接结构生成信息丰富的负样本，能够以最小的微调实现最先进的性能，展示了高效数据域适应的路径

Abstract: Hard negatives are essential for training effective retrieval models. Hard-negative mining typically relies on ranking documents using cross-encoders or static embedding models based on similarity metrics such as cosine distance. Hard negative mining becomes challenging for biomedical and scientific domains due to the difficulty in distinguishing between source and hard negative documents. However, referenced documents naturally share contextual relevance with the source document but are not duplicates, making them well-suited as hard negatives. In this work, we propose BiCA: Biomedical Dense Retrieval with Citation-Aware Hard Negatives, an approach for hard-negative mining by utilizing citation links in 20,000 PubMed articles for improving a domain-specific small dense retriever. We fine-tune the GTE_small and GTE_Base models using these citation-informed negatives and observe consistent improvements in zero-shot dense retrieval using nDCG@10 for both in-domain and out-of-domain tasks on BEIR and outperform baselines on long-tailed topics in LoTTE using Success@5. Our findings highlight the potential of leveraging document link structure to generate highly informative negatives, enabling state-of-the-art performance with minimal fine-tuning and demonstrating a path towards highly data-efficient domain adaptation.

</details>


### [5] [DiffuGR: Generative Document Retrieval with Diffusion Language Models](https://arxiv.org/abs/2511.08150)
*Xinpeng Zhao,Yukun Zhao,Zhenyang Li,Mengqi Zhang,Jun Feng,Ran Chen,Ying Zhou,Zhumin Chen,Shuaiqiang Wang,Zhaochun Ren,Dawei Yin,Xin Xin*

Main category: cs.IR

TL;DR: 本文提出DiffuGR，一种基于扩散语言模型的生成式文档检索方法，将文档ID生成建模为离散扩散过程，解决了自回归方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归模型的生成式检索方法存在两个主要问题：(1)文档ID生成与自然语言生成不匹配，早期错误会导致完全错误的检索；(2)无法动态平衡检索效率与准确性的权衡。

Method: 将文档ID生成建模为离散扩散过程：训练时通过随机掩码过程破坏文档ID，学习扩散语言模型在检索感知目标下恢复它们；推理时并行生成文档ID标记，并通过可控的去噪步骤进行精炼。

Result: 在基准检索数据集上的广泛实验表明，DiffuGR与强自回归生成检索器具有竞争力，同时通过可变去噪预算提供灵活的速度和准确性权衡。

Conclusion: 非自回归扩散模型是生成式文档检索的实用有效替代方案，提供了显式的运行时质量-延迟权衡控制。

Abstract: Generative retrieval (GR) re-frames document retrieval as a sequence-based document identifier (DocID) generation task, memorizing documents with model parameters and enabling end-to-end retrieval without explicit indexing. Existing GR methods are based on auto-regressive generative models, i.e., the token generation is performed from left to right. However, such auto-regressive methods suffer from: (1) mismatch between DocID generation and natural language generation, e.g., an incorrect DocID token generated in early left steps would lead to totally erroneous retrieval; and (2) failure to balance the trade-off between retrieval efficiency and accuracy dynamically, which is crucial for practical applications. To address these limitations, we propose generative document retrieval with diffusion language models, dubbed DiffuGR. It models DocID generation as a discrete diffusion process: during training, DocIDs are corrupted through a stochastic masking process, and a diffusion language model is learned to recover them under a retrieval-aware objective. For inference, DiffuGR attempts to generate DocID tokens in parallel and refines them through a controllable number of denoising steps. In contrast to conventional left-to-right auto-regressive decoding, DiffuGR provides a novel mechanism to first generate more confident DocID tokens and refine the generation through diffusion-based denoising. Moreover, DiffuGR also offers explicit runtime control over the qualitylatency tradeoff. Extensive experiments on benchmark retrieval datasets show that DiffuGR is competitive with strong auto-regressive generative retrievers, while offering flexible speed and accuracy tradeoffs through variable denoising budgets. Overall, our results indicate that non-autoregressive diffusion models are a practical and effective alternative for generative document retrieval.

</details>


### [6] [MARC: Multimodal and Multi-Task Agentic Retrieval-Augmented Generation for Cold-Start Recommender System](https://arxiv.org/abs/2511.08181)
*Seung Hwan Cho,Yujin Yang,Danik Baeck,Minjoo Kim,Young-Min Kim,Heejung Lee,Sangjin Park*

Main category: cs.IR

TL;DR: MARC是一个基于Agentic RAG的多模态多任务鸡尾酒推荐系统，在冷启动条件下利用图数据库生成高质量的上下文相关推荐。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统在冷启动条件下的局限性，利用模态信息和LLM的推理能力，结合鸡尾酒领域独特的数据属性和关系特征。

Method: 使用基于Agentic RAG的方法，包含任务识别路由器和反思过程，构建图数据库处理鸡尾酒数据。

Result: 通过200个手工制作的问题进行评估，使用LLM和人工评估，证明基于图数据库的答案质量优于简单向量数据库。

Conclusion: MARC系统在冷启动条件下能够生成高质量的鸡尾酒推荐，图数据库在推荐系统中具有优势。

Abstract: Recommender systems (RS) are currently being studied to mitigate limitations during cold-start conditions by leveraging modality information or introducing Agent concepts based on the exceptional reasoning capabilities of Large Language Models (LLMs). Meanwhile, food and beverage recommender systems have traditionally used knowledge graph and ontology concepts due to the domain's unique data attributes and relationship characteristics. On this background, we propose MARC, a multimodal and multi-task cocktail recommender system based on Agentic Retrieval-Augmented Generation (RAG) utilizing graph database under cold-start conditions. The proposed system generates high-quality, contextually appropriate answers through two core processes: a task recognition router and a reflection process. The graph database was constructed by processing cocktail data from Kaggle, and its effectiveness was evaluated using 200 manually crafted questions. The evaluation used both LLM-as-a-judge and human evaluation to demonstrate that answers generated via the graph database outperformed those from a simple vector database in terms of quality. The code is available at https://github.com/diddbwls/cocktail_rec_agentrag

</details>


### [7] [Bid Farewell to Seesaw: Towards Accurate Long-tail Session-based Recommendation via Dual Constraints of Hybrid Intents](https://arxiv.org/abs/2511.08378)
*Xiao Wang,Ke Qin,Dongyang Zhang,Xiurui Xie,Shuang Liang*

Main category: cs.IR

TL;DR: HID框架通过混合意图学习和意图约束损失，解决了基于会话推荐中长尾项目与准确性之间的冲突，实现了长尾性能和推荐精度的双赢。


<details>
  <summary>Details</summary>
Motivation: 在基于会话的推荐中，低曝光项目构成大多数交互，形成长尾分布，严重损害推荐多样性。现有方法试图通过推广尾部项目来解决这个问题，但会导致准确性下降，表现出长尾与准确性性能之间的'跷跷板'效应。

Method: 提出HID框架，包含两个关键创新：(1)混合意图学习：通过属性感知谱聚类重构项目到意图的映射，通过为目标和噪声意图分配每个会话来区分会话无关噪声；(2)意图约束损失：引入关于多样性和准确性的两种新约束范式，通过严格的理论推导将这两个目标统一到单个训练损失中。

Result: 在多个SBR模型和数据集上的广泛实验表明，HID可以同时增强长尾性能和推荐准确性，在长尾推荐系统中建立了新的最先进性能。

Conclusion: HID框架成功地将传统的'跷跷板'转化为'双赢'，通过引入混合意图的双重约束，有效解决了长尾推荐中多样性与准确性之间的根本冲突。

Abstract: Session-based recommendation (SBR) aims to predict anonymous users' next interaction based on their interaction sessions. In the practical recommendation scenario, low-exposure items constitute the majority of interactions, creating a long-tail distribution that severely compromises recommendation diversity. Existing approaches attempt to address this issue by promoting tail items but incur accuracy degradation, exhibiting a "see-saw" effect between long-tail and accuracy performance. We attribute such conflict to session-irrelevant noise within the tail items, which existing long-tail approaches fail to identify and constrain effectively. To resolve this fundamental conflict, we propose \textbf{HID} (\textbf{H}ybrid \textbf{I}ntent-based \textbf{D}ual Constraint Framework), a plug-and-play framework that transforms the conventional "see-saw" into "win-win" through introducing the hybrid intent-based dual constraints for both long-tail and accuracy. Two key innovations are incorporated in this framework: (i) \textit{Hybrid Intent Learning}, where we reformulate the intent extraction strategies by employing attribute-aware spectral clustering to reconstruct the item-to-intent mapping. Furthermore, discrimination of session-irrelevant noise is achieved through the assignment of the target and noise intents to each session. (ii) \textit{Intent Constraint Loss}, which incorporates two novel constraint paradigms regarding the \textit{diversity} and \textit{accuracy} to regulate the representation learning process of both items and sessions. These two objectives are unified into a single training loss through rigorous theoretical derivation. Extensive experiments across multiple SBR models and datasets demonstrate that HID can enhance both long-tail performance and recommendation accuracy, establishing new state-of-the-art performance in long-tail recommender systems.

</details>


### [8] [Advancing Scientific Knowledge Retrieval and Reuse with a Novel Digital Library for Machine-Readable Knowledge](https://arxiv.org/abs/2511.08476)
*Hadi Ghaemi,Lauren Snyder,Markus Stocker*

Main category: cs.IR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Digital libraries for research, such as the ACM Digital Library or Semantic Scholar, do not enable the machine-supported, efficient reuse of scientific knowledge (e.g., in synthesis research). This is because these libraries are based on document-centric models with narrative text knowledge expressions that require manual or semi-automated knowledge extraction, structuring, and organization. We present ORKG reborn, an emerging digital library that supports finding, accessing, and reusing accurate, fine-grained, and reproducible machine-readable expressions of scientific knowledge that relate scientific statements and their supporting evidence in terms of data and code. The rich expressions of scientific knowledge are published as reborn (born-reusable) articles and provide novel possibilities for scientific knowledge retrieval, for instance by statistical methods, software packages, variables, or data matching specific constraints. We describe the proposed system and demonstrate its practical viability and potential for information retrieval in contrast to state-of-the-art digital libraries and document-centric scholarly communication using several published articles in research fields ranging from computer science to soil science. Our work underscores the enormous potential of scientific knowledge databases and a viable approach to their construction.

</details>
