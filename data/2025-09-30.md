<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [How good are LLMs at Retrieving Documents in a Specific Domain?](https://arxiv.org/abs/2509.22658)
*Nafis Tanveer Islam,Zhiming Zhao*

Main category: cs.IR

TL;DR: 本文提出了一种自动构建领域特定评估数据集的方法，并集成了基于大语言模型的检索增强生成(RAG)技术，用于环境科学领域的自然语言查询检索，相比传统Elasticsearch系统在理解多意图查询方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统基于索引的搜索引擎虽然可扩展性强，但由于缺乏合适的评估数据集和对语义理解的限制，经常无法准确捕捉用户意图，在环境科学等特定领域的数据检索中产生不完整的响应。

Method: 提出自动构建领域特定评估数据集的方法，并集成基于大语言模型的检索增强生成(RAG)技术来处理自然语言查询。

Result: 定量和定性分析表明，基于LLM的信息检索系统在理解多意图查询时返回结果的精确度高于基于Elasticsearch的系统。

Conclusion: 基于大语言模型的检索增强生成方法在环境科学领域数据检索中能够更好地理解复杂查询意图，提高检索质量。

Abstract: Classical search engines using indexing methods in data infrastructures
primarily allow keyword-based queries to retrieve content. While these
indexing-based methods are highly scalable and efficient, due to a lack of an
appropriate evaluation dataset and a limited understanding of semantics, they
often fail to capture the user's intent and generate incomplete responses
during evaluation. This problem also extends to domain-specific search systems
that utilize a Knowledge Base (KB) to access data from various research
infrastructures. Research infrastructures (RIs) from the environmental and
earth science domain, which encompass the study of ecosystems, biodiversity,
oceanography, and climate change, generate, share, and reuse large volumes of
data. While there are attempts to provide a centralized search service using
Elasticsearch as a knowledge base, they also face similar challenges in
understanding queries with multiple intents. To address these challenges, we
proposed an automated method to curate a domain-specific evaluation dataset to
analyze the capability of a search system. Furthermore, we incorporate the
Retrieval of Augmented Generation (RAG), powered by Large Language Models
(LLMs), for high-quality retrieval of environmental domain data using natural
language queries. Our quantitative and qualitative analysis of the evaluation
dataset shows that LLM-based systems for information retrieval return results
with higher precision when understanding queries with multiple intents,
compared to Elasticsearch-based systems.

</details>


### [2] [Federated Consistency- and Complementarity-aware Consensus-enhanced Recommendation](https://arxiv.org/abs/2509.22659)
*Yunqi Mi,Boyang Yan,Guoshuai Zhao,Jialie Shen,Xueming Qian*

Main category: cs.IR

TL;DR: Fed3CR是一种个性化联邦推荐方法，通过自适应共识增强和一致性-互补性优化策略，解决大规模客户端交互数据稀疏性导致的共识质量下降和解耦不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统中，由于大规模客户端交互数据的稀疏性和高度均匀性，导致全局项目嵌入表的共识质量下降和解耦不足，降低了共识的效用。

Method: 提出自适应共识增强策略学习全局和客户端特定项目嵌入的关系，使客户端能自适应增强共识中的特定信息；提出一致性-互补性优化策略学习更有效和互补的表征。

Result: 在四个真实世界数据集上的广泛实验表明Fed3CR具有优越性能。

Conclusion: Fed3CR是一种即插即用的方法，可以与其他联邦推荐方法集成以提高性能。

Abstract: Personalized federated recommendation system (FedRec) has gained significant
attention for its ability to preserve privacy in delivering tailored
recommendations. To alleviate the statistical heterogeneity challenges among
clients and improve personalization, decoupling item embeddings into the server
and client-specific views has become a promising way. Among them, the global
item embedding table serves as a consensus representation that integrates and
reflects the collective patterns across all clients. However, the inherent
sparsity and high uniformity of interaction data from massive-scale clients
results in degraded consensus and insufficient decoupling, reducing consensus's
utility. To this end, we propose a \textbf{Fed}erated \textbf{C}onsistency- and
\textbf{C}omplementarity-aware \textbf{C}onsensus-enhanced
\textbf{R}ecommendation (Fed3CR) method for personalized FedRec. To improve the
efficiency of the utilization of consensus, we propose an \textbf{A}daptive
\textbf{C}onsensus \textbf{E}nhancement (ACE) strategy to learn the
relationship between global and client-specific item embeddings. It enables the
client to adaptively enhance specific information in the consensus,
transforming it into a form that best suits itself. To improve the quality of
decoupling, we propose a \textbf{C}onsistency- and
\textbf{C}omplementarity-aware \textbf{O}ptimization (C2O) strategy, which
helps to learn more effective and complementary representations. Notably, our
proposed Fed3CR is a plug-and-play method, which can be integrated with other
FedRec methods to improve its performance. Extensive experiments on four
real-world datasets represent the superior performance of Fed3CR.

</details>


### [3] [Fairness for niche users and providers: algorithmic choice and profile portability](https://arxiv.org/abs/2509.22660)
*Elizabeth McKinnie,Anas Buhayh,Clement Canel,Robin Burke*

Main category: cs.IR

TL;DR: 本文研究了推荐系统中算法多元化和用户档案可移植性对公平性的影响，通过模拟方法探索不同用户档案处理政策如何影响消费者和提供者的公平结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注算法干预来确保推荐系统对多方利益相关者的公平性，但很少研究推荐生态系统本身的结构性变化。本文旨在探索算法多元化（用户可以选择算法）和用户档案可移植性对公平性的影响。

Method: 使用模拟方法研究用户档案可移植性问题，分析不同用户档案处理政策如何与消费者和提供者的公平结果相互作用。

Result: 先前研究表明小众消费者和（特别是）小众提供者从算法选择中受益。本文进一步探索了用户档案可移植性政策对公平结果的影响。

Conclusion: 算法多元化和用户档案可移植性是影响推荐系统公平性的重要结构性因素，需要进一步研究这些政策如何影响不同利益相关者的公平结果。

Abstract: Ensuring fair outcomes for multiple stakeholders in recommender systems has
been studied mostly in terms of algorithmic interventions: building new models
with better fairness properties, or using reranking to improve outcomes from an
existing algorithm. What has rarely been studied is structural changes in the
recommendation ecosystem itself. Our work explores the fairness impact of
algorithmic pluralism, the idea that the recommendation algorithm is decoupled
from the platform through which users access content, enabling user choice in
algorithms. Prior work using a simulation approach has shown that niche
consumers and (especially) niche providers benefit from algorithmic choice. In
this paper, we use simulation to explore the question of profile portability,
to understand how different policies regarding the handling of user profiles
interact with fairness outcomes for consumers and providers.

</details>


### [4] [Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding](https://arxiv.org/abs/2509.22661)
*Lingyu Zhang,Guobin Wu,Yan Wang,Pengfei Xu,Jian Liang,Xuan Song,Yunhai Wang*

Main category: cs.IR

TL;DR: 该论文提出了一种基于多模态时空上下文特征嵌入的POI推荐模型，通过融合长期偏好和关键时空上下文信息来提升下一个兴趣点推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统POI预测模型主要依赖短期交通序列信息，往往忽略长期和短期偏好数据以及用户行为中关键的时空上下文特征，导致预测精度受限。

Method: 模型通过时空特征处理、多模态嵌入和自注意力聚合等模块提取长期偏好特征和关键时空上下文特征，使用加权融合方法动态调整长短期特征权重，最后通过注意力匹配计算各候选位置的概率。

Result: 在多个交通数据集上的实验验证表明，该结合多种类型特征的POI预测模型比现有SOTA模型具有更高的预测准确率。

Conclusion: 融合长期偏好和时空上下文特征能够有效提升POI推荐性能，为智能交通领域的兴趣点预测提供了更优的解决方案。

Abstract: The next Point-of-interest (POI) recommendation is mainly based on sequential
traffic information to predict the user's next boarding point location. This is
a highly regarded and widely applied research task in the field of intelligent
transportation, and there have been many research results to date. Traditional
POI prediction models primarily rely on short-term traffic sequence
information, often neglecting both long-term and short-term preference data, as
well as crucial spatiotemporal context features in user behavior. To address
this issue, this paper introduces user long-term preference information and key
spatiotemporal context information, and proposes a POI recommendation model
based on multimodal spatiotemporal context feature embedding. The model
extracts long-term preference features and key spatiotemporal context features
from traffic data through modules such as spatiotemporal feature processing,
multimodal embedding, and self-attention aggregation. It then uses a weighted
fusion method to dynamically adjust the weights of long-term and short-term
features based on users' historical behavior patterns and the current context.
Finally, the fused features are matched using attention, and the probability of
each location candidate becoming the next location is calculated. This paper
conducts experimental verification on multiple transportation datasets, and the
results show that the POI prediction model combining multiple types of features
has higher prediction accuracy than existing SOTA models and methods.

</details>


### [5] [MTRec: Learning to Align with User Preferences via Mental Reward Models](https://arxiv.org/abs/2509.22807)
*Mengchen Zhao,Yifan Gao,Yaqing Hou,Xiangyang Li,Pengjie Gu,Zhenhua Dong,Ruiming Tang,Yi Cai*

Main category: cs.IR

TL;DR: MTRec是一个新颖的序列推荐框架，通过量化用户对推荐项目的内部满意度来更好地对齐用户真实偏好，使用心理奖励模型和分布逆强化学习方法，显著提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 由于显式反馈获取成本高，推荐模型主要依赖隐式反馈（如点击），但隐式反馈并不总能反映用户真实偏好，可能误导推荐系统。

Method: 提出心理奖励模型来量化用户满意度，采用分布逆强化学习方法学习该模型，然后用学到的心理奖励模型指导推荐模型。

Result: 实验表明MTRec显著提升了多种推荐模型的性能，在工业短视频平台上部署后用户平均观看时间增加了7%。

Conclusion: MTRec通过挖掘用户内部满意度，能够有效解决隐式反馈与真实偏好不一致的问题，提升推荐系统的对齐效果。

Abstract: Recommendation models are predominantly trained using implicit user feedback,
since explicit feedback is often costly to obtain. However, implicit feedback,
such as clicks, does not always reflect users' real preferences. For example, a
user might click on a news article because of its attractive headline, but end
up feeling uncomfortable after reading the content. In the absence of explicit
feedback, such erroneous implicit signals may severely mislead recommender
systems. In this paper, we propose MTRec, a novel sequential recommendation
framework designed to align with real user preferences by uncovering their
internal satisfaction on recommended items. Specifically, we introduce a mental
reward model to quantify user satisfaction and propose a distributional inverse
reinforcement learning approach to learn it. The learned mental reward model is
then used to guide recommendation models to better align with users' real
preferences. Our experiments show that MTRec brings significant improvements to
a variety of recommendation models. We also deploy MTRec on an industrial short
video platform and observe a 7 percent increase in average user viewing time.

</details>


### [6] [WARBERT: A Hierarchical BERT-based Model for Web API Recommendation](https://arxiv.org/abs/2509.23175)
*Zishuo Xu,Yuhong Gu,Dezhong Yao*

Main category: cs.IR

TL;DR: WARBERT是一个基于分层BERT的Web API推荐模型，通过双组件特征融合和注意力比较来解决API推荐中的语义模糊、缺乏详细比较和时间效率问题。


<details>
  <summary>Details</summary>
Motivation: 随着Web 2.0和微服务架构的出现，Web API数量激增，对高效API推荐的需求日益迫切。现有方法存在语义模糊、缺乏详细比较和时间效率低等挑战。

Method: 提出WARBERT模型，包含WARBERT(R)用于推荐和WARBERT(M)用于匹配。WARBERT(R)作为初始过滤器缩小候选API范围，WARBERT(M)通过计算候选API与mashup的相似度来优化匹配过程。模型结合双组件特征融合和注意力比较来提取精确的语义表示。

Result: 在ProgrammableWeb数据集上的实验结果表明，WARBERT优于大多数现有解决方案，与MTFM模型相比提升了11.7%，在准确性和效率方面都有显著提升。

Conclusion: WARBERT通过分层BERT架构和双组件设计有效解决了Web API推荐中的关键挑战，在准确性和效率方面都取得了显著改进。

Abstract: With the emergence of Web 2.0 and microservices architecture, the number of
Web APIs has increased dramatically, further intensifying the demand for
efficient Web API recommendation. Existing solutions typically fall into two
categories: recommendation-type methods, which treat each API as a label for
classification, and match-type methods, which focus on matching mashups through
API retrieval. However, three critical challenges persist: 1) the semantic
ambiguities in comparing API and mashup descriptions, 2) the lack of detailed
comparisons between the individual API and the mashup in recommendation-type
methods, and 3) time inefficiencies for API retrieval in match-type methods. To
address these challenges, we propose WARBERT, a hierarchical BERT-based model
for Web API recommendation. WARBERT leverages dual-component feature fusion and
attention comparison to extract precise semantic representations of API and
mashup descriptions. WARBERT consists of two main components: WARBERT(R) for
Recommendation and WARBERT(M) for Matching. Specifically, WAR-BERT(R) serves as
an initial filter, narrowing down the candidate APIs, while WARBERT(M) refines
the matching process by calculating the similarity between candidate APIs and
mashup. The final likelihood of a mashup being matched with an API is
determined by combining the predictions from WARBERT(R) and WARBERT(M).
Additionally, WARBERT(R) incorporates an auxiliary task of mashup category
judgment, which enhances its effectiveness in candidate selection. Experimental
results on the ProgrammableWeb dataset demonstrate that WARBERT outperforms
most existing solutions and achieves improvements of up to 11.7% compared to
the model MTFM (Multi-Task Fusion Model), delivering significant enhancements
in accuracy and effiency.

</details>


### [7] [From Past To Path: Masked History Learning for Next-Item Prediction in Generative Recommendation](https://arxiv.org/abs/2509.23649)
*KaiWen Wei,Kejun He,Xiaomian Kang,Jie Zhang,Yuming Yang,Jiang Zhong,He Bai,Junnan Zhu*

Main category: cs.IR

TL;DR: 提出Masked History Learning (MHL)训练框架，通过历史重建任务增强生成式推荐模型对用户意图的理解，超越单纯的自回归预测


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐系统仅依赖自回归训练，只预测下一个物品而忽略用户交互历史的丰富内部结构，无法理解用户潜在意图

Method: MHL框架在标准自回归目标基础上增加重建被掩盖历史物品的辅助任务，包含熵引导掩盖策略和课程学习调度器

Result: 在三个公共数据集上的实验表明，该方法显著优于最先进的生成模型

Conclusion: 全面理解过去对于准确预测用户未来路径至关重要，历史理解是生成式推荐成功的关键

Abstract: Generative recommendation, which directly generates item identifiers, has
emerged as a promising paradigm for recommendation systems. However, its
potential is fundamentally constrained by the reliance on purely autoregressive
training. This approach focuses solely on predicting the next item while
ignoring the rich internal structure of a user's interaction history, thus
failing to grasp the underlying intent. To address this limitation, we propose
Masked History Learning (MHL), a novel training framework that shifts the
objective from simple next-step prediction to deep comprehension of history.
MHL augments the standard autoregressive objective with an auxiliary task of
reconstructing masked historical items, compelling the model to understand
``why'' an item path is formed from the user's past behaviors, rather than just
``what'' item comes next. We introduce two key contributions to enhance this
framework: (1) an entropy-guided masking policy that intelligently targets the
most informative historical items for reconstruction, and (2) a curriculum
learning scheduler that progressively transitions from history reconstruction
to future prediction. Experiments on three public datasets show that our method
significantly outperforms state-of-the-art generative models, highlighting that
a comprehensive understanding of the past is crucial for accurately predicting
a user's future path. The code will be released to the public.

</details>


### [8] [Constructing Opera Seria in the Iberian Courts: Metastasian Repertoire for Spain and Portugal](https://arxiv.org/abs/2509.23771)
*Ana Llorens,Alvaro Torrente*

Main category: cs.IR

TL;DR: 本文通过统计分析15部为马德里和里斯本宫廷剧院创作的歌剧，研究五位国际作曲家为伊比利亚宫廷创作歌剧时风格的变化，揭示了伊比利亚歌剧的独特音乐特征受当地音乐习俗、性别刻板印象和个人特质影响。


<details>
  <summary>Details</summary>
Motivation: 研究18世纪伊比利亚半岛歌剧的国际化和本土化特征，探究国际作曲家为伊比利亚宫廷创作时风格如何变化，以及当地观众的社会和音乐期望如何影响歌剧创作。

Method: 使用统计分析方法，比较15部为马德里和里斯本宫廷剧院特别创作的歌剧与从126个版本、2404首咏叹调中提取的平均数据，评估调性、节拍、速度和声乐处理等方面的特殊用法。

Result: 发现伊比利亚宫廷歌剧在调性、节拍、速度和声乐处理等方面具有独特特征，这些特征既体现了国际品味，也反映了当地音乐习俗、性别刻板印象和个人特质的影响。

Conclusion: 18世纪伊比利亚音乐生产和消费在欧洲歌剧背景下具有独特性，其音乐特征不仅受国际影响，也依赖于当地音乐习俗、性别刻板印象和个人特质。

Abstract: The exceptional reception of Pietro Metastasio's works during the eighteenth
century, all over Europe and in the Iberian Peninsula in particular, is well
documented. Due to that unparalleled success, it is possible to ascertain Spain
and Portugal's participation in international, contemporary tastes and artistic
webs, applicable to both composers and performers. However, this
internationalisation needs to be nuanced, as some characteristics of the
repertoire specifically written for the Peninsula indicate that their court
audiences may have had expectations, both social and strictly musical,
different from those of the public in opera theatres elsewhere in the
continent. In this light, this article investigates in what ways the style of
five composers in the international scene - Perez, Galuppi, Jommelli, Conforto,
and Corselli - varied when commissioned to write opera seria for the Iberian
courts. The statistical analysis of fifteen settings especially written for the
court theatres in Madrid and Lisbon, in comparison to the average data
extracted from a corpus of 2,404 arias from 126 versions of a select number of
Metastasian librettos, allows us to evaluate some particular usages regarding
key, metre, tempo, and treatment of the vocal part. In this manner, through
quantitative analysis, this article places eighteenth-century Iberian music
production and consumption in the context of European opera seria, while
ultimately suggesting that its unique musical characteristics were also partly
dependent on local musical customs, gender stereotypes, and personal
idiosyncrasies alike.

</details>


### [9] [Semantic Representation of Processes with Ontology Design Patterns](https://arxiv.org/abs/2509.23776)
*Ebrahim Norouzi,Sven Hertling,Jörg Waitelonis,Harald Sack*

Main category: cs.IR

TL;DR: 该研究调查了科学工作流和工程过程建模的相关本体，识别了其中隐含的设计模式，提出了从现有本体中自动提取设计模式的基线方法，并评估了该方法的效果。


<details>
  <summary>Details</summary>
Motivation: 材料科学工程中工作流和过程的表示对实验和计算的可重复性至关重要，但现有的过程建模本体通常复杂且难以重用，而本体设计模式虽然提供了模块化解决方案，但往往没有明确发布或文档化。

Method: 调查相关本体，识别其中隐含的设计模式，提出自动提取设计模式的基线方法，并与人工整理的真实模式进行评估比较。

Result: 开发了从现有本体中自动提取设计模式的方法，并将提取的模式和提取工作流在GitHub仓库中公开提供。

Conclusion: 该研究为材料科学过程表示提供了一种识别和提取可重用设计模式的方法，有助于提高过程建模的效率和质量。

Abstract: The representation of workflows and processes is essential in materials
science engineering, where experimental and computational reproducibility
depend on structured and semantically coherent process models. Although
numerous ontologies have been developed for process modeling, they are often
complex and challenging to reuse. Ontology Design Patterns (ODPs) offer modular
and reusable modeling solutions to recurring problems; however, these patterns
are frequently neither explicitly published nor documented in a manner
accessible to domain experts. This study surveys ontologies relevant to
scientific workflows and engineering process modeling and identifies implicit
design patterns embedded within their structures. We evaluate the capacity of
these ontologies to fulfill key requirements for process representation in
materials science. Furthermore, we propose a baseline method for the automatic
extraction of design patterns from existing ontologies and assess the approach
against curated ground truth patterns. All resources associated with this work,
including the extracted patterns and the extraction workflow, are made openly
available in a public GitHub repository.

</details>


### [10] [GSID: Generative Semantic Indexing for E-Commerce Product Understanding](https://arxiv.org/abs/2509.23860)
*Haiyang Yang,Qinye Xie,Qingheng Zhang,Liyu Chen,Huike Zou,Chengbao Lian,Shuguang Han,Fei Huang,Jufeng Chen,Bo Zheng*

Main category: cs.IR

TL;DR: 提出GSID方法，通过预训练学习产品语义嵌入，生成结构化产品表示，解决二手电商平台产品信息组织效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 当前电商平台基于人工分类和属性的产品信息组织方式无法充分覆盖长尾产品，且与买家偏好不匹配，成为效率瓶颈。

Method: GSID包含两个关键组件：(1) 在非结构化产品元数据上预训练学习领域内语义嵌入；(2) 为下游产品应用生成更有效的语义代码。

Result: 大量实验验证了GSID的有效性，已在真实电商平台部署，在产品理解和其他下游任务上取得良好效果。

Conclusion: GSID是一种数据驱动的方法，能够生成有效的产品结构化表示，提升电商平台的效率。

Abstract: Structured representation of product information is a major bottleneck for
the efficiency of e-commerce platforms, especially in second-hand ecommerce
platforms. Currently, most product information are organized based on manually
curated product categories and attributes, which often fail to adequately cover
long-tail products and do not align well with buyer preference. To address
these problems, we propose \textbf{G}enerative \textbf{S}emantic
\textbf{I}n\textbf{D}exings (GSID), a data-driven approach to generate product
structured representations. GSID consists of two key components: (1)
Pre-training on unstructured product metadata to learn in-domain semantic
embeddings, and (2) Generating more effective semantic codes tailored for
downstream product-centric applications. Extensive experiments are conducted to
validate the effectiveness of GSID, and it has been successfully deployed on
the real-world e-commerce platform, achieving promising results on product
understanding and other downstream tasks.

</details>


### [11] [Investigating Multi-layer Representations for Dense Passage Retrieval](https://arxiv.org/abs/2509.23861)
*Zhongbin Xie,Thomas Lukasiewicz*

Main category: cs.IR

TL;DR: 提出多层表示(MLR)方法，利用文档编码器多个层的表示来构建文档表示，在单向量检索设置中优于双编码器、ME-BERT和ColBERT。


<details>
  <summary>Details</summary>
Motivation: 传统密集检索模型仅使用编码器最后一层的向量表示文档，但预训练语言模型不同层包含不同类型的语言知识，且在微调过程中表现不同。

Method: 研究不同层表示对MLR性能的影响，提出使用池化策略将多向量模型简化为单向量模型以提高检索效率。

Result: 实验证明MLR在单向量检索设置中优于现有方法，且能与检索导向预训练和困难负样本挖掘等先进训练技术良好配合。

Conclusion: 多层表示方法能有效提升密集检索性能，同时保持检索效率。

Abstract: Dense retrieval models usually adopt vectors from the last hidden layer of
the document encoder to represent a document, which is in contrast to the fact
that representations in different layers of a pre-trained language model
usually contain different kinds of linguistic knowledge, and behave differently
during fine-tuning. Therefore, we propose to investigate utilizing
representations from multiple encoder layers to make up the representation of a
document, which we denote Multi-layer Representations (MLR). We first
investigate how representations in different layers affect MLR's performance
under the multi-vector retrieval setting, and then propose to leverage pooling
strategies to reduce multi-vector models to single-vector ones to improve
retrieval efficiency. Experiments demonstrate the effectiveness of MLR over
dual encoder, ME-BERT and ColBERT in the single-vector retrieval setting, as
well as demonstrate that it works well with other advanced training techniques
such as retrieval-oriented pre-training and hard negative mining.

</details>


### [12] [Multi-Value-Product Retrieval-Augmented Generation for Industrial Product Attribute Value Identification](https://arxiv.org/abs/2509.23874)
*Huike Zou,Haiyang Yang,Yindu Su,Liyu Chen,Chengbao Lian,Qingheng Zhang,Shuguang Han,Jufeng Chen*

Main category: cs.IR

TL;DR: 提出MVP-RAG方法解决产品属性值识别问题，结合检索、生成和分类范式，通过多级检索和LLM生成显著缓解OOD问题。


<details>
  <summary>Details</summary>
Motivation: 现有PAVI方法面临级联错误、无法处理分布外属性值和缺乏泛化能力等关键挑战。

Method: 将PAVI定义为检索生成任务，首先检索同类产品和候选属性值，然后生成标准化属性值，采用多级检索方案。

Result: 实验结果显示MVP-RAG优于现有最先进基线方法。

Conclusion: MVP-RAG成功解决了PAVI的关键挑战，并在真实工业环境中成功部署。

Abstract: Identifying attribute values from product profiles is a key task for
improving product search, recommendation, and business analytics on e-commerce
platforms, which we called Product Attribute Value Identification (PAVI) .
However, existing PAVI methods face critical challenges, such as cascading
errors, inability to handle out-of-distribution (OOD) attribute values, and
lack of generalization capability. To address these limitations, we introduce
Multi-Value-Product Retrieval-Augmented Generation (MVP-RAG), combining the
strengths of retrieval, generation, and classification paradigms. MVP-RAG
defines PAVI as a retrieval-generation task, where the product title
description serves as the query, and products and attribute values act as the
corpus. It first retrieves similar products of the same category and candidate
attribute values, and then generates the standardized attribute values. The key
advantages of this work are: (1) the proposal of a multi-level retrieval
scheme, with products and attribute values as distinct hierarchical levels in
PAVI domain (2) attribute value generation of large language model to
significantly alleviate the OOD problem and (3) its successful deployment in a
real-world industrial environment. Extensive experimental results demonstrate
that MVP-RAG performs better than the state-of-the-art baselines.

</details>


### [13] [Multi-Item-Query Attention for Stable Sequential Recommendation](https://arxiv.org/abs/2509.24424)
*Mingshi Xu,Haoren Zhu,Wilfred Siu Hung Ng*

Main category: cs.IR

TL;DR: 提出了多项目查询注意力机制(MIQ-Attn)来解决序列推荐系统中用户交互数据不稳定和噪声问题，通过构建多个多样化查询向量来增强模型稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 用户交互数据固有的不稳定性和噪声挑战序列推荐系统，现有基于单一最近项目查询的掩码注意力模型对噪声敏感，降低了预测可靠性。

Method: 提出多项目查询注意力机制(MIQ-Attn)，从用户交互中构建多个多样化查询向量，有效缓解噪声影响并提高一致性，可作为现有单查询注意力的即插即用替代方案。

Result: 实验表明MIQ-Attn在基准数据集上显著提升了性能表现。

Conclusion: MIQ-Attn机制通过多查询方法有效解决了序列推荐中的噪声敏感问题，提高了模型的稳定性和准确性。

Abstract: The inherent instability and noise in user interaction data challenge
sequential recommendation systems. Prevailing masked attention models, relying
on a single query from the most recent item, are sensitive to this noise,
reducing prediction reliability. We propose the Multi-Item-Query attention
mechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn
constructs multiple diverse query vectors from user interactions, effectively
mitigating noise and improving consistency. It is designed for easy adoption as
a drop-in replacement for existing single-query attention. Experiments show
MIQ-Attn significantly improves performance on benchmark datasets.

</details>


### [14] [UniDex: Rethinking Search Inverted Indexing with Unified Semantic Modeling](https://arxiv.org/abs/2509.24632)
*Zan Li,Jiahui Chen,Yuan Chai,Xiaoze Jiang,Xiaohua Qi,Zhiheng Qin,Runbin Zhou,Shun Zuo,Guangchao Hao,Kefeng Wang,Jingshan Lv,Yupeng Huang,Xiao Liang,Han Li*

Main category: cs.IR

TL;DR: UniDex是一种基于统一语义建模的新型模型索引方法，取代传统基于词项匹配的倒排索引，通过UniTouch生成语义ID和UniRank进行语义匹配排序，显著提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 传统倒排索引依赖精确词项匹配，强调表层词汇重叠，限制了系统的泛化能力和检索效果。

Method: 提出UniDex方法，包含两个核心组件：UniTouch将查询和文档映射为语义ID，UniRank使用语义匹配进行结果排序。

Result: 在大规模工业数据集和真实在线流量评估中，UniDex显著提升了检索能力，在快手短视频搜索系统中成功部署，服务数亿活跃用户。

Conclusion: UniDex实现了从基于词项到基于模型的索引范式转变，证明了模型化索引在实际工业应用中的有效性。

Abstract: Inverted indexing has traditionally been a cornerstone of modern search
systems, leveraging exact term matches to determine relevance between queries
and documents. However, this term-based approach often emphasizes surface-level
token overlap, limiting the system's generalization capabilities and retrieval
effectiveness. To address these challenges, we propose UniDex, a novel
model-based method that employs unified semantic modeling to revolutionize
inverted indexing. UniDex replaces complex manual designs with a streamlined
architecture, enhancing semantic generalization while reducing maintenance
overhead. Our approach involves two key components: UniTouch, which maps
queries and documents into semantic IDs for improved retrieval, and UniRank,
which employs semantic matching to rank results effectively. Through
large-scale industrial datasets and real-world online traffic assessments, we
demonstrate that UniDex significantly improves retrieval capabilities, marking
a paradigm shift from term-based to model-based indexing. Our deployment within
Kuaishou's short-video search systems further validates UniDex's practical
effectiveness, serving hundreds of millions of active users efficiently.

</details>


### [15] [Retro*: Optimizing LLMs for Reasoning-Intensive Document Retrieval](https://arxiv.org/abs/2509.24869)
*Junwei Lan,Jianlyu Chen,Zheng Liu,Chaofan Li,Siqi Bao,Defu Lian*

Main category: cs.IR

TL;DR: 提出了Retro*方法，通过基于标准的评分机制和强化学习优化，在推理密集型文档检索任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体和RAG的普及，需要检索与任务间接或隐式相关的文档，现有IR技术在细粒度推理方面面临挑战

Method: 引入基于标准的关联评分机制，通过明确标准评估任务与文档关系；支持测试时扩展，通过分数集成结合多个推理轨迹；使用强化学习算法优化推理能力

Result: 在BRIGHT基准测试中优于现有文档检索方法，达到最先进性能

Conclusion: Retro*通过细粒度推理和可扩展的评分机制，有效解决了推理密集型文档检索的挑战

Abstract: With the growing popularity of LLM agents and RAG, it has become increasingly
important to retrieve documents that are essential for solving a task, even
when their connection to the task is indirect or implicit. Addressing this
problem requires fine-grained reasoning to accurately assess the relevance
between the task and each candidate document. This capability, however, poses a
significant challenge for existing IR techniques. Despite recent progress in
reasoning-enhanced IR, existing approaches still face significant challenges in
applicability, scalability, and efficiency. In this work, we propose Retro*, a
novel approach for reasoning-intensive document retrieval. Our method
introduces a rubric-based relevance scoring mechanism, enabling the model to
reason about the relationship between a task and a document based on explicitly
defined criteria, whereby producing a fine-grained, interpretable relevance
score. Retro* also supports test-time scaling by combining multiple reasoning
trajectories via score integration, which produces more reliable relevance
estimates. To optimize Retro*'s reasoning capabilities, we introduce a novel
reinforcement learning algorithm tailored for its relevance scoring mechanism,
which employs two composite rewards to fully exploit the trajectories of each
training sample. Our experiments show that Retro* outperforms existing document
retrieval methods with notable advantages, leading to state-of-the-art
performance on the BRIGHT benchmark.

</details>
