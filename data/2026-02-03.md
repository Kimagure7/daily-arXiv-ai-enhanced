<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 23]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Disentangled Interest Network for Out-of-Distribution CTR Prediction](https://arxiv.org/abs/2602.00002)
*Yu Zheng,Chen Gao,Jianxin Chang,Yanan Niu,Yang Song,Depeng Jin,Meng Wang,Yong Li*

Main category: cs.IR

TL;DR: DiseCTR通过因果视角解耦用户多兴趣，缓解推荐系统中的分布外问题，显著提升CTR预测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测方法通常假设训练和测试数据来自相同分布，但实际中用户兴趣不断演变导致分布变化（OOD问题），且用户有多重兴趣，其中部分兴趣演化更快。

Method: 提出DiseCTR框架：1) 从因果角度对CTR预测进行因子分解（用户兴趣、曝光模型、点击模型）；2) 使用稀疏注意力的兴趣编码器；3) 弱监督兴趣解耦器学习独立兴趣嵌入；4) 注意力兴趣聚合器进行预测。

Result: 在三个真实数据集上，DiseCTR在OOD推荐中达到最佳准确性和鲁棒性，AUC和GAUC提升超过0.02，logloss降低超过13.7%。分析显示成功解耦了用户兴趣。

Conclusion: DiseCTR通过因果视角解耦用户多兴趣，有效缓解了CTR预测中的OOD问题，用户兴趣解耦是OOD泛化的关键。已开源代码和数据。

Abstract: Click-through rate (CTR) prediction, which estimates the probability of a user clicking on a given item, is a critical task for online information services. Existing approaches often make strong assumptions that training and test data come from the same distribution. However, the data distribution varies since user interests are constantly evolving, resulting in the out-of-distribution (OOD) issue. In addition, users tend to have multiple interests, some of which evolve faster than others. Towards this end, we propose Disentangled Click-Through Rate prediction (DiseCTR), which introduces a causal perspective of recommendation and disentangles multiple aspects of user interests to alleviate the OOD issue in recommendation. We conduct a causal factorization of CTR prediction involving user interest, exposure model, and click model, based on which we develop a deep learning implementation for these three causal mechanisms. Specifically, we first design an interest encoder with sparse attention which maps raw features to user interests, and then introduce a weakly supervised interest disentangler to learn independent interest embeddings, which are further integrated by an attentive interest aggregator for prediction. Experimental results on three real-world datasets show that DiseCTR achieves the best accuracy and robustness in OOD recommendation against state-of-the-art approaches, significantly improving AUC and GAUC by over 0.02 and reducing logloss by over 13.7%. Further analyses demonstrate that DiseCTR successfully disentangles user interests, which is the key to OOD generalization for CTR prediction. We have released the code and data at https://github.com/DavyMorgan/DiseCTR/.

</details>


### [2] [Efficient Multilingual Search Relevance Modeling in E-Commerce via LLM Mixture-of-Experts](https://arxiv.org/abs/2602.00003)
*Ye Liu,Xu Chen,Wuji Chen,Mang Li*

Main category: cs.IR

TL;DR: 提出一个基于LLM的混合专家框架，通过动态路由查询到专门专家并融合嵌入，优化多国电商搜索相关性，在提升效果的同时降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 多国电商平台中，语言、文化和产品目录的差异导致数据分布偏移，传统单一模型在数据多样性、覆盖范围和推理成本方面存在局限。研究发现不同LLM基础模型在不同语言和地区具有互补优势，因此需要专家架构来解决这些挑战。

Method: 提出可扩展的LLM混合专家框架，包含：1）动态路由查询到专门专家；2）通过拼接融合专家嵌入；3）比较基于规则、伪标签和端到端策略，发现端到端硬路由拼接效果最佳；4）开发工程优化的离线批处理管道，通过资源高效调度隐藏内存延迟，提高GPU利用率。

Result: 在东南亚六个市场数据集上，MoE相比相同活跃参数的密集基线提升AUC 0.72个百分点。优化管道达到27.6 QPS，吞吐量提升9%，GPU小时消耗减少高达35%。

Conclusion: 该混合专家框架在提升多语言搜索相关性的同时实现了高效推理，为实际电商搜索系统提供了优越的成本效益解决方案。

Abstract: In e-commerce platforms, search relevance directly influences both user experience and merchant revenue. In multi-country deployments, diverse linguistic, cultural, and product catalog contexts introduce significant distribution shifts, posing substantial challenges to relevance modeling. Existing approaches typically enhance the reasoning or multilingual abilities of a single monolithic model, yet they remain limited by data diversity, coverage gaps, and high inference costs in heterogeneous environments. Our empirical analysis reveals that different LLM base models exhibit complementary strengths across languages and regions, motivating an expert-based architecture. We propose a scalable LLM-based Mixture-of-Experts (MoE) framework that dynamically routes queries to specialized experts and fuses their embeddings through concatenation. Among rule-based, pseudo-label-based, and fully end-to-end strategies, end-to-end hard routing with concatenation offers the best balance of effectiveness and efficiency. To mitigate inference overhead, we further develop an engineering-optimized offline batch pipeline with resource-efficient scheduling, which hides memory latency, improves GPU utilization, and reduces GPU-hour consumption by up to 35% compared with synchronous execution. On datasets spanning six Southeast Asian markets, our MoE improves AUC by 0.72 percentage points over a dense baseline with the same active parameters. Meanwhile, the optimized pipeline achieves 27.6 queries per second (QPS), a 9% throughput improvement. These results demonstrate superior multilingual relevance and efficiency, delivering strong cost-effectiveness for real-world e-commerce search systems.

</details>


### [3] [C$^2$-Cite: Contextual-Aware Citation Generation for Attributed Large Language Models](https://arxiv.org/abs/2602.00004)
*Yue Yu,Ting Bai,HengZhi Lan,Li Qian,Li Peng,Jie Wu,Wei Liu,Jian Luan,Chuan Shi*

Main category: cs.IR

TL;DR: 提出C²-Cite框架，通过上下文感知的引用生成机制，提升LLM生成文本中引用的语义连贯性和准确性


<details>
  <summary>Details</summary>
Motivation: 现有指令调优的归因LLM在生成文本时，未能充分理解引用符号（如[i]）的上下文语义，导致引用不连贯且检索知识整合不佳

Method: 提出C²-Cite框架，采用上下文引用对齐机制：先将检索文档上下文编码到引用符号表示中，然后通过引用路由函数解码对齐标记编号

Result: 在ALCE基准测试的三个数据集上，C²-Cite++平均在引用质量上优于SOTA基线5.8%，在响应正确性上优于17.4%

Conclusion: C²-Cite框架成功将引用标记从通用占位符转变为主动知识指针，显著提升了LLM生成文本的引用质量和语义连贯性

Abstract: The attribution technique enhances the credibility of LLMs by adding citations to the generated sentences, enabling users to trace back to the original sources and verify the reliability of the output. However, existing instruction-tuned attributed LLMs often fail to properly interpret the contextual semantics of citation symbols (e.g., [i]) during text generation. This shortcoming arises from their insufficient awareness of the context information surrounding citation markers, which in turn leads to disjointed references and poor integration of retrieved knowledge into the generated content. To address this issue, we propose a novel \textbf{C}ontextual-aware \textbf{C}itation generation framework (\textbf{C$^2$}-\textbf{Cite}) that explicitly integrates the semantic relationships between citation markers and their referenced content. Specifically, a contextual citation alignment mechanism is adopted: it first encodes the retrieved document contexts into the symbol representation of citations, then aligns the marker numbers by decoding information from a citation router function. This mechanism enables the transformation of citation markers from generic placeholders into active knowledge pointers that link to the referenced source information. Experimental results on the ALCE benchmark across three datasets validate our framework C$^2$-Cite++: it outperforms the SOTA baseline by an average of 5.8\% in citation quality and 17.4\% in response correctness. The implementation is publicly available at https://github.com/BAI-LAB/c2cite

</details>


### [4] [AutoBool: An Reinforcement-Learning trained LLM for Effective Automated Boolean Query Generation for Systematic Reviews](https://arxiv.org/abs/2602.00005)
*Shuai Wang,Harrisen Scells,Bevan Koopman,Guido Zuccon*

Main category: cs.IR

TL;DR: AutoBool是一个强化学习框架，用于训练大语言模型生成医学系统综述的有效布尔查询，无需真实查询标签，通过检索指标直接优化，在多个数据集上超越提示方法并接近专家水平。


<details>
  <summary>Details</summary>
Motivation: 医学系统综述中布尔查询是文献检索的主要方法，需要在保持合理精度的同时达到高召回率，现有基于提示的LLM方法难以平衡这一挑战。主要限制是缺乏高质量的真实布尔查询标签，使得监督微调不可行。

Method: 使用强化学习框架直接优化查询生成与检索指标，无需目标查询标签。创建并发布了包含65588个主题的最大数据集，用于训练和评估自动布尔查询生成任务。

Result: 在新数据集和两个现有数据集（CLEF TAR和Seed Collection）上的实验表明，AutoBool显著优于零样本/少样本提示方法，匹配或超越更大的GPT模型（如GPT-4o、O3）的效果，同时接近专家编写的查询效果，但检索的文档数量减少10-16倍。

Conclusion: AutoBool通过强化学习有效解决了医学系统综述中布尔查询生成的挑战，无需真实查询标签，在多个数据集上表现出色，接近专家水平同时大幅减少检索负担。消融研究揭示了模型骨干、大小、解码温度和提示设计的关键作用。

Abstract: We present AutoBool, a reinforcement learning (RL) framework that trains large language models (LLMs) to generate effective Boolean queries for medical systematic reviews. Boolean queries are the primary mechanism for literature retrieval in this domain and must achieve high recall while maintaining reasonable precision - a challenging balance that existing prompt-based LLM approaches often struggle to achieve. A major limitation in this space is the lack of high-quality ground-truth Boolean queries for each topic, which makes supervised fine-tuning impractical. AutoBool addresses this challenge by using RL to directly optimize query generation with retrieval measures, without requiring target queries. To support this effort, we create and release the largest dataset of its kind: 65588 topics in total for training and evaluating the task of automatic Boolean query formulation. Experiments on our new dataset and two established datasets (CLEF TAR and Seed Collection) show that AutoBool significantly outperforms zero shot/few shot prompting and matches or exceeds the effectiveness of much larger GPT-based models (e.g., GPT-4o, O3) using smaller backbones. It also approaches effectiveness of expert-authored queries while retrieving 10 to 16 times fewer documents. Ablation studies reveal the critical roles of model backbone, size, decoding temperature, and prompt design. Code and data are available at https://github.com/ielab/AutoBool.

</details>


### [5] [FDA AI Search: Making FDA-Authorized AI Devices Searchable](https://arxiv.org/abs/2602.00006)
*Arun Kavishwar,William Lotter*

Main category: cs.IR

TL;DR: FDA AI Search是一个语义搜索网站，帮助医疗专业人员从FDA授权的1200多款AI医疗设备中快速找到符合临床需求的产品，解决了FDA数据库仅提供有限元数据和非可搜索PDF的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管FDA已授权超过1200款AI医疗设备，但由于FDA数据库仅包含有限的元数据和非可搜索的PDF摘要，医疗专业人员很难找到适合特定临床需求的设备。

Method: 开发了FDA AI Search网站，采用基于嵌入的检索系统，通过LLM从授权摘要中提取特征，并与用户查询进行语义匹配来寻找相关设备。

Result: 定量和定性评估表明，该检索算法相比基于关键词的方法更有效，能够更好地匹配用户查询和医疗设备。

Conclusion: 随着FDA授权的AI设备日益普及和应用场景扩展，该工具将帮助医疗提供者找到符合临床需求的设备，并支持开发者构思新的AI应用。

Abstract: Over 1,200 AI-enabled medical devices have received marketing authorization from the U.S. FDA, yet identifying devices suited to specific clinical needs remains challenging because the FDA's databases contain only limited metadata and non-searchable summary PDFs. To address this gap, we developed FDA AI Search, a website that enables semantic querying of FDA-authorized AI-enabled devices. The backend includes an embedding-based retrieval system, where LLM-extracted features from authorization summaries are compared to user queries to find relevant matches. We present quantitative and qualitative evaluation that support the effectiveness of the retrieval algorithm compared to keyword-based methods. As FDA-authorized AI devices become increasingly prevalent and their use cases expand, we envision that the tool will assist healthcare providers in identifying devices aligned with their clinical needs and support developers in formulating novel AI applications.

</details>


### [6] [Front-Loaded or Balanced? The Mechanism through Which Review Order Affects Overall Ratings in Premium Service Settings](https://arxiv.org/abs/2602.00008)
*He Wang,Ziyu Zhou,Hanxiang Liu*

Main category: cs.IR

TL;DR: 研究发现评价顺序影响评分：先评分后评价（如Yelp）导致评分更高且更两极分化，先评价后评分（如Letterboxd）则评分更集中。认知努力和情感启发是双重作用机制。


<details>
  <summary>Details</summary>
Motivation: 在高质量服务场景中，消费者评价界面的顺序（先评分后评价 vs 先评价后评分）对评分真实性和反馈质量有重要影响，但现有研究对此缺乏系统探讨。

Method: 通过探索性分析比较Letterboxd（先评价后评分）和Yelp（先评分后评价）的评分分布，并进行三个控制实验检验评价顺序对评分的影响机制。

Result: 先评分后评价的界面在高质量服务场景中显著提高消费者总体评分；认知努力减少和情感启发增强是双重作用机制；服务质量起调节作用，低质量服务时先评分后评价反而降低评分。

Conclusion: 评价顺序通过认知和情感双重路径影响消费者评分，为在线评分形成理论提供新视角，对优化平台界面设计以提升评分真实性和可信度具有实践意义。

Abstract: In the increasingly prevalent landscape of high-quality service contexts, whether consumer evaluation interfaces adopt a rating-first or review-first sequence has become a critical factor shaping rating authenticity and feedback quality. While prior research has primarily examined review content and sentiment, systematic investigation into how evaluation order influences rating outcomes remains limited. Through exploratory analyses, we find that Letterboxd -- which employs a review-first, rating-after mechanism -- exhibits a more centralized rating distribution with fewer extreme scores, whereas Yelp -- which adopts a rating-first, review-after mechanism -- shows a pronounced bimodal distribution with more polarized ratings. Three controlled experiments further demonstrate that in high-quality service contexts, a rating-first (vs. review-first) interface significantly elevates consumers' overall ratings. Mechanism analyses indicate that cognitive effort and affective heuristics serve as dual pathways: a rating-first (vs. review-first) sequence reduces cognitive effort and heightens affective heuristics, thereby increasing rating scores. Moreover, service quality moderates this process. When service quality is low, the rating-first (vs. review-first) sequence instead leads to lower ratings. This research reveals the psychological mechanisms through which evaluation order affects consumer ratings via cognitive and affective pathways. It extends theoretical understanding of online rating formation and offers practical implications for optimizing platform interface design to enhance rating authenticity and credibility.

</details>


### [7] [ChunkNorris: A High-Performance and Low-Energy Approach to PDF Parsing and Chunking](https://arxiv.org/abs/2602.00010)
*Mathieu Ciancone,Clovis Varangot-Reille,Marion Schaeffer*

Main category: cs.IR

TL;DR: ChunkNorris：一种基于启发式规则的新型PDF文档解析与分块技术，不依赖机器学习，在计算开销最小的情况下实现高性能，为资源受限的RAG应用提供实用高效方案。


<details>
  <summary>Details</summary>
Motivation: 在检索增强生成应用中，信息检索部分至关重要，因为它为大型语言模型提供上下文信息以生成适当且真实的回答。高质量的解析和分块直接影响下游任务（信息检索和答案生成）的效果。

Method: 提出ChunkNorris技术，这是一种基于启发式规则的方法，不依赖机器学习，采用一套简单而有效的启发式规则来优化PDF文档的解析和分块过程。

Result: 通过综合基准测试评估执行时间、能耗和检索准确性，ChunkNorris在各方面均优于基线和更先进的技术，为信息检索任务提供了实用高效的替代方案。

Conclusion: 这项研究强调了基于启发式规则的方法在实际资源受限的RAG用例中的潜力，ChunkNorris为PDF文档解析和分块提供了高效实用的解决方案。

Abstract: In Retrieval-Augmented Generation applications, the Information Retrieval part is central as it provides the contextual information that enables a Large Language Model to generate an appropriate and truthful response. High quality parsing and chunking are critical as efficient data segmentation directly impacts downstream tasks, i.e. Information Retrieval and answer generation. In this paper, we introduce ChunkNorris, a novel heuristic-based technique designed to optimise the parsing and chunking of PDF documents. Our approach does not rely on machine learning and employs a suite of simple yet effective heuristics to achieve high performance with minimal computational overhead. We demonstrate the efficiency of ChunkNorris through a comprehensive benchmark against existing parsing and chunking methods, evaluating criteria such as execution time, energy consumption, and retrieval accuracy. We propose an open-access dataset to produce our results. ChunkNorris outperforms baseline and more advanced techniques, offering a practical and efficient alternative for Information Retrieval tasks. Therefore, this research highlights the potential of heuristic-based methods for real-world, resource-constrained RAG use cases.

</details>


### [8] [Chained Prompting for Better Systematic Review Search Strategies](https://arxiv.org/abs/2602.00011)
*Fatima Nasser,Fouad Trad,Ammar Mohanna,Ghada El-Hajj Fuleihan,Ali Chehab*

Main category: cs.IR

TL;DR: LLM驱动的链式提示工程框架，用于系统综述中自动化构建搜索策略，实现高召回率


<details>
  <summary>Details</summary>
Motivation: 传统手动构建搜索策略方法资源密集且易受主观性影响，而启发式和自动化方法在召回率方面表现不佳。需要一种既能保持方法严谨性又能提高效率的自动化解决方案。

Method: 基于大语言模型的链式提示工程框架，模拟手动搜索设计流程：分解综述目标、提取和形式化PICO元素、生成概念表示、扩展术语、合成布尔查询。

Result: 在LEADSInstruct数据集子集上评估，框架达到0.9的平均召回率，显著优于现有方法。在生成结构化PICO元素方面也表现优异。

Conclusion: LLM驱动的管道能够产生透明、可重复且高性能的搜索策略，具有支持证据合成和循证实践的规模化潜力。精确的目标规范和术语对齐对检索效果至关重要。

Abstract: Systematic reviews require the use of rigorously designed search strategies to ensure both comprehensive retrieval and minimization of bias. Conventional manual approaches, although methodologically systematic, are resource-intensive and susceptible to subjectivity, whereas heuristic and automated techniques frequently under-perform in recall unless supplemented by extensive expert input. We introduce a Large Language Model (LLM)-based chained prompt engineering framework for the automated development of search strategies in systematic reviews. The framework replicates the procedural structure of manual search design while leveraging LLMs to decompose review objectives, extract and formalize PICO elements, generate conceptual representations, expand terminologies, and synthesize Boolean queries. In addition to query construction, the framework exhibits superior performance in generating well-structured PICO elements relative to existing methods, thereby strengthening the foundation for high-recall search strategies. Evaluation on a subset of the LEADSInstruct dataset demonstrates that the framework attains a 0.9 average recall. These results significantly exceed the performance of existing approaches. Error analysis further highlights the critical role of precise objective specification and terminological alignment in optimizing retrieval effectiveness. These findings confirm the capacity of LLM-based pipelines to yield transparent, reproducible, and high-performing search strategies, and highlight their potential as scalable instruments for supporting evidence synthesis and evidence-based practice.

</details>


### [9] [Linear-PAL: A Lightweight Ranker for Mitigating Shortcut Learning in Personalized, High-Bias Tabular Ranking](https://arxiv.org/abs/2602.00013)
*Vipul Dinesh Pawar*

Main category: cs.IR

TL;DR: 提出Linear-PAL框架，通过结构约束解决高偏差场景下深度学习模型的捷径学习问题，在去偏排序质量和计算效率上实现帕累托优势


<details>
  <summary>Details</summary>
Motivation: 电商排序中，隐式用户反馈存在严重的位置偏差问题。在高偏差场景下，最先进的深度集成模型会出现捷径学习，过度拟合排名信号，导致排序质量下降

Method: 提出Linear-PAL框架：1) 通过显式特征连接和激进正则化的结构约束强制去偏；2) 引入向量化整数哈希技术替代字符串操作，实现O(N)向量化算术

Result: 在大规模数据集(420万样本)上，Linear-PAL实现帕累托优势：去偏排序质量(相关性AUC: 0.7626 vs 0.6736)优于深度集成，训练延迟降低43倍(40秒 vs 1762秒)

Conclusion: Linear-PAL的计算效率支持高频重训练，能够捕捉用户特定的新兴市场趋势，实现近乎实时的鲁棒个性化排序

Abstract: In e-commerce ranking, implicit user feedback is systematically confounded by Position Bias -- the strong propensity of users to interact with top-ranked items regardless of relevance. While Deep Learning architectures (e.g., Two-Tower Networks) are the standard solution for de-biasing, we demonstrate that in High-Bias Regimes, state-of-the-art Deep Ensembles suffer from Shortcut Learning: they minimize training loss by overfitting to the rank signal, leading to degraded ranking quality despite high prediction accuracy. We propose Linear Position-bias Aware Learning (Linear-PAL), a lightweight framework that enforces de-biasing through structural constraints: explicit feature conjunctions and aggressive regularization. We further introduce a Vectorized Integer Hashing technique for feature generation, replacing string-based operations with $O(N)$ vectorized arithmetic. Evaluating on a large-scale dataset (4.2M samples), Linear-PAL achieves Pareto Dominance: it outperforms Deep Ensembles in de-biased ranking quality (Relevance AUC: 0.7626 vs. 0.6736) while reducing training latency by 43x (40s vs 1762s). This computational efficiency enables high-frequency retraining, allowing the system to capture user-specific emerging market trends and deliver robust, personalized ranking in near real-time.

</details>


### [10] [AI-assisted Protocol Information Extraction For Improved Accuracy and Efficiency in Clinical Trial Workflows](https://arxiv.org/abs/2602.00052)
*Ramtin Babaeipour,François Charest,Madison Wright*

Main category: cs.IR

TL;DR: 使用RAG增强的生成式LLM进行临床试验方案信息自动提取，相比独立LLM准确率更高（87.8% vs 62.6%），AI辅助工作流效率提升40%且用户偏好度更高。


<details>
  <summary>Details</summary>
Motivation: 临床试验方案日益复杂、修订频繁以及知识管理困难给试验团队带来沉重负担。将方案内容结构化到标准格式中，有望提高效率、提升文档质量并加强合规性。

Method: 开发基于检索增强生成（RAG）的AI系统，使用生成式LLM自动提取临床试验方案信息。比较临床试验专用RAG流程与公开可用独立LLM的提取准确性，并评估AI辅助对模拟提取工作流的操作影响。

Result: RAG流程准确率（87.8%）显著高于经过精细调优提示的独立LLM（62.6%）。在模拟提取工作流中，AI辅助任务完成速度快40%，认知负荷更低，用户强烈偏好AI辅助方式。

Conclusion: 虽然专家监督仍然必要，但AI辅助提取能够实现大规模方案智能化，推动类似方法整合到真实临床工作流中，进一步验证其对可行性、研究启动和激活后监测的影响。

Abstract: Increasing clinical trial protocol complexity, amendments, and challenges around knowledge management create significant burden for trial teams. Structuring protocol content into standard formats has the potential to improve efficiency, support documentation quality, and strengthen compliance. We evaluate an Artificial Intelligence (AI) system using generative LLMs with Retrieval-Augmented Generation (RAG) for automated clinical trial protocol information extraction. We compare the extraction accuracy of our clinical-trial-specific RAG process against that of publicly available (standalone) LLMs. We also assess the operational impact of AI-assistance on simulated extraction CRC workflows. Our RAG process was measured as more accurate (87.8%) than standalone LLMs with fine-tuned prompts (62.6%) against expert-supported reference annotations. In the simulated extraction workflows, AI-assisted tasks were completed 40% faster, rated as less cognitively demanding and strongly preferred by users. While expert oversight remains essential, this suggests that AI-assisted extraction can enable protocol intelligence at scale, motivating the integration of similar methodologies into real world clinical workflows to further validate its impact on feasibility, study start-up, and post-activation monitoring.

</details>


### [11] [SPARC-RAG: Adaptive Sequential-Parallel Scaling with Context Management for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.00083)
*Yuxin Yang,Gangda Deng,Ömer Faruk Akgül,Nima Chitsazan,Yash Govilkar,Akasha Tigalappanavara,Shi-Xiong Zhang,Sambit Sahu,Viktor Prasanna*

Main category: cs.IR

TL;DR: SPARC-RAG是一个多智能体框架，通过协调顺序和并行推理扩展来解决传统RAG在多跳问答中的局限性，采用全局上下文管理和轻量级微调方法，显著提升性能同时降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）在多跳问答任务中面临挑战，需要长推理链。现有的推理时扩展方法（顺序深度和并行宽度）存在上下文污染和扩展效率低的问题，导致计算增加但收益递减甚至为负。

Method: 提出SPARC-RAG多智能体框架：1）协调顺序和并行推理扩展的统一上下文管理机制；2）专用智能体维护共享全局上下文；3）为每个分支生成有针对性的互补子查询以实现多样化并行探索；4）基于答案正确性和证据基础明确调节退出决策；5）引入轻量级微调方法，使用过程级可验证偏好优化扩展行为。

Result: 在单跳和多跳问答基准测试中，SPARC-RAG始终优于之前的RAG基线方法，平均F1分数提升+6.2，同时推理成本更低。

Conclusion: SPARC-RAG通过协调顺序和并行推理扩展，结合统一上下文管理和轻量级微调，有效解决了传统RAG在多跳问答中的扩展效率问题，实现了性能提升和成本降低的双重优势。

Abstract: Retrieval-Augmented Generation (RAG) grounds large language model outputs in external evidence, but remains challenged on multi-hop question answering that requires long reasoning. Recent works scale RAG at inference time along two complementary dimensions: sequential depth for iterative refinement and parallel width for coverage expansion. However, naive scaling causes context contamination and scaling inefficiency, leading to diminishing or negative returns despite increased computation. To address these limitations, we propose SPARC-RAG, a multi-agent framework that coordinates sequential and parallel inference-time scaling under a unified context management mechanism. SPARC-RAG employs specialized agents that maintain a shared global context and provide explicit control over the scaling process. It generates targeted, complementary sub-queries for each branch to enable diverse parallel exploration, and explicitly regulates exiting decisions based on answer correctness and evidence grounding. To optimize scaling behavior, we further introduce a lightweight fine-tuning method with process-level verifiable preferences, which improves the efficiency of sequential scaling and effectiveness of parallel scaling. Across single- and multi-hop QA benchmarks, SPARC-RAG consistently outperforms previous RAG baselines, yielding an average +6.2 F1 improvement under lower inference cost.

</details>


### [12] [RAGRouter-Bench: A Dataset and Benchmark for Adaptive RAG Routing](https://arxiv.org/abs/2602.00296)
*Ziqi Wang,Xi Zhu,Shuhang Lin,Haochen Xue,Minghao Guo,Yongfeng Zhang*

Main category: cs.IR

TL;DR: RAGRouter-Bench：首个用于自适应RAG路由的数据集和基准测试，系统评估不同RAG范式在多样化查询-语料库上下文中的表现，发现没有单一最优范式，适用性取决于查询-语料库交互。


<details>
  <summary>Details</summary>
Motivation: 现有RAG研究主要关注查询侧复杂性或孤立方法改进，缺乏对不同RAG范式在不同查询-语料库上下文和效果-效率权衡中的系统性理解。

Method: 引入RAGRouter-Bench数据集和基准，从查询-语料库兼容性角度重新审视检索，标准化5种代表性RAG范式，在7,727个查询和21,460个文档上进行系统评估，包含3种规范查询类型和细粒度语义/结构语料库指标。

Result: 实验表明：1）没有单一RAG范式普遍最优；2）范式适用性受查询-语料库交互强烈影响；3）增加高级机制不一定带来更好的效果-效率权衡。

Conclusion: 研究强调了路由感知评估的必要性，为自适应、可解释、可泛化的下一代RAG系统奠定了基础。

Abstract: Retrieval-Augmented Generation (RAG) has become a core paradigm for grounding large language models with external knowledge. Despite extensive efforts exploring diverse retrieval strategies, existing studies predominantly focus on query-side complexity or isolated method improvements, lacking a systematic understanding of how RAG paradigms behave across different query-corpus contexts and effectiveness-efficiency trade-offs. In this work, we introduce RAGRouter-Bench, the first dataset and benchmark designed for adaptive RAG routing. RAGRouter-Bench revisits retrieval from a query-corpus compatibility perspective and standardizes five representative RAG paradigms for systematic evaluation across 7,727 queries and 21,460 documents spanning diverse domains. The benchmark incorporates three canonical query types together with fine-grained semantic and structural corpus metrics, as well as a unified evaluation for both generation quality and resource consumption. Experiments with DeepSeek-V3 and LLaMA-3.1-8B demonstrate that no single RAG paradigm is universally optimal, that paradigm applicability is strongly shaped by query-corpus interactions, and that increased advanced mechanism does not necessarily yield better effectiveness-efficiency trade-offs. These findings underscore the necessity of routing-aware evaluation and establish a foundation for adaptive, interpretable, and generalizable next-generation RAG systems.

</details>


### [13] [Equity vs. Equality: Optimizing Ranking Fairness for Tailored Provider Needs](https://arxiv.org/abs/2602.00495)
*Yiteng Tu,Weihang Su,Shuguang Han,Yiqun Liu,Qingyao Ai*

Main category: cs.IR

TL;DR: 本文提出EquityRank算法，通过建模不同提供商的个性化偏好（如曝光和销售），在保持检索效果的同时实现更公平的提供商端排名。


<details>
  <summary>Details</summary>
Motivation: 现有排名公平性研究主要关注曝光平等，但忽略了现实世界中不同提供商对曝光、销售等结果的差异化需求。曝光公平性无法准确反映具有不同优先级的提供商的实际效用。

Method: 提出基于公平的框架，显式建模每个提供商对关键结果（如曝光和销售）的偏好，开发EquityRank梯度算法，联合优化用户端效果和提供商端公平性。

Result: 大量离线和在线模拟表明，EquityRank在效果和公平性之间提供了更好的权衡，并能适应异构的提供商需求。

Conclusion: 通过考虑提供商的个性化偏好，EquityRank框架能够更准确地满足不同提供商的公平性需求，同时保持检索系统的整体效果。

Abstract: Ranking plays a central role in connecting users and providers in Information Retrieval (IR) systems, making provider-side fairness an important challenge. While recent research has begun to address fairness in ranking, most existing approaches adopt an equality-based perspective, aiming to ensure that providers with similar content receive similar exposure. However, it overlooks the diverse needs of real-world providers, whose utility from ranking may depend not only on exposure but also on outcomes like sales or engagement. Consequently, exposure-based fairness may not accurately capture the true utility perceived by different providers with varying priorities. To this end, we introduce an equity-oriented fairness framework that explicitly models each provider's preferences over key outcomes such as exposure and sales, thus evaluating whether a ranking algorithm can fulfill these individualized goals while maintaining overall fairness across providers. Based on this framework, we develop EquityRank, a gradient-based algorithm that jointly optimizes user-side effectiveness and provider-side equity. Extensive offline and online simulations demonstrate that EquityRank offers improved trade-offs between effectiveness and fairness and adapts to heterogeneous provider needs.

</details>


### [14] [Towards Sample-Efficient and Stable Reinforcement Learning for LLM-based Recommendation](https://arxiv.org/abs/2602.00632)
*Hongxun Ding,Keqin Bao,Jizhi Zhang,Yi Fang,Wenxin Xu,Fuli Feng,Xiangnan He*

Main category: cs.IR

TL;DR: 该论文批判性地分析了长链思维推理在推荐系统中的适用性，提出基于强化学习的RISER框架来替代CoT方法，通过将非学习轨迹转化为成对偏好数据，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理在推荐系统中的流行趋势存在根本性缺陷：推理延迟过高，且用户行为数据缺乏明确的认知推理模式。需要寻找更合适的替代方案来提升推荐质量。

Method: 提出RISER框架，放弃CoT结构，直接采用强化学习探索物品空间。通过将非学习轨迹转化为有效的成对偏好数据进行优化，并采用防止冗余轨迹和约束token级更新幅度等策略确保稳定性。

Result: 在三个真实世界数据集上的实验表明，RISER显著优于竞争基线方法，为RL增强的LLM推荐建立了稳健的范式。

Conclusion: 长链思维推理不适合序列推荐领域，而基于强化学习的RISER框架通过有效的物品空间探索和稳定训练策略，为LLM推荐系统提供了更优的解决方案。

Abstract: While Long Chain-of-Thought (Long CoT) reasoning has shown promise in Large Language Models (LLMs), its adoption for enhancing recommendation quality is growing rapidly. In this work, we critically examine this trend and argue that Long CoT is inherently ill-suited for the sequential recommendation domain. We attribute this misalignment to two primary factors: excessive inference latency and the lack of explicit cognitive reasoning patterns in user behavioral data. Driven by these observations, we propose pivoting away from the CoT structure to directly leverage its underlying mechanism: Reinforcement Learning (RL), to explore the item space. However, applying RL directly faces significant obstacles, notably low sample efficiency-where most actions fail to provide learning signals-and training instability. To overcome these limitations, we propose RISER, a novel Reinforced Item Space Exploration framework for Recommendation. RISER is designed to transform non-learnable trajectories into effective pairwise preference data for optimization. Furthermore, it incorporates specific strategies to ensure stability, including the prevention of redundant rollouts and the constraint of token-level update magnitudes. Extensive experiments on three real-world datasets show that RISER significantly outperforms competitive baselines, establishing a robust paradigm for RL-enhanced LLM recommendation. Our code will be available at https://anonymous.4open.science/r/RISER/.

</details>


### [15] [RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment](https://arxiv.org/abs/2602.00682)
*Yuecheng Li,Hengwei Ju,Zeyu Song,Wei Yang,Chi Lu,Peng Jiang,Kun Gai*

Main category: cs.IR

TL;DR: RecGOAT提出了一种双语义对齐框架，通过图注意力网络和双重粒度对齐（实例级和分布级）来弥合大模型与推荐系统之间的表征差异，提升多模态推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了大型语言模型（优化于通用语义任务）与推荐系统（依赖稀疏用户/物品ID特征）之间的表征差异，导致不兼容的多模态表示和次优的推荐性能。

Method: 1. 使用图注意力网络建模物品-物品、用户-物品、用户-用户关系，利用用户/物品的大模型表示和交互历史丰富协同语义；2. 设计双重粒度渐进式多模态-ID对齐框架，通过跨模态对比学习实现实例级对齐，通过最优自适应传输实现分布级对齐。

Result: 在三个公开基准测试中达到最先进的性能，理论证明了统一表示具有更好的语义一致性和全面性。在大型在线广告平台上的部署验证了模型在工业推荐场景中的有效性和可扩展性。

Conclusion: RecGOAT通过理论保证的双语义对齐框架成功弥合了大模型与推荐系统之间的表征差异，为LLM增强的多模态推荐提供了有效解决方案，并在工业场景中验证了实用性。

Abstract: Multimodal recommendation systems typically integrates user behavior with multimodal data from items, thereby capturing more accurate user preferences. Concurrently, with the rise of large models (LMs), multimodal recommendation is increasingly leveraging their strengths in semantic understanding and contextual reasoning. However, LM representations are inherently optimized for general semantic tasks, while recommendation models rely heavily on sparse user/item unique identity (ID) features. Existing works overlook the fundamental representational divergence between large models and recommendation systems, resulting in incompatible multimodal representations and suboptimal recommendation performance. To bridge this gap, we propose RecGOAT, a novel yet simple dual semantic alignment framework for LLM-enhanced multimodal recommendation, which offers theoretically guaranteed alignment capability. RecGOAT first employs graph attention networks to enrich collaborative semantics by modeling item-item, user-item, and user-user relationships, leveraging user/item LM representations and interaction history. Furthermore, we design a dual-granularity progressive multimodality-ID alignment framework, which achieves instance-level and distribution-level semantic alignment via cross-modal contrastive learning (CMCL) and optimal adaptive transport (OAT), respectively. Theoretically, we demonstrate that the unified representations derived from our alignment framework exhibit superior semantic consistency and comprehensiveness. Extensive experiments on three public benchmarks show that our RecGOAT achieves state-of-the-art performance, empirically validating our theoretical insights. Additionally, the deployment on a large-scale online advertising platform confirms the model's effectiveness and scalability in industrial recommendation scenarios. Code available at https://github.com/6lyc/RecGOAT-LLM4Rec.

</details>


### [16] [SWGCN: Synergy Weighted Graph Convolutional Network for Multi-Behavior Recommendation](https://arxiv.org/abs/2602.00727)
*Fangda Chen,Yueyang Wang,Chaoli Lou,Min Gao,Qingyu Xiong*

Main category: cs.IR

TL;DR: SWGCN通过目标偏好加权器和协同对齐任务，在多行为推荐中有效捕捉跨行为协同信号和细粒度行为强度，在多个数据集上显著提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于图的多行为推荐方法往往忽视跨行为协同信号和个体行为的细粒度强度，需要克服这些局限性来提升推荐效果。

Method: 提出Synergy Weighted Graph Convolutional Network (SWGCN)，包含两个核心组件：目标偏好加权器（为每个行为内的用户-物品交互自适应分配权重）和协同对齐任务（通过辅助偏好评估器指导训练，优先考虑能更准确反映用户偏好的协同信号交互）。

Result: 在Taobao、IJCAI和Beibei三个开源数据集上验证，在Taobao数据集上HR相对提升112.49%，NDCG相对提升156.36%，在其他数据集上也获得一致提升，证明模型的鲁棒性和泛化能力。

Conclusion: SWGCN通过有效捕捉跨行为协同信号和细粒度行为强度，显著提升了多行为推荐性能，具有实际应用价值，代码已开源。

Abstract: Multi-behavior recommendation paradigms have emerged to capture diverse user activities, forecasting primary conversions (e.g., purchases) by leveraging secondary signals like browsing history. However, current graph-based methods often overlook cross-behavioral synergistic signals and fine-grained intensity of individual actions. Motivated by the need to overcome these shortcomings, we introduce Synergy Weighted Graph Convolutional Network (SWGCN). SWGCN introduces two novel components: a Target Preference Weigher, which adaptively assigns weights to user-item interactions within each behavior, and a Synergy Alignment Task, which guides its training by leveraging an Auxiliary Preference Valuator. This task prioritizes interactions from synergistic signals that more accurately reflect user preferences. The performance of our model is rigorously evaluated through comprehensive tests on three open-source datasets, specifically Taobao, IJCAI, and Beibei. On the Taobao dataset, SWGCN yields relative gains of 112.49% and 156.36% in terms of Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG), respectively. It also yields consistent gains on IJCAI and Beibei, confirming its robustness and generalizability across various datasets. Our implementation is open-sourced and can be accessed via https://github.com/FangdChen/SWGCN.

</details>


### [17] [Towards Trustworthy Multimodal Recommendation](https://arxiv.org/abs/2602.00730)
*Zixuan Li*

Main category: cs.IR

TL;DR: 提出可插拔的模态级校正组件，通过软对应学习缓解不可信的多模态特征，提升多模态推荐系统的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现实世界多模态推荐面临可信度问题，多模态内容可能存在误导或不一致（如视觉不一致的产品图片或点击诱饵标题），现有推荐系统在模态损坏下变得脆弱

Method: 提出可插拔的模态级校正组件，使用轻量级投影和Sinkhorn软匹配学习物品与多模态特征间的软对应关系，抑制不匹配的模态信号同时保持语义一致性

Result: 在多个数据集和骨干网络上的实验表明，模态校正提高了鲁棒性，并验证了交互级可信度的两个观察：训练集伪交互和传播图伪边在噪声下的双重影响

Conclusion: 模态级校正组件能有效提升多模态推荐系统的可信度和鲁棒性，为处理不可信多模态内容提供了实用解决方案

Abstract: Recent advances in multimodal recommendation have demonstrated the effectiveness of incorporating visual and textual content into collaborative filtering. However, real-world deployments raise an increasingly important yet underexplored issue: trustworthiness. On modern e-commerce platforms, multimodal content can be misleading or unreliable (e.g., visually inconsistent product images or click-bait titles), injecting untrustworthy signals into multimodal representations and making existing recommenders brittle under modality corruption. In this work, we take a step towards trustworthy multimodal recommendation from both a method and an analysis perspective. First, we propose a plug-and-play modality-level rectification component that mitigates untrustworthy modality features by learning soft correspondences between items and multimodal features. Using lightweight projections and Sinkhorn-based soft matching, the rectification suppresses mismatched modality signals while preserving semantic consistency, and can be integrated into existing multimodal recommenders without architectural modifications. Second, we present two practical insights on interaction-level trustworthiness under noisy collaborative signals: (i) training-set pseudo interactions can help or hurt performance under noise depending on prior-signal alignment; and (ii) propagation-graph pseudo edges can also help or hurt robustness, as message passing may amplify misalignment. Extensive experiments on multiple datasets and backbones under varying corruption levels demonstrate improved robustness from modality rectification and validate the above interaction-level observations.

</details>


### [18] [Optimizing Retrieval Components for a Shared Backbone via Component-Wise Multi-Stage Training](https://arxiv.org/abs/2602.00805)
*Yunhan Li,Mingjie Xie,Zihan Gong,Zeyang Shi,Gengshen Wu,Min Yang*

Main category: cs.IR

TL;DR: 针对工业法律检索系统中共享检索骨干网络的优化，提出基于多阶段优化的组件级混合配置方法，替代单一最优检查点策略


<details>
  <summary>Details</summary>
Motivation: 在工业系统中，单一检索骨干网络通常被多个下游应用共享，检索质量直接影响系统性能和可扩展性，同时耦合了跨应用的模型选择、部署和回滚决策

Method: 采用多阶段优化框架对稠密检索器和重排序器进行优化，发现不同检索组件呈现阶段依赖的权衡，提出组件级混合阶段配置方法

Result: 通过端到端评估验证了优化后的检索骨干网络，并作为共享检索服务部署到支持多个工业应用中

Conclusion: 在工业法律检索系统中，组件级混合阶段配置比单一最优检查点策略更有效，能够优化共享检索骨干网络的性能

Abstract: Recent advances in embedding-based retrieval have enabled dense retrievers to serve as core infrastructure in many industrial systems, where a single retrieval backbone is often shared across multiple downstream applications. In such settings, retrieval quality directly constrains system performance and extensibility, while coupling model selection, deployment, and rollback decisions across applications.
  In this paper, we present empirical findings and a system-level solution for optimizing retrieval components deployed as a shared backbone in production legal retrieval systems. We adopt a multi-stage optimization framework for dense retrievers and rerankers, and show that different retrieval components exhibit stage-dependent trade-offs. These observations motivate a component-wise, mixed-stage configuration rather than relying on a single uniformly optimal checkpoint. The resulting backbone is validated through end-to-end evaluation and deployed as a shared retrieval service supporting multiple industrial applications.

</details>


### [19] [Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment](https://arxiv.org/abs/2602.01023)
*Kai Yuan,Anthony Zheng,Jia Hu,Divyanshu Sheth,Hemanth Velaga,Kylee Kim,Matteo Guarrera,Besim Avci,Xuetao Yin,Rajyashree Mukherjee,Sean Suchter*

Main category: cs.IR

TL;DR: 提出一个统一的查询自动补全框架，将QAC重新定义为端到端列表生成，结合检索增强生成和多目标直接偏好优化，在商业搜索平台上取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有查询自动补全方法面临根本挑战：传统的检索-排序流水线长尾覆盖有限且需要大量特征工程，而生成式方法存在幻觉和安全风险。需要一种统一框架来解决这些问题。

Method: 1) 将QAC重新定义为端到端列表生成并进行多目标优化；2) 部署基于规则、基于模型和LLM作为评判者的验证器套件，结合RAG、多目标DPO和迭代批判-修订方法生成高质量合成数据；3) 混合服务架构在严格延迟约束下实现高效生产部署。

Result: 在大规模商业搜索平台上评估显示：离线指标在所有维度均有提升，人工评估获得+0.40到+0.69偏好分数，受控在线实验实现5.44%击键减少和3.46%建议采纳率增加。

Conclusion: 这项工作代表了向由大语言模型、RAG和多目标对齐驱动的端到端生成的范式转变，建立了一个经过生产验证的框架，可为更广泛的搜索和推荐行业带来益处。

Abstract: Query Auto-Completion (QAC) suggests query completions as users type, helping them articulate intent and reach results more efficiently. Existing approaches face fundamental challenges: traditional retrieve-and-rank pipelines have limited long-tail coverage and require extensive feature engineering, while recent generative methods suffer from hallucination and safety risks. We present a unified framework that reformulates QAC as end-to-end list generation through Retrieval-Augmented Generation (RAG) and multi-objective Direct Preference Optimization (DPO). Our approach combines three key innovations: (1) reformulating QAC as end-to-end list generation with multi-objective optimization; (2) defining and deploying a suite of rule-based, model-based, and LLM-as-judge verifiers for QAC, and using them in a comprehensive methodology that combines RAG, multi-objective DPO, and iterative critique-revision for high-quality synthetic data; (3) a hybrid serving architecture enabling efficient production deployment under strict latency constraints. Evaluation on a large-scale commercial search platform demonstrates substantial improvements: offline metrics show gains across all dimensions, human evaluation yields +0.40 to +0.69 preference scores, and a controlled online experiment achieves 5.44\% reduction in keystrokes and 3.46\% increase in suggestion adoption, validating that unified generation with RAG and multi-objective alignment provides an effective solution for production QAC. This work represents a paradigm shift to end-to-end generation powered by large language models, RAG, and multi-objective alignment, establishing a production-validated framework that can benefit the broader search and recommendation industry.

</details>


### [20] [GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm](https://arxiv.org/abs/2602.01865)
*Shaopeng Chen,Chuyue Xie,Huimin Ren,Shaozong Zhang,Han Zhang,Ruobing Cheng,Zhiqiang Cao,Zehao Ju,Gao Yu,Jie Ding,Xiaodong Chen,Xuewu Jiao,Shuanglong Li,Liu Lin*

Main category: cs.IR

TL;DR: GRAB是一个基于生成式框架的CTR预测模型，通过创新的因果感知多通道注意力机制，在百度广告系统中显著提升了收入和点击率。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习推荐模型在性能和效率上面临瓶颈，特别是在泛化能力和长序列建模方面存在困难。受到大语言模型扩展成功的启发，研究者希望开发一个能够有效处理用户行为序列的端到端生成式框架。

Method: 提出了GRAB（Generative Ranking for Ads at Baidu）框架，采用创新的因果感知多通道注意力机制（CamA），能够有效捕捉用户行为序列中的时间动态和特定动作信号。

Result: 全规模在线部署显示，GRAB显著优于现有DLRMs，带来3.05%的收入增长和3.49%的CTR提升。模型表现出良好的扩展性：随着使用更长的交互序列，其表达能力呈现单调且近似线性的提升。

Conclusion: GRAB成功将生成式框架应用于CTR预测，通过创新的注意力机制解决了传统推荐模型的瓶颈，在实际部署中取得了显著的业务效果提升，并展现出良好的扩展特性。

Abstract: Traditional Deep Learning Recommendation Models (DLRMs) face increasing bottlenecks in performance and efficiency, often struggling with generalization and long-sequence modeling. Inspired by the scaling success of Large Language Models (LLMs), we propose Generative Ranking for Ads at Baidu (GRAB), an end-to-end generative framework for Click-Through Rate (CTR) prediction. GRAB integrates a novel Causal Action-aware Multi-channel Attention (CamA) mechanism to effectively capture temporal dynamics and specific action signals within user behavior sequences. Full-scale online deployment demonstrates that GRAB significantly outperforms established DLRMs, delivering a 3.05% increase in revenue and a 3.49% rise in CTR. Furthermore, the model demonstrates desirable scaling behavior: its expressive power shows a monotonic and approximately linear improvement as longer interaction sequences are utilized.

</details>


### [21] [Adaptive Quality-Diversity Trade-offs for Large-Scale Batch Recommendation](https://arxiv.org/abs/2602.02024)
*Clémence Réda,Tomas Rigaux,Hiba Bederina,Koh Takeuchi,Hisashi Kashima,Jill-Jênn Vie*

Main category: cs.IR

TL;DR: 提出B-DivRec算法，结合行列式点过程和模糊去重技术，在推荐系统中平衡相关性与多样性，并自适应调整质量-多样性权衡。


<details>
  <summary>Details</summary>
Motivation: 推荐系统需要同时推荐高度相关且多样化的物品，既要个性化又要突破用户舒适区，但现实中存在避免推荐过于相似物品和计算成本高等挑战。

Method: 1. 在用户反馈模型已知情况下，提出B-DivRec算法，结合行列式点过程和模糊去重技术调整物品多样性程度；2. 提出自适应方法，根据用户反馈动态调整质量-多样性权衡。

Result: 在电影推荐和药物再利用的真实数据集上展示了B-DivRec的性能和适应性，验证了算法在平衡相关性与多样性方面的有效性。

Conclusion: B-DivRec算法能有效解决推荐系统中的质量-多样性权衡问题，通过自适应调整机制可以优化用户体验和系统性能。

Abstract: A core research question in recommender systems is to propose batches of highly relevant and diverse items, that is, items personalized to the user's preferences, but which also might get the user out of their comfort zone. This diversity might induce properties of serendipidity and novelty which might increase user engagement or revenue. However, many real-life problems arise in that case: e.g., avoiding to recommend distinct but too similar items to reduce the churn risk, and computational cost for large item libraries, up to millions of items. First, we consider the case when the user feedback model is perfectly observed and known in advance, and introduce an efficient algorithm called B-DivRec combining determinantal point processes and a fuzzy denuding procedure to adjust the degree of item diversity. This helps enforcing a quality-diversity trade-off throughout the user history. Second, we propose an approach to adaptively tailor the quality-diversity trade-off to the user, so that diversity in recommendations can be enhanced if it leads to positive feedback, and vice-versa. Finally, we illustrate the performance and versatility of B-DivRec in the two settings on synthetic and real-life data sets on movie recommendation and drug repurposing.

</details>


### [22] [Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs](https://arxiv.org/abs/2602.02338)
*Yu Liang,Zhongjin Zhang,Yuxuan Zhu,Kerui Zhang,Zhiluohan Guo,Wenhang Zhou,Zonqi Yang,Kangle Wu,Yabo Ni,Anxiang Zeng,Cong Fu,Jianxin Wang,Jiazhi Xia*

Main category: cs.IR

TL;DR: ReSID是一个推荐原生的语义ID框架，通过场感知掩码自编码和全局对齐正交量化，在不依赖LLM的情况下实现更高效的序列推荐，性能提升10%以上，token化成本降低122倍。


<details>
  <summary>Details</summary>
Motivation: 现有语义ID推荐方法存在语义嵌入与协同预测弱耦合、通用量化对自回归建模效率低的问题，需要从信息保留和序列可预测性角度重新设计。

Method: 提出ReSID框架：1) 场感知掩码自编码(FAMAE)从结构化特征学习预测充分的物品表示；2) 全局对齐正交量化(GAOQ)通过联合减少语义模糊性和前缀条件不确定性来生成紧凑可预测的SID序列。

Result: 在10个数据集上的实验表明，ReSID持续优于强序列和SID生成基线，平均提升超过10%，同时token化成本降低高达122倍。

Conclusion: ReSID提供了一个推荐原生的语义ID框架，通过重新思考表示学习和量化设计，在不依赖LLM的情况下实现了更好的推荐性能和效率。

Abstract: Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.

</details>


### [23] [RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval](https://arxiv.org/abs/2602.02444)
*Tyler Skow,Alexander Martin,Benjamin Van Durme,Rama Chellappa,Reno Kriz*

Main category: cs.IR

TL;DR: RANKVIDEO：用于视频检索的基于推理的重新排序器，通过显式推理查询-视频对来提升检索性能


<details>
  <summary>Details</summary>
Motivation: 虽然大型推理模型在文本重新排序方面取得了快速进展，但基于推理的视频检索重新排序仍然未被充分探索。现有方法通常缺乏对查询-视频对的显式推理能力。

Method: 提出RANKVIDEO系统，采用两阶段课程训练：1）感知基础的监督微调；2）结合点对、对偶和教师置信度蒸馏目标的重新排序训练。支持数据合成流程构建推理密集的查询-视频对。

Result: 在MultiVENT 2.0基准测试中，RANKVIDEO在两级检索框架下平均提升31%的nDCG@10性能，优于纯文本和视觉语言重新排序替代方案，同时更高效。

Conclusion: RANKVIDEO证明了基于推理的重新排序在视频检索中的有效性，填补了该领域的研究空白，为视频检索系统提供了更精确的重新排序能力。

Abstract: Reranking is a critical component of modern retrieval systems, which typically pair an efficient first-stage retriever with a more expressive model to refine results. While large reasoning models have driven rapid progress in text-centric reranking, reasoning-based reranking for video retrieval remains underexplored. To address this gap, we introduce RANKVIDEO, a reasoning-based reranker for video retrieval that explicitly reasons over query-video pairs using video content to assess relevance. RANKVIDEO is trained using a two-stage curriculum consisting of perception-grounded supervised fine-tuning followed by reranking training that combines pointwise, pairwise, and teacher confidence distillation objectives, and is supported by a data synthesis pipeline for constructing reasoning-intensive query-video pairs. Experiments on the large-scale MultiVENT 2.0 benchmark demonstrate that RANKVIDEO consistently improves retrieval performance within a two-stage framework, yielding an average improvement of 31% on nDCG@10 and outperforming text-only and vision-language reranking alternatives, while more efficient.

</details>
