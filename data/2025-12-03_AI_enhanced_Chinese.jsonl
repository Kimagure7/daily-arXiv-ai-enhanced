{"id": "2512.02474", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02474", "abs": "https://arxiv.org/abs/2512.02474", "authors": ["Haofeng Huang", "Ling Gai"], "title": "Q-BERT4Rec: Quantized Semantic-ID Representation Learning for Multimodal Recommendation", "comment": "Submitted to KDD2026", "summary": "Sequential recommendation plays a critical role in modern online platforms such as e-commerce, advertising, and content streaming, where accurately predicting users' next interactions is essential for personalization. Recent Transformer-based methods like BERT4Rec have shown strong modeling capability, yet they still rely on discrete item IDs that lack semantic meaning and ignore rich multimodal information (e.g., text and image). This leads to weak generalization and limited interpretability. To address these challenges, we propose Q-Bert4Rec, a multimodal sequential recommendation framework that unifies semantic representation and quantized modeling. Specifically, Q-Bert4Rec consists of three stages: (1) cross-modal semantic injection, which enriches randomly initialized ID embeddings through a dynamic transformer that fuses textual, visual, and structural features; (2) semantic quantization, which discretizes fused representations into meaningful tokens via residual vector quantization; and (3) multi-mask pretraining and fine-tuning, which leverage diverse masking strategies -- span, tail, and multi-region -- to improve sequential understanding. We validate our model on public Amazon benchmarks and demonstrate that Q-Bert4Rec significantly outperforms many strong existing methods, confirming the effectiveness of semantic tokenization for multimodal sequential recommendation. Our source code will be publicly available on GitHub after publishing.", "AI": {"tldr": "Q-Bert4Rec\uff1a\u4e00\u4e2a\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u91cf\u5316\u548c\u8de8\u6a21\u6001\u878d\u5408\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\uff08\u5982BERT4Rec\uff09\u4f9d\u8d56\u79bb\u6563\u7269\u54c1ID\uff0c\u7f3a\u4e4f\u8bed\u4e49\u4fe1\u606f\u4e14\u5ffd\u7565\u591a\u6a21\u6001\u7279\u5f81\uff08\u6587\u672c\u3001\u56fe\u50cf\uff09\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5f31\u548c\u53ef\u89e3\u91ca\u6027\u5dee", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) \u8de8\u6a21\u6001\u8bed\u4e49\u6ce8\u5165\uff0c\u901a\u8fc7\u52a8\u6001Transformer\u878d\u5408\u6587\u672c\u3001\u89c6\u89c9\u548c\u7ed3\u6784\u7279\u5f81\u4e30\u5bccID\u5d4c\u5165\uff1b2) \u8bed\u4e49\u91cf\u5316\uff0c\u4f7f\u7528\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\u5c06\u878d\u5408\u8868\u793a\u79bb\u6563\u5316\u4e3a\u6709\u610f\u4e49\u7684token\uff1b3) \u591a\u63a9\u7801\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\uff0c\u91c7\u7528\u8de8\u5ea6\u3001\u5c3e\u90e8\u3001\u591a\u533a\u57df\u7b49\u591a\u6837\u5316\u63a9\u7801\u7b56\u7565\u63d0\u5347\u5e8f\u5217\u7406\u89e3", "result": "\u5728\u516c\u5f00\u7684Amazon\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQ-Bert4Rec\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8bed\u4e49\u91cf\u5316\u5bf9\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u7684\u6709\u6548\u6027", "conclusion": "\u8bed\u4e49\u91cf\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u7684\u6027\u80fd\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027"}}
{"id": "2512.02502", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02502", "abs": "https://arxiv.org/abs/2512.02502", "authors": ["Luyao Niu", "Zhicheng Deng", "Boyang Li", "Nuoxian Huang", "Ruiqi Liu", "Wenjia Zhang"], "title": "AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations", "comment": null, "summary": "The \"15-minute city\" envisions neighborhoods where residents can meet daily needs via a short walk or bike ride. Realizing this vision requires not only physical proximity but also efficient and reliable access to information about nearby places, services, and events. Existing location-based systems, however, focus mainly on city-level tasks and neglect the spatial, temporal, and cognitive factors that shape localized decision-making. We conceptualize this gap as the Local Life Information Accessibility (LLIA) problem and introduce AskNearby, an AI-driven community application that unifies retrieval and recommendation within the 15-minute life circle. AskNearby integrates (i) a three-layer Retrieval-Augmented Generation (RAG) pipeline that synergizes graph-based, semantic-vector, and geographic retrieval with (ii) a cognitive-map model that encodes each user's neighborhood familiarity and preferences. Experiments on real-world community datasets demonstrate that AskNearby significantly outperforms LLM-based and map-based baselines in retrieval accuracy and recommendation quality, achieving robust performance in spatiotemporal grounding and cognitive-aware ranking. Real-world deployments further validate its effectiveness. By addressing the LLIA challenge, AskNearby empowers residents to more effectively discover local resources, plan daily activities, and engage in community life.", "AI": {"tldr": "AskNearby\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u793e\u533a\u5e94\u7528\uff0c\u901a\u8fc7\u4e09\u5c42RAG\u7ba1\u9053\u548c\u8ba4\u77e5\u5730\u56fe\u6a21\u578b\uff0c\u89e3\u51b315\u5206\u949f\u751f\u6d3b\u5708\u5185\u7684\u672c\u5730\u751f\u6d3b\u4fe1\u606f\u53ef\u53ca\u6027\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "15\u5206\u949f\u57ce\u5e02\u613f\u666f\u4e0d\u4ec5\u9700\u8981\u7269\u7406\u90bb\u8fd1\u6027\uff0c\u8fd8\u9700\u8981\u9ad8\u6548\u53ef\u9760\u5730\u83b7\u53d6\u9644\u8fd1\u573a\u6240\u3001\u670d\u52a1\u548c\u6d3b\u52a8\u7684\u4fe1\u606f\u3002\u73b0\u6709\u57fa\u4e8e\u4f4d\u7f6e\u7684\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u57ce\u5e02\u7ea7\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u5f71\u54cd\u672c\u5730\u5316\u51b3\u7b56\u7684\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u8ba4\u77e5\u56e0\u7d20\uff0c\u5f62\u6210\u4e86\u672c\u5730\u751f\u6d3b\u4fe1\u606f\u53ef\u53ca\u6027\uff08LLIA\uff09\u95ee\u9898\u3002", "method": "\u63d0\u51faAskNearby\u7cfb\u7edf\uff0c\u6574\u5408\uff1a(1) \u4e09\u5c42\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7ba1\u9053\uff0c\u7ed3\u5408\u57fa\u4e8e\u56fe\u3001\u8bed\u4e49\u5411\u91cf\u548c\u5730\u7406\u68c0\u7d22\uff1b(2) \u8ba4\u77e5\u5730\u56fe\u6a21\u578b\uff0c\u7f16\u7801\u6bcf\u4e2a\u7528\u6237\u7684\u793e\u533a\u719f\u6089\u5ea6\u548c\u504f\u597d\u3002", "result": "\u5728\u771f\u5b9e\u793e\u533a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAskNearby\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u63a8\u8350\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u548c\u57fa\u4e8e\u5730\u56fe\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u65f6\u7a7a\u57fa\u7840\u548c\u8ba4\u77e5\u611f\u77e5\u6392\u5e8f\u65b9\u9762\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\u3002\u5b9e\u9645\u90e8\u7f72\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3LLIA\u6311\u6218\uff0cAskNearby\u4f7f\u5c45\u6c11\u80fd\u591f\u66f4\u6709\u6548\u5730\u53d1\u73b0\u672c\u5730\u8d44\u6e90\u3001\u89c4\u5212\u65e5\u5e38\u6d3b\u52a8\u5e76\u53c2\u4e0e\u793e\u533a\u751f\u6d3b\uff0c\u63a8\u52a8\u4e8615\u5206\u949f\u57ce\u5e02\u613f\u666f\u7684\u5b9e\u73b0\u3002"}}
{"id": "2512.03025", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03025", "abs": "https://arxiv.org/abs/2512.03025", "authors": ["Chenji Lu", "Zhuo Chen", "Hui Zhao", "Zhiyuan Zeng", "Gang Zhao", "Junjie Ren", "Ruicong Xu", "Haoran Li", "Songyan Liu", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "LORE: A Large Generative Model for Search Relevance", "comment": null, "summary": "Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceiling. We argue this stems from treating relevance as a monolithic task, lacking principled deconstruction. Our key insight is that relevance comprises distinct capabilities: knowledge and reasoning, multi-modal matching, and rule adherence. We contend that a qualitative-driven decomposition is essential for breaking through current performance bottlenecks. Contributions. LORE provides a complete blueprint for the LLM relevance lifecycle. Key contributions include: (1) A two-stage training paradigm combining progressive CoT synthesis via SFT with human preference alignment via RL. (2) A comprehensive benchmark, RAIR, designed to evaluate these core capabilities. (3) A query frequency-stratified deployment strategy that efficiently transfers offline LLM capabilities to the online system. LORE serves as both a practical solution and a methodological reference for other vertical domains.", "AI": {"tldr": "LORE\u662f\u4e00\u4e2a\u7528\u4e8e\u7535\u5546\u641c\u7d22\u7684\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u5173\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u76f8\u5173\u6027\u4efb\u52a1\u5206\u89e3\u4e3a\u77e5\u8bc6\u63a8\u7406\u3001\u591a\u6a21\u6001\u5339\u914d\u548c\u89c4\u5219\u9075\u5faa\u4e09\u4e2a\u6838\u5fc3\u80fd\u529b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u5728\u4e09\u5e74\u90e8\u7f72\u4e2d\u5b9e\u73b0\u4e86\u7d2f\u8ba127%\u7684GoodRate\u6307\u6807\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4f7f\u7528\u601d\u7ef4\u94fe\uff08CoT\uff09\u589e\u5f3a\u76f8\u5173\u6027\uff0c\u4f46\u5e38\u9047\u5230\u6027\u80fd\u74f6\u9888\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u5c06\u76f8\u5173\u6027\u89c6\u4e3a\u5355\u4e00\u4efb\u52a1\uff0c\u7f3a\u4e4f\u539f\u5219\u6027\u5206\u89e3\u3002\u5173\u952e\u6d1e\u5bdf\u662f\u76f8\u5173\u6027\u5305\u542b\u4e09\u4e2a\u4e0d\u540c\u80fd\u529b\uff1a\u77e5\u8bc6\u4e0e\u63a8\u7406\u3001\u591a\u6a21\u6001\u5339\u914d\u548c\u89c4\u5219\u9075\u5faa\uff0c\u9700\u8981\u5b9a\u6027\u9a71\u52a8\u7684\u5206\u89e3\u6765\u7a81\u7834\u5f53\u524d\u6027\u80fd\u74f6\u9888\u3002", "method": "LORE\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a1\uff09\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u8fdb\u884c\u6e10\u8fdb\u5f0fCoT\u5408\u6210\uff1b2\uff09\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002\u8fd8\u5f00\u53d1\u4e86RAIR\u57fa\u51c6\u6765\u8bc4\u4f30\u6838\u5fc3\u80fd\u529b\uff0c\u5e76\u91c7\u7528\u67e5\u8be2\u9891\u7387\u5206\u5c42\u90e8\u7f72\u7b56\u7565\u5c06\u79bb\u7ebfLLM\u80fd\u529b\u9ad8\u6548\u8f6c\u79fb\u5230\u5728\u7ebf\u7cfb\u7edf\u3002", "result": "\u7ecf\u8fc7\u4e09\u5e74\u90e8\u7f72\u548c\u8fed\u4ee3\uff0cLORE\u5728\u5728\u7ebfGoodRate\u6307\u6807\u4e0a\u5b9e\u73b0\u4e86\u7d2f\u8ba127%\u7684\u6539\u8fdb\u3002\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684LLM\u76f8\u5173\u6027\u751f\u547d\u5468\u671f\u84dd\u56fe\uff0c\u53ef\u4f5c\u4e3a\u5176\u4ed6\u5782\u76f4\u9886\u57df\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u548c\u65b9\u6cd5\u8bba\u53c2\u8003\u3002", "conclusion": "LORE\u8bc1\u660e\u4e86\u5c06\u76f8\u5173\u6027\u4efb\u52a1\u5206\u89e3\u4e3a\u4e0d\u540c\u6838\u5fc3\u80fd\u529b\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u548c\u5206\u5c42\u90e8\u7f72\u7b56\u7565\uff0c\u6210\u529f\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u74f6\u9888\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u4e3a\u7535\u5546\u641c\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4e5f\u4e3a\u5176\u4ed6\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u53c2\u8003\u3002"}}
