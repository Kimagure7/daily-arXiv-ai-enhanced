{"id": "2511.04901", "categories": ["cs.IR", "cs.CL", "H.3.3"], "pdf": "https://arxiv.org/pdf/2511.04901", "abs": "https://arxiv.org/abs/2511.04901", "authors": ["Anthony Gamst", "Lawrence Wilson"], "title": "Association via Entropy Reduction", "comment": null, "summary": "Prior to recent successes using neural networks, term frequency-inverse\ndocument frequency (tf-idf) was clearly regarded as the best choice for\nidentifying documents related to a query. We provide a different score, aver,\nand observe, on a dataset with ground truth marking for association, that aver\ndoes do better at finding assciated pairs than tf-idf. This example involves\nfinding associated vertices in a large graph and that may be an area where\nneural networks are not currently an obvious best choice. Beyond this one\nanecdote, we observe that (1) aver has a natural threshold for declaring pairs\nas unassociated while tf-idf does not, (2) aver can distinguish between pairs\nof documents for which tf-idf gives a score of 1.0, (3) aver can be applied to\nlarger collections of documents than pairs while tf-idf cannot, and (4) that\naver is derived from entropy under a simple statistical model while tf-idf is a\nconstruction designed to achieve a certain goal and hence aver may be more\n\"natural.\" To be fair, we also observe that (1) writing down and computing the\naver score for a pair is more complex than for tf-idf and (2) that the fact\nthat the aver score is naturally scale-free makes it more complicated to\ninterpret aver scores.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aaver\u7684\u65b0\u8bc4\u5206\u65b9\u6cd5\uff0c\u5728\u5173\u8054\u6587\u6863\u53d1\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684tf-idf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u56fe\u6570\u636e\u4e2d\u5bfb\u627e\u5173\u8054\u9876\u70b9\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u5728\u795e\u7ecf\u7f51\u7edc\u5e7f\u6cdb\u5e94\u7528\u4e4b\u524d\uff0ctf-idf\u88ab\u8ba4\u4e3a\u662f\u8bc6\u522b\u67e5\u8be2\u76f8\u5173\u6587\u6863\u7684\u6700\u4f73\u9009\u62e9\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0tf-idf\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u81ea\u7136\u4e14\u5177\u6709\u66f4\u597d\u6027\u80fd\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7b80\u5355\u7edf\u8ba1\u6a21\u578b\u4e0b\u7684\u71b5\u63a8\u5bfc\u51faaver\u8bc4\u5206\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u81ea\u7136\u9608\u503c\u3001\u80fd\u533a\u5206tf-idf\u5f97\u5206\u4e3a1.0\u7684\u6587\u6863\u5bf9\u3001\u53ef\u5e94\u7528\u4e8e\u66f4\u5927\u6587\u6863\u96c6\u5408\u7b49\u7279\u6027\u3002", "result": "\u5728\u5177\u6709\u771f\u5b9e\u5173\u8054\u6807\u6ce8\u7684\u6570\u636e\u96c6\u4e0a\uff0caver\u5728\u5bfb\u627e\u5173\u8054\u6587\u6863\u5bf9\u65b9\u9762\u8868\u73b0\u4f18\u4e8etf-idf\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u56fe\u5173\u8054\u9876\u70b9\u53d1\u73b0\u4efb\u52a1\u4e2d\u3002", "conclusion": "aver\u4f5c\u4e3a\u4e00\u79cd\u57fa\u4e8e\u71b5\u7684\u7edf\u8ba1\u6a21\u578b\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u6bd4tf-idf\u66f4\u81ea\u7136\u6709\u6548\uff0c\u5c3d\u7ba1\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8\u4e14\u5f97\u5206\u89e3\u91ca\u8f83\u590d\u6742\uff0c\u4f46\u5728\u7279\u5b9a\u5e94\u7528\u9886\u57df\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2511.04939", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04939", "abs": "https://arxiv.org/abs/2511.04939", "authors": ["Harshit Nainwani", "Hediyeh Baban"], "title": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG", "comment": "22 pages, 2 figures, technical framework paper", "summary": "Retrieval systems are essential to contemporary AI pipelines, although most\nconfuse two separate processes: finding relevant information and giving enough\ncontext for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)\nframework, a dual-layer architecture that distinguishes between fine-grained\nsearch representations and coarse-grained retrieval contexts. SINR enhances the\ncomposability, scalability, and context fidelity of retrieval systems by\ndirectly connecting small, semantically accurate search chunks to larger,\ncontextually complete retrieve chunks, all without incurring extra processing\ncosts. This design changes retrieval from a passive step to an active one,\nmaking the system architecture more like how people process information. We\ndiscuss the SINR framework's conceptual foundation, formal structure,\nimplementation issues, and qualitative outcomes. This provides a practical\nfoundation for the next generation of AI systems that use retrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e86Search-Is-Not-Retrieve (SINR)\u6846\u67b6\uff0c\u5c06\u68c0\u7d22\u7cfb\u7edf\u7684\u641c\u7d22\u548c\u68c0\u7d22\u8fc7\u7a0b\u5206\u79bb\u4e3a\u7ec6\u7c92\u5ea6\u641c\u7d22\u8868\u793a\u548c\u7c97\u7c92\u5ea6\u68c0\u7d22\u4e0a\u4e0b\u6587\u4e24\u4e2a\u5c42\u6b21\uff0c\u63d0\u9ad8\u7cfb\u7edf\u7684\u53ef\u7ec4\u5408\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u68c0\u7d22\u7cfb\u7edf\u6df7\u6dc6\u4e86\u4e24\u4e2a\u72ec\u7acb\u8fc7\u7a0b\uff1a\u5bfb\u627e\u76f8\u5173\u4fe1\u606f\u4e0e\u63d0\u4f9b\u8db3\u591f\u63a8\u7406\u4e0a\u4e0b\u6587\u3002\u9700\u8981\u533a\u5206\u7cbe\u7ec6\u641c\u7d22\u548c\u4e0a\u4e0b\u6587\u68c0\u7d22\uff0c\u4f7f\u7cfb\u7edf\u67b6\u6784\u66f4\u7b26\u5408\u4eba\u7c7b\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\u3002", "method": "SINR\u53cc\u5c42\u6b21\u67b6\u6784\uff0c\u5c06\u5c0f\u7684\u8bed\u4e49\u51c6\u786e\u641c\u7d22\u5757\u76f4\u63a5\u8fde\u63a5\u5230\u5927\u7684\u4e0a\u4e0b\u6587\u5b8c\u6574\u68c0\u7d22\u5757\uff0c\u65e0\u9700\u989d\u5916\u5904\u7406\u6210\u672c\u3002\u5c06\u68c0\u7d22\u4ece\u88ab\u52a8\u6b65\u9aa4\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u8fc7\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u68c0\u7d22\u7cfb\u7edf\u7684\u53ef\u7ec4\u5408\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4f7f\u7528\u68c0\u7d22\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002", "conclusion": "SINR\u6846\u67b6\u901a\u8fc7\u533a\u5206\u641c\u7d22\u548c\u68c0\u7d22\u8fc7\u7a0b\uff0c\u6539\u53d8\u4e86\u68c0\u7d22\u7cfb\u7edf\u67b6\u6784\uff0c\u4f7f\u5176\u66f4\u7b26\u5408\u4eba\u7c7b\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u68c0\u7d22\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.05000", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05000", "abs": "https://arxiv.org/abs/2511.05000", "authors": ["Hyunkyu Kim", "Yeeun Yoo", "Youngjun Kwak"], "title": "Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval", "comment": "Accepted(Oral) by ICAIF 2025. Hyunkyu Kim and Yeeun Yoo contributed\n  equally to this work", "summary": "As financial applications of large language models (LLMs) gain attention,\naccurate Information Retrieval (IR) remains crucial for reliable AI services.\nHowever, existing benchmarks fail to capture the complex and domain-specific\ninformation needs of real-world banking scenarios. Building domain-specific IR\nbenchmarks is costly and constrained by legal restrictions on using real\ncustomer data. To address these challenges, we propose a systematic methodology\nfor constructing domain-specific IR benchmarks through LLM-based query\ngeneration. As a concrete implementation of this methodology, our pipeline\ncombines single and multi-document query generation with an enhanced and\nreasoning-augmented answerability assessment method, achieving stronger\nalignment with human judgments than prior approaches. Using this methodology,\nwe construct KoBankIR, comprising 815 queries derived from 204 official banking\ndocuments. Our experiments show that existing retrieval models struggle with\nthe complex multi-document queries in KoBankIR, demonstrating the value of our\nsystematic approach for domain-specific benchmark construction and underscoring\nthe need for improved retrieval techniques in financial domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u5728\u94f6\u884c\u4e1a\u521b\u5efa\u4e86KoBankIR\u57fa\u51c6\uff0c\u5305\u542b815\u4e2a\u67e5\u8be2\u548c204\u4efd\u94f6\u884c\u6587\u6863\uff0c\u663e\u793a\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u591a\u6587\u6863\u67e5\u8be2\u65f6\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u94f6\u884c\u573a\u666f\u4e2d\u590d\u6742\u4e14\u9886\u57df\u7279\u5b9a\u7684\u4fe1\u606f\u9700\u6c42\uff0c\u800c\u6784\u5efa\u9886\u57df\u7279\u5b9aIR\u57fa\u51c6\u6210\u672c\u9ad8\u4e14\u53d7\u9650\u4e8e\u5ba2\u6237\u6570\u636e\u7684\u6cd5\u5f8b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7LLM\u751f\u6210\u67e5\u8be2\uff0c\u7ed3\u5408\u5355\u6587\u6863\u548c\u591a\u6587\u6863\u67e5\u8be2\u751f\u6210\uff0c\u4ee5\u53ca\u589e\u5f3a\u7684\u63a8\u7406\u589e\u5f3a\u53ef\u56de\u7b54\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86KoBankIR\u57fa\u51c6\uff0c\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u5728\u5904\u7406\u8be5\u57fa\u51c6\u4e2d\u7684\u590d\u6742\u591a\u6587\u6863\u67e5\u8be2\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u6784\u5efa\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u9014\u5f84\uff0c\u5e76\u5f3a\u8c03\u4e86\u91d1\u878d\u9886\u57df\u9700\u8981\u6539\u8fdb\u68c0\u7d22\u6280\u672f\u3002"}}
{"id": "2511.05079", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05079", "abs": "https://arxiv.org/abs/2511.05079", "authors": ["Grigory Kovalev", "Natalia Loukachevitch", "Mikhail Tikhomirov", "Olga Babina", "Pavel Mamaev"], "title": "Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR", "comment": null, "summary": "In this paper, we present a novel series of Russian information retrieval\ndatasets constructed from the \"Did you know...\" section of Russian Wikipedia.\nOur datasets support a range of retrieval tasks, including fact-checking,\nretrieval-augmented generation, and full-document retrieval, by leveraging\ninteresting facts and their referenced Wikipedia articles annotated at the\nsentence level with graded relevance. We describe the methodology for dataset\ncreation that enables the expansion of existing Russian Information Retrieval\n(IR) resources. Through extensive experiments, we extend the RusBEIR research\nby comparing lexical retrieval models, such as BM25, with state-of-the-art\nneural architectures fine-tuned for Russian, as well as multilingual models.\nResults of our experiments show that lexical methods tend to outperform neural\nmodels on full-document retrieval, while neural approaches better capture\nlexical semantics in shorter texts, such as in fact-checking or fine-grained\nretrieval. Using our newly created datasets, we also analyze the impact of\ndocument length on retrieval performance and demonstrate that combining\nretrieval with neural reranking consistently improves results. Our contribution\nexpands the resources available for Russian information retrieval research and\nhighlights the importance of accurate evaluation of retrieval models to achieve\noptimal performance. All datasets are publicly available at HuggingFace. To\nfacilitate reproducibility and future research, we also release the full\nimplementation on GitHub.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u57fa\u4e8e\u4fc4\u8bed\u7ef4\u57fa\u767e\u79d1'\u4f60\u77e5\u9053\u5417'\u680f\u76ee\u7684\u65b0\u578b\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u652f\u6301\u4e8b\u5b9e\u6838\u67e5\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5168\u6587\u68c0\u7d22\u7b49\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u8bcd\u6cd5\u68c0\u7d22\u6a21\u578b\u4e0e\u795e\u7ecf\u6a21\u578b\u5728\u4fc4\u8bed\u68c0\u7d22\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u6269\u5c55\u4fc4\u8bed\u4fe1\u606f\u68c0\u7d22\u8d44\u6e90\uff0c\u4e3a\u4e8b\u5b9e\u6838\u67e5\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5168\u6587\u68c0\u7d22\u7b49\u4efb\u52a1\u63d0\u4f9b\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5f25\u8865\u73b0\u6709\u4fc4\u8bedIR\u8d44\u6e90\u7684\u4e0d\u8db3\u3002", "method": "\u4ece\u4fc4\u8bed\u7ef4\u57fa\u767e\u79d1'\u4f60\u77e5\u9053\u5417'\u680f\u76ee\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542b\u6709\u8da3\u4e8b\u5b9e\u53ca\u5176\u5f15\u7528\u7684\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\uff0c\u5e76\u8fdb\u884c\u53e5\u5b50\u7ea7\u522b\u7684\u5206\u7ea7\u76f8\u5173\u6027\u6807\u6ce8\u3002\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83BM25\u7b49\u8bcd\u6cd5\u68c0\u7d22\u6a21\u578b\u4e0e\u9488\u5bf9\u4fc4\u8bed\u4f18\u5316\u7684\u5148\u8fdb\u795e\u7ecf\u67b6\u6784\u53ca\u591a\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8bcd\u6cd5\u65b9\u6cd5\u5728\u5168\u6587\u68c0\u7d22\u4e2d\u8868\u73b0\u4f18\u4e8e\u795e\u7ecf\u6a21\u578b\uff0c\u800c\u795e\u7ecf\u65b9\u6cd5\u5728\u4e8b\u5b9e\u6838\u67e5\u6216\u7ec6\u7c92\u5ea6\u68c0\u7d22\u7b49\u8f83\u77ed\u6587\u672c\u4e2d\u80fd\u66f4\u597d\u5730\u6355\u6349\u8bcd\u6c47\u8bed\u4e49\u3002\u7ed3\u5408\u68c0\u7d22\u4e0e\u795e\u7ecf\u91cd\u6392\u5e8f\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u65b0\u6570\u636e\u96c6\u6269\u5c55\u4e86\u4fc4\u8bed\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u8d44\u6e90\uff0c\u5f3a\u8c03\u4e86\u51c6\u786e\u8bc4\u4f30\u68c0\u7d22\u6a21\u578b\u5bf9\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002\u6240\u6709\u6570\u636e\u96c6\u548c\u5b9e\u73b0\u4ee3\u7801\u5747\u5df2\u516c\u5f00\uff0c\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u548c\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2511.05301", "categories": ["cs.IR", "cs.CL", "cs.LG", "68P20, 68T50", "H.3"], "pdf": "https://arxiv.org/pdf/2511.05301", "abs": "https://arxiv.org/abs/2511.05301", "authors": ["Arthur Satouf", "Yuxuan Zong", "Habiboulaye Amadou-Boubacar", "Pablo Piantanida", "Benjamin Piwowarski"], "title": "QUESTER: Query Specification for Generative Retrieval", "comment": null, "summary": "Generative Retrieval (GR) differs from the traditional index-then-retrieve\npipeline by storing relevance in model parameters and directly generating\ndocument identifiers. However, GR often struggles to generalize and is costly\nto scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),\nwhich reframes GR as query specification generation - in this work, a simple\nkeyword query handled by BM25 - using a (small) LLM. The policy is trained\nusing reinforcement learning techniques (GRPO). Across in- and out-of-domain\nevaluations, we show that our model is more effective than BM25, and\ncompetitive with neural IR models, while maintaining a good efficiency", "AI": {"tldr": "QUESTER\u5c06\u751f\u6210\u5f0f\u68c0\u7d22\u91cd\u6784\u4e3a\u67e5\u8be2\u89c4\u8303\u751f\u6210\uff0c\u4f7f\u7528\u5c0f\u578bLLM\u751f\u6210\u5173\u952e\u8bcd\u67e5\u8be2\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u5f0f\u68c0\u7d22\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u6269\u5c55\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5c0f\u578bLLM\u5c06\u751f\u6210\u5f0f\u68c0\u7d22\u91cd\u6784\u4e3a\u67e5\u8be2\u89c4\u8303\u751f\u6210\uff08\u751f\u6210BM25\u53ef\u5904\u7406\u7684\u5173\u952e\u8bcd\u67e5\u8be2\uff09\uff0c\u91c7\u7528GRPO\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u8bc4\u4f30\u4e2d\uff0cQUESTER\u6bd4BM25\u66f4\u6709\u6548\uff0c\u4e0e\u795e\u7ecfIR\u6a21\u578b\u7ade\u4e89\u529b\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6548\u7387\u3002", "conclusion": "QUESTER\u901a\u8fc7\u67e5\u8be2\u89c4\u8303\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4e0e\u5148\u8fdb\u795e\u7ecf\u68c0\u7d22\u6a21\u578b\u76f8\u5f53\u7684\u68c0\u7d22\u6548\u679c\u3002"}}
{"id": "2511.05385", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05385", "abs": "https://arxiv.org/abs/2511.05385", "authors": ["Chao Zhang", "Yuhao Wang", "Derong Xu", "Haoxin Zhang", "Yuanjie Lyu", "Yuhao Chen", "Shuochen Liu", "Tong Xu", "Xiangyu Zhao", "Yan Gao", "Yao Hu", "Enhong Chen"], "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework", "comment": "32 pages", "summary": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment\nLarge Language Models' (LLMs) reliability. For flexibility, agentic RAG employs\nautonomous, multi-round retrieval and reasoning to resolve queries. Although\nrecent agentic RAG has improved via reinforcement learning, they often incur\nsubstantial token overhead from search and reasoning processes. This trade-off\nprioritizes accuracy over efficiency. To address this issue, this work proposes\nTeaRAG, a token-efficient agentic RAG framework capable of compressing both\nretrieval content and reasoning steps. 1) First, the retrieved content is\ncompressed by augmenting chunk-based semantic retrieval with a graph retrieval\nusing concise triplets. A knowledge association graph is then built from\nsemantic similarity and co-occurrence. Finally, Personalized PageRank is\nleveraged to highlight key knowledge within this graph, reducing the number of\ntokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative\nProcess-aware Direct Preference Optimization (IP-DPO) is proposed.\nSpecifically, our reward function evaluates the knowledge sufficiency by a\nknowledge matching mechanism, while penalizing excessive reasoning steps. This\ndesign can produce high-quality preference-pair datasets, supporting iterative\nDPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the\naverage Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on\nLlama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/TeaRAG.", "AI": {"tldr": "TeaRAG\u662f\u4e00\u4e2atoken\u9ad8\u6548\u7684\u4ee3\u7406\u5f0fRAG\u6846\u67b6\uff0c\u901a\u8fc7\u538b\u7f29\u68c0\u7d22\u5185\u5bb9\u548c\u63a8\u7406\u6b65\u9aa4\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7406\u5f0fRAG\u7cfb\u7edf\u867d\u7136\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4f46\u641c\u7d22\u548c\u63a8\u7406\u8fc7\u7a0b\u4f1a\u4ea7\u751f\u5927\u91cftoken\u5f00\u9500\uff0c\u8fd9\u79cd\u6743\u8861\u4f18\u5148\u8003\u8651\u51c6\u786e\u6027\u800c\u975e\u6548\u7387\u3002", "method": "1) \u901a\u8fc7\u56fe\u68c0\u7d22\u548c\u77e5\u8bc6\u5173\u8054\u56fe\u538b\u7f29\u68c0\u7d22\u5185\u5bb9\uff0c\u4f7f\u7528\u4e2a\u6027\u5316PageRank\u7a81\u51fa\u5173\u952e\u77e5\u8bc6\uff1b2) \u63d0\u51fa\u8fed\u4ee3\u8fc7\u7a0b\u611f\u77e5\u76f4\u63a5\u504f\u597d\u4f18\u5316(IP-DPO)\uff0c\u901a\u8fc7\u77e5\u8bc6\u5339\u914d\u673a\u5236\u8bc4\u4f30\u77e5\u8bc6\u5145\u5206\u6027\u5e76\u60e9\u7f5a\u8fc7\u5ea6\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cTeaRAG\u5728Llama3-8B-Instruct\u548cQwen2.5-14B-Instruct\u4e0a\u5206\u522b\u5c06\u5e73\u5747\u7cbe\u786e\u5339\u914d\u63d0\u9ad8\u4e864%\u548c2%\uff0c\u540c\u65f6\u5c06\u8f93\u51fatoken\u51cf\u5c11\u4e8661%\u548c59%\u3002", "conclusion": "TeaRAG\u6210\u529f\u89e3\u51b3\u4e86\u4ee3\u7406\u5f0fRAG\u7cfb\u7edf\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86token\u4f7f\u7528\u91cf\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
