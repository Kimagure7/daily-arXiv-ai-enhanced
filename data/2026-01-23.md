<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics](https://arxiv.org/abs/2601.15484)
*Philipp Eibl,Erica Coppolillo,Simone Mungari,Luca Luceri*

Main category: cs.IR

TL;DR: 比较分析维基百科和Grokipedia在政治争议话题上的语义框架、政治倾向和内容优先级差异，发现两者语义相似度随文章章节递减，在争议话题上分歧更大，且两者都主要呈现左倾框架，但Grokipedia呈现更明显的双峰分布并增加了右倾内容。


<details>
  <summary>Details</summary>
Motivation: 在线百科全书是现代信息基础设施的核心，已成为意识形态偏见辩论的焦点。维基百科长期被指责存在左倾偏见，而xAI推出的AI生成百科全书Grokipedia则被定位为右倾替代品。本研究旨在比较分析这两个平台在政治争议话题上的差异。

Method: 对维基百科和Grokipedia在已确立的政治争议话题上进行比较分析，具体考察语义框架、政治倾向和内容优先级的差异。分析包括语义相似度随文章章节的变化、争议话题与随机抽样话题的对比，以及政治倾向的分布特征。

Result: 1) 两个平台之间的语义相似度随文章章节递减；2) 在争议话题上的分歧比随机抽样话题更大；3) 两个百科全书都主要呈现左倾框架；4) Grokipedia呈现更明显的双峰分布，右倾内容更加突出。

Conclusion: 研究揭示了维基百科和Grokipedia在政治争议话题上的系统性差异，表明AI生成的百科全书虽然也主要呈现左倾框架，但增加了右倾内容的可见度，形成了更复杂的政治倾向分布。实验代码已公开。

Abstract: Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.

</details>


### [2] [DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking](https://arxiv.org/abs/2601.15518)
*Wenxin Zhou,Ritesh Mehta,Anthony Miyaguchi*

Main category: cs.IR

TL;DR: 开发两阶段检索系统，结合多种检索方法与重排序，解决TREC Tip-of-the-Tongue任务，最佳系统在测试集上达到0.66召回率和0.41 NDCG@1000


<details>
  <summary>Details</summary>
Motivation: 解决TREC Tip-of-the-Tongue任务中的信息检索挑战，该任务需要从模糊记忆中检索具体信息，传统单一检索方法效果有限

Method: 两阶段系统：第一阶段使用混合检索（LLM检索、稀疏BM25、稠密BGE-M3）和主题感知多索引稠密检索；第二阶段使用LambdaMART训练重排序和LLM重排序；使用LLM生成5000个合成查询用于训练

Result: 最佳系统（混合检索+Gemini-2.5-flash重排序）在测试集上达到0.66召回率和0.41 NDCG@1000，证明融合检索的有效性

Conclusion: 融合多种互补检索方法与LLM重排序能有效解决Tip-of-the-Tongue检索任务，混合检索策略显著提升性能

Abstract: We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.

</details>


### [3] [Blockchain-Based Spectrum Resource Securitization via Semi-Fungible Token-Lock](https://arxiv.org/abs/2601.15594)
*Zhixian Zhou,Bin Chen,Zhe Peng,Zhiming Liang,Ruijun Wu,Chen Sun,Shuo Wang*

Main category: cs.IR

TL;DR: 本文提出SFT Lock方法，通过锁/解锁机制替代铸造/销毁操作，在保持NFT身份和历史可追溯性的同时实现频谱资产的部分所有权和可转移性，显著降低链上开销。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络发展，频谱资产需要灵活、动态、高效的利用，这推动了基于区块链的频谱证券化。现有的ERC404混合代币模型在资产转移时频繁进行铸造和销毁操作，破坏了代币身份连续性并增加了链上开销。

Method: 提出Semi Fungible Token Lock (SFT Lock)方法，采用锁/解锁机制替代铸造/销毁操作，通过确定性状态转换保持NFT身份和历史可追溯性。设计了模块化智能合约架构支持频谱授权、证券化和共享，并引入质押机制增强资产流动性。

Result: 在私有以太坊网络上的实验结果表明，与ERC404混合代币模型相比，所提方法在保持功能正确性和可追溯性的同时，实现了显著的gas节省。

Conclusion: SFT Lock方法通过锁/解锁机制有效解决了ERC404模型中的代币身份连续性问题，显著降低了链上操作开销，为6G网络中的频谱资产证券化提供了更高效的解决方案。

Abstract: As 6G networks evolve, spectrum assets require flexible, dynamic, and efficient utilization, motivating blockchain based spectrum securitization. Existing approaches based on ERC404 style hybrid token models rely on frequent minting and burning during asset transfers, which disrupt token identity continuity and increase on chain overhead. This paper proposes the Semi Fungible Token Lock (SFT Lock) method, a lock/unlock based mechanism that preserves NFT identity and historical traceability while enabling fractional ownership and transferability. By replacing mint/burn operations with deterministic state transitions, SFT Lock ensures consistent lifecycle representation of spectrum assets and significantly reduces on chain operations. Based on this mechanism, a modular smart contract architecture is designed to support spectrum authorization, securitization, and sharing, and a staking mechanism is introduced to enhance asset liquidity. Experimental results on a private Ethereum network demonstrate that, compared with ERC404 style hybrid token models, the proposed method achieves substantial gas savings while maintaining functional correctness and traceability.

</details>


### [4] [Enhancing guidance for missing data in diffusion-based sequential recommendation](https://arxiv.org/abs/2601.15673)
*Qilong Yan,Yifei Xing,Dugang Liu,Jingpu Duan,Jian Yin*

Main category: cs.IR

TL;DR: 提出CARD模型，通过反事实注意力机制增强用户兴趣转折点信号，抑制序列噪声，提升扩散模型在序列推荐中的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法从分类转向扩散生成范式，但用户序列中的缺失数据导致指导信号质量下降。现有方法仅移除局部相似项，忽略了用户兴趣的"关键转折点"，这些转折点对准确预测后续用户意图至关重要。

Method: 提出CARD模型：1) 双面Thompson采样方法识别经历显著兴趣转移的序列；2) 对这些序列使用反事实注意力机制量化每个项目的重要性，为扩散模型提供动态重新加权的交互向量作为高质量指导信号。

Result: 实验表明该方法在真实世界数据上表现良好，且计算成本不高。

Conclusion: CARD通过关注用户兴趣转折点并抑制序列噪声，有效提升了扩散模型在序列推荐中的生成质量，为解决序列数据缺失导致的指导信号质量问题提供了新思路。

Abstract: Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.

</details>


### [5] [CoNRec: Context-Discerning Negative Recommendation with LLMs](https://arxiv.org/abs/2601.15721)
*Xinda Chen,Jiawei Wu,Yishuang Liu,Jialin Zhu,Shuwen Xiao,Junjun Zheng,Xiangheng Kong,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出首个基于大语言模型的负反馈建模框架，通过语义ID表示、项目级对齐任务和渐进式GRPO训练范式，解决负反馈数据稀疏性和上下文理解偏差问题，并设计了基于多日未来负反馈的新奖励函数和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统主要将负反馈作为辅助信号来增强正向推荐，很少直接建模负向兴趣。由于负反馈数据固有的稀疏性，模型容易受到正向反馈主导带来的上下文理解偏差影响。此外，传统的下一个负项预测目标与用户真实负向偏好存在根本性错配，受到系统推荐顺序的严重影响。

Method: 1) 使用语义ID表示替代基于文本的项目描述；2) 引入项目级对齐任务，增强LLM对负反馈背后语义上下文的理解；3) 设计渐进式GRPO训练范式，使模型能够动态平衡正向和负向行为上下文的利用；4) 提出基于多日未来负反馈及其协同信号的新奖励函数和评估指标。

Result: 论文提出了首个大语言模型负反馈建模框架，能够更准确地理解用户负向偏好，缓解负反馈数据稀疏性带来的上下文理解偏差问题，并解决了传统负项预测目标与真实负向偏好的错配问题。

Conclusion: 该研究为负反馈建模提供了创新的大语言模型解决方案，通过语义表示、对齐任务和渐进式训练范式，显著提升了模型对用户负向偏好的理解能力，并为负反馈评估提供了更合理的指标设计。

Abstract: Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.

</details>


### [6] [CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval](https://arxiv.org/abs/2601.15849)
*Tsung-Hsiang Chou,Chen-Jui Yu,Shui-Hsiang Hsu,Yao-Chung Fan*

Main category: cs.IR

TL;DR: CGPT：通过LLM生成监督信号增强表格检索的训练框架，使用聚类构建语义多样的部分表格，生成合成查询进行对比学习，在多个基准测试中显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 通用嵌入模型在文本检索中表现良好，但在表格检索中效果不佳，因为高度结构化的内容导致语义压缩和查询-表格不匹配。现有LLM检索增强方法依赖启发式部分表格选择，且很少利用合成查询作为监督信号来改进嵌入模型。

Method: CGPT框架：1) 使用K-means聚类表格实例，跨集群采样构建语义多样的部分表格；2) 用LLM为这些部分表格生成合成查询；3) 通过硬负例对比学习微调嵌入模型。

Result: 在四个公共基准测试（MimoTable、OTTQA、FetaQA、E2E-WTQ）上，CGPT始终优于检索基线（包括QGpT），平均R@1提升16.54%。在统一多领域语料设置中，CGPT展现出强大的跨领域泛化能力，即使使用较小的LLM生成查询也有效。

Conclusion: 语义引导的部分表格构建结合LLM生成监督的对比训练，为大规模表格检索提供了有效且可扩展的范式。该方法显著提升了表格检索性能，并具有良好的泛化能力。

Abstract: General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.

</details>


### [7] [STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion](https://arxiv.org/abs/2601.15860)
*Shui-Hsiang Hsu,Tsung-Hsiang Chou,Chen-Jui Yu,Yao-Chung Fan*

Main category: cs.IR

TL;DR: STAR框架通过语义聚类和加权融合改进表格语义表示，在五个基准测试中比QGpT获得更高的召回率


<details>
  <summary>Details</summary>
Motivation: 现有表格检索方法面临结构和语义差异挑战，QGpT等方法依赖粗糙的部分表格采样和简单融合策略，限制了语义多样性和查询-表格对齐效果

Method: STAR采用语义聚类和加权融合：1) 基于表头的K-means聚类分组语义相似行，选择代表性中心实例构建多样化部分表格；2) 生成聚类特定的合成查询全面覆盖表格语义空间；3) 使用加权融合策略整合表格和查询嵌入，实现细粒度语义对齐

Result: 在五个基准测试中，STAR在所有数据集上都比QGpT获得更高的Recall，证明了语义聚类和自适应加权融合对鲁棒表格表示的有效性

Conclusion: STAR框架通过语义聚类和加权融合改进了表格语义表示，能够从结构和文本源捕获互补信息，提高表格表示的表达能力

Abstract: Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.

</details>


### [8] [MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging](https://arxiv.org/abs/2601.15930)
*Tianjun Wei,Enneng Yang,Yingpeng Du,Huizhong Guo,Jie Zhang,Zhu Sun*

Main category: cs.IR

TL;DR: 本文首次系统研究了生成式推荐系统中的模型合并问题，提出了MMGRid框架来组织不同上下文训练的模型，揭示了参数冲突和近因偏差等挑战，并提出了相应的解决方案。


<details>
  <summary>Details</summary>
Motivation: 模型合并（MM）在计算机视觉等领域已证明有效，但在推荐系统（RS）中尚未充分探索。生成式推荐（GR）作为RS新范式，模型规模快速增长且计算成本高昂，使得模型合并在成本敏感部署场景中特别有吸引力。本文旨在研究如何合并针对不同现实上下文（时间演化和领域异质性）专门化的生成式推荐器。

Method: 提出了统一的MMGRid框架，构建了一个结构化的上下文网格，组织由时间演化和领域多样性诱导的不同上下文训练的GR检查点。所有检查点都源自共享的基础LLM，但在特定上下文数据上微调，为系统分析GR范式和合并算法提供了现实可控的模型空间。

Result: 研究发现：1）从LLM训练GR模型会因token分布偏移和目标差异导致参数冲突，可通过基础模型替换来分离任务感知和上下文特定参数变化以缓解冲突；2）跨上下文增量训练会引入近因偏差，可通过加权上下文合并有效平衡；3）最优合并权重与上下文依赖的交互特征相关，为实际部署中的权重选择提供了实用指导。

Conclusion: 本文首次系统研究了生成式推荐系统中的模型合并问题，揭示了关键挑战并提出了解决方案。MMGRid框架为分析跨上下文模型合并提供了系统方法，研究结果为实际部署中的模型合并策略提供了重要指导，特别是在处理时间演化和领域异质性等现实挑战时。

Abstract: Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.

</details>


### [9] [Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory](https://arxiv.org/abs/2601.15975)
*Chen Xu,Zhipeng Yi,Ruizi Wang,Wenjie Wang,Jun Xu,Maarten de Rijke*

Main category: cs.IR

TL;DR: 提出AddictSim框架，结合经济学成瘾理论和推荐系统行为数据，模拟短视频成瘾行为，发现多样性推荐算法可缓解成瘾


<details>
  <summary>Details</summary>
Motivation: 短视频平台存在成瘾问题，但现有研究依赖问卷调查和小样本数据，而平台拥有大规模行为数据，需要利用这些数据分析成瘾行为模式

Method: 结合经济学成瘾理论和推荐系统隐式行为数据，提出AddictSim训练框架，采用mean-to-adapted策略和群体相对策略优化训练，建模个性化成瘾模式

Result: 短视频成瘾遵循与传统成瘾行为相似的功能模式，强度与社会科学研究一致；AddictSim在两个大规模数据集上优于现有训练策略；多样性算法能有效缓解成瘾行为

Conclusion: 利用平台大规模行为数据和经济学理论可有效分析短视频成瘾，AddictSim框架能建模个性化成瘾模式，多样性推荐算法是缓解成瘾的有效策略

Abstract: Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.

</details>
