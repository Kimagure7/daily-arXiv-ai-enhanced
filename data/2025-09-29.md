<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [SPELUNKER: Item Similarity Search Using Large Language Models and Custom K-Nearest Neighbors](https://arxiv.org/abs/2509.21323)
*Ana Rodrigues,João Mata,Rui Rego*

Main category: cs.IR

TL;DR: 提出结合大语言模型和自定义KNN算法的混合系统，用于直观的物品相似性搜索，提供更好的可解释性


<details>
  <summary>Details</summary>
Motivation: 解决黑盒密集向量系统缺乏可解释性的问题，弥合人类语言与机器可理解物品表示之间的差距

Method: 使用LLM将自然语言查询转换为结构化属性搜索，然后输入到采用BallTree搜索策略的自定义KNN算法中，使用异构距离度量

Result: 在500条葡萄酒评论数据集上评估，LLM信息提取F1分数达0.9779，Jaro字符串相似度0.9321；LLM重排显著提升召回率(p=0.013)

Conclusion: 该方法有效结合了LLM和KNN的优势，提供了透明且细致的搜索能力，能够识别符合用户微妙意图的相关物品

Abstract: This paper presents a hybrid system for intuitive item similarity search that
combines a Large Language Model (LLM) with a custom K-Nearest Neighbors (KNN)
algorithm. Unlike black-box dense vector systems, this architecture provides
superior interpretability by first using an LLM to convert natural language
queries into structured, attribute-based searches. This structured query then
serves as input to a custom KNN algorithm with a BallTree search strategy,
which uses a heterogeneous distance metric to preserve distinct data types. Our
evaluation, conducted on a dataset of 500 wine reviews, demonstrates the
system's effectiveness. The LLM achieved an F1-score of 0.9779 in information
extraction, while also demonstrating high fidelity with a Jaro string
similarity of 0.9321. When we augmented the KNN algorithm with LLM-based
re-ranking, we observed a statistically significant improvement in recall
(p=0.013), indicating the LLM's ability to identify and promote relevant items
that align with nuanced user intent. This approach effectively bridges the gap
between human language and machine-understandable item representations,
offering a transparent and nuanced search capability.

</details>


### [2] [From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data](https://arxiv.org/abs/2509.21324)
*Gurbinder Gill,Ritvik Gupta,Denis Lusson,Anand Chandrashekar,Donald Nguyen*

Main category: cs.IR

TL;DR: 提出了一个新的分类框架(L1-L5)来基于数据模态和任务复杂度对问答系统进行分类，并评估了四个最先进的平台，验证了多空间检索和动态编排对实现L1-L4能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于文本语义搜索和重排序的RAG在处理超越数据摘要或非文本数据的问题时存在不足，需要从问题导向的角度来理解RAG和相关问答系统。

Method: 提出了L1-L5分类框架，创建了与这些级别对齐的基准，并评估了LangChain、Azure AI Search、OpenAI和Corvic AI四个平台，使用代表企业用例的多样化数据集进行实证验证。

Result: 实验结果表明多空间检索和动态编排对于实现L1-L4能力具有重要价值，通过不同数据集验证了这些发现。

Conclusion: 该分类框架为理解RAG系统的能力提供了问题导向的视角，多空间检索和动态编排是实现更高级别问答能力的关键技术。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for
answering questions on enterprise data. Traditionally, RAG has centered on
text-based semantic search and re-ranking. However, this approach falls short
when dealing with questions beyond data summarization or non-text data. This
has led to various attempts to supplement RAG to bridge the gap between RAG,
the implementation paradigm, and the question answering problem that enterprise
users expect it to solve. Given that contemporary RAG is a collection of
techniques rather than a defined implementation, discussion of RAG and related
question-answering systems benefits from a problem-oriented understanding.
  We propose a new classification framework (L1-L5) to categorize systems based
on data modalities and task complexity of the underlying question answering
problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective
and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also
introduce benchmarks aligned with these levels and evaluate four
state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI.
Our experiments highlight the value of multi-space retrieval and dynamic
orchestration for enabling L1-L4 capabilities. We empirically validate our
findings using diverse datasets indicative of enterprise use cases.

</details>


### [3] [PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.21325)
*Baiqiang Wang,Qian Lou,Mengxin Zheng,Dongfang Zhao*

Main category: cs.IR

TL;DR: PIR-RAG是一个实用的隐私保护RAG系统，通过语义聚类和快速PIR协议实现高效、安全的文档检索，显著降低端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统存在隐私风险，用户查询会暴露给服务提供商，需要保护用户隐私的同时保持系统效率。

Method: 采用粗粒度语义聚类修剪搜索空间，结合基于格的快速私有信息检索协议，优化端到端RAG工作流程。

Result: 相比基于图的PIR和Tiptoe式私有评分等基线架构，PIR-RAG在可扩展性和"RAG就绪延迟"方面表现更优。

Conclusion: PIR-RAG是大规模AI系统中隐私保护的高效可行解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has become a foundational component of
modern AI systems, yet it introduces significant privacy risks by exposing user
queries to service providers. To address this, we introduce PIR-RAG, a
practical system for privacy-preserving RAG. PIR-RAG employs a novel
architecture that uses coarse-grained semantic clustering to prune the search
space, combined with a fast, lattice-based Private Information Retrieval (PIR)
protocol. This design allows for the efficient retrieval of entire document
clusters, uniquely optimizing for the end-to-end RAG workflow where full
document content is required. Our comprehensive evaluation against strong
baseline architectures, including graph-based PIR and Tiptoe-style private
scoring, demonstrates PIR-RAG's scalability and its superior performance in
terms of "RAG-Ready Latency"-the true end-to-end time required to securely
fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly
efficient solution for privacy in large-scale AI systems.

</details>


### [4] [HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores](https://arxiv.org/abs/2509.21336)
*Guohang Yan,Yue Zhang,Pinlong Cai,Ding Wang,Song Mao,Hongwei Zhang,Yaoze Zhang,Hairong Zhang,Xinyu Cai,Botian Shi*

Main category: cs.IR

TL;DR: HetaRAG是一个混合深度检索增强生成框架，通过协调异构数据存储中的跨模态证据，将向量索引、知识图谱、全文引擎和结构化数据库统一到单一检索平面中。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG系统通常只基于文本，依赖单一存储后端，存在不可避免的权衡：向量搜索捕获语义相似性但丢失全局上下文；知识图谱擅长关系精度但召回率低；全文索引快速准确但语义盲区；关系数据库提供强事务保证但无语义理解。

Method: 提出原则性融合方案，协调异构检索范式协同工作，减轻单一模态的弱点。构建混合深度检索增强生成框架，动态路由和融合证据以最大化召回率、精度和上下文保真度。

Result: 进行了初步探索并构建了初始RAG流水线，部分代码已在GitHub上开源。

Conclusion: 异构检索范式具有互补性，通过协调融合可以协同工作，缓解单一模态的局限性。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for
mitigating knowledge hallucination and staleness in large language models
(LLMs) while preserving data security. By retrieving relevant evidence from
private, domain-specific corpora and injecting it into carefully engineered
prompts, RAG delivers trustworthy responses without the prohibitive cost of
fine-tuning. Traditional retrieval-augmented generation (RAG) systems are
text-only and often rely on a single storage backend, most commonly a vector
database. In practice, this monolithic design suffers from unavoidable
trade-offs: vector search captures semantic similarity yet loses global
context; knowledge graphs excel at relational precision but struggle with
recall; full-text indexes are fast and exact yet semantically blind; and
relational engines such as MySQL provide strong transactional guarantees but no
semantic understanding. We argue that these heterogeneous retrieval paradigms
are complementary, and propose a principled fusion scheme to orchestrate them
synergistically, mitigating the weaknesses of any single modality. In this work
we introduce HetaRAG, a hybrid, deep-retrieval augmented generation framework
that orchestrates cross-modal evidence from heterogeneous data stores. We plan
to design a system that unifies vector indices, knowledge graphs, full-text
engines, and structured databases into a single retrieval plane, dynamically
routing and fusing evidence to maximize recall, precision, and contextual
fidelity. To achieve this design goal, we carried out preliminary explorations
and constructed an initial RAG pipeline; this technical report provides a brief
overview. The partial code is available at
https://github.com/KnowledgeXLab/HetaRAG.

</details>


### [5] [Cross-Modal Retrieval with Cauchy-Schwarz Divergence](https://arxiv.org/abs/2509.21339)
*Jiahao Zhang,Wenzhe Yin,Shujian Yu*

Main category: cs.IR

TL;DR: 提出基于柯西-施瓦茨散度的跨模态检索方法，通过广义CS散度支持多模态对齐，无需超参数调节且训练稳定。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态检索方法依赖KL散度、MMD等分布对齐技术，存在数值不稳定、超参数敏感、无法捕捉完整分布结构等问题。

Method: 引入柯西-施瓦茨散度作为无超参数对齐度量，并提出基于Hölder不等式的广义CS散度，通过双向循环比较实现三模态以上直接对齐。

Result: 在六个基准数据集上的实验表明，该方法在双模态和三模态检索任务中均表现优异。

Conclusion: CS/GCS散度提供了一种稳定、高效的多模态对齐框架，显著提升了跨模态检索性能。

Abstract: Effective cross-modal retrieval requires robust alignment of heterogeneous
data types. Most existing methods focus on bi-modal retrieval tasks and rely on
distributional alignment techniques such as Kullback-Leibler divergence,
Maximum Mean Discrepancy, and correlation alignment. However, these methods
often suffer from critical limitations, including numerical instability,
sensitivity to hyperparameters, and their inability to capture the full
structure of the underlying distributions. In this paper, we introduce the
Cauchy-Schwarz (CS) divergence, a hyperparameter-free measure that improves
both training stability and retrieval performance. We further propose a novel
Generalized CS (GCS) divergence inspired by H\"older's inequality. This
extension enables direct alignment of three or more modalities within a unified
mathematical framework through a bidirectional circular comparison scheme,
eliminating the need for exhaustive pairwise comparisons. Extensive experiments
on six benchmark datasets demonstrate the effectiveness of our method in both
bi-modal and tri-modal retrieval tasks. The code of our CS/GCS divergence is
publicly available at https://github.com/JiahaoZhang666/CSD.

</details>


### [6] [ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems](https://arxiv.org/abs/2509.21371)
*Dayu Yang,Hui Fang*

Main category: cs.IR

TL;DR: ReGeS是一个用于对话推荐系统的检索-生成协同框架，通过生成增强检索来从对话中提取用户意图，并通过检索增强生成来区分物品的细微特征，无需额外标注即可减少幻觉并简化持续更新。


<details>
  <summary>Details</summary>
Motivation: 现有对话推荐系统要么需要领域特定工程（灵活性差），要么仅依赖大语言模型（幻觉风险高）。朴素RAG方法在CRS中受限于嘈杂对话削弱检索效果以及忽略相似物品间的细微差异。

Method: 提出ReGeS框架，实现检索与生成的相互协同：生成增强检索从对话中提炼信息丰富的用户意图，检索增强生成区分相似物品的细微特征。

Result: 在多个CRS基准测试中，ReGeS在推荐准确性方面达到了最先进的性能。

Conclusion: 检索与生成的相互协同对于知识密集型CRS任务非常有效，能够在不需额外标注的情况下减少幻觉并简化系统更新。

Abstract: Connecting conversation with external domain knowledge is vital for
conversational recommender systems (CRS) to correctly understand user
preferences. However, existing solutions either require domain-specific
engineering, which limits flexibility, or rely solely on large language models,
which increases the risk of hallucination. While Retrieval-Augmented Generation
(RAG) holds promise, its naive use in CRS is hindered by noisy dialogues that
weaken retrieval and by overlooked nuances among similar items. We propose
ReGeS, a reciprocal Retrieval-Generation Synergy framework that unifies
generation-augmented retrieval to distill informative user intent from
conversations and retrieval-augmented generation to differentiate subtle item
features. This synergy obviates the need for extra annotations, reduces
hallucinations, and simplifies continuous updates. Experiments on multiple CRS
benchmarks show that ReGeS achieves state-of-the-art performance in
recommendation accuracy, demonstrating the effectiveness of reciprocal synergy
for knowledge-intensive CRS tasks.

</details>


### [7] [MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering](https://arxiv.org/abs/2509.21391)
*Lihui Liu,Carl J. Yang*

Main category: cs.IR

TL;DR: MIXRAG是一个基于混合专家机制的图增强检索生成框架，通过多个专门化的图检索器和动态路由控制器来处理多样化查询意图，并引入查询感知的图编码器来减少检索信息中的噪声。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG系统通常依赖单一检索器，难以捕捉复杂查询的多样化方面，且容易受到无关噪声的干扰，导致推理不准确。

Method: 提出MIXRAG框架，包含多个专门化图检索器（关注实体、关系、子图拓扑等不同语义方面），通过混合专家模块自适应选择和融合检索器，并使用查询感知的GraphEncoder分析检索子图中的关系，突出最相关部分。

Result: 实证结果表明，该方法实现了最先进的性能，在各种基准测试中始终优于多种基线方法，并在不同领域的图基任务中表现有效。

Conclusion: MIXRAG通过多专家检索器和噪声抑制机制，显著提升了图增强检索生成系统的性能，能够更好地处理复杂查询并减少幻觉问题。

Abstract: Large Language Models (LLMs) have achieved impressive performance across a
wide range of applications. However, they often suffer from hallucinations in
knowledge-intensive domains due to their reliance on static pretraining
corpora. To address this limitation, Retrieval-Augmented Generation (RAG)
enhances LLMs by incorporating external knowledge sources during inference.
Among these sources, textual graphs provide structured and semantically rich
information that supports more precise and interpretable reasoning. This has
led to growing interest in graph-based RAG systems. Despite their potential,
most existing approaches rely on a single retriever to identify relevant
subgraphs, which limits their ability to capture the diverse aspects of complex
queries. Moreover, these systems often struggle to accurately judge the
relevance of retrieved content, making them prone to distraction by irrelevant
noise. To address these challenges, in this paper, we propose MIXRAG, a
Mixture-of-Experts Graph-RAG framework that introduces multiple specialized
graph retrievers and a dynamic routing controller to better handle diverse
query intents. Each retriever is trained to focus on a specific aspect of graph
semantics, such as entities, relations, or subgraph topology. A
Mixture-of-Experts module adaptively selects and fuses relevant retrievers
based on the input query. To reduce noise in the retrieved information, we
introduce a query-aware GraphEncoder that carefully analyzes relationships
within the retrieved subgraphs, highlighting the most relevant parts while
down-weighting unnecessary noise. Empirical results demonstrate that our method
achieves state-of-the-art performance and consistently outperforms various
baselines. MIXRAG is effective across a wide range of graph-based tasks in
different domains. The code will be released upon paper acceptance.

</details>


### [8] [Effect of Model Merging in Domain-Specific Ad-hoc Retrieval](https://arxiv.org/abs/2509.21966)
*Taiga Sasaki,Takehiro Yamamoto,Hiroaki Ohshima,Sumio Fujita*

Main category: cs.IR

TL;DR: 模型融合在特定领域检索任务中的效果评估，通过线性插值方法结合检索模型和领域特定模型的权重，无需额外微调即可提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 探索模型融合技术在特定领域检索任务中的应用潜力，验证其是否能提高检索效果并作为LoRA微调的实用替代方案。

Method: 使用线性插值方法融合源检索模型和领域特定模型的权重，在医疗和日语领域进行实验，比较融合模型与源检索模型及LoRA微调模型的性能。

Result: 模型融合能够产生比源检索模型更有效的领域特定检索模型，在数据有限的情况下可作为LoRA微调的实用替代方案。

Conclusion: 模型融合是一种有效的领域适应方法，特别适用于数据有限的情况，能够在不进行额外微调的情况下提升检索性能。

Abstract: In this study, we evaluate the effect of model merging in ad-hoc retrieval
tasks. Model merging is a technique that combines the diverse characteristics
of multiple models. We hypothesized that applying model merging to
domain-specific ad-hoc retrieval tasks could improve retrieval effectiveness.
To verify this hypothesis, we merged the weights of a source retrieval model
and a domain-specific (non-retrieval) model using a linear interpolation
approach. A key advantage of our approach is that it requires no additional
fine-tuning of the models. We conducted two experiments each in the medical and
Japanese domains. The first compared the merged model with the source retrieval
model, and the second compared it with a LoRA fine-tuned model under both full
and limited data settings for model construction. The experimental results
indicate that model merging has the potential to produce more effective
domain-specific retrieval models than the source retrieval model, and may serve
as a practical alternative to LoRA fine-tuning, particularly when only a
limited amount of data is available.

</details>


### [9] [GoalRank: Group-Relative Optimization for a Large Ranking Model](https://arxiv.org/abs/2509.22046)
*Kaike Zhang,Xiaobei Wang,Shuchang Liu,Hailan Yang,Xiang Li,Lantao Hu,Han Li,Qi Cao,Fei Sun,Kun Gai*

Main category: cs.IR

TL;DR: 本文提出了一种仅使用生成器的单阶段排序框架GoalRank，证明了对于任何生成器-评估器模型，都存在性能更优的生成器单阶段模型，并通过理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统排序采用生成器-评估器两阶段范式，通过扩大候选集数量提升性能，但效果有限且快速饱和。受大型推荐模型端到端单阶段方法启发，重新从生成器单阶段视角审视排序问题。

Method: 理论证明生成器单阶段模型在逼近最优排序策略方面具有更小误差，推导单阶段优化目标的证据上界，利用用户反馈训练的奖励模型构建分组相对参考策略，提出GoalRank生成器单阶段排序框架。

Result: 在公共基准测试和大规模在线A/B测试中，GoalRank持续优于最先进方法。

Conclusion: 生成器单阶段排序模型不仅理论性能更优，且在实践中表现卓越，验证了排序问题中单阶段方法的有效性。

Abstract: Mainstream ranking approaches typically follow a Generator-Evaluator
two-stage paradigm, where a generator produces candidate lists and an evaluator
selects the best one. Recent work has attempted to enhance performance by
expanding the number of candidate lists, for example, through multi-generator
settings. However, ranking involves selecting a recommendation list from a
combinatorially large space. Simply enlarging the candidate set remains
ineffective, and performance gains quickly saturate. At the same time, recent
advances in large recommendation models have shown that end-to-end one-stage
models can achieve promising performance with the expectation of scaling laws.
Motivated by this, we revisit ranking from a generator-only one-stage
perspective. We theoretically prove that, for any (finite
Multi-)Generator-Evaluator model, there always exists a generator-only model
that achieves strictly smaller approximation error to the optimal ranking
policy, while also enjoying scaling laws as its size increases. Building on
this result, we derive an evidence upper bound of the one-stage optimization
objective, from which we find that one can leverage a reward model trained on
real user feedback to construct a reference policy in a group-relative manner.
This reference policy serves as a practical surrogate of the optimal policy,
enabling effective training of a large generator-only ranker. Based on these
insights, we propose GoalRank, a generator-only ranking framework. Extensive
offline experiments on public benchmarks and large-scale online A/B tests
demonstrate that GoalRank consistently outperforms state-of-the-art methods.

</details>


### [10] [Does Generative Retrieval Overcome the Limitations of Dense Retrieval?](https://arxiv.org/abs/2509.22116)
*Yingchen Zhang,Ruqing Zhang,Jiafeng Guo,Maarten de Rijke,Yixing Fan,Xueqi Cheng*

Main category: cs.IR

TL;DR: 生成式检索(GR)相比稠密检索(DR)在理论基础和扩展性方面具有优势，但在实践中尚未完全超越DR。GR通过全局归一化最大似然优化将语料库和相关性信息编码到模型参数中，而DR使用局部归一化目标和外部嵌入表示。


<details>
  <summary>Details</summary>
Motivation: 理论上研究生成式检索(GR)与稠密检索(DR)在学习目标和表示能力方面的根本差异，探索GR在大规模应用中的潜力。

Method: 通过理论和实证分析，比较GR和DR的学习机制，并在Natural Questions和MS MARCO数据集上进行控制实验，测试不同负采样策略、嵌入维度和模型规模的影响。

Result: 理论分析表明，随着规模扩大，GR可以克服DR的固有局限性：在大语料库中避免DR局部归一化引起的优化漂移，在大模型中参数规模不受全局低秩结构限制。但实验显示GR在实践中并未普遍优于DR。

Conclusion: GR具有理论优势但需要进一步研究来弥合理论与实践的差距，为可扩展和鲁棒的生成式检索提供未来研究方向。

Abstract: Generative retrieval (GR) has emerged as a new paradigm in neural information
retrieval, offering an alternative to dense retrieval (DR) by directly
generating identifiers of relevant documents. In this paper, we theoretically
and empirically investigate how GR fundamentally diverges from DR in both
learning objectives and representational capacity. GR performs globally
normalized maximum-likelihood optimization and encodes corpus and relevance
information directly in the model parameters, whereas DR adopts locally
normalized objectives and represents the corpus with external embeddings before
computing similarity via a bilinear interaction. Our analysis suggests that,
under scaling, GR can overcome the inherent limitations of DR, yielding two
major benefits. First, with larger corpora, GR avoids the sharp performance
degradation caused by the optimization drift induced by DR's local
normalization. Second, with larger models, GR's representational capacity
scales with parameter size, unconstrained by the global low-rank structure that
limits DR. We validate these theoretical insights through controlled
experiments on the Natural Questions and MS MARCO datasets, across varying
negative sampling strategies, embedding dimensions, and model scales. But
despite its theoretical advantages, GR does not universally outperform DR in
practice. We outline directions to bridge the gap between GR's theoretical
potential and practical performance, providing guidance for future research in
scalable and robust generative retrieval.

</details>


### [11] [Can Synthetic Query Rewrites Capture User Intent Better than Humans in Retrieval-Augmented Generation?](https://arxiv.org/abs/2509.22325)
*JiaYing Zheng,HaiNan Zhang,Liang Pang,YongXin Tong,ZhiMing Zheng*

Main category: cs.IR

TL;DR: 提出SynRewrite方法，通过合成数据驱动的查询重写模型，解决多轮RAG系统中口语化省略和模糊指代问题，在检索和生成任务上优于人工重写。


<details>
  <summary>Details</summary>
Motivation: 多轮RAG系统面临口语化省略和模糊指代问题，传统人工重写因标注者表达能力限制，导致改写查询与真实RAG系统需求存在差距，无法准确捕捉用户意图。

Method: 1) 使用GPT-4o基于对话历史、当前查询、正例文档和答案合成高质量重写数据；2) 在Flan-T5模型上微调，将对话历史和查询映射到合成重写；3) 通过DPO算法利用生成器反馈进一步增强重写器性能。

Result: 在TopiOCQA和QRECC数据集上的实验表明，SynRewrite在检索和生成任务上持续优于人工重写方法。

Conclusion: 合成重写可以作为人工标注的可扩展且有效的替代方案，更好地捕捉用户意图。

Abstract: Multi-turn RAG systems often face queries with colloquial omissions and
ambiguous references, posing significant challenges for effective retrieval and
generation. Traditional query rewriting relies on human annotators to clarify
queries, but due to limitations in annotators' expressive ability and depth of
understanding, manually rewritten queries often diverge from those needed in
real-world RAG systems, resulting in a gap between user intent and system
response. We observe that high-quality synthetic queries can better bridge this
gap, achieving superior performance in both retrieval and generation compared
to human rewrites. This raises an interesting question: Can rewriting models
trained on synthetic queries better capture user intent than human annotators?
In this paper, we propose SynRewrite, a synthetic data-driven query rewriting
model to generate high-quality synthetic rewrites more aligned with user
intent. To construct training data, we prompt GPT-4o with dialogue history,
current queries, positive documents, and answers to synthesize high-quality
rewrites. A Flan-T5 model is then finetuned on this dataset to map dialogue
history and queries to synthetic rewrites. Finally, we further enhance the
rewriter using the generator's feedback through the DPO algorithm to boost
end-task performance. Experiments on TopiOCQA and QRECC datasets show that
SynRewrite consistently outperforms human rewrites in both retrieval and
generation tasks. Our results demonstrate that synthetic rewrites can serve as
a scalable and effective alternative to human annotations.

</details>


### [12] [Your RAG is Unfair: Exposing Fairness Vulnerabilities in Retrieval-Augmented Generation via Backdoor Attacks](https://arxiv.org/abs/2509.22486)
*Gaurav Bagwe,Saket S. Chaturvedi,Xiaolong Ma,Xiaoyong Yuan,Kuang-Ching Wang,Lan Zhang*

Main category: cs.IR

TL;DR: BiasRAG是一个针对检索增强生成(RAG)系统的公平性漏洞攻击框架，通过两阶段后门攻击操纵目标群体与偏见之间的语义关系，实现持久隐蔽的内容生成影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RAG系统的虚假信息威胁，而公平性漏洞尚未充分探索。传统后门攻击依赖直接触发-目标映射，而公平性攻击利用检索与生成模型的交互，操纵目标群体与社会偏见之间的语义关系。

Method: 采用两阶段后门攻击：预训练阶段通过损害查询编码器使目标群体与特定社会偏见对齐；部署后阶段向知识库注入对抗性文档来强化后门，在保持标准公平性评估不可检测的同时微妙影响检索内容。

Result: 实证评估显示BiasRAG实现了高攻击成功率，同时保持了上下文相关性和实用性，对RAG系统的公平性构成了持久且不断演变的威胁。

Conclusion: BiasRAG暴露了RAG系统中被忽视的公平性漏洞，展示了通过操纵检索-生成交互来建立持久隐蔽影响的攻击方法，强调了需要更全面的安全评估。

Abstract: Retrieval-augmented generation (RAG) enhances factual grounding by
integrating retrieval mechanisms with generative models but introduces new
attack surfaces, particularly through backdoor attacks. While prior research
has largely focused on disinformation threats, fairness vulnerabilities remain
underexplored. Unlike conventional backdoors that rely on direct
trigger-to-target mappings, fairness-driven attacks exploit the interaction
between retrieval and generation models, manipulating semantic relationships
between target groups and social biases to establish a persistent and covert
influence on content generation.
  This paper introduces BiasRAG, a systematic framework that exposes fairness
vulnerabilities in RAG through a two-phase backdoor attack. During the
pre-training phase, the query encoder is compromised to align the target group
with the intended social bias, ensuring long-term persistence. In the
post-deployment phase, adversarial documents are injected into knowledge bases
to reinforce the backdoor, subtly influencing retrieved content while remaining
undetectable under standard fairness evaluations. Together, BiasRAG ensures
precise target alignment over sensitive attributes, stealthy execution, and
resilience. Empirical evaluations demonstrate that BiasRAG achieves high attack
success rates while preserving contextual relevance and utility, establishing a
persistent and evolving threat to fairness in RAG.

</details>
