<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks](https://arxiv.org/abs/2511.00072)
*Pradeep M,Ritesh Pallod,Satyen Abrol,Muthu Raman,Ian Anderson*

Main category: cs.IR

TL;DR: 提出了一个端到端的产品搜索系统，用于将AI生成的时尚造型与最相似的实体产品进行匹配，已在真实互联网规模部署，每天服务超过35万个AI造型。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑时尚行业，能够创建虚拟造型和头像，因此需要找到与AI生成风格最匹配的真实产品。

Method: 搜索管道包含四个关键组件：查询生成、向量化、候选检索和基于AI生成造型的重新排序。使用CLIP模型进行向量化，并通过人工判断的准确度分数评估推荐质量。

Result: 系统每天服务超过35万个AI造型，覆盖全球市场1200多万个产品。实验表明，CLIP模型在平均意见分数上比其他模型相对高出3-7%，虽然绝对改进不大，但能带来明显更好的用户感知匹配。

Conclusion: CLIP被确立为生产部署中最可靠的基础模型，其改进虽然绝对值不大，但在用户感知匹配方面产生了显著提升。

Abstract: Generative AI is reshaping fashion by enabling virtual looks and avatars
making it essential to find real products that best match AI-generated styles.
We propose an end-to-end product search system that has been deployed in a
real-world, internet scale which ensures that AI-generated looks presented to
users are matched with the most visually and semantically similar products from
the indexed vector space. The search pipeline is composed of four key
components: query generation, vectorization, candidate retrieval, and reranking
based on AI-generated looks. Recommendation quality is evaluated using
human-judged accuracy scores. The system currently serves more than 350,000 AI
Looks in production per day, covering diverse product categories across global
markets of over 12 million products. In our experiments, we observed that
across multiple annotators and categories, CLIP outperformed alternative models
by a small relative margin of 3--7\% in mean opinion scores. These
improvements, though modest in absolute numbers, resulted in noticeably better
user perception matches, establishing CLIP as the most reliable backbone for
production deployment.

</details>


### [2] [Effectiveness of LLMs in Temporal User Profiling for Recommendation](https://arxiv.org/abs/2511.00176)
*Milad Sabouri,Masoud Mansoury,Kun Lin,Bamshad Mobasher*

Main category: cs.IR

TL;DR: 该论文研究利用大语言模型(LLMs)捕捉用户偏好的时间动态，通过生成短期和长期交互历史的文本摘要来创建更丰富的用户表示，提升推荐系统的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统用户画像往往忽视短期兴趣和长期偏好的区别，需要更有效地建模用户偏好的动态特性来增强推荐准确性和透明度。

Method: 利用大语言模型生成用户交互历史的短期和长期文本摘要，创建区分性的用户表示，并分析不同领域下该方法的效果差异。

Result: 在用户参与度较高的领域(如电影电视)，LLMs能显著提升推荐质量，但在稀疏环境中效果不明显；短期和长期偏好的可区分性在不同领域存在差异。

Conclusion: LLM驱动的时序用户画像在性能提升和计算成本之间存在权衡，需要根据具体应用场景选择使用；该方法通过自然语言画像和注意力权重提供了内在的可解释性潜力。

Abstract: Effectively modeling the dynamic nature of user preferences is crucial for
enhancing recommendation accuracy and fostering transparency in recommender
systems. Traditional user profiling often overlooks the distinction between
transitory short-term interests and stable long-term preferences. This paper
examines the capability of leveraging Large Language Models (LLMs) to capture
these temporal dynamics, generating richer user representations through
distinct short-term and long-term textual summaries of interaction histories.
Our observations suggest that while LLMs tend to improve recommendation quality
in domains with more active user engagement, their benefits appear less
pronounced in sparser environments. This disparity likely stems from the
varying distinguishability of short-term and long-term preferences across
domains; the approach shows greater utility where these temporal interests are
more clearly separable (e.g., Movies\&TV) compared to domains with more stable
user profiles (e.g., Video Games). This highlights a critical trade-off between
enhanced performance and computational costs, suggesting context-dependent LLM
application. Beyond predictive capability, this LLM-driven approach inherently
provides an intrinsic potential for interpretability through its natural
language profiles and attention weights. This work contributes insights into
the practical capability and inherent interpretability of LLM-driven temporal
user profiling, outlining new research directions for developing adaptive and
transparent recommender systems.

</details>


### [3] [Simple and Behavior-Driven Augmentation for Recommendation with Rich Collaborative Signals](https://arxiv.org/abs/2511.00436)
*Doyun Choi,Cheonwoo Lee,Jaemin Yoo*

Main category: cs.IR

TL;DR: 提出SCAR方法，通过生成伪交互而非删除信息来增强图协同过滤中的对比学习效果


<details>
  <summary>Details</summary>
Motivation: 传统对比学习方法通过删除噪声交互来生成增强视图，但定义"噪声"存在模糊性，可能导致核心信息丢失和不可靠视图，同时增加了增强复杂度

Method: SCAR从用户-物品交互中提取协同信号来生成伪交互，然后将这些伪交互添加到现有交互中或替换现有交互，从而获得更鲁棒的表示

Result: 在四个基准数据集上的实验表明，SCAR在关键评估指标上优于先前的基于对比学习的图协同过滤方法和其他最先进的自监督学习方法

Conclusion: SCAR在不同超参数设置下表现出强鲁棒性，在稀疏数据场景中特别有效，避免了过度复杂的增强模块的缺陷

Abstract: Contrastive learning (CL) has been widely used for enhancing the performance
of graph collaborative filtering (GCF) for personalized recommendation. Since
data augmentation plays a crucial role in the success of CL, previous works
have designed augmentation methods to remove noisy interactions between users
and items in order to generate effective augmented views. However, the
ambiguity in defining ''noisiness'' presents a persistent risk of losing core
information and generating unreliable data views, while increasing the overall
complexity of augmentation. In this paper, we propose Simple Collaborative
Augmentation for Recommendation (SCAR), a novel and intuitive augmentation
method designed to maximize the effectiveness of CL for GCF. Instead of
removing information, SCAR leverages collaborative signals extracted from
user-item interactions to generate pseudo-interactions, which are then either
added to or used to replace existing interactions. This results in more robust
representations while avoiding the pitfalls of overly complex augmentation
modules. We conduct experiments on four benchmark datasets and show that SCAR
outperforms previous CL-based GCF methods as well as other state-of-the-art
self-supervised learning approaches across key evaluation metrics. SCAR
exhibits strong robustness across different hyperparameter settings and is
particularly effective in sparse data scenarios.

</details>


### [4] [LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026](https://arxiv.org/abs/2511.00444)
*Benjamin Clavié,Xianming Li,Antoine Chaffin,Omar Khattab,Tom Aarsen,Manuel Faysse,Jing Li*

Main category: cs.IR

TL;DR: 本文介绍了延迟交互检索方法（以ColBERT为代表）的优势、挑战以及LIR研讨会的目标，旨在促进该领域研究者与从业者之间的交流与合作。


<details>
  <summary>Details</summary>
Motivation: 延迟交互检索方法在泛化性和鲁棒性方面表现出色，尤其适用于跨域、推理和跨模态检索等新场景，但存在效率、可用性和系统集成等挑战，且研究分散，缺乏实践者参与。

Method: 通过组织LIR研讨会，为研究者与从业者提供高度互动的环境，讨论延迟交互的各个方面，包括早期研究探索、实际应用成果以及负面或令人困惑的结果。

Result: 研讨会旨在促进跨社区合作，分享经验，推动延迟交互检索方法的发展与应用。

Conclusion: LIR研讨会为延迟交互检索领域的研究者和实践者提供了一个自由交流和协作的平台，有助于解决现有挑战并推动该技术的进一步发展。

Abstract: Late interaction retrieval methods, pioneered by ColBERT, have emerged as a
powerful alternative to single-vector neural IR. By leveraging fine-grained,
token-level representations, they have been demonstrated to deliver strong
generalisation and robustness, particularly in out-of-domain settings. They
have recently been shown to be particularly well-suited for novel use cases,
such as reasoning-based or cross-modality retrieval. At the same time, these
models pose significant challenges of efficiency, usability, and integrations
into fully fledged systems; as well as the natural difficulties encountered
while researching novel application domains. Recent years have seen rapid
advances across many of these areas, but research efforts remain fragmented
across communities and frequently exclude practitioners. The purpose of this
workshop is to create an environment where all aspects of late interaction can
be discussed, with a focus on early research explorations, real-world outcomes,
and negative or puzzling results to be freely shared and discussed. The aim of
LIR is to provide a highly-interactive environment for researchers from various
backgrounds and practitioners to freely discuss their experience, fostering
further collaboration.

</details>


### [5] [Listwise Preference Diffusion Optimization for User Behavior Trajectories Prediction](https://arxiv.org/abs/2511.00530)
*Hongtao Huang,Chengkai Huang,Junda Wu,Tong Yu,Julian McAuley,Lina Yao*

Main category: cs.IR

TL;DR: 提出LPDO框架，使用扩散模型优化列表式偏好，解决多步用户行为轨迹预测问题，在真实数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐方法无法捕捉序列项之间的全局列表依赖关系，限制了多步用户行为轨迹预测的能力。

Method: 引入Listwise Preference Diffusion Optimization (LPDO)，基于扩散模型的训练框架，结合Plackett-Luce监督信号和变分下界，优化整个物品序列的结构化偏好。

Result: 在真实用户行为基准测试中，LPDO持续优于最先进的基线方法，为扩散模型的结构化偏好学习设立了新基准。

Conclusion: LPDO通过直接优化结构化偏好，有效解决了多步用户行为轨迹预测问题，克服了现有扩散方法的独立token假设限制。

Abstract: Forecasting multi-step user behavior trajectories requires reasoning over
structured preferences across future actions, a challenge overlooked by
traditional sequential recommendation. This problem is critical for
applications such as personalized commerce and adaptive content delivery, where
anticipating a user's complete action sequence enhances both satisfaction and
business outcomes. We identify an essential limitation of existing paradigms:
their inability to capture global, listwise dependencies among sequence items.
To address this, we formulate User Behavior Trajectory Prediction (UBTP) as a
new task setting that explicitly models long-term user preferences. We
introduce Listwise Preference Diffusion Optimization (LPDO), a diffusion-based
training framework that directly optimizes structured preferences over entire
item sequences. LPDO incorporates a Plackett-Luce supervision signal and
derives a tight variational lower bound aligned with listwise ranking
likelihoods, enabling coherent preference generation across denoising steps and
overcoming the independent-token assumption of prior diffusion methods. To
rigorously evaluate multi-step prediction quality, we propose the task-specific
metric Sequential Match (SeqMatch), which measures exact trajectory agreement,
and adopt Perplexity (PPL), which assesses probabilistic fidelity. Extensive
experiments on real-world user behavior benchmarks demonstrate that LPDO
consistently outperforms state-of-the-art baselines, establishing a new
benchmark for structured preference learning with diffusion models.

</details>


### [6] [Structurally Refined Graph Transformer for Multimodal Recommendation](https://arxiv.org/abs/2511.00584)
*Ke Shi,Yan Zhang,Miao Zhang,Lifan Chen,Jiali Yi,Kui Xiao,Xiaoju Hou,Zhifei Li*

Main category: cs.IR

TL;DR: SRGFormer是一个结构优化的多模态推荐模型，通过改进Transformer捕获用户整体行为模式，使用超图结构增强局部结构学习，并通过自监督任务整合多模态信息，在三个公开数据集上超越基准模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推荐模型过度关注提取多模态信息而忽略冗余与有价值数据的区分，依赖单一语义框架导致用户偏好表示不完整，且无法捕捉用户与物品间的复杂交互关系。

Method: 改进Transformer以捕获用户整体行为模式；将多模态信息嵌入超图结构学习用户-物品局部结构；应用自监督任务增强多模态信息整合。

Result: 在三个公开数据集上的实验表明，SRGFormer超越先前基准模型，在Sports数据集上平均性能提升4.47%。

Conclusion: SRGFormer通过结构优化和多模态信息整合，有效解决了现有推荐模型的局限性，显著提升了推荐性能。

Abstract: Multimodal recommendation systems utilize various types of information,
including images and text, to enhance the effectiveness of recommendations. The
key challenge is predicting user purchasing behavior from the available data.
Current recommendation models prioritize extracting multimodal information
while neglecting the distinction between redundant and valuable data. They also
rely heavily on a single semantic framework (e.g., local or global semantics),
resulting in an incomplete or biased representation of user preferences,
particularly those less expressed in prior interactions. Furthermore, these
approaches fail to capture the complex interactions between users and items,
limiting the model's ability to meet diverse users. To address these
challenges, we present SRGFormer, a structurally optimized multimodal
recommendation model. By modifying the transformer for better integration into
our model, we capture the overall behavior patterns of users. Then, we enhance
structural information by embedding multimodal information into a hypergraph
structure to aid in learning the local structures between users and items.
Meanwhile, applying self-supervised tasks to user-item collaborative signals
enhances the integration of multimodal information, thereby revealing the
representational features inherent to the data's modality. Extensive
experiments on three public datasets reveal that SRGFormer surpasses previous
benchmark models, achieving an average performance improvement of 4.47 percent
on the Sports dataset. The code is publicly available online.

</details>


### [7] [Taxonomy-based Negative Sampling In Personalized Semantic Search for E-commerce](https://arxiv.org/abs/2511.00694)
*Uthman Jinadu,Siawpeng Er,Le Yu,Chen Liang,Bingxin Li,Yi Ding,Aleksandar Velkoski*

Main category: cs.IR

TL;DR: 提出了一种用于电子商务搜索的语义检索模型，通过共享向量空间嵌入查询和产品，采用基于分类的硬负采样策略，并整合用户个性化历史数据，显著提升了检索效果和商业指标。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以理解相似商品的细微差异，采样方法计算成本高或实施困难，且未考虑用户历史购买行为，导致检索结果不相关。

Method: 构建查询和产品的共享向量空间嵌入，采用基于分类的硬负采样策略挖掘上下文相关且具有挑战性的负样本，并整合用户历史购买行为进行个性化建模。

Result: 离线实验中在Recall@K指标上优于BM25、ANCE和主流神经基线模型；在线A/B测试显示转化率、加购率和客单价显著提升；基于分类的负采样减少了训练开销并加速收敛。

Conclusion: 该方法在电子商务搜索中有效提升了检索质量和商业价值，基于分类的负采样策略具有实用价值，并分享了大规模部署的实际经验。

Abstract: Large retail outlets offer products that may be domain-specific, and this
requires having a model that can understand subtle differences in similar
items. Sampling techniques used to train these models are most of the time,
computationally expensive or logistically challenging. These models also do not
factor in users' previous purchase patterns or behavior, thereby retrieving
irrelevant items for them. We present a semantic retrieval model for e-commerce
search that embeds queries and products into a shared vector space and
leverages a novel taxonomy-based hard-negative sampling(TB-HNS) strategy to
mine contextually relevant yet challenging negatives. To further tailor
retrievals, we incorporate user-level personalization by modeling each
customer's past purchase history and behavior. In offline experiments, our
approach outperforms BM25, ANCE and leading neural baselines on Recall@K, while
live A/B testing shows substantial uplifts in conversion rate, add-to-cart
rate, and average order value. We also demonstrate that our taxonomy-driven
negatives reduce training overhead and accelerate convergence, and we share
practical lessons from deploying this system at scale.

</details>


### [8] [REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval](https://arxiv.org/abs/2511.00805)
*Rishita Agarwal,Himanshu Singhal,Peter Baile Chen,Manan Roy Choudhury,Dan Roth,Vivek Gupta*

Main category: cs.IR

TL;DR: REAR是一个三阶段、无需LLM的多表检索框架，通过分离语义相关性和结构可连接性来提升复杂表格问答中的多表检索质量。


<details>
  <summary>Details</summary>
Motivation: 现有的检索器主要优化查询-表格相关性，但忽略了表格间的结构兼容性，导致在需要跨多个表格推理的自然语言查询中表现不佳。

Method: 采用三阶段框架：(1)检索查询相关的表格，(2)通过预计算的列嵌入比较扩展结构可连接的表格，(3)通过剪枝噪声或弱相关候选来精炼结果。

Result: 在BIRD、MMQA和Spider等复杂表格问答数据集上，REAR显著提升了密集/稀疏检索器的性能，在多表检索质量和下游SQL执行方面都有改进，且延迟和成本远低于LLM增强系统。

Conclusion: REAR作为一个实用、可扩展的构建模块，为基于表格的下游任务（如Text-to-SQL）提供了高效的多表检索解决方案，无需依赖大型语言模型即可达到竞争性性能。

Abstract: Answering natural language queries over relational data often requires
retrieving and reasoning over multiple tables, yet most retrievers optimize
only for query-table relevance and ignore table table compatibility. We
introduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework
that separates semantic relevance from structural joinability for efficient,
high-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables,
(ii) expands these with structurally joinable tables via fast, precomputed
column-embedding comparisons, and (iii) refines them by pruning noisy or weakly
related candidates. Empirically, REAR is retriever-agnostic and consistently
improves dense/sparse retrievers on complex table QA datasets (BIRD, MMQA, and
Spider) by improving both multi-table retrieval quality and downstream SQL
execution. Despite being LLM-free, it delivers performance competitive with
state-of-the-art LLM-augmented retrieval systems (e.g.,ARM) while achieving
much lower latency and cost. Ablations confirm complementary gains from
expansion and refinement, underscoring REAR as a practical, scalable building
block for table-based downstream tasks (e.g., Text-to-SQL).

</details>


### [9] [Controlling Gender Bias in Retrieval via a Backpack Architecture](https://arxiv.org/abs/2511.00875)
*Amirabbas Afzali,Amirreza Velae,Iman Ahmadi,Mohammad Aliannejadi*

Main category: cs.IR

TL;DR: 提出了一种基于Backpack语言模型的去偏框架，用于减轻文本检索和排序任务中的性别偏见，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的社会偏见会传播有害刻板印象并扭曲决策过程，当集成到排序系统中时会导致不公平结果。

Method: 利用Backpack语言模型的架构特性，该模型通过非上下文学习的词方面（senses）的加权组合生成输出，构建去偏框架。

Result: 实验结果显示该框架能有效减轻文本检索和排序中的性别偏见，且性能下降最小。

Conclusion: 基于Backpack语言模型的去偏框架为解决LLM在排序系统中的偏见问题提供了有效方案。

Abstract: The presence of social biases in large language models (LLMs) has become a
significant concern in AI research. These biases, often embedded in training
data, can perpetuate harmful stereotypes and distort decision-making processes.
When LLMs are integrated into ranking systems, they can propagate these biases,
leading to unfair outcomes in critical applications such as search engines and
recommendation systems. Backpack Language Models, unlike traditional
transformer-based models that treat text sequences as monolithic structures,
generate outputs as weighted combinations of non-contextual, learned word
aspects, also known as senses. Leveraging this architecture, we propose a
framework for debiasing ranking tasks. Our experimental results show that this
framework effectively mitigates gender bias in text retrieval and ranking with
minimal degradation in performance.

</details>


### [10] [Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking](https://arxiv.org/abs/2511.01208)
*Jerry Huang,Siddarth Madala,Cheng Niu,Julia Hockenmaier,Tong Zhang*

Main category: cs.IR

TL;DR: 提出上下文相关性概念和TS-SetRank算法，通过考虑文档批次组合和排序位置来改进需要深度推理查询的文档重排序效果


<details>
  <summary>Details</summary>
Motivation: 当前重排序算法在处理需要深度推理的查询时面临挑战，这类查询具有多面性信息需求和细微解释，文档相关性高度依赖于上下文环境

Method: 提出上下文相关性定义，开发TS-SetRank算法——一种基于采样的不确定性感知重排序方法，同时考虑文档批次组合和排序位置

Result: 在BRIGHT数据集上nDCG@10提升15-25%，在BEIR数据集上提升6-21%，显著优于现有检索和重排序基线

Conclusion: 建模上下文依赖的相关性对改进重排序性能至关重要，文档批次组合与排序位置都显著影响重排序效果

Abstract: Reranking algorithms have made progress in improving document retrieval
quality by efficiently aggregating relevance judgments generated by large
language models (LLMs). However, identifying relevant documents for queries
that require in-depth reasoning remains a major challenge. Reasoning-intensive
queries often exhibit multifaceted information needs and nuanced
interpretations, rendering document relevance inherently context dependent. To
address this, we propose contextual relevance, which we define as the
probability that a document is relevant to a given query, marginalized over the
distribution of different reranking contexts it may appear in (i.e., the set of
candidate documents it is ranked alongside and the order in which the documents
are presented to a reranking model). While prior works have studied methods to
mitigate the positional bias LLMs exhibit by accounting for the ordering of
documents, we empirically find that the compositions of these batches also
plays an important role in reranking performance. To efficiently estimate
contextual relevance, we propose TS-SetRank, a sampling-based,
uncertainty-aware reranking algorithm. Empirically, TS-SetRank improves nDCG@10
over retrieval and reranking baselines by 15-25% on BRIGHT and 6-21% on BEIR,
highlighting the importance of modeling relevance as context-dependent.

</details>


### [11] [A semantic-based deep learning approach for mathematical expression retrieval](https://arxiv.org/abs/2511.01364)
*Pavan Kumar Perepu*

Main category: cs.IR

TL;DR: 提出了一种使用深度循环神经网络(DRNN)从数学表达式中提取语义特征的方法，用于基于语义相似性的数学表达式检索。


<details>
  <summary>Details</summary>
Motivation: 传统的数学表达式检索方法基于字符串匹配和向量空间模型，主要关注语法相似性，缺乏对语义相似性的考虑。

Method: 使用DRNN训练数学表达式复杂度分类任务（简单、中等、复杂三类），提取网络最后一层全连接层之前的输出作为语义特征，然后基于欧几里得距离进行匹配检索。

Result: 在包含829个数学表达式的数据库上验证了该方法的有效性。

Conclusion: 基于深度学习的语义特征提取方法能够有效实现数学表达式的语义相似性检索。

Abstract: Mathematical expressions (MEs) have complex two-dimensional structures in
which symbols can be present at any nested depth like superscripts, subscripts,
above, below etc. As MEs are represented using LaTeX format, several text
retrieval methods based on string matching, vector space models etc., have also
been applied for ME retrieval problem in the literature. As these methods are
based on syntactic similarity, recently deep learning approaches based on
embedding have been used for semantic similarity. In our present work, we have
focused on the retrieval of mathematical expressions using deep learning
approaches. In our approach, semantic features are extracted from the MEs using
a deep recurrent neural network (DRNN) and these features have been used for
matching and retrieval. We have trained the network for a classification task
which determines the complexity of an ME. ME complexity has been quantified in
terms of its nested depth. Based on the nested depth, we have considered three
complexity classes of MEs: Simple, Medium and Complex. After training the
network, outputs just before the the final fully connected layer are extracted
for all the MEs. These outputs form the semantic features of MEs and are stored
in a database. For a given ME query, its semantic features are computed using
the trained DRNN and matched against the semantic feature database. Matching is
performed based on the standard euclidean distance and top 'k' nearest matches
are retrieved, where 'k' is a user-defined parameter. Our approach has been
illustrated on a database of 829 MEs.

</details>


### [12] [A Soft-partitioned Semi-supervised Collaborative Transfer Learning Approach for Multi-Domain Recommendation](https://arxiv.org/abs/2511.01404)
*Xiaoyu Liu,Yiqing Wu,Ruidong Han,Fuzhen Zhuang,Xiang Li,Wei Lin*

Main category: cs.IR

TL;DR: 提出SSCTL方法解决多领域推荐中的领域数据不平衡问题，通过动态参数和伪标签增强技术改善非主导领域的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 工业多领域推荐面临数据不平衡问题：主导领域数据压倒模型性能，非主导领域数据稀疏导致过拟合。

Method: SSCTL方法包含动态参数生成解决压倒性问题，利用主导领域实例的带权重伪标签增强非主导领域数据。

Result: 在线测试显示各领域GMV提升0.54%-2.90%，CTR提升0.22%-1.69%。

Conclusion: SSCTL能有效解决多领域推荐中的数据不平衡问题，显著提升各领域推荐效果。

Abstract: In industrial practice, Multi-domain Recommendation (MDR) plays a crucial
role. Shared-specific architectures are widely used in industrial solutions to
capture shared and unique attributes via shared and specific parameters.
However, with imbalanced data across different domains, these models face two
key issues: (1) Overwhelming: Dominant domain data skews model performance,
neglecting non-dominant domains. (2) Overfitting: Sparse data in non-dominant
domains leads to overfitting in specific parameters. To tackle these
challenges, we propose Soft-partitioned Semi-supervised Collaborative Transfer
Learning (SSCTL) for multi-domain recommendation. SSCTL generates dynamic
parameters to address the overwhelming issue, thus shifting focus towards
samples from non-dominant domains. To combat overfitting, it leverages
pseudo-labels with weights from dominant domain instances to enhance
non-dominant domain data. We conduct comprehensive experiments, both online and
offline, to validate the efficacy of our proposed method. Online tests yielded
significant improvements across various domains, with increases in GMV ranging
from 0.54% to 2.90% and enhancements in CTR ranging from 0.22% to 1.69%.

</details>


### [13] [LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning](https://arxiv.org/abs/2511.01448)
*Zhengjun Huang,Zhoujin Tian,Qintian Guo,Fangyuan Zhang,Yingli Zhou,Di Jiang,Xiaofang Zhou*

Main category: cs.IR

TL;DR: LiCoMemory是一个端到端的智能体记忆框架，通过引入CogniGraph层次图结构，使用实体和关系作为语义索引层，结合时间和层次感知搜索，解决了传统图记忆结构中语义与拓扑纠缠导致的冗余表示和无结构检索问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体虽然具备出色的对话和推理能力，但受到有限上下文窗口和缺乏持久记忆的限制。现有的外部记忆架构大多采用平面、纠缠的结构，将语义与拓扑交织在一起，导致表示冗余、检索无结构，以及效率和准确性的下降。

Method: 提出LiCoMemory框架，引入CogniGraph轻量级层次图，使用实体和关系作为语义索引层，采用时间和层次感知搜索，并结合重排序实现自适应和连贯的知识检索。

Result: 在长期对话基准测试LoCoMo和LongMemEval上，LiCoMemory在时间推理、多会话一致性和检索效率方面优于现有基线方法，同时显著降低了更新延迟。

Conclusion: LiCoMemory通过层次化图结构和语义索引层，有效解决了传统记忆架构中的表示冗余和检索效率问题，为LLM智能体提供了更高效、准确的持久记忆能力。

Abstract: Large Language Model (LLM) agents exhibit remarkable conversational and
reasoning capabilities but remain constrained by limited context windows and
the lack of persistent memory. Recent efforts address these limitations via
external memory architectures, often employing graph-based representations, yet
most adopt flat, entangled structures that intertwine semantics with topology,
leading to redundant representations, unstructured retrieval, and degraded
efficiency and accuracy. To resolve these issues, we propose LiCoMemory, an
end-to-end agentic memory framework for real-time updating and retrieval, which
introduces CogniGraph, a lightweight hierarchical graph that utilizes entities
and relations as semantic indexing layers, and employs temporal and
hierarchy-aware search with integrated reranking for adaptive and coherent
knowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and
LongMemEval, show that LiCoMemory not only outperforms established baselines in
temporal reasoning, multi-session consistency, and retrieval efficiency, but
also notably reduces update latency. Our official code and data are available
at https://github.com/EverM0re/LiCoMemory.

</details>


### [14] [CAT-ID$^2$: Category-Tree Integrated Document Identifier Learning for Generative Retrieval In E-commerce](https://arxiv.org/abs/2511.01461)
*Xiaoyu Liu,Fuwei Zhang,Yiqing Wu,Xinyu Jia,Zenghua Xia,Fuzhen Zhuang,Zhao Zhang,Fei Jiang,Wei Lin*

Main category: cs.IR

TL;DR: 提出CAT-ID²方法，将类别信息融入文档语义标识符生成，通过分层类别约束、聚类尺度约束和分散损失三个模块，提升生成检索中文档ID的表征能力。


<details>
  <summary>Details</summary>
Motivation: 现有生成检索方法大多忽略电商场景中常见的原生类别信息，而这些信息对文档标识符的表征能力至关重要。好的文档ID应具备相似文档ID相似、不同文档ID独特的特性。

Method: CAT-ID²包含三个核心模块：分层类别约束损失（逐层整合类别信息）、聚类尺度约束损失（均匀分布ID令牌）、分散损失（提升重构文档区分度）。

Result: 离线和在线实验验证了方法的有效性，在线A/B测试显示模糊意图查询的千用户平均订单数提升0.33%，长尾查询提升0.24%。

Conclusion: CAT-ID²通过整合类别信息成功提升了文档语义标识符的表征能力，在电商检索场景中取得了显著效果提升。

Abstract: Generative retrieval (GR) has gained significant attention as an effective
paradigm that integrates the capabilities of large language models (LLMs). It
generally consists of two stages: constructing discrete semantic identifiers
(IDs) for documents and retrieving documents by autoregressively generating ID
tokens.The core challenge in GR is how to construct document IDs (DocIDS) with
strong representational power. Good IDs should exhibit two key properties:
similar documents should have more similar IDs, and each document should
maintain a distinct and unique ID.However, most existing methods ignore native
category information, which is common and critical in E-commerce. Therefore, we
propose a novel ID learning method, CAtegory-Tree Integrated Document
IDentifier (CAT-ID$^2$), incorporating prior category information into the
semantic IDs.CAT-ID$^2$ includes three key modules: a Hierarchical Class
Constraint Loss to integrate category information layer by layer during
quantization, a Cluster Scale Constraint Loss for uniform ID token
distribution, and a Dispersion Loss to improve the distinction of reconstructed
documents. These components enable CAT-ID$^2$ to generate IDs that make similar
documents more alike while preserving the uniqueness of different documents'
representations.Extensive offline and online experiments confirm the
effectiveness of our method, with online A/B tests showing a 0.33% increase in
average orders per thousand users for ambiguous intent queries and 0.24% for
long-tail queries.

</details>


### [15] [Trove: A Flexible Toolkit for Dense Retrieval](https://arxiv.org/abs/2511.01857)
*Reza Esfandiarpoor,Max Zuo,Stephen H. Bach*

Main category: cs.IR

TL;DR: Trove是一个易于使用的开源检索工具包，简化研究实验而不牺牲灵活性或速度，提供高效的数据管理功能和高度可定制性。


<details>
  <summary>Details</summary>
Motivation: 为了解决检索实验中数据管理复杂、内存消耗大、缺乏灵活性等问题，使研究人员能够轻松进行实验和探索性研究。

Method: 引入动态数据管理功能，支持过滤、选择、转换和组合检索数据集；提供高度可定制的组件和低代码统一评估流程；支持多节点执行。

Result: 数据管理功能将内存消耗减少2.6倍；推理管道无开销且推理时间随节点数线性减少；简化了检索实验并支持任意定制。

Conclusion: Trove通过简化实验流程和提供高度定制能力，有效促进了检索领域的探索性研究。

Abstract: We introduce Trove, an easy-to-use open-source retrieval toolkit that
simplifies research experiments without sacrificing flexibility or speed. For
the first time, we introduce efficient data management features that load and
process (filter, select, transform, and combine) retrieval datasets on the fly,
with just a few lines of code. This gives users the flexibility to easily
experiment with different dataset configurations without the need to compute
and store multiple copies of large datasets. Trove is highly customizable: in
addition to many built-in options, it allows users to freely modify existing
components or replace them entirely with user-defined objects. It also provides
a low-code and unified pipeline for evaluation and hard negative mining, which
supports multi-node execution without any code changes. Trove's data management
features reduce memory consumption by a factor of 2.6. Moreover, Trove's
easy-to-use inference pipeline incurs no overhead, and inference times decrease
linearly with the number of available nodes. Most importantly, we demonstrate
how Trove simplifies retrieval experiments and allows for arbitrary
customizations, thus facilitating exploratory research.

</details>
