<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 29]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [MTMD: A Multi-Task Multi-Domain Framework for Unified Ad Lightweight Ranking at Pinterest](https://arxiv.org/abs/2510.09857)
*Xiao Yang,Peifeng Yin,Abe Engle,Jinfeng Zhuang,Ling Leng*

Main category: cs.IR

TL;DR: 提出了一种多任务多领域（MTMD）架构，用于轻量级广告排序层的联合优化，通过专家混合架构和领域适应模块实现跨领域知识共享与迁移。


<details>
  <summary>Details</summary>
Motivation: 解决广告推荐系统中多优化任务（如CTR、CVR）、多广告产品（购物广告、标准广告）和多投放场景（首页、搜索、相关推荐）的联合优化问题，最大化平台、广告主和用户价值。

Method: 基于双塔范式构建MTMD架构，采用专家混合架构学习领域专业知识和共享知识，引入领域适应模块促进专家间知识迁移，并对不同预测任务进行约束建模。

Result: 离线损失值降低12%-36%，对应在线每次点击成本减少2%，已部署到生产环境替代9个生产模型。

Conclusion: MTMD框架成功统一了多任务多领域的广告推荐优化，通过知识共享和迁移显著提升了系统性能。

Abstract: The lightweight ad ranking layer, living after the retrieval stage and before
the fine ranker, plays a critical role in the success of a cascaded ad
recommendation system. Due to the fact that there are multiple optimization
tasks depending on the ad domain, e.g., Click Through Rate (CTR) for click ads
and Conversion Rate (CVR) for conversion ads, as well as multiple surfaces
where an ad is served (home feed, search, or related item recommendation) with
diverse ad products (shopping or standard ad); it is an essentially challenging
problem in industry on how to do joint holistic optimization in the lightweight
ranker, such that the overall platform's value, advertiser's value, and user's
value are maximized.
  Deep Neural Network (DNN)-based multitask learning (MTL) can handle multiple
goals naturally, with each prediction head mapping to a particular optimization
goal. However, in practice, it is unclear how to unify data from different
surfaces and ad products into a single model. It is critical to learn
domain-specialized knowledge and explicitly transfer knowledge between domains
to make MTL effective. We present a Multi-Task Multi-Domain (MTMD) architecture
under the classic Two-Tower paradigm, with the following key contributions: 1)
handle different prediction tasks, ad products, and ad serving surfaces in a
unified framework; 2) propose a novel mixture-of-expert architecture to learn
both specialized knowledge each domain and common knowledge shared between
domains; 3) propose a domain adaption module to encourage knowledge transfer
between experts; 4) constrain the modeling of different prediction tasks. MTMD
improves the offline loss value by 12% to 36%, mapping to 2% online reduction
in cost per click. We have deployed this single MTMD framework into production
for Pinterest ad recommendation replacing 9 production models.

</details>


### [2] [PairSem: LLM-Guided Pairwise Semantic Matching for Scientific Document Retrieval](https://arxiv.org/abs/2510.09897)
*Wonbin Kweon,Runchu Tian,SeongKu Kang,Pengcheng Jiang,Zhiyong Lu,Jiawei Han,Hwanjo Yu*

Main category: cs.IR

TL;DR: 提出了Pairwise Semantic Matching (PairSem)框架，通过实体-方面对表示相关语义，捕捉复杂多方面的科学概念，显著提升科学文档检索性能


<details>
  <summary>Details</summary>
Motivation: 现有密集检索方法难以捕捉文本中的细粒度科学概念，因为它们依赖整体嵌入且领域理解有限。虽然最近方法利用LLM提取细粒度语义实体，但通常将实体视为独立片段，忽略了科学概念的多方面性质

Method: 提出PairSem框架，将相关语义表示为实体-方面对，捕捉复杂多方面的科学概念。该框架是无监督的、基础检索器无关的、即插即用的，无需查询-文档标签或实体标注

Result: 在多个数据集和检索器上的广泛实验表明，PairSem显著提高了检索性能

Conclusion: 证明了在科学信息检索中建模多方面语义的重要性

Abstract: Scientific document retrieval is a critical task for enabling knowledge
discovery and supporting research across diverse domains. However, existing
dense retrieval methods often struggle to capture fine-grained scientific
concepts in texts due to their reliance on holistic embeddings and limited
domain understanding. Recent approaches leverage large language models (LLMs)
to extract fine-grained semantic entities and enhance semantic matching, but
they typically treat entities as independent fragments, overlooking the
multi-faceted nature of scientific concepts. To address this limitation, we
propose Pairwise Semantic Matching (PairSem), a framework that represents
relevant semantics as entity-aspect pairs, capturing complex, multi-faceted
scientific concepts. PairSem is unsupervised, base retriever-agnostic, and
plug-and-play, enabling precise and context-aware matching without requiring
query-document labels or entity annotations. Extensive experiments on multiple
datasets and retrievers demonstrate that PairSem significantly improves
retrieval performance, highlighting the importance of modeling multi-aspect
semantics in scientific information retrieval.

</details>


### [3] [CardRewriter: Leveraging Knowledge Cards for Long-Tail Query Rewriting on Short-Video Platforms](https://arxiv.org/abs/2510.10095)
*Peiyuan Gong,Feiran Zhu,Yaqi Yin,Chenglei Dai,Chao Zhang,Kai Zheng,Wentian Bao,Jiaxin Mao,Yi Zhang*

Main category: cs.IR

TL;DR: CardRewriter是一个基于LLM的框架，通过整合短视频平台特定领域知识来改进长尾查询重写，显著提升了查询相关性和检索效果。


<details>
  <summary>Details</summary>
Motivation: 短视频平台用户查询存在拼写错误、表述不完整和意图模糊等问题，导致检索结果与用户期望不匹配。传统LLM在短视频平台专有内容上表现不佳，因为这些内容不在其训练分布中。

Method: 为每个查询聚合多源相关知识并总结成信息丰富的知识卡片，用该卡片指导LLM更好地捕捉用户意图。采用两阶段训练流程：监督微调后接组相对策略优化，并设计平衡查询相关性和检索效果的奖励系统。

Result: 离线实验显示CardRewriter显著提升专有内容查询的重写质量。在线A/B测试证实长观看率和点击率显著提升，同时主动查询重构率明显降低。

Conclusion: CardRewriter自2025年9月起已在快手平台部署，每日为数亿用户提供服务，有效解决了短视频平台长尾查询重写问题。

Abstract: Short-video platforms have rapidly become a new generation of information
retrieval systems, where users formulate queries to access desired videos.
However, user queries, especially long-tail ones, often suffer from spelling
errors, incomplete phrasing, and ambiguous intent, resulting in mismatches
between user expectations and retrieved results. While large language models
(LLMs) have shown success in long-tail query rewriting within e-commerce, they
struggle on short-video platforms, where proprietary content such as short
videos, live streams, micro dramas, and user social networks falls outside
their training distribution. To address this challenge, we introduce
\textbf{CardRewriter}, an LLM-based framework that incorporates domain-specific
knowledge to enhance long-tail query rewriting. For each query, our method
aggregates multi-source knowledge relevant to the query and summarizes it into
an informative and query-relevant knowledge card. This card then guides the LLM
to better capture user intent and produce more effective query rewrites. We
optimize CardRewriter using a two-stage training pipeline: supervised
fine-tuning followed by group relative policy optimization, with a tailored
reward system balancing query relevance and retrieval effectiveness. Offline
experiments show that CardRewriter substantially improves rewriting quality for
queries targeting proprietary content. Online A/B testing further confirms
significant gains in long-view rate (LVR) and click-through rate (CTR), along
with a notable reduction in initiative query reformulation rate (IQRR). Since
September 2025, CardRewriter has been deployed on Kuaishou, one of China's
largest short-video platforms, serving hundreds of millions of users daily.

</details>


### [4] [Integrating Structure-Aware Attention and Knowledge Graphs in Explainable Recommendation Systems](https://arxiv.org/abs/2510.10109)
*Shuangquan Lyu,Ming Wang,Huajun Zhang,Jiasen Zheng,Junjiang Lin,Xiaoxuan Sun*

Main category: cs.IR

TL;DR: 提出了一种结合知识图谱和结构感知注意力机制的可解释推荐模型，通过图神经网络和多跳邻居聚合策略，动态分配邻居重要性以捕捉隐式偏好关系。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统难以捕捉用户和物品间的复杂隐式关系，需要结合知识图谱的结构信息来提升推荐效果和可解释性。

Method: 将用户和物品嵌入统一图结构，基于知识图谱实体和关系构建多级语义路径，使用结构感知注意力机制动态分配邻居重要性，通过用户-目标物品表示交互生成推荐。

Result: 在Amazon Books数据集上的实验表明，该模型在各项评估指标上表现优异，具有良好的收敛性和稳定性。

Conclusion: 结构感知注意力机制在知识图谱增强推荐中具有显著的有效性和实用性，能够提升推荐性能和可解释性。

Abstract: This paper designs and implements an explainable recommendation model that
integrates knowledge graphs with structure-aware attention mechanisms. The
model is built on graph neural networks and incorporates a multi-hop neighbor
aggregation strategy. By integrating the structural information of knowledge
graphs and dynamically assigning importance to different neighbors through an
attention mechanism, the model enhances its ability to capture implicit
preference relationships. In the proposed method, users and items are embedded
into a unified graph structure. Multi-level semantic paths are constructed
based on entities and relations in the knowledge graph to extract richer
contextual information. During the rating prediction phase, recommendations are
generated through the interaction between user and target item representations.
The model is optimized using a binary cross-entropy loss function. Experiments
conducted on the Amazon Books dataset validate the superior performance of the
proposed model across various evaluation metrics. The model also shows good
convergence and stability. These results further demonstrate the effectiveness
and practicality of structure-aware attention mechanisms in knowledge
graph-enhanced recommendation.

</details>


### [5] [Breaking the Likelihood Trap: Consistent Generative Recommendation with Graph-structured Model](https://arxiv.org/abs/2510.10127)
*Qiya Yang,Xiaoxi Liang,Zeping Xiao,Yingjie Deng,Yalong Wang,Yongqi Liu,Han Li*

Main category: cs.IR

TL;DR: 提出Congrats框架解决生成式重排序中的"似然陷阱"问题，通过图结构解码器捕获多样化序列，提升推荐多样性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法存在"似然陷阱"，高似然序列往往质量低，导致重复推荐高频项目，造成列表同质化，限制用户参与度。

Method: 设计图结构解码器捕获多路径多样化序列，扩展解码空间；构建可微分级联系统包含评估器，直接从用户偏好学习训练目标。

Result: 离线实验显示优于最先进重排序方法；在快手3亿日活用户的大规模评估中，显著提升推荐质量和多样性。

Conclusion: Congrats框架有效解决生成式重排序的多样性问题，在工业环境中验证了其有效性。

Abstract: Reranking, as the final stage of recommender systems, demands real-time
inference, accuracy, and diversity. It plays a crucial role in determining the
final exposure, directly influencing user experience. Recently, generative
reranking has gained increasing attention for its strong ability to model
complex dependencies among items. However, most existing methods suffer from
the "likelihood trap", where high-likelihood sequences are often perceived as
low-quality by humans. These models tend to repeatedly recommend a set of
high-frequency items, resulting in list homogeneity, thereby limiting user
engagement. In this work, we propose Consistent Graph-structured Generative
Recommendation (Congrats), a novel generative reranking framework. To break the
likelihood trap, we introduce a novel graph-structured decoder that can capture
diverse sequences along multiple paths. This design not only expands the
decoding space to promote diversity, but also improves prediction accuracy by
implicit item dependencies derived from vertex transitions. Furthermore, we
design a differentiable cascade system that incorporates an evaluator, enabling
the model to learn directly from user preferences as the training objective.
Extensive offline experiments validate the superior performance of Congrats
over state-of-the-art reranking methods. Moreover, Congrats has been evaluated
on a large-scale video-sharing app, Kuaishou, with over 300 million daily
active users, demonstrating that our approach significantly improves both
recommendation quality and diversity, validating our effectiveness in practical
industrial environments.

</details>


### [6] [ZeroGR: A Generalizable and Scalable Framework for Zero-Shot Generative Retrieval](https://arxiv.org/abs/2510.10419)
*Weiwei Sun,Keyi Kong,Xinyu Ma,Shuaiqiang Wang,Dawei Yin,Maarten de Rijke,Zhaochun Ren,Yiming Yang*

Main category: cs.IR

TL;DR: ZeroGR是一个零样本生成式检索框架，通过自然语言指令将生成式检索扩展到各种信息检索任务，在零样本设置下优于密集检索和生成式基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式检索在监督训练下取得进展，但在现实应用中常见的零样本检索场景中仍难以泛化。

Method: 包含三个关键组件：基于语言模型的文档ID生成器、指令调优的查询生成器，以及平衡精度和召回率的反向退火解码策略。

Result: 在BEIR和MAIR基准测试中，ZeroGR在零样本设置下优于强基线方法，建立了指令驱动生成式检索的新SOTA。

Conclusion: 通过指令微调规模的扩展，性能持续提升，证明了指令驱动方法在零样本生成式检索中的有效性。

Abstract: Generative retrieval (GR) reformulates information retrieval (IR) by framing
it as the generation of document identifiers (docids), thereby enabling an
end-to-end optimization and seamless integration with generative language
models (LMs). Despite notable progress under supervised training, GR still
struggles to generalize to zero-shot IR scenarios, which are prevalent in
real-world applications. To tackle this challenge, we propose \textsc{ZeroGR},
a zero-shot generative retrieval framework that leverages natural language
instructions to extend GR across a wide range of IR tasks. Specifically,
\textsc{ZeroGR} is composed of three key components: (i) an LM-based docid
generator that unifies heterogeneous documents (e.g., text, tables, code) into
semantically meaningful docids; (ii) an instruction-tuned query generator that
generates diverse types of queries from natural language task descriptions to
enhance corpus indexing; and (iii) a reverse annealing decoding strategy to
balance precision and recall during docid generation. We investigate the impact
of instruction fine-tuning scale and find that performance consistently
improves as the number of IR tasks encountered during training increases.
Empirical results on the BEIR and MAIR benchmarks demonstrate that
\textsc{ZeroGR} outperforms strong dense retrieval and generative baselines in
zero-shot settings, establishing a new state-of-the-art for instruction-driven
GR.

</details>


### [7] [Does Weighting Improve Matrix Factorization for Recommender Systems?](https://arxiv.org/abs/2510.10440)
*Alex Ayoub,Samuel Robertson,Dawen Liang,Harald Steck,Nathan Kallus*

Main category: cs.IR

TL;DR: 研究发现，在隐式反馈数据的矩阵分解推荐系统中，未加权训练的表现与加权训练相当甚至更好，特别是在大模型中，这挑战了传统认知。


<details>
  <summary>Details</summary>
Motivation: 研究矩阵分解在隐式反馈数据中常用的加权策略是否总是有效，以及不同加权方案与算法之间的相互作用。

Method: 系统研究各种加权方案和矩阵分解算法，包括推导几种加权目标函数的高效精确最小化算法。

Result: 未加权数据训练的表现与加权训练相当甚至更好，特别是在大模型中；但在低容量模型和特定正则化方案中，加权仍有优势。

Conclusion: 权重策略、正则化和模型容量之间存在复杂相互作用，为推荐系统中的矩阵分解提供了全面分析框架。

Abstract: Matrix factorization is a widely used approach for top-N recommendation and
collaborative filtering. When implemented on implicit feedback data (such as
clicks), a common heuristic is to upweight the observed interactions. This
strategy has been shown to improve performance for certain algorithms. In this
paper, we conduct a systematic study of various weighting schemes and matrix
factorization algorithms. Somewhat surprisingly, we find that training with
unweighted data can perform comparably to, and sometimes outperform, training
with weighted data, especially for large models. This observation challenges
the conventional wisdom. Nevertheless, we identify cases where weighting can be
beneficial, particularly for models with lower capacity and specific
regularization schemes. We also derive efficient algorithms for exactly
minimizing several weighted objectives that were previously considered
computationally intractable. Our work provides a comprehensive analysis of the
interplay between weighting, regularization, and model capacity in matrix
factorization for recommender systems.

</details>


### [8] [Towards Long-Term User Welfare in Recommender Systems via Creator-Oriented Information Revelation](https://arxiv.org/abs/2510.10511)
*Xu Zhao,Xiaopeng Ye,Chen Xu,Weiran Shen,Jun Xu*

Main category: cs.IR

TL;DR: 提出LoRe框架，通过信息揭示而非重新排序算法来优化推荐系统的长期用户福利，使用贝叶斯劝说方法将平台作为发送者、创作者作为接收者，通过MDP建模解决传统经济方法假设不现实的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于重新排序的方法在提升长期用户福利时与短期推荐准确性目标冲突，导致性能下降。受经济学研究启发，通过信息揭示可以更有效地引导创作者行为，从而优化推荐系统生态系统。

Method: 提出LoRe框架，使用贝叶斯劝说作为信息揭示方法，将信息揭示过程建模为马尔可夫决策过程，并设计学习算法在有界理性创作者环境中进行训练和推理。

Result: 在两个真实世界推荐系统数据集上的实验表明，该方法在提升长期用户福利方面优于现有的公平重新排序方法和信息揭示策略。

Conclusion: LoRe框架通过信息揭示有效解决了长期福利优化问题，避免了与短期目标的冲突，为推荐系统生态系统健康提供了新思路。

Abstract: Improving the long-term user welfare (e.g., sustained user engagement) has
become a central objective of recommender systems (RS). In real-world
platforms, the creation behaviors of content creators plays a crucial role in
shaping long-term welfare beyond short-term recommendation accuracy, making the
effective steering of creator behavior essential to foster a healthier RS
ecosystem. Existing works typically rely on re-ranking algorithms that
heuristically adjust item exposure to steer creators' behavior. However, when
embedded within recommendation pipelines, such a strategy often conflicts with
the short-term objective of improving recommendation accuracy, leading to
performance degradation and suboptimal long-term welfare. The well-established
economics studies offer us valuable insights for an alternative approach
without relying on recommendation algorithmic design: revealing information
from an information-rich party (sender) to a less-informed party (receiver) can
effectively change the receiver's beliefs and steer their behavior. Inspired by
this idea, we propose an information-revealing framework, named Long-term
Welfare Optimization via Information Revelation (LoRe). In this framework, we
utilize a classical information revelation method (i.e., Bayesian persuasion)
to map the stakeholders in RS, treating the platform as the sender and creators
as the receivers. To address the challenge posed by the unrealistic assumption
of traditional economic methods, we formulate the process of information
revelation as a Markov Decision Process (MDP) and propose a learning algorithm
trained and inferred in environments with boundedly rational creators.
Extensive experiments on two real-world RS datasets demonstrate that our method
can effectively outperform existing fair re-ranking methods and information
revealing strategies in improving long-term user welfare.

</details>


### [9] [Self-Supervised Representation Learning with ID-Content Modality Alignment for Sequential Recommendation](https://arxiv.org/abs/2510.10556)
*Donglin Zhou,Weike Pan,Zhong Ming*

Main category: cs.IR

TL;DR: 提出SICSRec模型，通过自监督表示学习和ID-内容模态对齐来解决内容序列推荐中的三大挑战：模态语义差距、行为与内容偏好联合建模、ID与内容表示对齐训练策略。


<details>
  <summary>Details</summary>
Motivation: 传统基于ID的序列推荐在交互历史有限时性能不佳，而现有内容推荐方法面临模态语义差距、偏好联合建模和表示对齐三大挑战。

Method: 1. LLM驱动的样本构建和监督微调对齐项目级模态表示；2. 基于Transformer的三模块架构：ID模态序列编码器、内容模态序列编码器和混合模态序列解码器；3. 两步训练策略和内容感知对比学习任务。

Result: 在四个公共视频流数据集上，SICSRec相比最先进的ID模态和内容模态序列推荐器，NDCG@5平均提升8.04%，NDCG@10平均提升6.62%。

Conclusion: SICSRec通过有效的模态对齐和联合建模方法，显著提升了序列推荐性能，特别是在交互历史有限的情况下。

Abstract: Sequential recommendation (SR) models often capture user preferences based on
the historically interacted item IDs, which usually obtain sub-optimal
performance when the interaction history is limited. Content-based sequential
recommendation has recently emerged as a promising direction that exploits
items' textual and visual features to enhance preference learning. However,
there are still three key challenges: (i) how to reduce the semantic gap
between different content modality representations; (ii) how to jointly model
user behavior preferences and content preferences; and (iii) how to design an
effective training strategy to align ID representations and content
representations. To address these challenges, we propose a novel model,
self-supervised representation learning with ID-Content modality alignment,
named SICSRec. Firstly, we propose a LLM-driven sample construction method and
develop a supervised fine-tuning approach to align item-level modality
representations. Secondly, we design a novel Transformer-based sequential
model, where an ID-modality sequence encoder captures user behavior
preferences, a content-modality sequence encoder learns user content
preferences, and a mix-modality sequence decoder grasps the intrinsic
relationship between these two types of preferences. Thirdly, we propose a
two-step training strategy with a content-aware contrastive learning task to
align modality representations and ID representations, which decouples the
training process of content modality dependency and item collaborative
dependency. Extensive experiments conducted on four public video streaming
datasets demonstrate our SICSRec outperforms the state-of-the-art ID-modality
sequential recommenders and content-modality sequential recommenders by 8.04%
on NDCG@5 and 6.62% on NDCD@10 on average, respectively.

</details>


### [10] [Multi-Granularity Sequence Denoising with Weakly Supervised Signal for Sequential Recommendation](https://arxiv.org/abs/2510.10564)
*Liang Li,Zhou Yang,Xiaofei Zhu*

Main category: cs.IR

TL;DR: 提出MGSD-WSS方法，通过多粒度序列去噪和弱监督信号解决序列推荐中的噪声问题，在五个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史交互序列常包含无关噪声项，现有无监督方法缺乏显式噪声标签，容易误判用户兴趣项为噪声，且只关注项粒度噪声而忽略兴趣粒度噪声。

Method: 使用多高斯核感知器模块映射序列到共同表示空间，利用弱监督信号识别噪声项；通过噪声加权对比学习获得去噪项表示；从真实项提取目标兴趣表示并去噪；基于去噪表示预测下一项。

Result: 在五个数据集上的广泛实验表明，该方法显著优于最先进的序列推荐和去噪模型。

Conclusion: MGSD-WSS通过多粒度去噪和弱监督信号有效解决了序列推荐中的噪声问题，提升了推荐性能。

Abstract: Sequential recommendation aims to predict the next item based on user
interests in historical interaction sequences. Historical interaction sequences
often contain irrelevant noisy items, which significantly hinders the
performance of recommendation systems. Existing research employs unsupervised
methods that indirectly identify item-granularity irrelevant noise by
predicting the ground truth item. Since these methods lack explicit noise
labels, they are prone to misidentify users' interested items as noise.
Additionally, while these methods focus on removing item-granularity noise
driven by the ground truth item, they overlook interest-granularity noise,
limiting their ability to perform broader denoising based on user interests. To
address these issues, we propose Multi-Granularity Sequence Denoising with
Weakly Supervised Signal for Sequential Recommendation(MGSD-WSS). MGSD-WSS
first introduces the Multiple Gaussian Kernel Perceptron module to map the
original and enhance sequence into a common representation space and utilizes
weakly supervised signals to accurately identify noisy items in the historical
interaction sequence. Subsequently, it employs the item-granularity denoising
module with noise-weighted contrastive learning to obtain denoised item
representations. Then, it extracts target interest representations from the
ground truth item and applies noise-weighted contrastive learning to obtain
denoised interest representations. Finally, based on the denoised item and
interest representations, MGSD-WSS predicts the next item. Extensive
experiments on five datasets demonstrate that the proposed method significantly
outperforms state-of-the-art sequence recommendation and denoising models. Our
code is available at https://github.com/lalunex/MGSD-WSS.

</details>


### [11] [VeritasFi: An Adaptable, Multi-tiered RAG Framework for Multi-modal Financial Question Answering](https://arxiv.org/abs/2510.10828)
*Zhenghan Tai,Hanwei Wu,Qingchen Hu,Jijun Chi,Hailin He,Lei Ding,Tung Sum Thomas Kwok,Bohuai Xiao,Yuchen Hua,Suyuchen Wang,Peng Lu,Muzhi Li,Yihong Wu,Liheng Ma,Jerry Huang,Jiayi Zhang,Gonghao Zhang,Chaolong Jiang,Jingrui Tian,Sicheng Lyu,Zeyu Li,Boyu Han,Fengran Mo,Xinyue Yu,Yufei Cui,Ling Zhou,Xinyu Wang*

Main category: cs.IR

TL;DR: VeritasFi是一个创新的混合RAG框架，通过多模态预处理、三重混合检索引擎和两阶段重排序训练策略，解决了金融QA中处理异构数据和平衡通用性与公司特定适应的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有金融RAG系统面临两个主要挑战：难以处理文本、表格、图形等异构数据格式，以及在通用领域适用性和公司特定适应性之间难以平衡。

Method: 提出VeritasFi混合RAG框架，包含：1）多模态预处理管道将异构数据转换为统一格式；2）三重混合检索引擎并行运行，结合语义索引文档检索、实时数据获取和专家记忆库；3）两阶段重排序训练策略，先构建通用模型再针对公司微调。

Result: VeritasFi显著增强了金融RAG系统的适应性和鲁棒性，为通用领域和公司特定的QA任务提供了可扩展的解决方案。

Conclusion: VeritasFi通过集成多模态处理、混合检索和两阶段训练策略，为金融QA系统提供了一个突破性的框架，有效解决了现有系统的局限性。

Abstract: Retrieval-Augmented Generation (RAG) is becoming increasingly essential for
Question Answering (QA) in the financial sector, where accurate and
contextually grounded insights from complex public disclosures are crucial.
However, existing financial RAG systems face two significant challenges: (1)
they struggle to process heterogeneous data formats, such as text, tables, and
figures; and (2) they encounter difficulties in balancing general-domain
applicability with company-specific adaptation. To overcome these challenges,
we present VeritasFi, an innovative hybrid RAG framework that incorporates a
multi-modal preprocessing pipeline alongside a cutting-edge two-stage training
strategy for its re-ranking component. VeritasFi enhances financial QA through
three key innovations: (1) A multi-modal preprocessing pipeline that seamlessly
transforms heterogeneous data into a coherent, machine-readable format. (2) A
tripartite hybrid retrieval engine that operates in parallel, combining deep
multi-path retrieval over a semantically indexed document corpus, real-time
data acquisition through tool utilization, and an expert-curated memory bank
for high-frequency questions, ensuring comprehensive scope, accuracy, and
efficiency. (3) A two-stage training strategy for the document re-ranker, which
initially constructs a general, domain-specific model using anonymized data,
followed by rapid fine-tuning on company-specific data for targeted
applications. By integrating our proposed designs, VeritasFi presents a
groundbreaking framework that greatly enhances the adaptability and robustness
of financial RAG systems, providing a scalable solution for both general-domain
and company-specific QA tasks. Code accompanying this work is available at
https://github.com/simplew4y/VeritasFi.git.

</details>


### [12] [Comparative Explanations via Counterfactual Reasoning in Recommendations](https://arxiv.org/abs/2510.10920)
*Yi Yu,Zhenxing Hu*

Main category: cs.IR

TL;DR: 提出CoCountER方法，通过软交换操作生成反事实数据，为任意对比物品对提供可解释的推荐解释，解决现有方法导致解释事实不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法通过最小化产品方面变化来反转推荐决策，但往往导致解释存在事实不准确性，需要改进。

Method: CoCountER方法使用软交换操作创建反事实数据，能够为任意对比物品对生成推荐解释。

Result: 实证实验验证了该方法的有效性。

Conclusion: CoCountER方法能够提供更准确的可解释推荐，通过反事实推理识别物品方面的影响力。

Abstract: Explainable recommendation through counterfactual reasoning seeks to identify
the influential aspects of items in recommendations, which can then be used as
explanations. However, state-of-the-art approaches, which aim to minimize
changes in product aspects while reversing their recommended decisions
according to an aggregated decision boundary score, often lead to factual
inaccuracies in explanations. To solve this problem, in this work we propose a
novel method of Comparative Counterfactual Explanations for Recommendation
(CoCountER). CoCountER creates counterfactual data based on soft swap
operations, enabling explanations for recommendations of arbitrary pairs of
comparative items. Empirical experiments validate the effectiveness of our
approach.

</details>


### [13] [HatLLM: Hierarchical Attention Masking for Enhanced Collaborative Modeling in LLM-based Recommendation](https://arxiv.org/abs/2510.10955)
*Yu Cui,Feng Liu,Jiawei Chen,Canghong Jin,Xingyu Lou,Changwang Zhang,Jun Wang,Yuegang Sun,Can Wang*

Main category: cs.IR

TL;DR: 提出HatLLM方法，通过分层注意力掩码策略解决LLMs在序列推荐中难以有效建模协作信号的问题，在浅层关注项目内语义，深层关注项目间相关性。


<details>
  <summary>Details</summary>
Motivation: LLMs在序列推荐中表现出强大的语义推理能力，但难以有效建模用户历史交互中的行为相关性（协作信号），且注意力机制倾向于过度关注同一项目内的token。

Method: 提出分层注意力掩码策略HatLLM：浅层掩码不同项目间token的注意力，促进项目内语义理解；深层掩码项目内token的注意力，强制模型捕捉项目间相关性。

Result: 在三个真实数据集上的实验表明，HatLLM相比现有LLM方法平均提升9.13%的性能。

Conclusion: 分层注意力掩码策略能有效提升LLMs在序列推荐中的表现，使其能够联合建模token级和项目级依赖关系。

Abstract: Recent years have witnessed a surge of research on leveraging large language
models (LLMs) for sequential recommendation. LLMs have demonstrated remarkable
potential in inferring users' nuanced preferences through fine-grained semantic
reasoning. However, they also exhibit a notable limitation in effectively
modeling collaborative signals, i.e., behavioral correlations inherent in
users' historical interactions. Our empirical analysis further reveals that the
attention mechanisms in LLMs tend to disproportionately focus on tokens within
the same item, thereby impeding the capture of cross-item correlations.
  To address this limitation, we propose a novel hierarchical attention masking
strategy for LLM-based recommendation, termed HatLLM. Specifically, in shallow
layers, HatLLM masks attention between tokens from different items,
facilitating intra-item semantic understanding; in contrast, in deep layers,
HatLLM masks attention within items, thereby compelling the model to capture
cross-item correlations. This progressive, layer-wise approach enables LLMs to
jointly model both token-level and item-level dependencies. Extensive
experiments on three real-world datasets demonstrate that HatLLM achieves
significant performance gains (9.13% on average) over existing LLM-based
methods.

</details>


### [14] [Does LLM Focus on the Right Words? Diagnosing Language Bias in LLM-based Recommenders](https://arxiv.org/abs/2510.10978)
*Bohao Wang,Jiawei Chen,Feng Liu,Changwang Zhang,Jun Wang,Canghong Jin,Chun Chen,Can Wang*

Main category: cs.IR

TL;DR: 提出GDRT方法解决LLM在推荐系统中存在的语言偏见问题，通过分组分布鲁棒优化提升推荐准确性和公平性


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法导致语言偏见，模型过度依赖辅助标记而忽视核心用户交互标记，影响推荐准确性和公平性

Method: 提出基于分组分布鲁棒优化的调优方法(GDRT)，通过自适应加权表现不佳的标记组，将模型注意力从辅助线索转向信息丰富的用户交互标记

Result: 在三个公共数据集上的实验表明，GDRT有效缓解语言偏见，NDCG@10平均提升24.29%，显著提高推荐公平性

Conclusion: GDRT是一种有效的微调范式，能够缓解LLM在推荐系统中的语言偏见问题，提升推荐性能和公平性

Abstract: Large language models (LLMs), owing to their extensive open-domain knowledge
and semantic reasoning capabilities, have been increasingly integrated into
recommender systems (RS). However, a substantial gap remains between the
pre-training objectives of LLMs and the specific requirements of recommendation
tasks. To address this gap, supervised fine-tuning (SFT) is commonly performed
on specially curated recommendation datasets to further enhance their
predictive ability. Despite its success, SFT exhibits a critical limitation: it
induces Language Bias, whereby the model over-relies on auxiliary tokens-such
as task descriptions and prefix-generated tokens-while underutilizing core user
interaction tokens that encode user-specific preferences. This bias not only
undermines recommendation accuracy but also raises unfairness concerns.
  To address this issue, we propose Group Distributionally Robust
Optimization-based Tuning (GDRT), a novel fine-tuning paradigm that enforces
consistent model performance across token groups with varying degrees of
relevance to auxiliary tokens. By adaptively upweighting underperforming
groups, typically those weakly correlated with auxiliary tokens, GDRT shifts
the model's attention from superficial auxiliary cues to informative user
interaction tokens, thereby mitigating language bias. Extensive experiments
conducted on three public datasets demonstrate that GDRT effectively mitigates
language bias, yielding substantial improvements in recommendation accuracy
(with an average NDCG@10 gain of 24.29%) and significantly enhancing
recommendation fairness.

</details>


### [15] [From Reasoning LLMs to BERT: A Two-Stage Distillation Framework for Search Relevance](https://arxiv.org/abs/2510.11056)
*Runze Xia,Yupeng Ji,Yuxi Zhou,Haodong Liu,Teng Zhang,Piji Li*

Main category: cs.IR

TL;DR: 提出两阶段推理蒸馏框架，将大型语言模型的推理能力迁移到轻量级学生模型中，解决电商搜索系统中查询-服务相关性预测的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 电商搜索系统对延迟有严格要求，无法直接应用大型语言模型(LLMs)，需要开发轻量级但具备推理能力的模型。

Method: 第一阶段构建领域适应教师模型：通过领域自适应预训练、监督微调和偏好优化；第二阶段引入对比推理自蒸馏(CRSD)，通过标准输入和推理增强输入的对比学习实现知识迁移。

Result: 在美团搜索广告系统的离线和在线A/B测试中，该框架在多个指标上取得显著提升。

Conclusion: 该框架有效解决了LLMs在电商搜索中的延迟问题，实现了推理能力的成功迁移，具有实际应用价值。

Abstract: Query-service relevance prediction in e-commerce search systems faces strict
latency requirements that prevent the direct application of Large Language
Models (LLMs). To bridge this gap, we propose a two-stage reasoning
distillation framework to transfer reasoning capabilities from a powerful
teacher LLM to a lightweight, deployment-friendly student model. In the first
stage, we address the limitations of general-purpose LLMs by constructing a
domain-adapted teacher model. This is achieved through a three-step process:
domain-adaptive pre-training to inject platform knowledge, supervised
fine-tuning to elicit reasoning skills, and preference optimization with a
multi-dimensional reward model to ensure the generation of reliable and
preference-aligned reasoning paths. This teacher can then automatically
annotate massive query-service pairs from search logs with both relevance
labels and reasoning chains. In the second stage, to address the challenges of
architectural heterogeneity in standard distillation, we introduce Contrastive
Reasoning Self-Distillation (CRSD). By modeling the behavior of the same
student model under "standard" and "reasoning-augmented" inputs as a
teacher-student relationship, CRSD enables the lightweight model to internalize
the teacher's complex decision-making mechanisms without needing the explicit
reasoning path at inference. Offline evaluations and online A/B testing in the
Meituan search advertising system demonstrate that our framework achieves
significant improvements across multiple metrics, validating its effectiveness
and practical value.

</details>


### [16] [Decoupled Multimodal Fusion for User Interest Modeling in Click-Through Rate Prediction](https://arxiv.org/abs/2510.11066)
*Alin Fan,Hanqing Li,Sihan Lu,Jingsong Yuan,Jiandong Zhang*

Main category: cs.IR

TL;DR: 提出了解耦多模态融合(DMF)方法，通过模态增强建模策略实现ID表示与多模态表示的细粒度交互，在保持计算效率的同时提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常采用模态中心建模策略，独立处理ID和多模态嵌入，无法捕捉内容语义与行为信号之间的细粒度交互。

Method: 构建目标感知特征来桥接不同嵌入空间的语义鸿沟，设计推理优化的注意力机制解耦目标感知特征和ID嵌入的计算，结合模态中心和模态增强两种建模策略。

Result: 在公开和工业数据集上验证了有效性，在Lazada电商平台部署后，CTCVR相对提升5.30%，GMV相对提升7.43%，计算开销可忽略。

Conclusion: DMF通过模态增强建模策略成功实现了细粒度的多模态交互，在提升推荐性能的同时保持了计算效率，具有实际部署价值。

Abstract: Modern industrial recommendation systems improve recommendation performance
by integrating multimodal representations from pre-trained models into ID-based
Click-Through Rate (CTR) prediction frameworks. However, existing approaches
typically adopt modality-centric modeling strategies that process ID-based and
multimodal embeddings independently, failing to capture fine-grained
interactions between content semantics and behavioral signals. In this paper,
we propose Decoupled Multimodal Fusion (DMF), which introduces a
modality-enriched modeling strategy to enable fine-grained interactions between
ID-based collaborative representations and multimodal representations for user
interest modeling. Specifically, we construct target-aware features to bridge
the semantic gap across different embedding spaces and leverage them as side
information to enhance the effectiveness of user interest modeling.
Furthermore, we design an inference-optimized attention mechanism that
decouples the computation of target-aware features and ID-based embeddings
before the attention layer, thereby alleviating the computational bottleneck
introduced by incorporating target-aware features. To achieve comprehensive
multimodal integration, DMF combines user interest representations learned
under the modality-centric and modality-enriched modeling strategies. Offline
experiments on public and industrial datasets demonstrate the effectiveness of
DMF. Moreover, DMF has been deployed on the product recommendation system of
the international e-commerce platform Lazada, achieving relative improvements
of 5.30% in CTCVR and 7.43% in GMV with negligible computational overhead.

</details>


### [17] [HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction](https://arxiv.org/abs/2510.11100)
*Shuwei Chen,Jiajun Cui,Zhengqi Xu,Fan Zhang,Jiangke Fan,Teng Zhang,Xingxing Wang*

Main category: cs.IR

TL;DR: HoMer提出了一种面向同质性的Transformer模型，通过特征对齐、集合式预测和统一架构设计，解决了CTR预测中的特征异质性、上下文异质性和架构异质性问题，在工业推荐系统中实现了性能提升和资源节省。


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测方法面临三种异质性问题：特征异质性（序列特征与非序列特征不平衡）、上下文异质性（点式预测忽略跨项目交互）、架构异质性（模块化集成影响效率）。这些限制了模型在工业部署中的性能、效率和可扩展性。

Method: 1. 序列特征与非序列特征对齐，实现精确序列建模和细粒度兴趣表示；2. 从点式预测转向集合式预测，支持高度并行的跨项目交互；3. 采用统一的编码器-解码器架构，通过结构简化和共享计算实现双重优化。

Result: 在工业基准测试中，AUC指标提升0.0099，在线业务指标CTR/RPM分别提升1.99%/2.46%。通过初步工程优化节省27%的GPU资源，验证了模型的优越性和实用性。

Conclusion: HoMer通过同质性导向的设计，在不改变预测流程的情况下成功扩展并超越了工业基线，证明了其在解决CTR预测异质性问题和提升工业推荐系统性能方面的有效性。

Abstract: Click-through rate (CTR) prediction, which models behavior sequence and
non-sequential features (e.g., user/item profiles or cross features) to infer
user interest, underpins industrial recommender systems. However, most methods
face three forms of heterogeneity that degrade predictive performance: (i)
Feature Heterogeneity persists when limited sequence side features provide less
granular interest representation compared to extensive non-sequential features,
thereby impairing sequence modeling performance; (ii) Context Heterogeneity
arises because a user's interest in an item will be influenced by other items,
yet point-wise prediction neglects cross-item interaction context from the
entire item set; (iii) Architecture Heterogeneity stems from the fragmented
integration of specialized network modules, which compounds the model's
effectiveness, efficiency and scalability in industrial deployments. To tackle
the above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for
modeling sequential and set-wise contexts. First, we align sequence side
features with non-sequential features for accurate sequence modeling and
fine-grained interest representation. Second, we shift the prediction paradigm
from point-wise to set-wise, facilitating cross-item interaction in a highly
parallel manner. Third, HoMer's unified encoder-decoder architecture achieves
dual optimization through structural simplification and shared computation,
ensuring computational efficiency while maintaining scalability with model
size. Without arduous modification to the prediction pipeline, HoMer
successfully scales up and outperforms our industrial baseline by 0.0099 in the
AUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%.
Additionally, HoMer saves 27% of GPU resources via preliminary engineering
optimization, further validating its superiority and practicality.

</details>


### [18] [DyKnow-RAG: Dynamic Knowledge Utilization Reinforcement Framework for Noisy Retrieval-Augmented Generation in E-commerce Search Relevance](https://arxiv.org/abs/2510.11122)
*Tingqiao Xu,Shaowei Yao,Chenhe Dong,Yiming Jin,Zerui Huang,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: DyKnow-RAG是一个动态噪声RAG框架，通过Group Relative Policy Optimization训练模型在电商排序中自适应决定是否使用外部上下文，无需额外推理步骤即可在单次推理中处理噪声外部信息。


<details>
  <summary>Details</summary>
Motivation: 电商排序中，长尾查询、知识密集和快速变化的查询超出了参数化LLM的覆盖范围，而外部上下文（评论、属性百科、UGC）存在噪声且无法进行清理-总结步骤，需要在单次推理中判断是否使用上下文。

Method: 基于Group Relative Policy Optimization，训练两个rollout组（无外部上下文 vs 单个检索块），应用后验驱动的组间优势缩放，根据每查询正确性差距自适应重新加权它们的贡献。训练包括监督初始化、基于SFT不确定性的RL池优先排序和可选DPO预热。

Result: 在统一检索/索引和固定延迟预算下，DyKnow-RAG在离线测试中优于SFT、DPO和普通GRPO，在淘宝A/B测试中在GSB、Query Goodrate和Item Goodrate指标上持续提升，已在淘宝生产相关性系统中部署。

Conclusion: DyKnow-RAG是首批用于电商相关性的单次RAG解决方案之一，将噪声外部信号转化为可靠收益，而无需增加在线复杂性。

Abstract: Accurately modeling query-item relevance drives e-commerce ranking, yet
long-tail, knowledge-heavy, and fast-evolving queries exceed parametric LLM
coverage. External context (reviews, attribute encyclopedias, UGC) can help but
is noisy, and single-pass latency and cost forbid any clean-then-summarize
step. The model must, per query, judge relevance and decide whether to use,
partially use, or ignore the context. DyKnow-RAG is a dynamic noisy-RAG
framework built on Group Relative Policy Optimization. It trains two rollout
groups (no external context vs a single retrieved chunk) and applies
posterior-driven inter-group advantage scaling that adaptively reweights their
contributions by the per-query correctness gap. This teaches when to trust
retrieval versus fall back to parametric knowledge, without process labels,
value networks, or extra inference passes, preserving single-pass, single-chunk
deployment under production latency. Training combines: (1) supervised
initialization with a structured rationale that explicitly records the
context-usage decision; (2) an RL pool prioritized by SFT uncertainty to focus
where context choice is most consequential; and (3) an optional lightweight DPO
warm start to stabilize with-context calibration. Under a unified
retrieval/index and fixed latency budget, DyKnow-RAG outperforms SFT, DPO, and
vanilla GRPO in offline tests, and delivers consistent lifts on GSB, Query
Goodrate, and Item Goodrate in Taobao A/B testing. It is deployed in Taobao's
production relevance system, serving live traffic. To our knowledge, it is
among the first single-pass RAG solutions for e-commerce relevance, turning
noisy external signals into reliable gains without added online complexity.

</details>


### [19] [Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines](https://arxiv.org/abs/2510.11317)
*Chen Gao,Zixin Zhao,Lv Shao,Tong Liu*

Main category: cs.IR

TL;DR: 提出AMEN框架，通过生成式预训练预测用户未来兴趣流，解决传统CTR预测模型的局限性，并通过双向对齐策略协调生成和判别阶段。


<details>
  <summary>Details</summary>
Motivation: 传统CTR预测模型主要基于判别式方法，被动响应用户历史行为而非主动建模用户意图。现有生成式方法存在语义不匹配和冷启动问题。

Method: 提出Next Interest Flow预测，建模兴趣多样性和演化速度；采用双向对齐策略，包括跨阶段权重初始化和语义对齐模块；引入TSP机制增强时序因果建模。

Result: 离线实验显示AMEN优于强基线，大规模在线A/B测试证明其在关键业务指标上带来显著提升。

Conclusion: AMEN框架成功解决了生成式与判别式模型间的目标不匹配问题，为CTR预测提供了更有效的解决方案。

Abstract: Click-Through Rate (CTR) prediction, a cornerstone of modern recommender
systems, has been dominated by discriminative models that react to past user
behavior rather than proactively modeling user intent. Existing generative
paradigms attempt to address this but suffer from critical limitations: Large
Language Model (LLM) based methods create a semantic mismatch by forcing
e-commerce signals into a linguistic space, while ID-based generation is
constrained by item memorization and cold-start issues. To overcome these
limitations, we propose a novel generative pre-training paradigm. Our model
learns to predict the Next Interest Flow, a dense vector sequence representing
a user's future intent, while simultaneously modeling its internal Interest
Diversity and Interest Evolution Velocity to ensure the representation is both
rich and coherent. However, this two-stage approach introduces a critical
objective mismatch between the generative and discriminative stages. We resolve
this via a bidirectional alignment strategy, which harmonizes the two stages
through cross-stage weight initialization and a dynamic Semantic Alignment
Module for fine-tuning. Additionally, we enhance the underlying discriminative
model with a Temporal Sequential Pairwise (TSP) mechanism to better capture
temporal causality. We present the All-domain Moveline Evolution Network
(AMEN), a unified framework implementing our entire pipeline. Extensive offline
experiments validate AMEN's superiority over strong baselines, and a
large-scale online A/B test demonstrates its significant real-world impact,
delivering substantial improvements in key business metrics.

</details>


### [20] [Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate Marketing](https://arxiv.org/abs/2510.11323)
*Zhe Wang,Yaming Yang,Ziyu Guan,Bin Tong,Rui Wang,Wei Zhao,Hongbo Deng*

Main category: cs.IR

TL;DR: 本文提出了一种评估联盟营销中推广者间接贡献的新指标——传播规模，并开发了一个两阶段预测模型来解决该指标的多因素影响和动态复杂性。


<details>
  <summary>Details</summary>
Motivation: 联盟营销中准确评估和预测推广者在产品推广中的贡献是一个关键但未被充分探索的挑战，现有时间序列预测技术由于传播规模受多因素影响和动态场景复杂性而无法提供准确预测。

Method: 采用两阶段解决方案：首先分别进行基本自销售和网络结构预测，然后合成传播规模。设计了基于后代邻居的图卷积编码方案，并引入超图卷积来有效捕捉复杂的推广动态，同时使用三个辅助任务来缓解高波动性问题。

Result: 在大规模工业数据集上的离线实验验证了方法的优越性。在拥有超过10万推广者的Alimama平台上部署模型，实现了GMV提升9.29%和销售量增加5.89%。

Conclusion: 所提出的方法能够有效预测联盟营销中推广者的传播规模，显著提升了业务指标，为联盟营销贡献评估提供了有效的解决方案。

Abstract: In recent years, affiliate marketing has emerged as a revenue-sharing
strategy where merchants collaborate with promoters to promote their products.
It not only increases product exposure but also allows promoters to earn a
commission. This paper addresses the pivotal yet under-explored challenge in
affiliate marketing: accurately assessing and predicting the contributions of
promoters in product promotion. We design a novel metric for evaluating the
indirect contributions of the promoter, called propagation scale.
Unfortunately, existing time series forecasting techniques fail to deliver
accurate predictions due to the propagation scale being influenced by multiple
factors and the inherent complexities arising from dynamic scenarios. To
address this issue, we decouple the network structure from the node signals and
propose a two-stage solution: initially, the basic self-sales and network
structure prediction are conducted separately, followed by the synthesis of the
propagation scale. Specifically, we design a graph convolution encoding scheme
based on descendant neighbors and incorporate hypergraph convolution to
efficiently capture complex promotional dynamics. Additionally, three auxiliary
tasks are employed: self-sales prediction for base estimations, descendant
prediction to synthesize propagation scale, and promoter activation prediction
to mitigate high volatility issues. Extensive offline experiments on
large-scale industrial datasets validate the superiority of our method. We
further deploy our model on Alimama platform with over $100,000$ promoters,
achieving a $9.29\%$ improvement in GMV and a $5.89\%$ increase in sales
volume.

</details>


### [21] [VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification](https://arxiv.org/abs/2510.11394)
*Haosheng Qian,Yixing Fan,Jiafeng Guo,Ruqing Zhang,Qi Chen,Dawei Yin,Xueqi Cheng*

Main category: cs.IR

TL;DR: VeriCite是一个三阶段框架，通过NLI模型验证、支持证据选择和答案精炼来增强RAG系统的引用生成质量，显著减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在引用生成方面存在困难，微调方法需要大量标注数据和计算资源，后处理方法在处理多引用时效果不佳。

Method: 三阶段生成：1)基于上下文生成初始答案并用NLI模型验证；2)评估文档效用并提取支持证据；3)整合初始答案和证据生成最终精炼答案。

Result: 在五个开源LLM和四个数据集上的实验表明，VeriCite能显著提高引用质量，同时保持答案正确性。

Conclusion: VeriCite框架有效解决了RAG系统中的引用生成问题，通过严谨的证据验证和答案精炼过程提升了系统的可靠性和可信度。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for
enhancing the responses of large language models (LLMs) with external knowledge
sources. Despite the impressive performance in complex question-answering
tasks, RAG still struggles with hallucinations. Attributing RAG-generated
content through in-line citations has demonstrated potential in reducing
hallucinations and facilitating human verification. Existing citation
generation methods primarily rely on either fine-tuning the generator or
employing post-processing approaches for citation matching. However, the former
approach demands substantial annotated data and computational resources, while
the latter often encounters difficulties in managing multiple citations and
frequently produces suboptimal results. In this paper, we introduce a novel
framework, called VeriCite, designed to rigorously validate supporting evidence
and enhance answer attribution. Specifically, VeriCite breaks down into a
three-stage generation: 1) The initial answer generation first generates a
response based on all available contexts and has its claims verified through
the NLI model; 2) the supporting evidence selection assesses the utility of
each document and extracts useful supporting evidences; 3) the final answer
refinement integrates the initial response and collected evidences to produce
the final, refined answer.We conduct experiments across five open-source LLMs
and four datasets, demonstrating that VeriCite can significantly improve
citation quality while maintaining the correctness of the answers.

</details>


### [22] [On Inherited Popularity Bias in Cold-Start Item Recommendation](https://arxiv.org/abs/2510.11402)
*Gregor Meehan,Johan Pauwels*

Main category: cs.IR

TL;DR: 冷启动推荐系统会继承热启动模型的流行度偏见，甚至更严重，因为它们只能基于内容特征来估计流行度，导致对与热门物品内容相似的冷物品进行过度预测。


<details>
  <summary>Details</summary>
Motivation: 冷启动推荐系统通常通过监督学习从热启动CF模型中学习，但这样可能会继承热启动模型的预测偏见，特别是流行度偏见，从而影响推荐公平性。

Method: 在三个多媒体数据集上分析三种生成式冷启动方法的行为，并提出一种简单的后处理偏见缓解方法，使用嵌入向量大小作为预测流行度的代理。

Result: 实验表明冷启动推荐器不仅镜像热模型的流行度偏见，而且受影响更严重，因为它们无法从交互数据推断流行度，只能基于内容特征进行估计。

Conclusion: 提出的后处理偏见缓解方法能够产生更平衡的推荐，同时对用户导向的冷启动准确性影响有限。

Abstract: Collaborative filtering (CF) recommender systems struggle with making
predictions on unseen, or 'cold', items. Systems designed to address this
challenge are often trained with supervision from warm CF models in order to
leverage collaborative and content information from the available interaction
data. However, since they learn to replicate the behavior of CF methods,
cold-start models may therefore also learn to imitate their predictive biases.
In this paper, we show that cold-start systems can inherit popularity bias, a
common cause of recommender system unfairness arising when CF models overfit to
more popular items, thereby maximizing user-oriented accuracy but neglecting
rarer items. We demonstrate that cold-start recommenders not only mirror the
popularity biases of warm models, but are in fact affected more severely:
because they cannot infer popularity from interaction data, they instead
attempt to estimate it based solely on content features. This leads to
significant over-prediction of certain cold items with similar content to
popular warm items, even if their ground truth popularity is very low. Through
experiments on three multimedia datasets, we analyze the impact of this
behavior on three generative cold-start methods. We then describe a simple
post-processing bias mitigation method that, by using embedding magnitude as a
proxy for predicted popularity, can produce more balanced recommendations with
limited harm to user-oriented cold-start accuracy.

</details>


### [23] [What Generative Search Engines Like and How to Optimize Web Content Cooperatively](https://arxiv.org/abs/2510.11438)
*Yujiang Wu,Shanshan Zhong,Yubin Kim,Chenyan Xiong*

Main category: cs.IR

TL;DR: AutoGEO是一个自动学习生成引擎偏好的框架，通过提取偏好规则来优化网页内容，以提升在生成引擎中的曝光度。


<details>
  <summary>Details</summary>
Motivation: 随着生成式搜索引擎的普及，内容提供者需要优化内容以获得更多曝光，但手动优化成本高昂且效果有限。

Method: 首先使用前沿LLM解释生成引擎偏好并提取规则，然后利用这些规则进行提示工程和训练成本效益模型。

Result: 在标准GEO-Bench和真实用户查询基准测试中，AutoGEO有效提升了内容曝光度，同时保持了搜索实用性。

Conclusion: AutoGEO能够自动学习并嵌入生成引擎的偏好规则，为内容优化提供了一种高效且可扩展的解决方案。

Abstract: By employing large language models (LLMs) to retrieve documents and generate
natural language responses, Generative Engines, such as Google AI overview and
ChatGPT, provide significantly enhanced user experiences and have rapidly
become the new form of search. Their rapid adoption also drives the needs of
Generative Engine Optimization (GEO), as content providers are eager to gain
more traction from them. In this paper, we introduce AutoGEO, a framework to
automatically learn generative engine preferences when using retrieved contents
for response generation, and rewrite web contents for more such traction.
AutoGEO first prompts frontier LLMs to explain generative engine preferences
and extract meaningful preference rules from these explanations. Then it uses
preference rules as context engineering for AutoGEO$_\text{API}$, a
prompt-based GEO system, and as rule-based rewards to train
AutoGEO$_\text{Mini}$, a cost-effective GEO model. Experiments on the standard
GEO-Bench and two newly constructed benchmarks using real user queries
demonstrate the effectiveness of AutoGEO in enhancing content traction while
preserving search utility. Analyses confirm the learned rules' robustness and
abilities to capture unique preferences in variant domains, and AutoGEO
systems' ability to embed them in content optimization. The code is released at
https://github.com/cxcscmu/AutoGEO.

</details>


### [24] [Uncertainty Quantification for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2510.11483)
*Heydar Soudani,Hamed Zamani,Faegheh Hasibi*

Main category: cs.IR

TL;DR: 提出了R2C方法，通过扰动多步推理过程来量化检索增强推理(RAR)中的不确定性，显著提升了不确定性量化性能


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法无法有效处理检索增强推理(RAR)中的多步推理过程，需要同时考虑检索和生成环节的不确定性来源

Method: R2C通过在推理步骤中应用各种扰动操作，改变检索器的输入，从而通过迭代反馈循环捕获检索器和生成器的不确定性

Result: 在五个RAR系统和多个QA数据集上的实验显示，R2C相比现有最优UQ基线平均提升AUROC超过5%，在下游任务中也有显著改进

Conclusion: R2C是首个专门针对RAR系统的不确定性量化方法，能有效捕获多步推理中的不确定性，显著提升系统可靠性和下游任务性能

Abstract: Retrieval-augmented reasoning (RAR) is a recent evolution of
retrieval-augmented generation (RAG) that employs multiple reasoning steps for
retrieval and generation. While effective for some complex queries, RAR remains
vulnerable to errors and misleading outputs. Uncertainty quantification (UQ)
offers methods to estimate the confidence of systems' outputs. These methods,
however, often handle simple queries with no retrieval or single-step
retrieval, without properly handling RAR setup. Accurate estimation of UQ for
RAR requires accounting for all sources of uncertainty, including those arising
from retrieval and generation. In this paper, we account for all these sources
and introduce Retrieval-Augmented Reasoning Consistency (R2C)--a novel UQ
method for RAR. The core idea of R2C is to perturb the multi-step reasoning
process by applying various actions to reasoning steps. These perturbations
alter the retriever's input, which shifts its output and consequently modifies
the generator's input at the next step. Through this iterative feedback loop,
the retriever and generator continuously reshape one another's inputs, enabling
us to capture uncertainty arising from both components. Experiments on five
popular RAR systems across diverse QA datasets show that R2C improves AUROC by
over 5% on average compared to the state-of-the-art UQ baselines. Extrinsic
evaluations using R2C as an external signal further confirm its effectiveness
for two downstream tasks: in Abstention, it achieves ~5% gains in both
F1Abstain and AccAbstain; in Model Selection, it improves the exact match by
~7% over single models and ~3% over selection methods.

</details>


### [25] [Characterizing Web Search in The Age of Generative AI](https://arxiv.org/abs/2510.11560)
*Elisabeth Kirsten,Jost Grosse Perdekamp,Mihir Upadhyay,Krishna P. Gummadi,Muhammad Bilal Zafar*

Main category: cs.IR

TL;DR: 比较传统搜索引擎与生成式搜索引擎在搜索结果覆盖范围、知识来源、概念多样性等方面的差异


<details>
  <summary>Details</summary>
Motivation: 随着LLM的发展，生成式搜索（直接生成连贯文本回答）与传统搜索（返回网页排名列表）形成鲜明对比，需要系统比较两者的差异维度

Method: 比较Google传统搜索引擎与来自Google和OpenAI的四个生成式搜索引擎，使用来自四个领域的查询进行分析

Result: 生成式搜索引擎覆盖更广的来源；不同生成式引擎在依赖模型内部知识vs外部检索知识方面存在差异；生成式搜索呈现更多样化的概念，为搜索多样性和偶然发现创造新机会

Conclusion: 生成式搜索与传统搜索存在显著差异，需要重新审视生成AI时代下的网络搜索评估标准

Abstract: The advent of LLMs has given rise to a new type of web search: Generative
search, where LLMs retrieve web pages related to a query and generate a single,
coherent text as a response. This output modality stands in stark contrast to
traditional web search, where results are returned as a ranked list of
independent web pages. In this paper, we ask: Along what dimensions do
generative search outputs differ from traditional web search? We compare
Google, a traditional web search engine, with four generative search engines
from two providers (Google and OpenAI) across queries from four domains. Our
analysis reveals intriguing differences. Most generative search engines cover a
wider range of sources compared to web search. Generative search engines vary
in the degree to which they rely on internal knowledge contained within the
model parameters v.s. external knowledge retrieved from the web. Generative
search engines surface varying sets of concepts, creating new opportunities for
enhancing search diversity and serendipity. Our results also highlight the need
for revisiting evaluation criteria for web search in the age of Generative AI.

</details>


### [26] [QDER: Query-Specific Document and Entity Representations for Multi-Vector Document Re-Ranking](https://arxiv.org/abs/2510.11589)
*Shubham Chatterjee,Jeff Dalton*

Main category: cs.IR

TL;DR: QDER是一个神经重排序模型，通过将知识图谱语义整合到多向量模型中，统一了实体导向和多向量方法。它采用"延迟聚合"策略，在最终评分阶段才进行聚合，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 统一神经信息检索中的两种主要方法：基于知识图谱的实体导向方法和捕捉细粒度语义的多向量模型，以克服各自局限性。

Method: 保持单独的token和实体表示，通过学习的注意力模式转换这些细粒度表示，然后在最终评分阶段应用精心选择的数学运算进行精确匹配。

Result: 在五个标准基准测试中，QDER实现了显著性能提升，在TREC Robust 2004上nDCG@20比最强基线提高36%，在困难查询上达到0.70的nDCG@20，而传统方法完全失败。

Conclusion: QDER为实体感知检索的未来工作奠定了基础，特别在困难查询上表现出色，证明了延迟聚合方法的有效性。

Abstract: Neural IR has advanced through two distinct paths: entity-oriented approaches
leveraging knowledge graphs and multi-vector models capturing fine-grained
semantics. We introduce QDER, a neural re-ranking model that unifies these
approaches by integrating knowledge graph semantics into a multi-vector model.
QDER's key innovation lies in its modeling of query-document relationships:
rather than computing similarity scores on aggregated embeddings, we maintain
individual token and entity representations throughout the ranking process,
performing aggregation only at the final scoring stage - an approach we call
"late aggregation." We first transform these fine-grained representations
through learned attention patterns, then apply carefully chosen mathematical
operations for precise matches. Experiments across five standard benchmarks
show that QDER achieves significant performance gains, with improvements of 36%
in nDCG@20 over the strongest baseline on TREC Robust 2004 and similar
improvements on other datasets. QDER particularly excels on difficult queries,
achieving an nDCG@20 of 0.70 where traditional approaches fail completely
(nDCG@20 = 0.0), setting a foundation for future work in entity-aware
retrieval.

</details>


### [27] [REGENT: Relevance-Guided Attention for Entity-Aware Multi-Vector Neural Re-Ranking](https://arxiv.org/abs/2510.11592)
*Shubham Chatterjee*

Main category: cs.IR

TL;DR: REGENT模型通过将实体语义直接集成到神经注意力机制中，解决了神经重排模型在处理复杂信息需求和长文档时的内容选择问题，在三个挑战性数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前神经重排模型在处理复杂信息需求和内容丰富的长文档时存在困难，根本问题在于智能内容选择。人类理解围绕关键实体和概念展开，而神经模型在固定token窗口内处理文本，将所有交互视为同等重要，错过了关键的语义信号。

Method: REGENT模型使用实体作为"语义骨架"来引导注意力，模仿人类理解方式。它将相关性指导直接集成到注意力机制中，结合细粒度词汇匹配和高层次语义推理，使模型能够专注于概念上重要的内容，同时保持对精确术语匹配的敏感性。

Result: REGENT在三个挑战性数据集上实现了最先进的性能，相比BM25提供了高达108%的改进，并持续优于包括ColBERT和RankVicuna在内的强基线模型。

Conclusion: 这是首个成功将实体语义直接集成到神经注意力中的工作，为实体感知信息检索建立了新范式。

Abstract: Current neural re-rankers often struggle with complex information needs and
long, content-rich documents. The fundamental issue is not computational--it is
intelligent content selection: identifying what matters in lengthy,
multi-faceted texts. While humans naturally anchor their understanding around
key entities and concepts, neural models process text within rigid token
windows, treating all interactions as equally important and missing critical
semantic signals. We introduce REGENT, a neural re-ranking model that mimics
human-like understanding by using entities as a "semantic skeleton" to guide
attention. REGENT integrates relevance guidance directly into the attention
mechanism, combining fine-grained lexical matching with high-level semantic
reasoning. This relevance-guided attention enables the model to focus on
conceptually important content while maintaining sensitivity to precise term
matches. REGENT achieves new state-of-the-art performance in three challenging
datasets, providing up to 108% improvement over BM25 and consistently
outperforming strong baselines including ColBERT and RankVicuna. To our
knowledge, this is the first work to successfully integrate entity semantics
directly into neural attention, establishing a new paradigm for entity-aware
information retrieval.

</details>


### [28] [OneRec-Think: In-Text Reasoning for Generative Recommendation](https://arxiv.org/abs/2510.11639)
*Zhanyu Liu,Shiyao Wang,Xingmei Wang,Rongzhou Zhang,Jiaxin Deng,Honghui Bao,Jinghao Zhang,Wuchao Li,Pengfei Zheng,Xiangyu Wu,Yifei Hu,Qigen Hu,Xinchen Luo,Lejian Ren,Zixing Zhang,Qianqian Wang,Kuo Cai,Yunfan Wu,Hongtao Cheng,Zexuan Cheng,Lu Ren,Huanjie Wang,Yi Su,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: OneRec-Think是一个统一的推荐框架，通过显式推理能力将对话、推理和个性化推荐相结合，在快手平台上验证了实际效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型缺乏显式和可控的推理能力，而这正是大语言模型的关键优势。

Method: 提出三阶段方法：项目对齐（跨模态项目-文本对齐）、推理激活（在推荐上下文中激活LLM推理）、推理增强（设计考虑用户偏好多有效性的特定奖励函数）。

Result: 在公共基准测试中达到最先进性能，在快手平台上部署获得0.159%的APP停留时间提升。

Conclusion: OneRec-Think框架成功将显式推理能力引入推荐系统，验证了其在工业部署中的实际价值。

Abstract: The powerful generative capacity of Large Language Models (LLMs) has
instigated a paradigm shift in recommendation. However, existing generative
models (e.g., OneRec) operate as implicit predictors, critically lacking the
capacity for explicit and controllable reasoning-a key advantage of LLMs. To
bridge this gap, we propose OneRec-Think, a unified framework that seamlessly
integrates dialogue, reasoning, and personalized recommendation. OneRec-Think
incorporates: (1) Itemic Alignment: cross-modal Item-Textual Alignment for
semantic grounding; (2) Reasoning Activation: Reasoning Scaffolding to activate
LLM reasoning within the recommendation context; and (3) Reasoning Enhancement,
where we design a recommendation-specific reward function that accounts for the
multi-validity nature of user preferences. Experiments across public benchmarks
show state-of-the-art performance. Moreover, our proposed "Think-Ahead"
architecture enables effective industrial deployment on Kuaishou, achieving a
0.159\% gain in APP Stay Time and validating the practical efficacy of the
model's explicit reasoning capability.

</details>


### [29] [FinVet: A Collaborative Framework of RAG and External Fact-Checking Agents for Financial Misinformation Detection](https://arxiv.org/abs/2510.11654)
*Daniel Berhane Araya,Duoduo Liao*

Main category: cs.IR

TL;DR: FinVet是一个新颖的多智能体框架，通过集成两个检索增强生成(RAG)管道和外部事实核查，采用置信度加权投票机制来对抗金融市场中的错误信息。


<details>
  <summary>Details</summary>
Motivation: 金融市场面临错误信息的威胁，现有方法缺乏决策透明度且难以溯源可信来源。

Method: FinVet采用自适应三层处理机制，根据检索置信度动态调整验证策略：从直接元数据提取到混合推理再到完整模型分析，结合置信度加权投票。

Result: 在FinFact数据集上的实验表明，FinVet达到0.85的F1分数，比最佳单管道(事实核查管道)提升10.4%，比独立RAG方法提升37%。

Conclusion: FinVet通过提供证据支持的裁决、来源归属、置信度评分和明确的不确定性标记，显著提升了金融市场错误信息检测的准确性和透明度。

Abstract: Financial markets face growing threats from misinformation that can trigger
billions in losses in minutes. Most existing approaches lack transparency in
their decision-making and provide limited attribution to credible sources. We
introduce FinVet, a novel multi-agent framework that integrates two
Retrieval-Augmented Generation (RAG) pipelines with external fact-checking
through a confidence-weighted voting mechanism. FinVet employs adaptive
three-tier processing that dynamically adjusts verification strategies based on
retrieval confidence, from direct metadata extraction to hybrid reasoning to
full model-based analysis. Unlike existing methods, FinVet provides
evidence-backed verdicts, source attribution, confidence scores, and explicit
uncertainty flags when evidence is insufficient. Experimental evaluation on the
FinFact dataset shows that FinVet achieves an F1 score of 0.85, which is a
10.4% improvement over the best individual pipeline (fact-check pipeline) and
37% improvement over standalone RAG approaches.

</details>
