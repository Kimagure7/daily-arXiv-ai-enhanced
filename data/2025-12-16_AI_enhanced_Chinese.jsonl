{"id": "2512.12084", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.12084", "abs": "https://arxiv.org/abs/2512.12084", "authors": ["Hanzhou Liu", "Kai Yin", "Zhitong Chen", "Chenyue Liu", "Ali Mostafavi"], "title": "FloodSQL-Bench: A Retrieval-Augmented Benchmark for Geospatially-Grounded Text-to-SQL", "comment": null, "summary": "Existing Text-to-SQL benchmarks primarily focus on single-table queries or limited joins in general-purpose domains, and thus fail to reflect the complexity of domain-specific, multi-table and geospatial reasoning, To address this limitation, we introduce FLOODSQL-BENCH, a geospatially grounded benchmark for the flood management domain that integrates heterogeneous datasets through key-based, spatial, and hybrid joins. The benchmark captures realistic flood-related information needs by combining social, infrastructural, and hazard data layers. We systematically evaluate recent large language models with the same retrieval-augmented generation settings and measure their performance across difficulty tiers. By providing a unified, open benchmark grounded in real-world disaster management data, FLOODSQL-BENCH establishes a practical testbed for advancing Text-to-SQL research in high-stakes application domains.", "AI": {"tldr": "FLOODSQL-BENCH\u662f\u4e00\u4e2a\u9488\u5bf9\u6d2a\u6c34\u7ba1\u7406\u9886\u57df\u7684\u7a7a\u95f4\u5730\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6574\u5408\u5f02\u6784\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u952e\u503c\u3001\u7a7a\u95f4\u548c\u6df7\u5408\u8fde\u63a5\uff0c\u8bc4\u4f30LLM\u5728\u590d\u6742\u9886\u57df\u7279\u5b9aText-to-SQL\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709Text-to-SQL\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5355\u8868\u67e5\u8be2\u6216\u901a\u7528\u9886\u57df\u7684\u6709\u9650\u8fde\u63a5\uff0c\u65e0\u6cd5\u53cd\u6620\u9886\u57df\u7279\u5b9a\u3001\u591a\u8868\u548c\u7a7a\u95f4\u63a8\u7406\u7684\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u5728\u6d2a\u6c34\u7ba1\u7406\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u9886\u57df\u3002", "method": "\u5f15\u5165FLOODSQL-BENCH\u57fa\u51c6\uff0c\u6574\u5408\u793e\u4f1a\u3001\u57fa\u7840\u8bbe\u65bd\u548c\u707e\u5bb3\u6570\u636e\u5c42\uff0c\u901a\u8fc7\u952e\u503c\u3001\u7a7a\u95f4\u548c\u6df7\u5408\u8fde\u63a5\u5f02\u6784\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u707e\u5bb3\u7ba1\u7406\u6570\u636e\u7684\u7edf\u4e00\u5f00\u653e\u57fa\u51c6\uff0c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u9886\u57df\u7684Text-to-SQL\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "conclusion": "FLOODSQL-BENCH\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u9886\u57df\u7279\u5b9a\u3001\u591a\u8868\u548c\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u63a8\u8fdb\u9ad8\u98ce\u9669\u5e94\u7528\u9886\u57df\u7684Text-to-SQL\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.12458", "categories": ["cs.IR", "cs.CG", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.12458", "abs": "https://arxiv.org/abs/2512.12458", "authors": ["Vihan Lakshman", "Blaise Munyampirwa", "Julian Shun", "Benjamin Coleman"], "title": "Breaking the Curse of Dimensionality: On the Stability of Modern Vector Retrieval", "comment": "27 pages", "summary": "Modern vector databases enable efficient retrieval over high-dimensional neural embeddings, powering applications from web search to retrieval-augmented generation. However, classical theory predicts such tasks should suffer from the curse of dimensionality, where distances between points become nearly indistinguishable, thereby crippling efficient nearest-neighbor search. We revisit this paradox through the lens of stability, the property that small perturbations to a query do not radically alter its nearest neighbors. Building on foundational results, we extend stability theory to three key retrieval settings widely used in practice: (i) multi-vector search, where we prove that the popular Chamfer distance metric preserves single-vector stability, while average pooling aggregation may destroy it; (ii) filtered vector search, where we show that sufficiently large penalties for mismatched filters can induce stability even when the underlying search is unstable; and (iii) sparse vector search, where we formalize and prove novel sufficient stability conditions. Across synthetic and real datasets, our experimental results match our theoretical predictions, offering concrete guidance for model and system design to avoid the curse of dimensionality.", "AI": {"tldr": "\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u9ad8\u7ef4\u5411\u91cf\u68c0\u7d22\u4e2d\u7684\u7ef4\u5ea6\u8bc5\u5492\u95ee\u9898\uff0c\u901a\u8fc7\u7a33\u5b9a\u6027\u7406\u8bba\u5206\u6790\u4e09\u79cd\u5b9e\u9645\u68c0\u7d22\u573a\u666f\uff0c\u4e3a\u6a21\u578b\u548c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "motivation": "\u73b0\u4ee3\u5411\u91cf\u6570\u636e\u5e93\u652f\u6301\u9ad8\u7ef4\u795e\u7ecf\u5d4c\u5165\u7684\u9ad8\u6548\u68c0\u7d22\uff0c\u4f46\u7ecf\u5178\u7406\u8bba\u9884\u6d4b\u6b64\u7c7b\u4efb\u52a1\u4f1a\u906d\u53d7\u7ef4\u5ea6\u8bc5\u5492\uff0c\u5bfc\u81f4\u70b9\u95f4\u8ddd\u79bb\u96be\u4ee5\u533a\u5206\uff0c\u4ece\u800c\u5f71\u54cd\u6700\u8fd1\u90bb\u641c\u7d22\u6548\u7387\u3002\u672c\u6587\u65e8\u5728\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u6096\u8bba\u3002", "method": "\u901a\u8fc7\u7a33\u5b9a\u6027\u7406\u8bba\u89c6\u89d2\uff0c\u5c06\u7a33\u5b9a\u6027\u5206\u6790\u6269\u5c55\u5230\u4e09\u79cd\u5173\u952e\u68c0\u7d22\u573a\u666f\uff1a\u591a\u5411\u91cf\u641c\u7d22\uff08\u5206\u6790Chamfer\u8ddd\u79bb\u548c\u5e73\u5747\u6c60\u5316\uff09\u3001\u8fc7\u6ee4\u5411\u91cf\u641c\u7d22\uff08\u7814\u7a76\u60e9\u7f5a\u673a\u5236\u7684\u5f71\u54cd\uff09\u3001\u7a00\u758f\u5411\u91cf\u641c\u7d22\uff08\u5f62\u5f0f\u5316\u7a33\u5b9a\u6027\u6761\u4ef6\uff09\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1a1) \u591a\u5411\u91cf\u641c\u7d22\u4e2d\uff0cChamfer\u8ddd\u79bb\u4fdd\u6301\u5355\u5411\u91cf\u7a33\u5b9a\u6027\uff0c\u800c\u5e73\u5747\u6c60\u5316\u53ef\u80fd\u7834\u574f\u7a33\u5b9a\u6027\uff1b2) \u8fc7\u6ee4\u5411\u91cf\u641c\u7d22\u4e2d\uff0c\u8db3\u591f\u5927\u7684\u4e0d\u5339\u914d\u60e9\u7f5a\u53ef\u4ee5\u8bf1\u5bfc\u7a33\u5b9a\u6027\uff1b3) \u7a00\u758f\u5411\u91cf\u641c\u7d22\u4e2d\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5145\u5206\u7a33\u5b9a\u6027\u6761\u4ef6\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "\u901a\u8fc7\u7a33\u5b9a\u6027\u7406\u8bba\u5206\u6790\uff0c\u4e3a\u5b9e\u9645\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u5e2e\u52a9\u907f\u514d\u7ef4\u5ea6\u8bc5\u5492\u95ee\u9898\uff0c\u786e\u4fdd\u68c0\u7d22\u6027\u80fd\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.12740", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.12740", "abs": "https://arxiv.org/abs/2512.12740", "authors": ["Dezhi Yi", "Wei Guo", "Wenyang Cui", "Wenxuan He", "Huifeng Guo", "Yong Liu", "Zhenhua Dong", "Ye Lu"], "title": "FuXi-$\u03b3$: Efficient Sequential Recommendation with Exponential-Power Temporal Encoder and Diagonal-Sparse Positional Mechanism", "comment": "Accepted by KDD 2026", "summary": "Sequential recommendation aims to model users' evolving preferences based on their historical interactions. Recent advances leverage Transformer-based architectures to capture global dependencies, but existing methods often suffer from high computational overhead, primarily due to discontinuous memory access in temporal encoding and dense attention over long sequences. To address these limitations, we propose FuXi-$\u03b3$, a novel sequential recommendation framework that improves both effectiveness and efficiency through principled architectural design. FuXi-$\u03b3$ adopts a decoder-only Transformer structure and introduces two key innovations: (1) An exponential-power temporal encoder that encodes relative temporal intervals using a tunable exponential decay function inspired by the Ebbinghaus forgetting curve. This encoder enables flexible modeling of both short-term and long-term preferences while maintaining high efficiency through continuous memory access and pure matrix operations. (2) A diagonal-sparse positional mechanism that prunes low-contribution attention blocks using a diagonal-sliding strategy guided by the persymmetry of Toeplitz matrix. Extensive experiments on four real-world datasets demonstrate that FuXi-$\u03b3$ achieves state-of-the-art performance in recommendation quality, while accelerating training by up to 4.74$\\times$ and inference by up to 6.18$\\times$, making it a practical and scalable solution for long-sequence recommendation. Our code is available at https://github.com/Yeedzhi/FuXi-gamma.", "AI": {"tldr": "FuXi-\u03b3\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u5e8f\u5217\u63a8\u8350\u6846\u67b6\uff0c\u91c7\u7528\u89e3\u7801\u5668Transformer\u7ed3\u6784\uff0c\u901a\u8fc7\u6307\u6570\u5e42\u65f6\u95f4\u7f16\u7801\u5668\u548c\u5bf9\u89d2\u7a00\u758f\u4f4d\u7f6e\u673a\u5236\uff0c\u5728\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u52a0\u901f\u8bad\u7ec3\u548c\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u9ad8\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u65f6\u95f4\u7f16\u7801\u4e2d\u7684\u4e0d\u8fde\u7eed\u5185\u5b58\u8bbf\u95ee\u548c\u957f\u5e8f\u5217\u4e0a\u7684\u5bc6\u96c6\u6ce8\u610f\u529b\u673a\u5236\u3002", "method": "\u91c7\u7528\u89e3\u7801\u5668Transformer\u7ed3\u6784\uff0c\u5f15\u5165\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u57fa\u4e8e\u827e\u5bbe\u6d69\u65af\u9057\u5fd8\u66f2\u7ebf\u7684\u6307\u6570\u5e42\u65f6\u95f4\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u53ef\u8c03\u6307\u6570\u8870\u51cf\u51fd\u6570\u7f16\u7801\u76f8\u5bf9\u65f6\u95f4\u95f4\u9694\uff1b2) \u5bf9\u89d2\u7a00\u758f\u4f4d\u7f6e\u673a\u5236\uff0c\u5229\u7528Toeplitz\u77e9\u9635\u7684\u5bf9\u79f0\u6027\u901a\u8fc7\u5bf9\u89d2\u6ed1\u52a8\u7b56\u7565\u4fee\u526a\u4f4e\u8d21\u732e\u6ce8\u610f\u529b\u5757\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFuXi-\u03b3\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u540c\u65f6\u8bad\u7ec3\u52a0\u901f\u9ad8\u8fbe4.74\u500d\uff0c\u63a8\u7406\u52a0\u901f\u9ad8\u8fbe6.18\u500d\u3002", "conclusion": "FuXi-\u03b3\u901a\u8fc7\u539f\u5219\u6027\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u5728\u63d0\u5347\u63a8\u8350\u6548\u679c\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u6548\u7387\uff0c\u4e3a\u957f\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.12760", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12760", "abs": "https://arxiv.org/abs/2512.12760", "authors": ["Sina Jani", "Arman Heidari", "Amirmohammad Anvari", "Zahra Rahimi"], "title": "Intelligent Scientific Literature Explorer using Machine Learning (ISLE)", "comment": "18 pages, 7 figures, 3 tables", "summary": "The rapid acceleration of scientific publishing has created substantial challenges for researchers attempting to discover, contextualize, and interpret relevant literature. Traditional keyword-based search systems provide limited semantic understanding, while existing AI-driven tools typically focus on isolated tasks such as retrieval, clustering, or bibliometric visualization. This paper presents an integrated system for scientific literature exploration that combines large-scale data acquisition, hybrid retrieval, semantic topic modeling, and heterogeneous knowledge graph construction. The system builds a comprehensive corpus by merging full-text data from arXiv with structured metadata from OpenAlex. A hybrid retrieval architecture fuses BM25 lexical search with embedding-based semantic search using Reciprocal Rank Fusion. Topic modeling is performed on retrieved results using BERTopic or non-negative matrix factorization depending on computational resources. A knowledge graph unifies papers, authors, institutions, countries, and extracted topics into an interpretable structure. The system provides a multi-layered exploration environment that reveals not only relevant publications but also the conceptual and relational landscape surrounding a query. Evaluation across multiple queries demonstrates improvements in retrieval relevance, topic coherence, and interpretability. The proposed framework contributes an extensible foundation for AI-assisted scientific discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6574\u5408\u68c0\u7d22\u3001\u4e3b\u9898\u5efa\u6a21\u548c\u77e5\u8bc6\u56fe\u8c31\u7684AI\u9a71\u52a8\u79d1\u5b66\u6587\u732e\u63a2\u7d22\u7cfb\u7edf\uff0c\u878d\u5408arXiv\u5168\u6587\u548cOpenAlex\u5143\u6570\u636e\uff0c\u63d0\u5347\u6587\u732e\u53d1\u73b0\u4e0e\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u79d1\u5b66\u51fa\u7248\u52a0\u901f\u5bfc\u81f4\u7814\u7a76\u8005\u96be\u4ee5\u53d1\u73b0\u3001\u5b9a\u4f4d\u548c\u89e3\u91ca\u76f8\u5173\u6587\u732e\u3002\u4f20\u7edf\u5173\u952e\u8bcd\u641c\u7d22\u8bed\u4e49\u7406\u89e3\u6709\u9650\uff0c\u73b0\u6709AI\u5de5\u5177\u4ec5\u5173\u6ce8\u68c0\u7d22\u3001\u805a\u7c7b\u6216\u53ef\u89c6\u5316\u7b49\u5b64\u7acb\u4efb\u52a1\uff0c\u7f3a\u4e4f\u6574\u5408\u65b9\u6848\u3002", "method": "1) \u6574\u5408arXiv\u5168\u6587\u548cOpenAlex\u5143\u6570\u636e\u6784\u5efa\u7efc\u5408\u8bed\u6599\u5e93\uff1b2) \u878d\u5408BM25\u8bcd\u6cd5\u641c\u7d22\u548c\u5d4c\u5165\u8bed\u4e49\u641c\u7d22\u7684\u6df7\u5408\u68c0\u7d22\u67b6\u6784\uff1b3) \u4f7f\u7528BERTopic\u6216\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff1b4) \u6784\u5efa\u7edf\u4e00\u8bba\u6587\u3001\u4f5c\u8005\u3001\u673a\u6784\u3001\u56fd\u5bb6\u548c\u4e3b\u9898\u7684\u5f02\u8d28\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "\u7cfb\u7edf\u5728\u591a\u4e2a\u67e5\u8be2\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa\u68c0\u7d22\u76f8\u5173\u6027\u3001\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6539\u8fdb\uff0c\u63d0\u4f9b\u591a\u5c42\u63a2\u7d22\u73af\u5883\uff0c\u63ed\u793a\u67e5\u8be2\u76f8\u5173\u7684\u6982\u5ff5\u548c\u5173\u7cfb\u56fe\u8c31\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u8f85\u52a9\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cdAI\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u66f4\u5168\u9762\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u79d1\u5b66\u6587\u732e\u63a2\u7d22\u3002"}}
{"id": "2512.12938", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.12938", "abs": "https://arxiv.org/abs/2512.12938", "authors": ["Duy A. Nguyen", "Hai H. Do", "Minh Doan", "Minh N. Do"], "title": "SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems", "comment": null, "summary": "The ability to extract value from historical data is essential for enterprise decision-making. However, much of this information remains inaccessible within large legacy file systems that lack structured organization and semantic indexing, making retrieval and analysis inefficient and error-prone. We introduce SPAR (Session-based Pipeline for Adaptive Retrieval), a conceptual framework that integrates Large Language Models (LLMs) into a Retrieval-Augmented Generation (RAG) architecture specifically designed for legacy enterprise environments. Unlike conventional RAG pipelines, which require costly construction and maintenance of full-scale vector databases that mirror the entire file system, SPAR employs a lightweight two-stage process: a semantic Metadata Index is first created, after which session-specific vector databases are dynamically generated on demand. This design reduces computational overhead while improving transparency, controllability, and relevance in retrieval. We provide a theoretical complexity analysis comparing SPAR with standard LLM-based RAG pipelines, demonstrating its computational advantages. To validate the framework, we apply SPAR to a synthesized enterprise-scale file system containing a large corpus of biomedical literature, showing improvements in both retrieval effectiveness and downstream model accuracy. Finally, we discuss design trade-offs and outline open challenges for deploying SPAR across diverse enterprise settings.", "AI": {"tldr": "SPAR\u662f\u4e00\u4e2a\u7528\u4e8e\u4f01\u4e1a\u9057\u7559\u6587\u4ef6\u7cfb\u7edf\u7684\u4f1a\u8bdd\u5f0f\u81ea\u9002\u5e94\u68c0\u7d22\u6846\u67b6\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u4e24\u9636\u6bb5\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edfRAG\u7684\u5b8c\u6574\u5411\u91cf\u6570\u636e\u5e93\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u5e76\u63d0\u5347\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u4f01\u4e1a\u5386\u53f2\u6570\u636e\u5927\u591a\u5b58\u50a8\u5728\u7f3a\u4e4f\u7ed3\u6784\u5316\u7ec4\u7ec7\u548c\u8bed\u4e49\u7d22\u5f15\u7684\u5927\u578b\u9057\u7559\u6587\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u5bfc\u81f4\u68c0\u7d22\u548c\u5206\u6790\u6548\u7387\u4f4e\u4e0b\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SPAR\u6846\u67b6\u5c06LLM\u96c6\u6210\u5230RAG\u67b6\u6784\u4e2d\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a\u9996\u5148\u521b\u5efa\u8bed\u4e49\u5143\u6570\u636e\u7d22\u5f15\uff0c\u7136\u540e\u6309\u9700\u52a8\u6001\u751f\u6210\u4f1a\u8bdd\u7279\u5b9a\u7684\u5411\u91cf\u6570\u636e\u5e93\uff0c\u66ff\u4ee3\u4f20\u7edfRAG\u7684\u5b8c\u6574\u5411\u91cf\u6570\u636e\u5e93\u6784\u5efa\u3002", "result": "\u7406\u8bba\u590d\u6742\u5ea6\u5206\u6790\u663e\u793aSPAR\u76f8\u6bd4\u6807\u51c6LLM-based RAG\u5177\u6709\u8ba1\u7b97\u4f18\u52bf\uff1b\u5728\u5408\u6210\u4f01\u4e1a\u7ea7\u751f\u7269\u533b\u5b66\u6587\u732e\u6587\u4ef6\u7cfb\u7edf\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0cSPAR\u5728\u68c0\u7d22\u6548\u679c\u548c\u4e0b\u6e38\u6a21\u578b\u51c6\u786e\u6027\u65b9\u9762\u5747\u6709\u63d0\u5347\u3002", "conclusion": "SPAR\u4e3a\u4f01\u4e1a\u9057\u7559\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u63a7\u7684\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u90e8\u7f72\u5230\u4e0d\u540c\u4f01\u4e1a\u73af\u5883\u4ecd\u9762\u4e34\u8bbe\u8ba1\u6743\u8861\u548c\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2512.12964", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.12964", "abs": "https://arxiv.org/abs/2512.12964", "authors": ["Yupeng Li", "Mingyue Cheng", "Yucong Luo", "Yitong Zhou", "Qingyang Mao", "Shijin Wang"], "title": "BLADE: A Behavior-Level Data Augmentation Framework with Dual Fusion Modeling for Multi-Behavior Sequential Recommendation", "comment": null, "summary": "Multi-behavior sequential recommendation aims to capture users' dynamic interests by modeling diverse types of user interactions over time. Although several studies have explored this setting, the recommendation performance remains suboptimal, mainly due to two fundamental challenges: the heterogeneity of user behaviors and data sparsity. To address these challenges, we propose BLADE, a framework that enhances multi-behavior modeling while mitigating data sparsity. Specifically, to handle behavior heterogeneity, we introduce a dual item-behavior fusion architecture that incorporates behavior information at both the input and intermediate levels, enabling preference modeling from multiple perspectives. To mitigate data sparsity, we design three behavior-level data augmentation methods that operate directly on behavior sequences rather than core item sequences. These methods generate diverse augmented views while preserving the semantic consistency of item sequences. These augmented views further enhance representation learning and generalization via contrastive learning. Experiments on three real-world datasets demonstrate the effectiveness of our approach.", "AI": {"tldr": "BLADE\u6846\u67b6\u901a\u8fc7\u53cc\u9879\u76ee-\u884c\u4e3a\u878d\u5408\u67b6\u6784\u5904\u7406\u884c\u4e3a\u5f02\u8d28\u6027\uff0c\u5e76\u901a\u8fc7\u884c\u4e3a\u7ea7\u6570\u636e\u589e\u5f3a\u7f13\u89e3\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u63d0\u5347\u591a\u884c\u4e3a\u5e8f\u5217\u63a8\u8350\u6027\u80fd", "motivation": "\u591a\u884c\u4e3a\u5e8f\u5217\u63a8\u8350\u9762\u4e34\u4e24\u4e2a\u57fa\u672c\u6311\u6218\uff1a\u7528\u6237\u884c\u4e3a\u7684\u5f02\u8d28\u6027\u548c\u6570\u636e\u7a00\u758f\u6027\uff0c\u5bfc\u81f4\u63a8\u8350\u6027\u80fd\u4e0d\u7406\u60f3", "method": "\u63d0\u51faBLADE\u6846\u67b6\uff1a1) \u53cc\u9879\u76ee-\u884c\u4e3a\u878d\u5408\u67b6\u6784\uff0c\u5728\u8f93\u5165\u5c42\u548c\u4e2d\u95f4\u5c42\u878d\u5165\u884c\u4e3a\u4fe1\u606f\uff1b2) \u4e09\u79cd\u884c\u4e3a\u7ea7\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u76f4\u63a5\u5728\u884c\u4e3a\u5e8f\u5217\u4e0a\u64cd\u4f5c\uff1b3) \u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u8868\u793a\u5b66\u4e60\u548c\u6cdb\u5316\u80fd\u529b", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "BLADE\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u884c\u4e3a\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u884c\u4e3a\u5f02\u8d28\u6027\u548c\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd"}}
{"id": "2512.12978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.12978", "abs": "https://arxiv.org/abs/2512.12978", "authors": ["Chee Heng Tan", "Huiying Zheng", "Jing Wang", "Zhuoyi Lin", "Shaodi Feng", "Huijing Zhan", "Xiaoli Li", "J. Senthilnath"], "title": "Do Reviews Matter for Recommendations in the Era of Large Language Models?", "comment": "11 pages, 9 figures, 3 tables", "summary": "With the advent of large language models (LLMs), the landscape of recommender systems is undergoing a significant transformation. Traditionally, user reviews have served as a critical source of rich, contextual information for enhancing recommendation quality. However, as LLMs demonstrate an unprecedented ability to understand and generate human-like text, this raises the question of whether explicit user reviews remain essential in the era of LLMs. In this paper, we provide a systematic investigation of the evolving role of text reviews in recommendation by comparing deep learning methods and LLM approaches. Particularly, we conduct extensive experiments on eight public datasets with LLMs and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We further introduce a benchmarking evaluation framework for review-aware recommender systems, RAREval, to comprehensively assess the contribution of textual reviews to the recommendation performance of review-aware recommender systems. Our framework examines various scenarios, including the removal of some or all textual reviews, random distortion, as well as recommendation performance in data sparsity and cold-start user settings. Our findings demonstrate that LLMs are capable of functioning as effective review-aware recommendation engines, generally outperforming traditional deep learning approaches, particularly in scenarios characterized by data sparsity and cold-start conditions. In addition, the removal of some or all textual reviews and random distortion does not necessarily lead to declines in recommendation accuracy. These findings motivate a rethinking of how user preference from text reviews can be more effectively leveraged. All code and supplementary materials are available at: https://github.com/zhytk/RAREval-data-processing.", "AI": {"tldr": "LLMs\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u80fd\u6709\u6548\u66ff\u4ee3\u4f20\u7edf\u7528\u6237\u8bc4\u8bba\uff0c\u5c24\u5176\u5728\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u573a\u666f\u8868\u73b0\u66f4\u4f18\uff0c\u90e8\u5206\u6216\u5168\u90e8\u79fb\u9664\u6587\u672c\u8bc4\u8bba\u4e0d\u4e00\u5b9a\u964d\u4f4e\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u53d8\u9769\u3002\u4f20\u7edf\u4e0a\u7528\u6237\u8bc4\u8bba\u662f\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u7684\u91cd\u8981\u4e0a\u4e0b\u6587\u4fe1\u606f\u6e90\uff0c\u4f46LLMs\u5177\u6709\u5f3a\u5927\u7684\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u5728LLM\u65f6\u4ee3\uff0c\u663e\u5f0f\u7684\u7528\u6237\u8bc4\u8bba\u662f\u5426\u4ecd\u7136\u5fc5\u8981\uff1f", "method": "\u57288\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5bf9LLMs\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5176\u5728\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u5fae\u8c03\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002\u5f15\u5165RAREval\u57fa\u51c6\u8bc4\u4f30\u6846\u67b6\uff0c\u5168\u9762\u8bc4\u4f30\u6587\u672c\u8bc4\u8bba\u5bf9\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u7684\u8d21\u732e\uff0c\u5305\u62ec\uff1a\u79fb\u9664\u90e8\u5206\u6216\u5168\u90e8\u6587\u672c\u8bc4\u8bba\u3001\u968f\u673a\u626d\u66f2\u3001\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u7528\u6237\u8bbe\u7f6e\u7b49\u573a\u666f\u3002", "result": "LLMs\u80fd\u591f\u4f5c\u4e3a\u6709\u6548\u7684\u8bc4\u8bba\u611f\u77e5\u63a8\u8350\u5f15\u64ce\uff0c\u901a\u5e38\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u6761\u4ef6\u4e0b\u3002\u6b64\u5916\uff0c\u79fb\u9664\u90e8\u5206\u6216\u5168\u90e8\u6587\u672c\u8bc4\u8bba\u4ee5\u53ca\u968f\u673a\u626d\u66f2\u4e0d\u4e00\u5b9a\u5bfc\u81f4\u63a8\u8350\u51c6\u786e\u6027\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u4fc3\u4f7f\u91cd\u65b0\u601d\u8003\u5982\u4f55\u66f4\u6709\u6548\u5730\u5229\u7528\u6587\u672c\u8bc4\u8bba\u4e2d\u7684\u7528\u6237\u504f\u597d\u3002LLMs\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5c55\u73b0\u51fa\u66ff\u4ee3\u4f20\u7edf\u7528\u6237\u8bc4\u8bba\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u3002"}}
{"id": "2512.12980", "categories": ["cs.IR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.12980", "abs": "https://arxiv.org/abs/2512.12980", "authors": ["Tingyang Chen", "Cong Fu", "Jiahua Wu", "Haotian Wu", "Hua Fan", "Xiangyu Ke", "Yunjun Gao", "Yabo Ni", "Anxiang Zeng"], "title": "Reveal Hidden Pitfalls and Navigate Next Generation of Vector Similarity Search from Task-Centric Views", "comment": "SIGMOD2026", "summary": "Vector Similarity Search (VSS) in high-dimensional spaces is rapidly emerging as core functionality in next-generation database systems for numerous data-intensive services -- from embedding lookups in large language models (LLMs), to semantic information retrieval and recommendation engines. Current benchmarks, however, evaluate VSS primarily on the recall-latency trade-off against a ground truth defined solely by distance metrics, neglecting how retrieval quality ultimately impacts downstream tasks. This disconnect can mislead both academic research and industrial practice.\n  We present Iceberg, a holistic benchmark suite for end-to-end evaluation of VSS methods in realistic application contexts. From a task-centric view, Iceberg uncovers the Information Loss Funnel, which identifies three principal sources of end-to-end performance degradation: (1) Embedding Loss during feature extraction; (2) Metric Misuse, where distances poorly reflect task relevance; (3) Data Distribution Sensitivity, highlighting index robustness across skews and modalities. For a more comprehensive assessment, Iceberg spans eight diverse datasets across key domains such as image classification, face recognition, text retrieval, and recommendation systems. Each dataset, ranging from 1M to 100M vectors, includes rich, task-specific labels and evaluation metrics, enabling assessment of retrieval algorithms within the full application pipeline rather than in isolation. Iceberg benchmarks 13 state-of-the-art VSS methods and re-ranks them based on application-level metrics, revealing substantial deviations from traditional rankings derived purely from recall-latency evaluations. Building on these insights, we define a set of task-centric meta-features and derive an interpretable decision tree to guide practitioners in selecting and tuning VSS methods for their specific workloads.", "AI": {"tldr": "Iceberg\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u7ef4\u5411\u91cf\u76f8\u4f3c\u6027\u641c\u7d22\u7684\u7aef\u5230\u7aef\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5173\u6ce8\u5b9e\u9645\u5e94\u7528\u6548\u679c\u800c\u975e\u4ec5\u53ec\u56de\u7387-\u5ef6\u8fdf\u6743\u8861\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u8bc4\u4f30\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u5411\u91cf\u76f8\u4f3c\u6027\u641c\u7d22\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u53ec\u56de\u7387-\u5ef6\u8fdf\u6743\u8861\uff0c\u4ec5\u57fa\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u5b9a\u4e49\u771f\u5b9e\u503c\uff0c\u5ffd\u89c6\u4e86\u68c0\u7d22\u8d28\u91cf\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5b66\u672f\u7814\u7a76\u548c\u5de5\u4e1a\u5b9e\u8df5\u7684\u8bef\u5bfc\u3002", "method": "\u63d0\u51faIceberg\u57fa\u51c6\u5957\u4ef6\uff0c\u4ece\u4efb\u52a1\u4e2d\u5fc3\u89c6\u89d2\u8bc6\u522b\u4fe1\u606f\u635f\u5931\u6f0f\u6597\u7684\u4e09\u4e2a\u4e3b\u8981\u6765\u6e90\uff1a\u5d4c\u5165\u635f\u5931\u3001\u5ea6\u91cf\u8bef\u7528\u548c\u6570\u636e\u5206\u5e03\u654f\u611f\u6027\u3002\u6db5\u76d68\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\uff081M-100M\u5411\u91cf\uff09\uff0c\u5305\u542b\u4e30\u5bcc\u7684\u4efb\u52a1\u7279\u5b9a\u6807\u7b7e\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5bf913\u79cd\u6700\u5148\u8fdb\u7684VSS\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u57fa\u4e8e\u5e94\u7528\u7ea7\u6307\u6807\u7684\u91cd\u65b0\u6392\u540d\u4e0e\u4f20\u7edf\u57fa\u4e8e\u53ec\u56de\u7387-\u5ef6\u8fdf\u7684\u6392\u540d\u5b58\u5728\u663e\u8457\u504f\u5dee\u3002\u5b9a\u4e49\u4e86\u4efb\u52a1\u4e2d\u5fc3\u5143\u7279\u5f81\u5e76\u63a8\u5bfc\u51fa\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u6811\uff0c\u4e3a\u4ece\u4e1a\u8005\u6839\u636e\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u548c\u8c03\u4f18VSS\u65b9\u6cd5\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "Iceberg\u63d0\u4f9b\u4e86\u5411\u91cf\u76f8\u4f3c\u6027\u641c\u7d22\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u8bc4\u4f30\u4e0e\u5b9e\u9645\u5e94\u7528\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u65b9\u6cd5\u9009\u62e9\u548c\u8c03\u4f18\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2512.13001", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.13001", "abs": "https://arxiv.org/abs/2512.13001", "authors": ["Genki Kusano", "Kenya Abe", "Kunihiro Takeoka"], "title": "Are Large Language Models Really Effective for Training-Free Cold-Start Recommendation?", "comment": null, "summary": "Recommender systems usually rely on large-scale interaction data to learn from users' past behaviors and make accurate predictions. However, real-world applications often face situations where no training data is available, such as when launching new services or handling entirely new users. In such cases, conventional approaches cannot be applied. This study focuses on training-free recommendation, where no task-specific training is performed, and particularly on \\textit{training-free cold-start recommendation} (TFCSR), the more challenging case where the target user has no interactions. Large language models (LLMs) have recently been explored as a promising solution, and numerous studies have been proposed. As the ability of text embedding models (TEMs) increases, they are increasingly recognized as applicable to training-free recommendation, but no prior work has directly compared LLMs and TEMs under identical conditions. We present the first controlled experiments that systematically evaluate these two approaches in the same setting. The results show that TEMs outperform LLM rerankers, and this trend holds not only in cold-start settings but also in warm-start settings with rich interactions. These findings indicate that direct LLM ranking is not the only viable option, contrary to the commonly shared belief, and TEM-based approaches provide a stronger and more scalable basis for training-free recommendation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u7cfb\u7edf\u6bd4\u8f83\u4e86LLM\u548cTEM\u5728\u8bad\u7ec3\u514d\u8d39\u63a8\u8350\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0TEM\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u548c\u70ed\u542f\u52a8\u573a\u666f\u4e0b\u5747\u4f18\u4e8eLLM\u91cd\u6392\u5e8f\u5668\uff0c\u6311\u6218\u4e86LLM\u76f4\u63a5\u6392\u5e8f\u662f\u552f\u4e00\u53ef\u884c\u65b9\u6848\u7684\u666e\u904d\u8ba4\u77e5\u3002", "motivation": "\u73b0\u5b9e\u63a8\u8350\u7cfb\u7edf\u5e38\u9762\u4e34\u65e0\u8bad\u7ec3\u6570\u636e\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff08\u5982\u65b0\u670d\u52a1\u4e0a\u7ebf\u6216\u5168\u65b0\u7528\u6237\uff09\uff0c\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5e94\u7528\u3002\u867d\u7136LLM\u88ab\u63a2\u7d22\u4e3a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff08TEM\uff09\u80fd\u529b\u63d0\u5347\u540e\u4e5f\u9002\u7528\u4e8e\u8bad\u7ec3\u514d\u8d39\u63a8\u8350\uff0c\u4f46\u6b64\u524d\u6ca1\u6709\u7814\u7a76\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u76f4\u63a5\u6bd4\u8f83\u8fd9\u4e24\u79cd\u65b9\u6cd5\u3002", "method": "\u9996\u6b21\u5728\u76f8\u540c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u548cTEM\u4e24\u79cd\u65b9\u6cd5\u5728\u8bad\u7ec3\u514d\u8d39\u63a8\u8350\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u5173\u6ce8\u8bad\u7ec3\u514d\u8d39\u51b7\u542f\u52a8\u63a8\u8350\uff08TFCSR\uff09\u8fd9\u4e00\u66f4\u5177\u6311\u6218\u6027\u7684\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aTEM\u65b9\u6cd5\u4f18\u4e8eLLM\u91cd\u6392\u5e8f\u5668\uff0c\u8fd9\u4e00\u8d8b\u52bf\u4e0d\u4ec5\u5728\u51b7\u542f\u52a8\u8bbe\u7f6e\u4e2d\u6210\u7acb\uff0c\u5728\u5177\u6709\u4e30\u5bcc\u4ea4\u4e92\u7684\u70ed\u542f\u52a8\u8bbe\u7f6e\u4e2d\u4e5f\u540c\u6837\u6210\u7acb\u3002", "conclusion": "\u76f4\u63a5LLM\u6392\u5e8f\u5e76\u975e\u552f\u4e00\u53ef\u884c\u9009\u9879\uff0cTEM\u65b9\u6cd5\u4e3a\u8bad\u7ec3\u514d\u8d39\u63a8\u8350\u63d0\u4f9b\u4e86\u66f4\u5f3a\u4e14\u66f4\u5177\u6269\u5c55\u6027\u7684\u57fa\u7840\uff0c\u6311\u6218\u4e86\u5f53\u524d\u666e\u904d\u8ba4\u77e5\u3002"}}
{"id": "2512.13037", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13037", "abs": "https://arxiv.org/abs/2512.13037", "authors": ["Taoran Sheng", "Sathappan Muthiah", "Atiq Islam", "Jinming Feng"], "title": "Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer", "comment": null, "summary": "In e-commerce shopping, aligning search results with a buyer's immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer's shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer's interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u81ea\u9002\u5e94\u7535\u5546\u641c\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u7b80\u5355\u542f\u53d1\u5f0f\u7279\u5f81\u5230\u5148\u8fdb\u5e8f\u5217\u6a21\u578b\u7684\u6e10\u8fdb\u5f0f\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u7ed3\u679c\u4e0e\u4e70\u5bb6\u5f53\u524d\u610f\u56fe\u7684\u5339\u914d\u5ea6\u3002", "motivation": "\u7535\u5546\u641c\u7d22\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u5982\u4f55\u5728\u4e70\u5bb6\u8d2d\u7269\u65c5\u7a0b\u4e2d\uff08\u4ece\u6d4f\u89c8\u5230\u8d2d\u4e70\u51b3\u7b56\uff0c\u6216\u610f\u56fe\u8f6c\u6362\u65f6\uff09\u52a8\u6001\u8c03\u6574\u641c\u7d22\u7ed3\u679c\u4ee5\u5339\u914d\u5176\u5373\u65f6\u9700\u6c42\u548c\u504f\u597d\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6e10\u8fdb\u65b9\u6cd5\uff1a\u4ece\u57fa\u7840\u65b9\u6cd5\u5f00\u59cb\uff0c\u9010\u6b65\u878d\u5165\u66f4\u591a\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u6700\u5148\u8fdb\u6280\u672f\uff0c\u6784\u5efa\u6f14\u5316\u4e0a\u4e0b\u6587\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u641c\u7d22\u7ed3\u679c\u9875\u9762\u7684\u5546\u54c1\u6392\u5e8f\u3002", "result": "\u4ece\u7b80\u5355\u542f\u53d1\u5f0f\u81ea\u56de\u5f52\u7279\u5f81\u5230\u5148\u8fdb\u5e8f\u5217\u6a21\u578b\u7684\u6e10\u8fdb\u589e\u5f3a\u663e\u8457\u63d0\u5347\u4e86\u6392\u5e8f\u5668\u6027\u80fd\uff0c\u4e0a\u4e0b\u6587\u6280\u672f\u7684\u96c6\u6210\u6539\u5584\u4e86\u751f\u4ea7\u6392\u5e8f\u5668\u6548\u679c\uff0c\u5728\u79bb\u7ebf\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5747\u63d0\u9ad8\u4e86\u5e73\u5747\u5012\u6570\u6392\u540d(MRR)\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u8fed\u4ee3\u65b9\u6cd5\u5728\u7535\u5546\u5e73\u53f0\u641c\u7d22\u7ed3\u679c\u4e0a\u4e0b\u6587\u5316\u65b9\u9762\u7684\u91cd\u8981\u8d21\u732e\uff0c\u8bc1\u660e\u4e86\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u641c\u7d22\u7ed3\u679c\u4e0e\u4e70\u5bb6\u5174\u8da3\u548c\u5f53\u524d\u641c\u7d22\u610f\u56fe\u7684\u5339\u914d\u5ea6\u3002"}}
{"id": "2512.13074", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13074", "abs": "https://arxiv.org/abs/2512.13074", "authors": ["Huimu Wang", "Yiming Qiu", "Xingzhi Yao", "Zhiguo Chen", "Guoyu Tang", "Songlin Wang", "Sulong Xu", "Mingming Li"], "title": "A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval", "comment": null, "summary": "Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.\n  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCI\u6846\u67b6\u89e3\u51b3\u7a20\u5bc6\u68c0\u7d22\u4e2d\u53cc\u5854\u67b6\u6784\u5e26\u6765\u7684\u8868\u793a\u7a7a\u95f4\u4e0d\u5bf9\u9f50\u548c\u68c0\u7d22\u7d22\u5f15\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7\u5bf9\u79f0\u8868\u793a\u5bf9\u9f50\u548c\u53cc\u5854\u534f\u540c\u4e00\u81f4\u7d22\u5f15\u4e24\u4e2a\u6a21\u5757\uff0c\u63d0\u5347\u5339\u914d\u7cbe\u5ea6\u548c\u68c0\u7d22\u7a33\u5b9a\u6027\u3002", "motivation": "\u7a20\u5bc6\u68c0\u7d22\u5df2\u6210\u4e3a\u5927\u89c4\u6a21\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u884c\u4e1a\u6807\u51c6\uff0c\u4f46\u5176\u5e7f\u6cdb\u91c7\u7528\u7684\u53cc\u5854\u7f16\u7801\u67b6\u6784\u5b58\u5728\u8868\u793a\u7a7a\u95f4\u4e0d\u5bf9\u9f50\u548c\u68c0\u7d22\u7d22\u5f15\u4e0d\u4e00\u81f4\u7684\u56fa\u6709\u6311\u6218\uff0c\u8fd9\u4f1a\u964d\u4f4e\u5339\u914d\u7cbe\u5ea6\u3001\u68c0\u7d22\u7a33\u5b9a\u6027\u4ee5\u53ca\u5bf9\u957f\u5c3e\u67e5\u8be2\u7684\u6027\u80fd\uff0c\u8fd9\u4e9b\u95ee\u9898\u5728\u8bed\u4e49ID\u751f\u6210\u4e2d\u8fdb\u4e00\u6b65\u653e\u5927\uff0c\u9650\u5236\u4e86\u4e0b\u6e38\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u4e0a\u9650\u3002", "method": "\u63d0\u51faSCI\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u6a21\u5757\uff1a1) \u5bf9\u79f0\u8868\u793a\u5bf9\u9f50\u6a21\u5757\uff1a\u91c7\u7528\u521b\u65b0\u7684\u8f93\u5165\u4ea4\u6362\u673a\u5236\u7edf\u4e00\u53cc\u5854\u8868\u793a\u7a7a\u95f4\uff0c\u65e0\u9700\u589e\u52a0\u53c2\u6570\uff1b2) \u53cc\u5854\u534f\u540c\u4e00\u81f4\u7d22\u5f15\u6a21\u5757\uff1a\u901a\u8fc7\u53cc\u89c6\u56fe\u7d22\u5f15\u7b56\u7565\u91cd\u65b0\u8bbe\u8ba1\u68c0\u7d22\u8def\u5f84\uff0c\u4fdd\u6301\u4ece\u8bad\u7ec3\u5230\u63a8\u7406\u7684\u4e00\u81f4\u6027\u3002\u8be5\u6846\u67b6\u7cfb\u7edf\u3001\u8f7b\u91cf\u3001\u5de5\u7a0b\u53cb\u597d\uff0c\u652f\u6301\u5341\u4ebf\u7ea7\u90e8\u7f72\u3002", "result": "\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5728\u516c\u5171\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u7535\u5546\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "SCI\u6846\u67b6\u901a\u8fc7\u89e3\u51b3\u53cc\u5854\u67b6\u6784\u7684\u56fa\u6709\u6311\u6218\uff0c\u63d0\u5347\u4e86\u7a20\u5bc6\u68c0\u7d22\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8bed\u4e49ID\u751f\u6210\u548c\u4e0b\u6e38\u751f\u6210\u6a21\u578b\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.13120", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13120", "abs": "https://arxiv.org/abs/2512.13120", "authors": ["Mabiao Long", "Jiaxi Liu", "Yufeng Li", "Hao Xiong", "Junchi Yan", "Kefan Wang", "Yi Cao", "Jiandong Ding"], "title": "Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation", "comment": null, "summary": "Deploying dynamic heterogeneous graph embeddings in production faces key challenges of scalability, data freshness, and cold-start. This paper introduces a practical, two-stage solution that balances deep graph representation with low-latency incremental updates. Our framework combines HetSGFormer, a scalable graph transformer for static learning, with Incremental Locally Linear Embedding (ILLE), a lightweight, CPU-based algorithm for real-time updates. HetSGFormer captures global structure with linear scalability, while ILLE provides rapid, targeted updates to incorporate new data, thus avoiding costly full retraining. This dual approach is cold-start resilient, leveraging the graph to create meaningful embeddings from sparse data. On billion-scale graphs, A/B tests show HetSGFormer achieved up to a 6.11% lift in Advertiser Value over previous methods, while the ILLE module added another 3.22% lift and improved embedding refresh timeliness by 83.2%. Our work provides a validated framework for deploying dynamic graph learning in production environments.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u52a8\u6001\u5f02\u6784\u56fe\u5d4c\u5165\u6846\u67b6\uff1aHetSGFormer\u7528\u4e8e\u9759\u6001\u5b66\u4e60\uff0cILLE\u7528\u4e8e\u5b9e\u65f6\u589e\u91cf\u66f4\u65b0\uff0c\u89e3\u51b3\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3001\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u52a8\u6001\u5f02\u6784\u56fe\u5d4c\u5165\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u53ef\u6269\u5c55\u6027\uff08\u5904\u7406\u5341\u4ebf\u7ea7\u56fe\uff09\u3001\u6570\u636e\u65b0\u9c9c\u5ea6\uff08\u5b9e\u65f6\u66f4\u65b0\uff09\u548c\u51b7\u542f\u52a8\u95ee\u9898\uff08\u7a00\u758f\u6570\u636e\uff09\u3002\u9700\u8981\u5e73\u8861\u6df1\u5ea6\u56fe\u8868\u793a\u548c\u4f4e\u5ef6\u8fdf\u589e\u91cf\u66f4\u65b0\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) HetSGFormer - \u53ef\u6269\u5c55\u7684\u56fe\u53d8\u6362\u5668\uff0c\u7528\u4e8e\u9759\u6001\u5b66\u4e60\uff0c\u5177\u6709\u7ebf\u6027\u53ef\u6269\u5c55\u6027\uff1b2) ILLE - \u8f7b\u91cf\u7ea7CPU\u589e\u91cf\u5c40\u90e8\u7ebf\u6027\u5d4c\u5165\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u66f4\u65b0\u3002\u4e24\u8005\u7ed3\u5408\u907f\u514d\u6602\u8d35\u7684\u5168\u91cf\u91cd\u8bad\u7ec3\u3002", "result": "\u5728\u5341\u4ebf\u7ea7\u56fe\u4e0a\uff0cHetSGFormer\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u63d0\u5347\u5e7f\u544a\u4e3b\u4ef7\u503c6.11%\uff0cILLE\u6a21\u5757\u989d\u5916\u63d0\u53473.22%\uff0c\u5d4c\u5165\u5237\u65b0\u53ca\u65f6\u6027\u6539\u558483.2%\u3002\u6846\u67b6\u5177\u6709\u51b7\u542f\u52a8\u5f39\u6027\uff0c\u80fd\u4ece\u7a00\u758f\u6570\u636e\u751f\u6210\u6709\u610f\u4e49\u7684\u5d4c\u5165\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u751f\u4ea7\u73af\u5883\u52a8\u6001\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u6210\u529f\u5e73\u8861\u4e86\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u548c\u5b9e\u65f6\u66f4\u65b0\u9700\u6c42\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2512.13173", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.13173", "abs": "https://arxiv.org/abs/2512.13173", "authors": ["Ivica Kostric", "Ujwal Gadiraju", "Krisztian Balog"], "title": "Know Your Users! Estimating User Domain Knowledge in Conversational Recommenders", "comment": null, "summary": "The ideal conversational recommender system (CRS) acts like a savvy salesperson, adapting its language and suggestions to each user's level of expertise. However, most current systems treat all users as experts, leading to frustrating and inefficient interactions when users are unfamiliar with a domain. Systems that can adapt their conversational strategies to a user's knowledge level stand to offer a much more natural and effective experience. To make a step toward such adaptive systems, we introduce a new task: estimating user domain knowledge from conversations, enabling a CRS to better understand user needs and personalize interactions. A key obstacle to developing such adaptive systems is the lack of suitable data; to our knowledge, no existing dataset captures the conversational behaviors of users with varying levels of domain knowledge. Furthermore, in most dialogue collection protocols, users are free to express their own preferences, which tends to concentrate on popular items and well-known features, offering little insight into how novices explore or learn about unfamiliar features. To address this, we design a game-based data collection protocol that elicits varied expressions of knowledge, release the resulting dataset, and provide an initial analysis to highlight its potential for future work on user-knowledge-aware CRS.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u4efb\u52a1\uff1a\u4ece\u5bf9\u8bdd\u4e2d\u4f30\u8ba1\u7528\u6237\u9886\u57df\u77e5\u8bc6\uff0c\u4ee5\u6784\u5efa\u81ea\u9002\u5e94\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u5e76\u53d1\u5e03\u9996\u4e2a\u5305\u542b\u4e0d\u540c\u77e5\u8bc6\u6c34\u5e73\u7528\u6237\u5bf9\u8bdd\u884c\u4e3a\u7684\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524d\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u5c06\u6240\u6709\u7528\u6237\u89c6\u4e3a\u4e13\u5bb6\uff0c\u5bfc\u81f4\u4e0d\u719f\u6089\u9886\u57df\u7684\u7528\u6237\u4ea4\u4e92\u4f53\u9a8c\u5dee\u3002\u9700\u8981\u80fd\u6839\u636e\u7528\u6237\u77e5\u8bc6\u6c34\u5e73\u81ea\u9002\u5e94\u8c03\u6574\u5bf9\u8bdd\u7b56\u7565\u7684\u7cfb\u7edf\uff0c\u4f46\u7f3a\u4e4f\u5408\u9002\u7684\u6570\u636e\u96c6\u6765\u7814\u7a76\u4e0d\u540c\u77e5\u8bc6\u6c34\u5e73\u7528\u6237\u7684\u5bf9\u8bdd\u884c\u4e3a\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u6e38\u620f\u7684\u6570\u636e\u6536\u96c6\u534f\u8bae\uff0c\u6fc0\u53d1\u7528\u6237\u8868\u8fbe\u4e0d\u540c\u5c42\u6b21\u7684\u77e5\u8bc6\uff0c\u5e76\u53d1\u5e03\u7531\u6b64\u4ea7\u751f\u7684\u6570\u636e\u96c6\u3002\u63d0\u51fa\u4ece\u5bf9\u8bdd\u4e2d\u4f30\u8ba1\u7528\u6237\u9886\u57df\u77e5\u8bc6\u7684\u65b0\u4efb\u52a1\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u6355\u6349\u4e0d\u540c\u77e5\u8bc6\u6c34\u5e73\u7528\u6237\u5bf9\u8bdd\u884c\u4e3a\u7684\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u4e86\u521d\u6b65\u5206\u6790\uff0c\u5c55\u793a\u4e86\u8be5\u6570\u636e\u96c6\u5728\u672a\u6765\u7528\u6237\u77e5\u8bc6\u611f\u77e5\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u7528\u6237\u9886\u57df\u77e5\u8bc6\u4f30\u8ba1\u4efb\u52a1\u548c\u53d1\u5e03\u76f8\u5e94\u6570\u636e\u96c6\uff0c\u4e3a\u6784\u5efa\u81ea\u9002\u5e94\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u4e2a\u6027\u5316\u4ea4\u4e92\u80fd\u529b\u7684\u95ee\u9898\u3002"}}
{"id": "2512.13368", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.13368", "abs": "https://arxiv.org/abs/2512.13368", "authors": ["Mengyang Ma", "Xiaopeng Li", "Wanyu Wang", "Zhaocheng Du", "Jingtong Gao", "Pengyue Jia", "Yuyang Ye", "Yiqi Wang", "Yunpeng Weng", "Weihong Luo", "Xiao Han", "Xiangyu Zhao"], "title": "BlossomRec: Block-level Fused Sparse Attention Mechanism for Sequential Recommendations", "comment": null, "summary": "Transformer structures have been widely used in sequential recommender systems (SRS). However, as user interaction histories increase, computational time and memory requirements also grow. This is mainly caused by the standard attention mechanism. Although there exist many methods employing efficient attention and SSM-based models, these approaches struggle to effectively model long sequences and may exhibit unstable performance on short sequences. To address these challenges, we design a sparse attention mechanism, BlossomRec, which models both long-term and short-term user interests through attention computation to achieve stable performance across sequences of varying lengths. Specifically, we categorize user interests in recommendation systems into long-term and short-term interests, and compute them using two distinct sparse attention patterns, with the results combined through a learnable gated output. Theoretically, it significantly reduces the number of interactions participating in attention computation. Extensive experiments on four public datasets demonstrate that BlossomRec, when integrated with state-of-the-art Transformer-based models, achieves comparable or even superior performance while significantly reducing memory usage, providing strong evidence of BlossomRec's efficiency and effectiveness.The code is available at https://github.com/ronineume/BlossomRec.", "AI": {"tldr": "BlossomRec\u662f\u4e00\u79cd\u7528\u4e8e\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u5206\u79bb\u5efa\u6a21\u957f\u77ed\u671f\u7528\u6237\u5174\u8da3\u6765\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edfTransformer\u5728\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u4e2d\u968f\u7740\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u589e\u957f\uff0c\u8ba1\u7b97\u65f6\u95f4\u548c\u5185\u5b58\u9700\u6c42\u6025\u5267\u589e\u52a0\u3002\u73b0\u6709\u9ad8\u6548\u6ce8\u610f\u529b\u65b9\u6cd5\u548cSSM\u6a21\u578b\u5728\u957f\u5e8f\u5217\u5efa\u6a21\u6548\u679c\u4e0d\u4f73\uff0c\u5728\u77ed\u5e8f\u5217\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002", "method": "\u8bbe\u8ba1\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236BlossomRec\uff0c\u5c06\u7528\u6237\u5174\u8da3\u5206\u4e3a\u957f\u671f\u548c\u77ed\u671f\u5174\u8da3\uff0c\u5206\u522b\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u7a00\u758f\u6ce8\u610f\u529b\u6a21\u5f0f\u8ba1\u7b97\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u95e8\u63a7\u8f93\u51fa\u7ed3\u5408\u7ed3\u679c\uff0c\u663e\u8457\u51cf\u5c11\u53c2\u4e0e\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u4ea4\u4e92\u6570\u91cf\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBlossomRec\u4e0e\u6700\u5148\u8fdb\u7684Transformer\u6a21\u578b\u7ed3\u5408\u65f6\uff0c\u5728\u4fdd\u6301\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\u3002", "conclusion": "BlossomRec\u901a\u8fc7\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u5efa\u6a21\u4e0d\u540c\u957f\u5ea6\u7684\u5e8f\u5217\uff0c\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.13396", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.13396", "abs": "https://arxiv.org/abs/2512.13396", "authors": ["Chaohua Yang", "Dugang Liu", "Shiwei Li", "Yuwen Fu", "Xing Tang", "Weihong Luo", "Xiangyu Zhao", "Xiuqiang He", "Zhong Ming"], "title": "Automated Information Flow Selection for Multi-scenario Multi-task Recommendation", "comment": "10 Pages, 6 Figures, WSDM 2026 Accepted", "summary": "Multi-scenario multi-task recommendation (MSMTR) systems must address recommendation demands across diverse scenarios while simultaneously optimizing multiple objectives, such as click-through rate and conversion rate. Existing MSMTR models typically consist of four information units: scenario-shared, scenario-specific, task-shared, and task-specific networks. These units interact to generate four types of relationship information flows, directed from scenario-shared or scenario-specific networks to task-shared or task-specific networks. However, these models face two main limitations: 1) They often rely on complex architectures, such as mixture-of-experts (MoE) networks, which increase the complexity of information fusion, model size, and training cost. 2) They extract all available information flows without filtering out irrelevant or even harmful content, introducing potential noise. Regarding these challenges, we propose a lightweight Automated Information Flow Selection (AutoIFS) framework for MSMTR. To tackle the first issue, AutoIFS incorporates low-rank adaptation (LoRA) to decouple the four information units, enabling more flexible and efficient information fusion with minimal parameter overhead. To address the second issue, AutoIFS introduces an information flow selection network that automatically filters out invalid scenario-task information flows based on model performance feedback. It employs a simple yet effective pruning function to eliminate useless information flows, thereby enhancing the impact of key relationships and improving model performance. Finally, we evaluate AutoIFS and confirm its effectiveness through extensive experiments on two public benchmark datasets and an online A/B test.", "AI": {"tldr": "\u63d0\u51faAutoIFS\u6846\u67b6\uff0c\u901a\u8fc7LoRA\u89e3\u8026\u4fe1\u606f\u5355\u5143\u548c\u81ea\u52a8\u4fe1\u606f\u6d41\u9009\u62e9\uff0c\u89e3\u51b3\u591a\u573a\u666f\u591a\u4efb\u52a1\u63a8\u8350\u4e2d\u67b6\u6784\u590d\u6742\u548c\u4fe1\u606f\u566a\u58f0\u95ee\u9898", "motivation": "\u73b0\u6709MSMTR\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u4f9d\u8d56\u590d\u6742\u67b6\u6784\uff08\u5982MoE\uff09\uff0c\u589e\u52a0\u4fe1\u606f\u878d\u5408\u590d\u6742\u5ea6\u3001\u6a21\u578b\u5927\u5c0f\u548c\u8bad\u7ec3\u6210\u672c\uff1b2) \u63d0\u53d6\u6240\u6709\u4fe1\u606f\u6d41\u800c\u4e0d\u8fc7\u6ee4\u65e0\u5173\u6216\u6709\u5bb3\u5185\u5bb9\uff0c\u5f15\u5165\u566a\u58f0", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7AutoIFS\u6846\u67b6\uff1a1) \u4f7f\u7528\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u89e3\u8026\u56db\u4e2a\u4fe1\u606f\u5355\u5143\uff0c\u5b9e\u73b0\u7075\u6d3b\u9ad8\u6548\u7684\u4fe1\u606f\u878d\u5408\uff1b2) \u5f15\u5165\u4fe1\u606f\u6d41\u9009\u62e9\u7f51\u7edc\uff0c\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u53cd\u9988\u81ea\u52a8\u8fc7\u6ee4\u65e0\u6548\u573a\u666f-\u4efb\u52a1\u4fe1\u606f\u6d41\uff0c\u4f7f\u7528\u526a\u679d\u51fd\u6570\u6d88\u9664\u65e0\u7528\u4fe1\u606f\u6d41", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86AutoIFS\u7684\u6709\u6548\u6027", "conclusion": "AutoIFS\u901a\u8fc7LoRA\u89e3\u8026\u548c\u81ea\u52a8\u4fe1\u606f\u6d41\u9009\u62e9\uff0c\u89e3\u51b3\u4e86MSMTR\u4e2d\u7684\u67b6\u6784\u590d\u6742\u6027\u548c\u4fe1\u606f\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd"}}
