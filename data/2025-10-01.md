<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [On-Premise AI for the Newsroom: Evaluating Small Language Models for Investigative Document Search](https://arxiv.org/abs/2509.25494)
*Nick Hagar,Nicholas Diakopoulos,Jeremy Gilbert*

Main category: cs.IR

TL;DR: 本文提出了一种面向新闻工作者的LLM文档搜索方法，通过五阶段流程（语料库摘要、搜索规划、并行线程执行、质量评估和合成）使用小型本地部署模型，确保数据安全和可审计性。


<details>
  <summary>Details</summary>
Motivation: 解决新闻编辑室采用LLM进行文档发现时面临的幻觉风险、验证负担和数据隐私问题，为记者提供透明可控的AI工具。

Method: 使用小型本地部署语言模型（Gemma 3 12B、Qwen 3 14B和GPT-OSS 20B），构建五阶段管道：语料库摘要、搜索规划、并行线程执行、质量评估和合成，通过显式引用链确保完全可审计性。

Result: 所有模型都实现了高引用有效性，可在标准桌面硬件（如24GB内存）上有效运行，但存在错误传播和多阶段合成中的性能变化问题，性能受训练数据与语料内容重叠度影响显著。

Conclusion: 有效的新闻编辑室AI部署需要仔细的模型选择和系统设计，以及人工监督来保持准确性和问责标准。

Abstract: Investigative journalists routinely confront large document collections.
Large language models (LLMs) with retrieval-augmented generation (RAG)
capabilities promise to accelerate the process of document discovery, but
newsroom adoption remains limited due to hallucination risks, verification
burden, and data privacy concerns. We present a journalist-centered approach to
LLM-powered document search that prioritizes transparency and editorial control
through a five-stage pipeline -- corpus summarization, search planning,
parallel thread execution, quality evaluation, and synthesis -- using small,
locally-deployable language models that preserve data security and maintain
complete auditability through explicit citation chains. Evaluating three
quantized models (Gemma 3 12B, Qwen 3 14B, and GPT-OSS 20B) on two corpora, we
find substantial variation in reliability. All models achieved high citation
validity and ran effectively on standard desktop hardware (e.g., 24 GB of
memory), demonstrating feasibility for resource-constrained newsrooms. However,
systematic challenges emerged, including error propagation through multi-stage
synthesis and dramatic performance variation based on training data overlap
with corpus content. These findings suggest that effective newsroom AI
deployment requires careful model selection and system design, alongside human
oversight for maintaining standards of accuracy and accountability.

</details>


### [2] [TRUE: A Reproducible Framework for LLM-Driven Relevance Judgment in Information Retrieval](https://arxiv.org/abs/2509.25602)
*Mouly Dewan,Jiqun Liu,Chirag Shah*

Main category: cs.IR

TL;DR: 本文提出了TRUE框架，用于生成基于LLM的相关性判断，解决了现有方法缺乏标准化工作流程的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的相关性判断方法严重依赖敏感提示策略，缺乏生成可靠标签的标准化工作流程。

Method: 采用任务感知的基于标准的评估(TRUE)框架，通过迭代数据采样和推理，从意图、覆盖范围、特异性、准确性和有用性等多个维度评估相关性判断。

Result: 在TREC DL 2019、2020和LLMJudge数据集上的评估显示，TRUE在系统排名LLM排行榜上表现出色。

Conclusion: TRUE提供了一个可复现的LLM相关性判断框架，并在多个维度上证明了其有效性。

Abstract: LLM-based relevance judgment generation has become a crucial approach in
advancing evaluation methodologies in Information Retrieval (IR). It has
progressed significantly, often showing high correlation with human judgments
as reflected in LLMJudge leaderboards \cite{rahmani2025judging}. However,
existing methods for relevance judgments, rely heavily on sensitive prompting
strategies, lacking standardized workflows for generating reliable labels. To
fill this gap, we reintroduce our method, \textit{Task-aware Rubric-based
Evaluation} (TRUE), for relevance judgment generation. Originally developed for
usefulness evaluation in search sessions, we extend TRUE to mitigate the gap in
relevance judgment due to its demonstrated effectiveness and reproducible
workflow. This framework leverages iterative data sampling and reasoning to
evaluate relevance judgments across multiple factors including intent,
coverage, specificity, accuracy and usefulness. In this paper, we evaluate TRUE
on the TREC DL 2019, 2020 and LLMJudge datasets and our results show that TRUE
achieves strong performance on the system-ranking LLM leaderboards. The primary
focus of this work is to provide a reproducible framework for LLM-based
relevance judgments, and we further analyze the effectiveness of TRUE across
multiple dimensions.

</details>


### [3] [HiFIRec: Towards High-Frequency yet Low-Intention Behaviors for Multi-Behavior Recommendation](https://arxiv.org/abs/2509.25755)
*Ruiqi Luo,Ran Jin,Zhenglong Li,Kaixi Hu,Xiaohui Tao,Lin Li*

Main category: cs.IR

TL;DR: 提出HiFIRec方法，通过分层行为建模解决多行为推荐中高频低意图行为的噪声问题，显著提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有多行为推荐方法统一建模用户意图，未能充分考虑不同行为间的异质性，特别是高频低意图行为可能包含噪声信号和误导性频繁模式，阻碍用户意图学习

Method: 采用分层行为建模：通过层间邻域聚合提取邻域信息，自适应跨层特征融合捕捉用户意图；提出强度感知非采样策略动态调整负样本权重

Result: 在两个基准数据集上，HiFIRec相比多个最先进方法，HR@10指标相对提升4.21%-6.81%

Conclusion: HiFIRec通过分层抑制高频低意图行为的噪声影响，有效提升了多行为推荐的性能

Abstract: Multi-behavior recommendation leverages multiple types of user-item
interactions to address data sparsity and cold-start issues, providing
personalized services in domains such as healthcare and e-commerce. Most
existing methods utilize graph neural networks to model user intention in a
unified manner, which inadequately considers the heterogeneity across different
behaviors. Especially, high-frequency yet low-intention behaviors may
implicitly contain noisy signals, and frequent patterns that are plausible
while misleading, thereby hindering the learning of user intentions. To this
end, this paper proposes a novel multi-behavior recommendation method, HiFIRec,
that corrects the effect of high-frequency yet low-intention behaviors by
differential behavior modeling. To revise the noisy signals, we hierarchically
suppress it across layers by extracting neighborhood information through
layer-wise neighborhood aggregation and further capturing user intentions
through adaptive cross-layer feature fusion. To correct plausible frequent
patterns, we propose an intensity-aware non-sampling strategy that dynamically
adjusts the weights of negative samples. Extensive experiments on two
benchmarks show that HiFIRec relatively improves HR@10 by 4.21%-6.81% over
several state-of-the-art methods.

</details>


### [4] [Better with Less: Small Proprietary Models Surpass Large Language Models in Financial Transaction Understanding](https://arxiv.org/abs/2509.25803)
*Wanying Ding,Savinay Narendra,Xiran Shi,Adwait Ratnaparkhi,Chengrui Yang,Nikoo Sabzevar,Ziyan Yin*

Main category: cs.IR

TL;DR: 本文评估了三种Transformer模型在金融交易理解任务中的表现，发现针对特定领域开发的专有小模型在速度和成本效率上优于通用大语言模型，最终采用专有解码器模型实现了14%的交易覆盖提升和1300万美元的年成本节约。


<details>
  <summary>Details</summary>
Motivation: 金融交易分析对监管合规、欺诈检测和决策支持至关重要。鉴于Transformer模型在多个领域表现出色，本文旨在探索其在金融交易理解方面的潜力。

Method: 对三种Transformer模型类型（仅编码器、仅解码器、编码器-解码器）进行广泛实验，每种类型评估预训练LLM、微调LLM和从头开发的专有小模型三种选项。

Result: LLaMA3-8b、Flan-T5和SBERT等LLM在金融交易理解任务中并未显著优于专有小模型，特别是在速度和成本效率方面。专有模型处理速度更快、运营成本更低。

Conclusion: 基于领域特定需求进行模型选择至关重要，在专业应用中定制化的专有模型相比通用LLM具有潜在优势。最终采用专有仅解码器模型处理复杂交易，实现14%交易覆盖提升和1300万美元年成本节约。

Abstract: Analyzing financial transactions is crucial for ensuring regulatory
compliance, detecting fraud, and supporting decisions. The complexity of
financial transaction data necessitates advanced techniques to extract
meaningful insights and ensure accurate analysis. Since Transformer-based
models have shown outstanding performance across multiple domains, this paper
seeks to explore their potential in understanding financial transactions. This
paper conducts extensive experiments to evaluate three types of Transformer
models: Encoder-Only, Decoder-Only, and Encoder-Decoder models. For each type,
we explore three options: pretrained LLMs, fine-tuned LLMs, and small
proprietary models developed from scratch. Our analysis reveals that while
LLMs, such as LLaMA3-8b, Flan-T5, and SBERT, demonstrate impressive
capabilities in various natural language processing tasks, they do not
significantly outperform small proprietary models in the specific context of
financial transaction understanding. This phenomenon is particularly evident in
terms of speed and cost efficiency. Proprietary models, tailored to the unique
requirements of transaction data, exhibit faster processing times and lower
operational costs, making them more suitable for real-time applications in the
financial sector. Our findings highlight the importance of model selection
based on domain-specific needs and underscore the potential advantages of
customized proprietary models over general-purpose LLMs in specialized
applications. Ultimately, we chose to implement a proprietary decoder-only
model to handle the complex transactions that we previously couldn't manage.
This model can help us to improve 14% transaction coverage, and save more than
\$13 million annual cost.

</details>


### [5] [RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search](https://arxiv.org/abs/2509.25839)
*Han Zhang,Dongfang Zhao*

Main category: cs.IR

TL;DR: 提出了一种正则化自编码器(RAE)用于k-NN保持的降维方法，通过神经网络优化能力和瑞利商界的约束，在降维过程中保持最近邻关系，相比传统降维方法具有更好的k-NN召回率和检索效率。


<details>
  <summary>Details</summary>
Motivation: 高维嵌入向量在RAG和推荐系统等任务中广泛应用，但传统降维方法如PCA和UMAP由于无法保持向量间的最近邻关系，很少被用于加速检索过程。

Method: 使用正则化自编码器，通过正则化项约束网络参数变化，调整奇异值来控制嵌入向量在降维过程中的幅度变化，从而保持k-NN关系。

Result: RAE在适度训练开销下，相比现有降维方法实现了更优的k-NN召回率，同时保持了快速的检索效率。

Conclusion: 通过严格的数学分析证明正则化建立了变换向量范数失真率的上界，为k-NN保持提供了可证明的保证，RAE是一种有效的k-NN保持降维方法。

Abstract: While high-dimensional embedding vectors are being increasingly employed in
various tasks like Retrieval-Augmented Generation and Recommendation Systems,
popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely
been adopted for accelerating the retrieval process due to their inability of
preserving the nearest neighbor (NN) relationship among vectors. Empowered by
neural networks' optimization capability and the bounding effect of Rayleigh
quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving
dimensionality reduction. RAE constrains the network parameter variation
through regularization terms, adjusting singular values to control embedding
magnitude changes during reduction, thus preserving k-NN relationships. We
provide a rigorous mathematical analysis demonstrating that regularization
establishes an upper bound on the norm distortion rate of transformed vectors,
thereby offering provable guarantees for k-NN preservation. With modest
training overhead, RAE achieves superior k-NN recall compared to existing DR
approaches while maintaining fast retrieval efficiency.

</details>


### [6] [Fading to Grow: Growing Preference Ratios via Preference Fading Discrete Diffusion for Recommendation](https://arxiv.org/abs/2509.26063)
*Guoqing Hu,An Zhang. Shuchang Liu,Wenyu Mao,Jiancan Wu,Xun Yang,Xiang Li,Lantao Hu,Han Li,Kun Gai,Xiang Wang*

Main category: cs.IR

TL;DR: 提出了PreferGrow，一种基于离散扩散的推荐系统，通过偏好淡化和增长来建模用户偏好比率，解决了连续高斯噪声与离散用户偏好数据不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的推荐系统主要依赖连续高斯噪声，这与推荐中用户偏好数据的离散性质不匹配。需要一种更符合推荐任务离散和排序导向特性的方法。

Method: PreferGrow采用离散扩散模型，通过偏好淡化（用替代项替换首选项）和偏好增长（从估计比率迭代重建偏好）来建模项目对之间的相对偏好比率。

Result: 在五个基准数据集上，PreferGrow相比最先进的基于扩散的推荐系统表现出持续的性能提升，证明了其理论严谨性和实证有效性。

Conclusion: PreferGrow提供了一个定义良好的基于矩阵的公式，具有马尔可夫性和可逆性的理论保证，为离散推荐任务提供了更合适的解决方案。

Abstract: Recommenders aim to rank items from a discrete item corpus in line with user
interests, yet suffer from extremely sparse user preference data. Recent
advances in diffusion models have inspired diffusion-based recommenders, which
alleviate sparsity by injecting noise during a forward process to prevent the
collapse of perturbed preference distributions. However, current
diffusion-based recommenders predominantly rely on continuous Gaussian noise,
which is intrinsically mismatched with the discrete nature of user preference
data in recommendation. In this paper, building upon recent advances in
discrete diffusion, we propose PreferGrow, a discrete diffusion-based
recommender system that models preference ratios by fading and growing user
preferences over the discrete item corpus. PreferGrow differs from existing
diffusion-based recommenders in three core aspects: (1) Discrete modeling of
preference ratios: PreferGrow models relative preference ratios between item
pairs, rather than operating in the item representation or raw score simplex.
This formulation aligns naturally with the discrete and ranking-oriented nature
of recommendation tasks. (2) Perturbing via preference fading: Instead of
injecting continuous noise, PreferGrow fades user preferences by replacing the
preferred item with alternatives -- physically akin to negative sampling --
thereby eliminating the need for any prior noise assumption. (3) Preference
reconstruction via growing: PreferGrow reconstructs user preferences by
iteratively growing the preference signals from the estimated ratios.
PreferGrow offers a well-defined matrix-based formulation with theoretical
guarantees on Markovianity and reversibility, and it demonstrates consistent
performance gains over state-of-the-art diffusion-based recommenders across
five benchmark datasets, highlighting both its theoretical soundness and
empirical effectiveness.

</details>


### [7] [Items Proxy Bridging: Enabling Frictionless Critiquing in Knowledge Graph Recommendations](https://arxiv.org/abs/2509.26107)
*Huanyu Zhang,Xiaoxuan Shen,Yu Lei,Baolin Yi,Jianfang Liu,Yinao xie*

Main category: cs.IR

TL;DR: 提出了IPGC框架，这是一个通用的可批判推荐系统插件，通过物品代理机制将用户-关键词对的批判优化目标转换为用户-物品对，适用于大多数基于协同过滤的知识图谱推荐模型，并引入抗遗忘正则化器解决连续多步批判中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有可批判推荐系统需要专门构建用户与关键词直接关联的模型，限制了应用场景，且忽视了连续多步批判中参数累积变化导致的灾难性遗忘问题。

Method: IPGC框架采用物品代理机制，将用户-关键词对的批判优化转换为用户-物品对优化，使其能作为通用插件集成到主流推荐模型中，同时引入抗遗忘正则化器防止模型性能崩溃。

Result: IPGC提供了一个无缝集成批判机制的新范式，支持迭代推荐优化，适用于主流推荐场景，无需专门设计的用户-关键词关联模块。

Conclusion: IPGC框架解决了现有可批判推荐系统的局限性，通过通用插件设计和抗遗忘机制，实现了在主流推荐模型中高效集成批判功能的目标。

Abstract: Modern recommender systems place great inclination towards facilitating user
experience, as more applications enabling users to critique and then refine
recommendations immediately. Considering the real-time requirements,
critique-able recommender systems typically straight modify the model
parameters and update the recommend list through analyzing the user critiquing
keyphrases in the inference phase. Current critiquing methods require first
constructing a specially designated model which establish direct correlations
between users and keyphrases during the training phase allowing for innovative
recommendations upon the critiquing,restricting the applicable scenarios.
Additionally, all these approaches ignore the catastrophic forgetting problem,
where the cumulative changes in parameters during continuous multi-step
critiquing may lead to a collapse in model performance. Thus, We conceptualize
a proxy bridging users and keyphrases, proposing a streamlined yet potent Items
Proxy Generic Critiquing Framework (IPGC) framework, which can serve as a
universal plugin for most knowledge graph recommender models based on
collaborative filtering (CF) strategies. IPGC provides a new paradigm for
frictionless integration of critique mechanisms to enable iterative
recommendation refinement in mainstream recommendation scenarios. IPGC
describes the items proxy mechanism for transforming the critiquing
optimization objective of user-keyphrase pairs into user-item pairs, adapting
it for general CF recommender models without the necessity of specifically
designed user-keyphrase correlation module. Furthermore, an anti-forgetting
regularizer is introduced in order to efficiently mitigate the catastrophic
forgetting problem of the model as a prior for critiquing optimization.

</details>


### [8] [Leveraging Scene Context with Dual Networks for Sequential User Behavior Modeling](https://arxiv.org/abs/2509.26172)
*Xu Chen,Yunmeng Shu,Yuangang Pan,Jinsong Lan,Xiaoyong Zhu,Shuai Xiao,Haojin Zhu,Ivor W. Tsang,Bo Zheng*

Main category: cs.IR

TL;DR: 提出DSPnet模型，通过双序列网络分别学习用户对物品和场景的动态兴趣，结合序列特征增强模块和对比正则化损失，有效捕捉场景与物品间的交互关系，提升未来行为预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有序列行为模型要么忽略场景特征，要么仅将其作为属性嵌入，无法有效捕捉场景与物品之间的动态兴趣和交互关系。不同场景具有不同的功能和使用习惯，导致用户参与度分布存在显著差异。

Method: 提出Dual Sequence Prediction networks (DSPnet)，包含两个并行网络分别学习用户对物品和场景的动态兴趣，以及序列特征增强模块捕捉场景与物品间的交互关系。引入Conditional Contrastive Regularization (CCR)损失来捕捉相似历史序列的不变性。

Result: 在一个公共基准数据集和两个工业数据集上进行了广泛实验。该方法已在系统中在线部署，带来CTR提升0.04点，交易量增长0.78%，GMV增长0.64%。

Conclusion: DSPnet是学习场景和物品序列联合关系的原理性方法，能够有效捕捉动态兴趣和场景-物品交互，显著提升未来行为预测性能。

Abstract: Modeling sequential user behaviors for future behavior prediction is crucial
in improving user's information retrieval experience. Recent studies highlight
the importance of incorporating contextual information to enhance prediction
performance. One crucial but usually neglected contextual information is the
scene feature which we define as sub-interfaces within an app, created by
developers to provide specific functionalities, such as ``text2product search"
and ``live" modules in e-commence apps. Different scenes exhibit distinct
functionalities and usage habits, leading to significant distribution gap in
user engagement across them. Popular sequential behavior models either ignore
the scene feature or merely use it as attribute embeddings, which cannot
effectively capture the dynamic interests and interplay between scenes and
items when modeling user sequences. In this work, we propose a novel Dual
Sequence Prediction networks (DSPnet) to effectively capture the dynamic
interests and interplay between scenes and items for future behavior
prediction. DSPnet consists of two parallel networks dedicated to learn users'
dynamic interests over items and scenes, and a sequence feature enhancement
module to capture the interplay for enhanced future behavior prediction.
Further, we introduce a Conditional Contrastive Regularization (CCR) loss to
capture the invariance of similar historical sequences. Theoretical analysis
suggests that DSPnet is a principled way to learn the joint relationships
between scene and item sequences. Extensive experiments are conducted on one
public benchmark and two collected industrial datasets. The method has been
deployed online in our system, bringing a 0.04 point increase in CTR, 0.78\%
growth in deals, and 0.64\% rise in GMV. The codes are available at this
anonymous github:
\textcolor{blue}{https://anonymous.4open.science/r/DSPNet-ForPublish-2506/}.

</details>


### [9] [Auto-ARGUE: LLM-Based Report Generation Evaluation](https://arxiv.org/abs/2509.26184)
*William Walden,Marc Mason,Orion Weller,Laura Dietz,Hannah Recknor,Bryan Li,Gabrielle Kaili-May Liu,Yu Hou,James Mayfield,Eugene Yang*

Main category: cs.IR

TL;DR: 介绍了Auto-ARGUE，一个基于LLM的报告生成评估工具，在TREC 2024 NeuCLIR任务中与人工评估有良好相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的开源RAG评估工具缺乏针对报告生成任务的专门工具，需要开发专门用于报告生成评估的工具。

Method: 基于ARGUE框架开发了Auto-ARGUE，这是一个基于大语言模型的鲁棒实现，用于报告生成评估。

Result: 在TREC 2024 NeuCLIR track的报告生成试点任务中，Auto-ARGUE在系统级别与人工评估结果显示出良好的相关性。

Conclusion: Auto-ARGUE是一个有效的报告生成评估工具，并发布了用于可视化输出的Web应用程序。

Abstract: Generation of long-form, citation-backed reports is a primary use case for
retrieval augmented generation (RAG) systems. While open-source evaluation
tools exist for various RAG tasks, ones tailored to report generation are
lacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-based
implementation of the recent ARGUE framework for report generation evaluation.
We present analysis of Auto-ARGUE on the report generation pilot task from the
TREC 2024 NeuCLIR track, showing good system-level correlations with human
judgments. We further release a web app for visualization of Auto-ARGUE
outputs.

</details>


### [10] [Self-supervised learning for phase retrieval](https://arxiv.org/abs/2509.26203)
*Victor Sechaud,Patrice Abry,Laurent Jacques,Julián Tachella*

Main category: cs.IR

TL;DR: 提出了一种自监督的相位恢复方法，利用图像平移不变性，无需参考图像即可从测量数据重建图像。


<details>
  <summary>Details</summary>
Motivation: 在医学和科学成像中，缺乏全采样数据限制了监督学习。现有方法仅限于线性问题，无法处理非线性问题如相位恢复。

Method: 利用图像平移不变性的自监督方法，通过测量数据本身进行重建，无需参考图像。

Result: 该方法能够克服现有方法的局限性，成功处理非线性相位恢复问题。

Conclusion: 提出的自监督方法为非线性逆成像问题提供了可行的解决方案，特别是在缺乏参考数据的情况下。

Abstract: In recent years, deep neural networks have emerged as a solution for inverse
imaging problems. These networks are generally trained using pairs of images:
one degraded and the other of high quality, the latter being called 'ground
truth'. However, in medical and scientific imaging, the lack of fully sampled
data limits supervised learning. Recent advances have made it possible to
reconstruct images from measurement data alone, eliminating the need for
references. However, these methods remain limited to linear problems, excluding
non-linear problems such as phase retrieval. We propose a self-supervised
method that overcomes this limitation in the case of phase retrieval by using
the natural invariance of images to translations.

</details>


### [11] [Analyzing BEV Suitability and Charging Strategies Using Italian Driving Data](https://arxiv.org/abs/2509.26262)
*Homa Jamalof,Luca Vassio,Danilo Giordano,Marco Mellia,Claudio De Tommasi*

Main category: cs.IR

TL;DR: 基于意大利10,441名燃油车用户的出行数据分析，研究评估在不改变出行习惯的情况下转向电动车的可行性，发现至少35%的用户在夜间充电条件下可改用低容量电动车。


<details>
  <summary>Details</summary>
Motivation: 电动车正从替代选择发展为主流交通工具，但仍面临续航焦虑、充电不便和成本高等障碍，需要评估用户在不改变出行行为情况下转向电动车的实际可行性。

Method: 收集燃油车用户的出行数据，模拟复制行程和停车事件，在不同充电场景下监测电池电量状态，评估电动车满足出行需求的能力。

Result: 分析显示充电行为与有限续航之间存在权衡。假设具备夜间充电条件，至少35%的用户可改用低容量电动车。

Conclusion: 相当大比例的用户在现有出行模式下已具备转向电动车的条件，夜间充电基础设施对电动车普及至关重要。

Abstract: Battery Electric Vehicles (BEVs) are rapidly evolving from a niche
alternative to an established option for private transportation, often
replacing Internal Combustion Engine (ICE) vehicles. Despite growing interest,
significant barriers remain, including range anxiety, the inconvenience
associated with public charging stations, and higher costs. This study analyses
extensive telemetry data collected from 10,441 users using ICE vehicles in an
Italian province to assess the potential for switching to BEVs without changing
current travel behaviour. We evaluate to what extent the BEV models can fulfil
their mobility needs under different charging scenarios. To do so, we replicate
trips and parking events, simulating and monitoring the battery state of
charge. The analysis reveals the compromises between charging behaviours and
limited BEV autonomy. Assuming access to overnight charging, at least 35% of
the users could already adopt even low-capacity BEVs.

</details>


### [12] [MR$^2$-Bench: Going Beyond Matching to Reasoning in Multimodal Retrieval](https://arxiv.org/abs/2509.26378)
*Junjie Zhou,Ze Liu,Lei Xiong,Jin-Ge Yao,Yueze Wang,Shitao Xiao,Fenfen Lin,Miguel Hu Chen,Zhicheng Dou,Siqi Bao,Defu Lian,Yongping Xiong,Zheng Liu*

Main category: cs.IR

TL;DR: MR²-Bench是一个推理密集的多模态检索基准，超越表面语义匹配，评估模型在逻辑、空间和因果推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要测试表面语义对应（如物体-文本匹配），无法评估视觉和文本信息之间复杂关系所需的深度推理能力。

Method: 构建包含1,309个精心策划查询的基准，涵盖自然图像、图表和视觉谜题等多样化多模态数据，支持包含多个图像的复杂查询和文档。

Result: 当前最先进模型在MR²-Bench上表现不佳，例如Seed1.6-Embedding模型在MMEB上Recall@1为77.78，但在MR²-Bench上仅为9.91。

Conclusion: MR²-Bench揭示了多模态检索中推理能力的重大挑战，强调了在推理密集型多模态检索方面进一步发展的迫切需求。

Abstract: Multimodal retrieval is becoming a crucial component of modern AI
applications, yet its evaluation lags behind the demands of more realistic and
challenging scenarios. Existing benchmarks primarily probe surface-level
semantic correspondence (e.g., object-text matching) while failing to assess
the deeper reasoning required to capture complex relationships between visual
and textual information. To address this gap, we introduce MR$^2$-Bench, a
reasoning-intensive benchmark for multimodal retrieval. MR$^2$-Bench presents
the following critical values: 1) all tasks are reasoning-driven, going beyond
shallow matching to effectively assess models' capacity for logical, spatial,
and causal inference; 2) it features diverse multimodal data, such as natural
images, diagrams, and visual puzzles, enabling comprehensive evaluation across
content types; 3) it supports complex queries and documents containing multiple
images and covers diverse retrieval scenarios, more accurately reflecting
real-world applications. Our benchmark contains 1,309 curated queries, derived
either from manual collection and annotation or from selective consolidation of
public datasets. Despite achieving strong results on existing benchmarks,
current state-of-the-art models still struggle on MR$^2$-Bench: for example,
the leading Seed1.6-Embedding model attains a Recall@1 of 77.78 on MMEB, but
only 9.91 on MR$^2$-Bench. This substantial performance gap highlights both the
increased challenge posed by our benchmark and the pressing need for further
advances in reasoning-intensive multimodal retrieval. The dataset and
evaluation code will be made publicly available at
https://github.com/VectorSpaceLab/MR2-Bench.

</details>


### [13] [Informed Dataset Selection](https://arxiv.org/abs/2509.26448)
*Abdullah Abbas,Michael Heep,Theodor Sperle*

Main category: cs.IR

TL;DR: 开发了APS Explorer网络应用，基于算法性能空间框架为推荐系统研究提供数据驱动的数据集选择方法，包含可视化、算法比较和元数据分析功能。


<details>
  <summary>Details</summary>
Motivation: 推荐系统研究中数据集选择缺乏系统性方法，研究者通常基于流行度而非实证适用性选择数据集。

Method: 实现算法性能空间框架，分析96个数据集、28种算法在三个指标和五个K值下的表现，扩展了基于统计的五级难度分类系统和基于马氏距离的方差归一化相似度度量。

Result: 成功开发APS Explorer，包含三个交互模块：算法性能可视化、直接算法比较和数据集元数据分析。

Conclusion: 该工具将数据集选择过程从基于直觉转变为基于证据的实践，并已公开可用。

Abstract: The selection of datasets in recommender systems research lacks a systematic
methodology. Researchers often select datasets based on popularity rather than
empirical suitability. We developed the APS Explorer, a web application that
implements the Algorithm Performance Space (APS) framework for informed dataset
selection. The system analyzes 96 datasets using 28 algorithms across three
metrics (nDCG, Hit Ratio, Recall) at five K-values. We extend the APS framework
with a statistical based classification system that categorizes datasets into
five difficulty levels based on quintiles. We also introduce a
variance-normalized distance metric based on Mahalanobis distance to measure
similarity. The APS Explorer was successfully developed with three interactive
modules for visualizing algorithm performance, direct comparing algorithms, and
analyzing dataset metadata. This tool shifts the process of selecting datasets
from intuition-based to evidence-based practices, and it is publicly available
at datasets.recommender-systems.com.

</details>
