<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 3]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Q-BERT4Rec: Quantized Semantic-ID Representation Learning for Multimodal Recommendation](https://arxiv.org/abs/2512.02474)
*Haofeng Huang,Ling Gai*

Main category: cs.IR

TL;DR: Q-Bert4Rec：一个多模态序列推荐框架，通过语义量化和跨模态融合提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的序列推荐方法（如BERT4Rec）依赖离散物品ID，缺乏语义信息且忽略多模态特征（文本、图像），导致泛化能力弱和可解释性差

Method: 提出三阶段框架：1) 跨模态语义注入，通过动态Transformer融合文本、视觉和结构特征丰富ID嵌入；2) 语义量化，使用残差向量量化将融合表示离散化为有意义的token；3) 多掩码预训练和微调，采用跨度、尾部、多区域等多样化掩码策略提升序列理解

Result: 在公开的Amazon基准测试中，Q-Bert4Rec显著优于现有强基线方法，验证了语义量化对多模态序列推荐的有效性

Conclusion: 语义量化方法能够有效提升多模态序列推荐的性能，为推荐系统提供了更好的泛化能力和可解释性

Abstract: Sequential recommendation plays a critical role in modern online platforms such as e-commerce, advertising, and content streaming, where accurately predicting users' next interactions is essential for personalization. Recent Transformer-based methods like BERT4Rec have shown strong modeling capability, yet they still rely on discrete item IDs that lack semantic meaning and ignore rich multimodal information (e.g., text and image). This leads to weak generalization and limited interpretability. To address these challenges, we propose Q-Bert4Rec, a multimodal sequential recommendation framework that unifies semantic representation and quantized modeling. Specifically, Q-Bert4Rec consists of three stages: (1) cross-modal semantic injection, which enriches randomly initialized ID embeddings through a dynamic transformer that fuses textual, visual, and structural features; (2) semantic quantization, which discretizes fused representations into meaningful tokens via residual vector quantization; and (3) multi-mask pretraining and fine-tuning, which leverage diverse masking strategies -- span, tail, and multi-region -- to improve sequential understanding. We validate our model on public Amazon benchmarks and demonstrate that Q-Bert4Rec significantly outperforms many strong existing methods, confirming the effectiveness of semantic tokenization for multimodal sequential recommendation. Our source code will be publicly available on GitHub after publishing.

</details>


### [2] [AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations](https://arxiv.org/abs/2512.02502)
*Luyao Niu,Zhicheng Deng,Boyang Li,Nuoxian Huang,Ruiqi Liu,Wenjia Zhang*

Main category: cs.IR

TL;DR: AskNearby是一个AI驱动的社区应用，通过三层RAG管道和认知地图模型，解决15分钟生活圈内的本地生活信息可及性问题，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 15分钟城市愿景不仅需要物理邻近性，还需要高效可靠地获取附近场所、服务和活动的信息。现有基于位置的系统主要关注城市级任务，忽视了影响本地化决策的空间、时间和认知因素，形成了本地生活信息可及性（LLIA）问题。

Method: 提出AskNearby系统，整合：(1) 三层检索增强生成（RAG）管道，结合基于图、语义向量和地理检索；(2) 认知地图模型，编码每个用户的社区熟悉度和偏好。

Result: 在真实社区数据集上的实验表明，AskNearby在检索准确性和推荐质量上显著优于基于LLM和基于地图的基线方法，在时空基础和认知感知排序方面表现出稳健性能。实际部署进一步验证了其有效性。

Conclusion: 通过解决LLIA挑战，AskNearby使居民能够更有效地发现本地资源、规划日常活动并参与社区生活，推动了15分钟城市愿景的实现。

Abstract: The "15-minute city" envisions neighborhoods where residents can meet daily needs via a short walk or bike ride. Realizing this vision requires not only physical proximity but also efficient and reliable access to information about nearby places, services, and events. Existing location-based systems, however, focus mainly on city-level tasks and neglect the spatial, temporal, and cognitive factors that shape localized decision-making. We conceptualize this gap as the Local Life Information Accessibility (LLIA) problem and introduce AskNearby, an AI-driven community application that unifies retrieval and recommendation within the 15-minute life circle. AskNearby integrates (i) a three-layer Retrieval-Augmented Generation (RAG) pipeline that synergizes graph-based, semantic-vector, and geographic retrieval with (ii) a cognitive-map model that encodes each user's neighborhood familiarity and preferences. Experiments on real-world community datasets demonstrate that AskNearby significantly outperforms LLM-based and map-based baselines in retrieval accuracy and recommendation quality, achieving robust performance in spatiotemporal grounding and cognitive-aware ranking. Real-world deployments further validate its effectiveness. By addressing the LLIA challenge, AskNearby empowers residents to more effectively discover local resources, plan daily activities, and engage in community life.

</details>


### [3] [LORE: A Large Generative Model for Search Relevance](https://arxiv.org/abs/2512.03025)
*Chenji Lu,Zhuo Chen,Hui Zhao,Zhiyuan Zeng,Gang Zhao,Junjie Ren,Ruicong Xu,Haoran Li,Songyan Liu,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: LORE是一个用于电商搜索的大语言模型相关性框架，通过将相关性任务分解为知识推理、多模态匹配和规则遵循三个核心能力，采用两阶段训练范式，在三年部署中实现了累计27%的GoodRate指标提升。


<details>
  <summary>Details</summary>
Motivation: 现有工作使用思维链（CoT）增强相关性，但常遇到性能瓶颈。作者认为这是因为将相关性视为单一任务，缺乏原则性分解。关键洞察是相关性包含三个不同能力：知识与推理、多模态匹配和规则遵循，需要定性驱动的分解来突破当前性能瓶颈。

Method: LORE采用两阶段训练范式：1）通过监督微调进行渐进式CoT合成；2）通过强化学习进行人类偏好对齐。还开发了RAIR基准来评估核心能力，并采用查询频率分层部署策略将离线LLM能力高效转移到在线系统。

Result: 经过三年部署和迭代，LORE在在线GoodRate指标上实现了累计27%的改进。该框架提供了完整的LLM相关性生命周期蓝图，可作为其他垂直领域的实用解决方案和方法论参考。

Conclusion: LORE证明了将相关性任务分解为不同核心能力的重要性，通过两阶段训练和分层部署策略，成功突破了现有方法的性能瓶颈。该框架不仅为电商搜索提供了有效解决方案，也为其他领域的大语言模型应用提供了方法论参考。

Abstract: Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceiling. We argue this stems from treating relevance as a monolithic task, lacking principled deconstruction. Our key insight is that relevance comprises distinct capabilities: knowledge and reasoning, multi-modal matching, and rule adherence. We contend that a qualitative-driven decomposition is essential for breaking through current performance bottlenecks. Contributions. LORE provides a complete blueprint for the LLM relevance lifecycle. Key contributions include: (1) A two-stage training paradigm combining progressive CoT synthesis via SFT with human preference alignment via RL. (2) A comprehensive benchmark, RAIR, designed to evaluate these core capabilities. (3) A query frequency-stratified deployment strategy that efficiently transfers offline LLM capabilities to the online system. LORE serves as both a practical solution and a methodological reference for other vertical domains.

</details>
