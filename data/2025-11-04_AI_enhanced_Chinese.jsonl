{"id": "2511.00072", "categories": ["cs.IR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00072", "abs": "https://arxiv.org/abs/2511.00072", "authors": ["Pradeep M", "Ritesh Pallod", "Satyen Abrol", "Muthu Raman", "Ian Anderson"], "title": "LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks", "comment": "4 pages, 5 figures. Accepted at the International Conference on Data\n  Science (IKDD CODS 2025), Demonstration Track. Demo video:\n  https://youtu.be/DZdlWmTUwjc", "summary": "Generative AI is reshaping fashion by enabling virtual looks and avatars\nmaking it essential to find real products that best match AI-generated styles.\nWe propose an end-to-end product search system that has been deployed in a\nreal-world, internet scale which ensures that AI-generated looks presented to\nusers are matched with the most visually and semantically similar products from\nthe indexed vector space. The search pipeline is composed of four key\ncomponents: query generation, vectorization, candidate retrieval, and reranking\nbased on AI-generated looks. Recommendation quality is evaluated using\nhuman-judged accuracy scores. The system currently serves more than 350,000 AI\nLooks in production per day, covering diverse product categories across global\nmarkets of over 12 million products. In our experiments, we observed that\nacross multiple annotators and categories, CLIP outperformed alternative models\nby a small relative margin of 3--7\\% in mean opinion scores. These\nimprovements, though modest in absolute numbers, resulted in noticeably better\nuser perception matches, establishing CLIP as the most reliable backbone for\nproduction deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4ea7\u54c1\u641c\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8e\u5c06AI\u751f\u6210\u7684\u65f6\u5c1a\u9020\u578b\u4e0e\u6700\u76f8\u4f3c\u7684\u5b9e\u4f53\u4ea7\u54c1\u8fdb\u884c\u5339\u914d\uff0c\u5df2\u5728\u771f\u5b9e\u4e92\u8054\u7f51\u89c4\u6a21\u90e8\u7f72\uff0c\u6bcf\u5929\u670d\u52a1\u8d85\u8fc735\u4e07\u4e2aAI\u9020\u578b\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u91cd\u5851\u65f6\u5c1a\u884c\u4e1a\uff0c\u80fd\u591f\u521b\u5efa\u865a\u62df\u9020\u578b\u548c\u5934\u50cf\uff0c\u56e0\u6b64\u9700\u8981\u627e\u5230\u4e0eAI\u751f\u6210\u98ce\u683c\u6700\u5339\u914d\u7684\u771f\u5b9e\u4ea7\u54c1\u3002", "method": "\u641c\u7d22\u7ba1\u9053\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u67e5\u8be2\u751f\u6210\u3001\u5411\u91cf\u5316\u3001\u5019\u9009\u68c0\u7d22\u548c\u57fa\u4e8eAI\u751f\u6210\u9020\u578b\u7684\u91cd\u65b0\u6392\u5e8f\u3002\u4f7f\u7528CLIP\u6a21\u578b\u8fdb\u884c\u5411\u91cf\u5316\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u5224\u65ad\u7684\u51c6\u786e\u5ea6\u5206\u6570\u8bc4\u4f30\u63a8\u8350\u8d28\u91cf\u3002", "result": "\u7cfb\u7edf\u6bcf\u5929\u670d\u52a1\u8d85\u8fc735\u4e07\u4e2aAI\u9020\u578b\uff0c\u8986\u76d6\u5168\u7403\u5e02\u573a1200\u591a\u4e07\u4e2a\u4ea7\u54c1\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCLIP\u6a21\u578b\u5728\u5e73\u5747\u610f\u89c1\u5206\u6570\u4e0a\u6bd4\u5176\u4ed6\u6a21\u578b\u76f8\u5bf9\u9ad8\u51fa3-7%\uff0c\u867d\u7136\u7edd\u5bf9\u6539\u8fdb\u4e0d\u5927\uff0c\u4f46\u80fd\u5e26\u6765\u660e\u663e\u66f4\u597d\u7684\u7528\u6237\u611f\u77e5\u5339\u914d\u3002", "conclusion": "CLIP\u88ab\u786e\u7acb\u4e3a\u751f\u4ea7\u90e8\u7f72\u4e2d\u6700\u53ef\u9760\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5176\u6539\u8fdb\u867d\u7136\u7edd\u5bf9\u503c\u4e0d\u5927\uff0c\u4f46\u5728\u7528\u6237\u611f\u77e5\u5339\u914d\u65b9\u9762\u4ea7\u751f\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.00176", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00176", "abs": "https://arxiv.org/abs/2511.00176", "authors": ["Milad Sabouri", "Masoud Mansoury", "Kun Lin", "Bamshad Mobasher"], "title": "Effectiveness of LLMs in Temporal User Profiling for Recommendation", "comment": "Accepted to the IEEE International Conference on Data Mining (ICDM\n  2025), Workshop on User Modeling and Recommendation (UMRec). To appear in the\n  IEEE ICDMW 2025 proceedings", "summary": "Effectively modeling the dynamic nature of user preferences is crucial for\nenhancing recommendation accuracy and fostering transparency in recommender\nsystems. Traditional user profiling often overlooks the distinction between\ntransitory short-term interests and stable long-term preferences. This paper\nexamines the capability of leveraging Large Language Models (LLMs) to capture\nthese temporal dynamics, generating richer user representations through\ndistinct short-term and long-term textual summaries of interaction histories.\nOur observations suggest that while LLMs tend to improve recommendation quality\nin domains with more active user engagement, their benefits appear less\npronounced in sparser environments. This disparity likely stems from the\nvarying distinguishability of short-term and long-term preferences across\ndomains; the approach shows greater utility where these temporal interests are\nmore clearly separable (e.g., Movies\\&TV) compared to domains with more stable\nuser profiles (e.g., Video Games). This highlights a critical trade-off between\nenhanced performance and computational costs, suggesting context-dependent LLM\napplication. Beyond predictive capability, this LLM-driven approach inherently\nprovides an intrinsic potential for interpretability through its natural\nlanguage profiles and attention weights. This work contributes insights into\nthe practical capability and inherent interpretability of LLM-driven temporal\nuser profiling, outlining new research directions for developing adaptive and\ntransparent recommender systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u65f6\u95f4\u52a8\u6001\uff0c\u901a\u8fc7\u751f\u6210\u77ed\u671f\u548c\u957f\u671f\u4ea4\u4e92\u5386\u53f2\u7684\u6587\u672c\u6458\u8981\u6765\u521b\u5efa\u66f4\u4e30\u5bcc\u7684\u7528\u6237\u8868\u793a\uff0c\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7528\u6237\u753b\u50cf\u5f80\u5f80\u5ffd\u89c6\u77ed\u671f\u5174\u8da3\u548c\u957f\u671f\u504f\u597d\u7684\u533a\u522b\uff0c\u9700\u8981\u66f4\u6709\u6548\u5730\u5efa\u6a21\u7528\u6237\u504f\u597d\u7684\u52a8\u6001\u7279\u6027\u6765\u589e\u5f3a\u63a8\u8350\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u7684\u77ed\u671f\u548c\u957f\u671f\u6587\u672c\u6458\u8981\uff0c\u521b\u5efa\u533a\u5206\u6027\u7684\u7528\u6237\u8868\u793a\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u9886\u57df\u4e0b\u8be5\u65b9\u6cd5\u7684\u6548\u679c\u5dee\u5f02\u3002", "result": "\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u8f83\u9ad8\u7684\u9886\u57df(\u5982\u7535\u5f71\u7535\u89c6)\uff0cLLMs\u80fd\u663e\u8457\u63d0\u5347\u63a8\u8350\u8d28\u91cf\uff0c\u4f46\u5728\u7a00\u758f\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u660e\u663e\uff1b\u77ed\u671f\u548c\u957f\u671f\u504f\u597d\u7684\u53ef\u533a\u5206\u6027\u5728\u4e0d\u540c\u9886\u57df\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u65f6\u5e8f\u7528\u6237\u753b\u50cf\u5728\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u9009\u62e9\u4f7f\u7528\uff1b\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u753b\u50cf\u548c\u6ce8\u610f\u529b\u6743\u91cd\u63d0\u4f9b\u4e86\u5185\u5728\u7684\u53ef\u89e3\u91ca\u6027\u6f5c\u529b\u3002"}}
{"id": "2511.00436", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00436", "abs": "https://arxiv.org/abs/2511.00436", "authors": ["Doyun Choi", "Cheonwoo Lee", "Jaemin Yoo"], "title": "Simple and Behavior-Driven Augmentation for Recommendation with Rich Collaborative Signals", "comment": "10 pages. This paper is accepted at IEEE BigData 2025 (Short)", "summary": "Contrastive learning (CL) has been widely used for enhancing the performance\nof graph collaborative filtering (GCF) for personalized recommendation. Since\ndata augmentation plays a crucial role in the success of CL, previous works\nhave designed augmentation methods to remove noisy interactions between users\nand items in order to generate effective augmented views. However, the\nambiguity in defining ''noisiness'' presents a persistent risk of losing core\ninformation and generating unreliable data views, while increasing the overall\ncomplexity of augmentation. In this paper, we propose Simple Collaborative\nAugmentation for Recommendation (SCAR), a novel and intuitive augmentation\nmethod designed to maximize the effectiveness of CL for GCF. Instead of\nremoving information, SCAR leverages collaborative signals extracted from\nuser-item interactions to generate pseudo-interactions, which are then either\nadded to or used to replace existing interactions. This results in more robust\nrepresentations while avoiding the pitfalls of overly complex augmentation\nmodules. We conduct experiments on four benchmark datasets and show that SCAR\noutperforms previous CL-based GCF methods as well as other state-of-the-art\nself-supervised learning approaches across key evaluation metrics. SCAR\nexhibits strong robustness across different hyperparameter settings and is\nparticularly effective in sparse data scenarios.", "AI": {"tldr": "\u63d0\u51faSCAR\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u4f2a\u4ea4\u4e92\u800c\u975e\u5220\u9664\u4fe1\u606f\u6765\u589e\u5f3a\u56fe\u534f\u540c\u8fc7\u6ee4\u4e2d\u7684\u5bf9\u6bd4\u5b66\u4e60\u6548\u679c", "motivation": "\u4f20\u7edf\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u901a\u8fc7\u5220\u9664\u566a\u58f0\u4ea4\u4e92\u6765\u751f\u6210\u589e\u5f3a\u89c6\u56fe\uff0c\u4f46\u5b9a\u4e49\"\u566a\u58f0\"\u5b58\u5728\u6a21\u7cca\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u6838\u5fc3\u4fe1\u606f\u4e22\u5931\u548c\u4e0d\u53ef\u9760\u89c6\u56fe\uff0c\u540c\u65f6\u589e\u52a0\u4e86\u589e\u5f3a\u590d\u6742\u5ea6", "method": "SCAR\u4ece\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u4e2d\u63d0\u53d6\u534f\u540c\u4fe1\u53f7\u6765\u751f\u6210\u4f2a\u4ea4\u4e92\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u4f2a\u4ea4\u4e92\u6dfb\u52a0\u5230\u73b0\u6709\u4ea4\u4e92\u4e2d\u6216\u66ff\u6362\u73b0\u6709\u4ea4\u4e92\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u9c81\u68d2\u7684\u8868\u793a", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSCAR\u5728\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u5148\u524d\u7684\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u56fe\u534f\u540c\u8fc7\u6ee4\u65b9\u6cd5\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5", "conclusion": "SCAR\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u5728\u7a00\u758f\u6570\u636e\u573a\u666f\u4e2d\u7279\u522b\u6709\u6548\uff0c\u907f\u514d\u4e86\u8fc7\u5ea6\u590d\u6742\u7684\u589e\u5f3a\u6a21\u5757\u7684\u7f3a\u9677"}}
{"id": "2511.00444", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00444", "abs": "https://arxiv.org/abs/2511.00444", "authors": ["Benjamin Clavi\u00e9", "Xianming Li", "Antoine Chaffin", "Omar Khattab", "Tom Aarsen", "Manuel Faysse", "Jing Li"], "title": "LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026", "comment": "Accepted workshop at ECIR 2026", "summary": "Late interaction retrieval methods, pioneered by ColBERT, have emerged as a\npowerful alternative to single-vector neural IR. By leveraging fine-grained,\ntoken-level representations, they have been demonstrated to deliver strong\ngeneralisation and robustness, particularly in out-of-domain settings. They\nhave recently been shown to be particularly well-suited for novel use cases,\nsuch as reasoning-based or cross-modality retrieval. At the same time, these\nmodels pose significant challenges of efficiency, usability, and integrations\ninto fully fledged systems; as well as the natural difficulties encountered\nwhile researching novel application domains. Recent years have seen rapid\nadvances across many of these areas, but research efforts remain fragmented\nacross communities and frequently exclude practitioners. The purpose of this\nworkshop is to create an environment where all aspects of late interaction can\nbe discussed, with a focus on early research explorations, real-world outcomes,\nand negative or puzzling results to be freely shared and discussed. The aim of\nLIR is to provide a highly-interactive environment for researchers from various\nbackgrounds and practitioners to freely discuss their experience, fostering\nfurther collaboration.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\uff08\u4ee5ColBERT\u4e3a\u4ee3\u8868\uff09\u7684\u4f18\u52bf\u3001\u6311\u6218\u4ee5\u53caLIR\u7814\u8ba8\u4f1a\u7684\u76ee\u6807\uff0c\u65e8\u5728\u4fc3\u8fdb\u8be5\u9886\u57df\u7814\u7a76\u8005\u4e0e\u4ece\u4e1a\u8005\u4e4b\u95f4\u7684\u4ea4\u6d41\u4e0e\u5408\u4f5c\u3002", "motivation": "\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u8de8\u57df\u3001\u63a8\u7406\u548c\u8de8\u6a21\u6001\u68c0\u7d22\u7b49\u65b0\u573a\u666f\uff0c\u4f46\u5b58\u5728\u6548\u7387\u3001\u53ef\u7528\u6027\u548c\u7cfb\u7edf\u96c6\u6210\u7b49\u6311\u6218\uff0c\u4e14\u7814\u7a76\u5206\u6563\uff0c\u7f3a\u4e4f\u5b9e\u8df5\u8005\u53c2\u4e0e\u3002", "method": "\u901a\u8fc7\u7ec4\u7ec7LIR\u7814\u8ba8\u4f1a\uff0c\u4e3a\u7814\u7a76\u8005\u4e0e\u4ece\u4e1a\u8005\u63d0\u4f9b\u9ad8\u5ea6\u4e92\u52a8\u7684\u73af\u5883\uff0c\u8ba8\u8bba\u5ef6\u8fdf\u4ea4\u4e92\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5305\u62ec\u65e9\u671f\u7814\u7a76\u63a2\u7d22\u3001\u5b9e\u9645\u5e94\u7528\u6210\u679c\u4ee5\u53ca\u8d1f\u9762\u6216\u4ee4\u4eba\u56f0\u60d1\u7684\u7ed3\u679c\u3002", "result": "\u7814\u8ba8\u4f1a\u65e8\u5728\u4fc3\u8fdb\u8de8\u793e\u533a\u5408\u4f5c\uff0c\u5206\u4eab\u7ecf\u9a8c\uff0c\u63a8\u52a8\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u7684\u53d1\u5c55\u4e0e\u5e94\u7528\u3002", "conclusion": "LIR\u7814\u8ba8\u4f1a\u4e3a\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u9886\u57df\u7684\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u7531\u4ea4\u6d41\u548c\u534f\u4f5c\u7684\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u73b0\u6709\u6311\u6218\u5e76\u63a8\u52a8\u8be5\u6280\u672f\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2511.00530", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00530", "abs": "https://arxiv.org/abs/2511.00530", "authors": ["Hongtao Huang", "Chengkai Huang", "Junda Wu", "Tong Yu", "Julian McAuley", "Lina Yao"], "title": "Listwise Preference Diffusion Optimization for User Behavior Trajectories Prediction", "comment": null, "summary": "Forecasting multi-step user behavior trajectories requires reasoning over\nstructured preferences across future actions, a challenge overlooked by\ntraditional sequential recommendation. This problem is critical for\napplications such as personalized commerce and adaptive content delivery, where\nanticipating a user's complete action sequence enhances both satisfaction and\nbusiness outcomes. We identify an essential limitation of existing paradigms:\ntheir inability to capture global, listwise dependencies among sequence items.\nTo address this, we formulate User Behavior Trajectory Prediction (UBTP) as a\nnew task setting that explicitly models long-term user preferences. We\nintroduce Listwise Preference Diffusion Optimization (LPDO), a diffusion-based\ntraining framework that directly optimizes structured preferences over entire\nitem sequences. LPDO incorporates a Plackett-Luce supervision signal and\nderives a tight variational lower bound aligned with listwise ranking\nlikelihoods, enabling coherent preference generation across denoising steps and\novercoming the independent-token assumption of prior diffusion methods. To\nrigorously evaluate multi-step prediction quality, we propose the task-specific\nmetric Sequential Match (SeqMatch), which measures exact trajectory agreement,\nand adopt Perplexity (PPL), which assesses probabilistic fidelity. Extensive\nexperiments on real-world user behavior benchmarks demonstrate that LPDO\nconsistently outperforms state-of-the-art baselines, establishing a new\nbenchmark for structured preference learning with diffusion models.", "AI": {"tldr": "\u63d0\u51faLPDO\u6846\u67b6\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4f18\u5316\u5217\u8868\u5f0f\u504f\u597d\uff0c\u89e3\u51b3\u591a\u6b65\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u5e8f\u5217\u9879\u4e4b\u95f4\u7684\u5168\u5c40\u5217\u8868\u4f9d\u8d56\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u591a\u6b65\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165Listwise Preference Diffusion Optimization (LPDO)\uff0c\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408Plackett-Luce\u76d1\u7763\u4fe1\u53f7\u548c\u53d8\u5206\u4e0b\u754c\uff0c\u4f18\u5316\u6574\u4e2a\u7269\u54c1\u5e8f\u5217\u7684\u7ed3\u6784\u5316\u504f\u597d\u3002", "result": "\u5728\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLPDO\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u7ed3\u6784\u5316\u504f\u597d\u5b66\u4e60\u8bbe\u7acb\u4e86\u65b0\u57fa\u51c6\u3002", "conclusion": "LPDO\u901a\u8fc7\u76f4\u63a5\u4f18\u5316\u7ed3\u6784\u5316\u504f\u597d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6b65\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u95ee\u9898\uff0c\u514b\u670d\u4e86\u73b0\u6709\u6269\u6563\u65b9\u6cd5\u7684\u72ec\u7acbtoken\u5047\u8bbe\u9650\u5236\u3002"}}
{"id": "2511.00584", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00584", "abs": "https://arxiv.org/abs/2511.00584", "authors": ["Ke Shi", "Yan Zhang", "Miao Zhang", "Lifan Chen", "Jiali Yi", "Kui Xiao", "Xiaoju Hou", "Zhifei Li"], "title": "Structurally Refined Graph Transformer for Multimodal Recommendation", "comment": "Comment: 13 pages, 7 figures, accepted by IEEE Transactions on\n  Multimedia 2025", "summary": "Multimodal recommendation systems utilize various types of information,\nincluding images and text, to enhance the effectiveness of recommendations. The\nkey challenge is predicting user purchasing behavior from the available data.\nCurrent recommendation models prioritize extracting multimodal information\nwhile neglecting the distinction between redundant and valuable data. They also\nrely heavily on a single semantic framework (e.g., local or global semantics),\nresulting in an incomplete or biased representation of user preferences,\nparticularly those less expressed in prior interactions. Furthermore, these\napproaches fail to capture the complex interactions between users and items,\nlimiting the model's ability to meet diverse users. To address these\nchallenges, we present SRGFormer, a structurally optimized multimodal\nrecommendation model. By modifying the transformer for better integration into\nour model, we capture the overall behavior patterns of users. Then, we enhance\nstructural information by embedding multimodal information into a hypergraph\nstructure to aid in learning the local structures between users and items.\nMeanwhile, applying self-supervised tasks to user-item collaborative signals\nenhances the integration of multimodal information, thereby revealing the\nrepresentational features inherent to the data's modality. Extensive\nexperiments on three public datasets reveal that SRGFormer surpasses previous\nbenchmark models, achieving an average performance improvement of 4.47 percent\non the Sports dataset. The code is publicly available online.", "AI": {"tldr": "SRGFormer\u662f\u4e00\u4e2a\u7ed3\u6784\u4f18\u5316\u7684\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u6539\u8fdbTransformer\u6355\u83b7\u7528\u6237\u6574\u4f53\u884c\u4e3a\u6a21\u5f0f\uff0c\u4f7f\u7528\u8d85\u56fe\u7ed3\u6784\u589e\u5f3a\u5c40\u90e8\u7ed3\u6784\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u81ea\u76d1\u7763\u4efb\u52a1\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u57fa\u51c6\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u8fc7\u5ea6\u5173\u6ce8\u63d0\u53d6\u591a\u6a21\u6001\u4fe1\u606f\u800c\u5ffd\u7565\u5197\u4f59\u4e0e\u6709\u4ef7\u503c\u6570\u636e\u7684\u533a\u5206\uff0c\u4f9d\u8d56\u5355\u4e00\u8bed\u4e49\u6846\u67b6\u5bfc\u81f4\u7528\u6237\u504f\u597d\u8868\u793a\u4e0d\u5b8c\u6574\uff0c\u4e14\u65e0\u6cd5\u6355\u6349\u7528\u6237\u4e0e\u7269\u54c1\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u5173\u7cfb\u3002", "method": "\u6539\u8fdbTransformer\u4ee5\u6355\u83b7\u7528\u6237\u6574\u4f53\u884c\u4e3a\u6a21\u5f0f\uff1b\u5c06\u591a\u6a21\u6001\u4fe1\u606f\u5d4c\u5165\u8d85\u56fe\u7ed3\u6784\u5b66\u4e60\u7528\u6237-\u7269\u54c1\u5c40\u90e8\u7ed3\u6784\uff1b\u5e94\u7528\u81ea\u76d1\u7763\u4efb\u52a1\u589e\u5f3a\u591a\u6a21\u6001\u4fe1\u606f\u6574\u5408\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSRGFormer\u8d85\u8d8a\u5148\u524d\u57fa\u51c6\u6a21\u578b\uff0c\u5728Sports\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u53474.47%\u3002", "conclusion": "SRGFormer\u901a\u8fc7\u7ed3\u6784\u4f18\u5316\u548c\u591a\u6a21\u6001\u4fe1\u606f\u6574\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u63a8\u8350\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2511.00694", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00694", "abs": "https://arxiv.org/abs/2511.00694", "authors": ["Uthman Jinadu", "Siawpeng Er", "Le Yu", "Chen Liang", "Bingxin Li", "Yi Ding", "Aleksandar Velkoski"], "title": "Taxonomy-based Negative Sampling In Personalized Semantic Search for E-commerce", "comment": "Accepted at 2025 IEEE International Conference on Big Data", "summary": "Large retail outlets offer products that may be domain-specific, and this\nrequires having a model that can understand subtle differences in similar\nitems. Sampling techniques used to train these models are most of the time,\ncomputationally expensive or logistically challenging. These models also do not\nfactor in users' previous purchase patterns or behavior, thereby retrieving\nirrelevant items for them. We present a semantic retrieval model for e-commerce\nsearch that embeds queries and products into a shared vector space and\nleverages a novel taxonomy-based hard-negative sampling(TB-HNS) strategy to\nmine contextually relevant yet challenging negatives. To further tailor\nretrievals, we incorporate user-level personalization by modeling each\ncustomer's past purchase history and behavior. In offline experiments, our\napproach outperforms BM25, ANCE and leading neural baselines on Recall@K, while\nlive A/B testing shows substantial uplifts in conversion rate, add-to-cart\nrate, and average order value. We also demonstrate that our taxonomy-driven\nnegatives reduce training overhead and accelerate convergence, and we share\npractical lessons from deploying this system at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7535\u5b50\u5546\u52a1\u641c\u7d22\u7684\u8bed\u4e49\u68c0\u7d22\u6a21\u578b\uff0c\u901a\u8fc7\u5171\u4eab\u5411\u91cf\u7a7a\u95f4\u5d4c\u5165\u67e5\u8be2\u548c\u4ea7\u54c1\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u7c7b\u7684\u786c\u8d1f\u91c7\u6837\u7b56\u7565\uff0c\u5e76\u6574\u5408\u7528\u6237\u4e2a\u6027\u5316\u5386\u53f2\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u679c\u548c\u5546\u4e1a\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u7406\u89e3\u76f8\u4f3c\u5546\u54c1\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u91c7\u6837\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u5b9e\u65bd\u56f0\u96be\uff0c\u4e14\u672a\u8003\u8651\u7528\u6237\u5386\u53f2\u8d2d\u4e70\u884c\u4e3a\uff0c\u5bfc\u81f4\u68c0\u7d22\u7ed3\u679c\u4e0d\u76f8\u5173\u3002", "method": "\u6784\u5efa\u67e5\u8be2\u548c\u4ea7\u54c1\u7684\u5171\u4eab\u5411\u91cf\u7a7a\u95f4\u5d4c\u5165\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u7c7b\u7684\u786c\u8d1f\u91c7\u6837\u7b56\u7565\u6316\u6398\u4e0a\u4e0b\u6587\u76f8\u5173\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u8d1f\u6837\u672c\uff0c\u5e76\u6574\u5408\u7528\u6237\u5386\u53f2\u8d2d\u4e70\u884c\u4e3a\u8fdb\u884c\u4e2a\u6027\u5316\u5efa\u6a21\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u4e2d\u5728Recall@K\u6307\u6807\u4e0a\u4f18\u4e8eBM25\u3001ANCE\u548c\u4e3b\u6d41\u795e\u7ecf\u57fa\u7ebf\u6a21\u578b\uff1b\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\u8f6c\u5316\u7387\u3001\u52a0\u8d2d\u7387\u548c\u5ba2\u5355\u4ef7\u663e\u8457\u63d0\u5347\uff1b\u57fa\u4e8e\u5206\u7c7b\u7684\u8d1f\u91c7\u6837\u51cf\u5c11\u4e86\u8bad\u7ec3\u5f00\u9500\u5e76\u52a0\u901f\u6536\u655b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7535\u5b50\u5546\u52a1\u641c\u7d22\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u68c0\u7d22\u8d28\u91cf\u548c\u5546\u4e1a\u4ef7\u503c\uff0c\u57fa\u4e8e\u5206\u7c7b\u7684\u8d1f\u91c7\u6837\u7b56\u7565\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u5e76\u5206\u4eab\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u5b9e\u9645\u7ecf\u9a8c\u3002"}}
{"id": "2511.00805", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00805", "abs": "https://arxiv.org/abs/2511.00805", "authors": ["Rishita Agarwal", "Himanshu Singhal", "Peter Baile Chen", "Manan Roy Choudhury", "Dan Roth", "Vivek Gupta"], "title": "REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval", "comment": "13 pages, 2 figures, 8 tables", "summary": "Answering natural language queries over relational data often requires\nretrieving and reasoning over multiple tables, yet most retrievers optimize\nonly for query-table relevance and ignore table table compatibility. We\nintroduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework\nthat separates semantic relevance from structural joinability for efficient,\nhigh-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables,\n(ii) expands these with structurally joinable tables via fast, precomputed\ncolumn-embedding comparisons, and (iii) refines them by pruning noisy or weakly\nrelated candidates. Empirically, REAR is retriever-agnostic and consistently\nimproves dense/sparse retrievers on complex table QA datasets (BIRD, MMQA, and\nSpider) by improving both multi-table retrieval quality and downstream SQL\nexecution. Despite being LLM-free, it delivers performance competitive with\nstate-of-the-art LLM-augmented retrieval systems (e.g.,ARM) while achieving\nmuch lower latency and cost. Ablations confirm complementary gains from\nexpansion and refinement, underscoring REAR as a practical, scalable building\nblock for table-based downstream tasks (e.g., Text-to-SQL).", "AI": {"tldr": "REAR\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u3001\u65e0\u9700LLM\u7684\u591a\u8868\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u8bed\u4e49\u76f8\u5173\u6027\u548c\u7ed3\u6784\u53ef\u8fde\u63a5\u6027\u6765\u63d0\u5347\u590d\u6742\u8868\u683c\u95ee\u7b54\u4e2d\u7684\u591a\u8868\u68c0\u7d22\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u5668\u4e3b\u8981\u4f18\u5316\u67e5\u8be2-\u8868\u683c\u76f8\u5173\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u8868\u683c\u95f4\u7684\u7ed3\u6784\u517c\u5bb9\u6027\uff0c\u5bfc\u81f4\u5728\u9700\u8981\u8de8\u591a\u4e2a\u8868\u683c\u63a8\u7406\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6846\u67b6\uff1a(1)\u68c0\u7d22\u67e5\u8be2\u76f8\u5173\u7684\u8868\u683c\uff0c(2)\u901a\u8fc7\u9884\u8ba1\u7b97\u7684\u5217\u5d4c\u5165\u6bd4\u8f83\u6269\u5c55\u7ed3\u6784\u53ef\u8fde\u63a5\u7684\u8868\u683c\uff0c(3)\u901a\u8fc7\u526a\u679d\u566a\u58f0\u6216\u5f31\u76f8\u5173\u5019\u9009\u6765\u7cbe\u70bc\u7ed3\u679c\u3002", "result": "\u5728BIRD\u3001MMQA\u548cSpider\u7b49\u590d\u6742\u8868\u683c\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\uff0cREAR\u663e\u8457\u63d0\u5347\u4e86\u5bc6\u96c6/\u7a00\u758f\u68c0\u7d22\u5668\u7684\u6027\u80fd\uff0c\u5728\u591a\u8868\u68c0\u7d22\u8d28\u91cf\u548c\u4e0b\u6e38SQL\u6267\u884c\u65b9\u9762\u90fd\u6709\u6539\u8fdb\uff0c\u4e14\u5ef6\u8fdf\u548c\u6210\u672c\u8fdc\u4f4e\u4e8eLLM\u589e\u5f3a\u7cfb\u7edf\u3002", "conclusion": "REAR\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u6784\u5efa\u6a21\u5757\uff0c\u4e3a\u57fa\u4e8e\u8868\u683c\u7684\u4e0b\u6e38\u4efb\u52a1\uff08\u5982Text-to-SQL\uff09\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u591a\u8868\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5373\u53ef\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\u3002"}}
{"id": "2511.00875", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00875", "abs": "https://arxiv.org/abs/2511.00875", "authors": ["Amirabbas Afzali", "Amirreza Velae", "Iman Ahmadi", "Mohammad Aliannejadi"], "title": "Controlling Gender Bias in Retrieval via a Backpack Architecture", "comment": null, "summary": "The presence of social biases in large language models (LLMs) has become a\nsignificant concern in AI research. These biases, often embedded in training\ndata, can perpetuate harmful stereotypes and distort decision-making processes.\nWhen LLMs are integrated into ranking systems, they can propagate these biases,\nleading to unfair outcomes in critical applications such as search engines and\nrecommendation systems. Backpack Language Models, unlike traditional\ntransformer-based models that treat text sequences as monolithic structures,\ngenerate outputs as weighted combinations of non-contextual, learned word\naspects, also known as senses. Leveraging this architecture, we propose a\nframework for debiasing ranking tasks. Our experimental results show that this\nframework effectively mitigates gender bias in text retrieval and ranking with\nminimal degradation in performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBackpack\u8bed\u8a00\u6a21\u578b\u7684\u53bb\u504f\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u8f7b\u6587\u672c\u68c0\u7d22\u548c\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u4f1a\u4f20\u64ad\u6709\u5bb3\u523b\u677f\u5370\u8c61\u5e76\u626d\u66f2\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5f53\u96c6\u6210\u5230\u6392\u5e8f\u7cfb\u7edf\u4e2d\u65f6\u4f1a\u5bfc\u81f4\u4e0d\u516c\u5e73\u7ed3\u679c\u3002", "method": "\u5229\u7528Backpack\u8bed\u8a00\u6a21\u578b\u7684\u67b6\u6784\u7279\u6027\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u975e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u8bcd\u65b9\u9762\uff08senses\uff09\u7684\u52a0\u6743\u7ec4\u5408\u751f\u6210\u8f93\u51fa\uff0c\u6784\u5efa\u53bb\u504f\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u80fd\u6709\u6548\u51cf\u8f7b\u6587\u672c\u68c0\u7d22\u548c\u6392\u5e8f\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u4e14\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\u3002", "conclusion": "\u57fa\u4e8eBackpack\u8bed\u8a00\u6a21\u578b\u7684\u53bb\u504f\u6846\u67b6\u4e3a\u89e3\u51b3LLM\u5728\u6392\u5e8f\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2511.01208", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01208", "abs": "https://arxiv.org/abs/2511.01208", "authors": ["Jerry Huang", "Siddarth Madala", "Cheng Niu", "Julia Hockenmaier", "Tong Zhang"], "title": "Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking", "comment": null, "summary": "Reranking algorithms have made progress in improving document retrieval\nquality by efficiently aggregating relevance judgments generated by large\nlanguage models (LLMs). However, identifying relevant documents for queries\nthat require in-depth reasoning remains a major challenge. Reasoning-intensive\nqueries often exhibit multifaceted information needs and nuanced\ninterpretations, rendering document relevance inherently context dependent. To\naddress this, we propose contextual relevance, which we define as the\nprobability that a document is relevant to a given query, marginalized over the\ndistribution of different reranking contexts it may appear in (i.e., the set of\ncandidate documents it is ranked alongside and the order in which the documents\nare presented to a reranking model). While prior works have studied methods to\nmitigate the positional bias LLMs exhibit by accounting for the ordering of\ndocuments, we empirically find that the compositions of these batches also\nplays an important role in reranking performance. To efficiently estimate\ncontextual relevance, we propose TS-SetRank, a sampling-based,\nuncertainty-aware reranking algorithm. Empirically, TS-SetRank improves nDCG@10\nover retrieval and reranking baselines by 15-25% on BRIGHT and 6-21% on BEIR,\nhighlighting the importance of modeling relevance as context-dependent.", "AI": {"tldr": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u6982\u5ff5\u548cTS-SetRank\u7b97\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u6587\u6863\u6279\u6b21\u7ec4\u5408\u548c\u6392\u5e8f\u4f4d\u7f6e\u6765\u6539\u8fdb\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u67e5\u8be2\u7684\u6587\u6863\u91cd\u6392\u5e8f\u6548\u679c", "motivation": "\u5f53\u524d\u91cd\u6392\u5e8f\u7b97\u6cd5\u5728\u5904\u7406\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u7684\u67e5\u8be2\u65f6\u9762\u4e34\u6311\u6218\uff0c\u8fd9\u7c7b\u67e5\u8be2\u5177\u6709\u591a\u9762\u6027\u4fe1\u606f\u9700\u6c42\u548c\u7ec6\u5fae\u89e3\u91ca\uff0c\u6587\u6863\u76f8\u5173\u6027\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u73af\u5883", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5b9a\u4e49\uff0c\u5f00\u53d1TS-SetRank\u7b97\u6cd5\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u540c\u65f6\u8003\u8651\u6587\u6863\u6279\u6b21\u7ec4\u5408\u548c\u6392\u5e8f\u4f4d\u7f6e", "result": "\u5728BRIGHT\u6570\u636e\u96c6\u4e0anDCG@10\u63d0\u534715-25%\uff0c\u5728BEIR\u6570\u636e\u96c6\u4e0a\u63d0\u53476-21%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u57fa\u7ebf", "conclusion": "\u5efa\u6a21\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u76f8\u5173\u6027\u5bf9\u6539\u8fdb\u91cd\u6392\u5e8f\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u6587\u6863\u6279\u6b21\u7ec4\u5408\u4e0e\u6392\u5e8f\u4f4d\u7f6e\u90fd\u663e\u8457\u5f71\u54cd\u91cd\u6392\u5e8f\u6548\u679c"}}
{"id": "2511.01364", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01364", "abs": "https://arxiv.org/abs/2511.01364", "authors": ["Pavan Kumar Perepu"], "title": "A semantic-based deep learning approach for mathematical expression retrieval", "comment": null, "summary": "Mathematical expressions (MEs) have complex two-dimensional structures in\nwhich symbols can be present at any nested depth like superscripts, subscripts,\nabove, below etc. As MEs are represented using LaTeX format, several text\nretrieval methods based on string matching, vector space models etc., have also\nbeen applied for ME retrieval problem in the literature. As these methods are\nbased on syntactic similarity, recently deep learning approaches based on\nembedding have been used for semantic similarity. In our present work, we have\nfocused on the retrieval of mathematical expressions using deep learning\napproaches. In our approach, semantic features are extracted from the MEs using\na deep recurrent neural network (DRNN) and these features have been used for\nmatching and retrieval. We have trained the network for a classification task\nwhich determines the complexity of an ME. ME complexity has been quantified in\nterms of its nested depth. Based on the nested depth, we have considered three\ncomplexity classes of MEs: Simple, Medium and Complex. After training the\nnetwork, outputs just before the the final fully connected layer are extracted\nfor all the MEs. These outputs form the semantic features of MEs and are stored\nin a database. For a given ME query, its semantic features are computed using\nthe trained DRNN and matched against the semantic feature database. Matching is\nperformed based on the standard euclidean distance and top 'k' nearest matches\nare retrieved, where 'k' is a user-defined parameter. Our approach has been\nillustrated on a database of 829 MEs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u6df1\u5ea6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc(DRNN)\u4ece\u6570\u5b66\u8868\u8fbe\u5f0f\u4e2d\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u68c0\u7d22\u3002", "motivation": "\u4f20\u7edf\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u68c0\u7d22\u65b9\u6cd5\u57fa\u4e8e\u5b57\u7b26\u4e32\u5339\u914d\u548c\u5411\u91cf\u7a7a\u95f4\u6a21\u578b\uff0c\u4e3b\u8981\u5173\u6ce8\u8bed\u6cd5\u76f8\u4f3c\u6027\uff0c\u7f3a\u4e4f\u5bf9\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u8003\u8651\u3002", "method": "\u4f7f\u7528DRNN\u8bad\u7ec3\u6570\u5b66\u8868\u8fbe\u5f0f\u590d\u6742\u5ea6\u5206\u7c7b\u4efb\u52a1\uff08\u7b80\u5355\u3001\u4e2d\u7b49\u3001\u590d\u6742\u4e09\u7c7b\uff09\uff0c\u63d0\u53d6\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u4e4b\u524d\u7684\u8f93\u51fa\u4f5c\u4e3a\u8bed\u4e49\u7279\u5f81\uff0c\u7136\u540e\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u8fdb\u884c\u5339\u914d\u68c0\u7d22\u3002", "result": "\u5728\u5305\u542b829\u4e2a\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u6570\u636e\u5e93\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8bed\u4e49\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u68c0\u7d22\u3002"}}
{"id": "2511.01404", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01404", "abs": "https://arxiv.org/abs/2511.01404", "authors": ["Xiaoyu Liu", "Yiqing Wu", "Ruidong Han", "Fuzhen Zhuang", "Xiang Li", "Wei Lin"], "title": "A Soft-partitioned Semi-supervised Collaborative Transfer Learning Approach for Multi-Domain Recommendation", "comment": "Accepted by CIKM'25", "summary": "In industrial practice, Multi-domain Recommendation (MDR) plays a crucial\nrole. Shared-specific architectures are widely used in industrial solutions to\ncapture shared and unique attributes via shared and specific parameters.\nHowever, with imbalanced data across different domains, these models face two\nkey issues: (1) Overwhelming: Dominant domain data skews model performance,\nneglecting non-dominant domains. (2) Overfitting: Sparse data in non-dominant\ndomains leads to overfitting in specific parameters. To tackle these\nchallenges, we propose Soft-partitioned Semi-supervised Collaborative Transfer\nLearning (SSCTL) for multi-domain recommendation. SSCTL generates dynamic\nparameters to address the overwhelming issue, thus shifting focus towards\nsamples from non-dominant domains. To combat overfitting, it leverages\npseudo-labels with weights from dominant domain instances to enhance\nnon-dominant domain data. We conduct comprehensive experiments, both online and\noffline, to validate the efficacy of our proposed method. Online tests yielded\nsignificant improvements across various domains, with increases in GMV ranging\nfrom 0.54% to 2.90% and enhancements in CTR ranging from 0.22% to 1.69%.", "AI": {"tldr": "\u63d0\u51faSSCTL\u65b9\u6cd5\u89e3\u51b3\u591a\u9886\u57df\u63a8\u8350\u4e2d\u7684\u9886\u57df\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u53c2\u6570\u548c\u4f2a\u6807\u7b7e\u589e\u5f3a\u6280\u672f\u6539\u5584\u975e\u4e3b\u5bfc\u9886\u57df\u7684\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u5de5\u4e1a\u591a\u9886\u57df\u63a8\u8350\u9762\u4e34\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff1a\u4e3b\u5bfc\u9886\u57df\u6570\u636e\u538b\u5012\u6a21\u578b\u6027\u80fd\uff0c\u975e\u4e3b\u5bfc\u9886\u57df\u6570\u636e\u7a00\u758f\u5bfc\u81f4\u8fc7\u62df\u5408\u3002", "method": "SSCTL\u65b9\u6cd5\u5305\u542b\u52a8\u6001\u53c2\u6570\u751f\u6210\u89e3\u51b3\u538b\u5012\u6027\u95ee\u9898\uff0c\u5229\u7528\u4e3b\u5bfc\u9886\u57df\u5b9e\u4f8b\u7684\u5e26\u6743\u91cd\u4f2a\u6807\u7b7e\u589e\u5f3a\u975e\u4e3b\u5bfc\u9886\u57df\u6570\u636e\u3002", "result": "\u5728\u7ebf\u6d4b\u8bd5\u663e\u793a\u5404\u9886\u57dfGMV\u63d0\u53470.54%-2.90%\uff0cCTR\u63d0\u53470.22%-1.69%\u3002", "conclusion": "SSCTL\u80fd\u6709\u6548\u89e3\u51b3\u591a\u9886\u57df\u63a8\u8350\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5404\u9886\u57df\u63a8\u8350\u6548\u679c\u3002"}}
{"id": "2511.01448", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01448", "abs": "https://arxiv.org/abs/2511.01448", "authors": ["Zhengjun Huang", "Zhoujin Tian", "Qintian Guo", "Fangyuan Zhang", "Yingli Zhou", "Di Jiang", "Xiaofang Zhou"], "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning", "comment": null, "summary": "Large Language Model (LLM) agents exhibit remarkable conversational and\nreasoning capabilities but remain constrained by limited context windows and\nthe lack of persistent memory. Recent efforts address these limitations via\nexternal memory architectures, often employing graph-based representations, yet\nmost adopt flat, entangled structures that intertwine semantics with topology,\nleading to redundant representations, unstructured retrieval, and degraded\nefficiency and accuracy. To resolve these issues, we propose LiCoMemory, an\nend-to-end agentic memory framework for real-time updating and retrieval, which\nintroduces CogniGraph, a lightweight hierarchical graph that utilizes entities\nand relations as semantic indexing layers, and employs temporal and\nhierarchy-aware search with integrated reranking for adaptive and coherent\nknowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and\nLongMemEval, show that LiCoMemory not only outperforms established baselines in\ntemporal reasoning, multi-session consistency, and retrieval efficiency, but\nalso notably reduces update latency. Our official code and data are available\nat https://github.com/EverM0re/LiCoMemory.", "AI": {"tldr": "LiCoMemory\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u667a\u80fd\u4f53\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165CogniGraph\u5c42\u6b21\u56fe\u7ed3\u6784\uff0c\u4f7f\u7528\u5b9e\u4f53\u548c\u5173\u7cfb\u4f5c\u4e3a\u8bed\u4e49\u7d22\u5f15\u5c42\uff0c\u7ed3\u5408\u65f6\u95f4\u548c\u5c42\u6b21\u611f\u77e5\u641c\u7d22\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u56fe\u8bb0\u5fc6\u7ed3\u6784\u4e2d\u8bed\u4e49\u4e0e\u62d3\u6251\u7ea0\u7f20\u5bfc\u81f4\u7684\u5197\u4f59\u8868\u793a\u548c\u65e0\u7ed3\u6784\u68c0\u7d22\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u867d\u7136\u5177\u5907\u51fa\u8272\u7684\u5bf9\u8bdd\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u53d7\u5230\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u7f3a\u4e4f\u6301\u4e45\u8bb0\u5fc6\u7684\u9650\u5236\u3002\u73b0\u6709\u7684\u5916\u90e8\u8bb0\u5fc6\u67b6\u6784\u5927\u591a\u91c7\u7528\u5e73\u9762\u3001\u7ea0\u7f20\u7684\u7ed3\u6784\uff0c\u5c06\u8bed\u4e49\u4e0e\u62d3\u6251\u4ea4\u7ec7\u5728\u4e00\u8d77\uff0c\u5bfc\u81f4\u8868\u793a\u5197\u4f59\u3001\u68c0\u7d22\u65e0\u7ed3\u6784\uff0c\u4ee5\u53ca\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u4e0b\u964d\u3002", "method": "\u63d0\u51faLiCoMemory\u6846\u67b6\uff0c\u5f15\u5165CogniGraph\u8f7b\u91cf\u7ea7\u5c42\u6b21\u56fe\uff0c\u4f7f\u7528\u5b9e\u4f53\u548c\u5173\u7cfb\u4f5c\u4e3a\u8bed\u4e49\u7d22\u5f15\u5c42\uff0c\u91c7\u7528\u65f6\u95f4\u548c\u5c42\u6b21\u611f\u77e5\u641c\u7d22\uff0c\u5e76\u7ed3\u5408\u91cd\u6392\u5e8f\u5b9e\u73b0\u81ea\u9002\u5e94\u548c\u8fde\u8d2f\u7684\u77e5\u8bc6\u68c0\u7d22\u3002", "result": "\u5728\u957f\u671f\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5LoCoMo\u548cLongMemEval\u4e0a\uff0cLiCoMemory\u5728\u65f6\u95f4\u63a8\u7406\u3001\u591a\u4f1a\u8bdd\u4e00\u81f4\u6027\u548c\u68c0\u7d22\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u66f4\u65b0\u5ef6\u8fdf\u3002", "conclusion": "LiCoMemory\u901a\u8fc7\u5c42\u6b21\u5316\u56fe\u7ed3\u6784\u548c\u8bed\u4e49\u7d22\u5f15\u5c42\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u8bb0\u5fc6\u67b6\u6784\u4e2d\u7684\u8868\u793a\u5197\u4f59\u548c\u68c0\u7d22\u6548\u7387\u95ee\u9898\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u6301\u4e45\u8bb0\u5fc6\u80fd\u529b\u3002"}}
{"id": "2511.01461", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01461", "abs": "https://arxiv.org/abs/2511.01461", "authors": ["Xiaoyu Liu", "Fuwei Zhang", "Yiqing Wu", "Xinyu Jia", "Zenghua Xia", "Fuzhen Zhuang", "Zhao Zhang", "Fei Jiang", "Wei Lin"], "title": "CAT-ID$^2$: Category-Tree Integrated Document Identifier Learning for Generative Retrieval In E-commerce", "comment": "Accepted by WSDM'26", "summary": "Generative retrieval (GR) has gained significant attention as an effective\nparadigm that integrates the capabilities of large language models (LLMs). It\ngenerally consists of two stages: constructing discrete semantic identifiers\n(IDs) for documents and retrieving documents by autoregressively generating ID\ntokens.The core challenge in GR is how to construct document IDs (DocIDS) with\nstrong representational power. Good IDs should exhibit two key properties:\nsimilar documents should have more similar IDs, and each document should\nmaintain a distinct and unique ID.However, most existing methods ignore native\ncategory information, which is common and critical in E-commerce. Therefore, we\npropose a novel ID learning method, CAtegory-Tree Integrated Document\nIDentifier (CAT-ID$^2$), incorporating prior category information into the\nsemantic IDs.CAT-ID$^2$ includes three key modules: a Hierarchical Class\nConstraint Loss to integrate category information layer by layer during\nquantization, a Cluster Scale Constraint Loss for uniform ID token\ndistribution, and a Dispersion Loss to improve the distinction of reconstructed\ndocuments. These components enable CAT-ID$^2$ to generate IDs that make similar\ndocuments more alike while preserving the uniqueness of different documents'\nrepresentations.Extensive offline and online experiments confirm the\neffectiveness of our method, with online A/B tests showing a 0.33% increase in\naverage orders per thousand users for ambiguous intent queries and 0.24% for\nlong-tail queries.", "AI": {"tldr": "\u63d0\u51faCAT-ID\u00b2\u65b9\u6cd5\uff0c\u5c06\u7c7b\u522b\u4fe1\u606f\u878d\u5165\u6587\u6863\u8bed\u4e49\u6807\u8bc6\u7b26\u751f\u6210\uff0c\u901a\u8fc7\u5206\u5c42\u7c7b\u522b\u7ea6\u675f\u3001\u805a\u7c7b\u5c3a\u5ea6\u7ea6\u675f\u548c\u5206\u6563\u635f\u5931\u4e09\u4e2a\u6a21\u5757\uff0c\u63d0\u5347\u751f\u6210\u68c0\u7d22\u4e2d\u6587\u6863ID\u7684\u8868\u5f81\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u68c0\u7d22\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u7535\u5546\u573a\u666f\u4e2d\u5e38\u89c1\u7684\u539f\u751f\u7c7b\u522b\u4fe1\u606f\uff0c\u800c\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u6587\u6863\u6807\u8bc6\u7b26\u7684\u8868\u5f81\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u597d\u7684\u6587\u6863ID\u5e94\u5177\u5907\u76f8\u4f3c\u6587\u6863ID\u76f8\u4f3c\u3001\u4e0d\u540c\u6587\u6863ID\u72ec\u7279\u7684\u7279\u6027\u3002", "method": "CAT-ID\u00b2\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u5206\u5c42\u7c7b\u522b\u7ea6\u675f\u635f\u5931\uff08\u9010\u5c42\u6574\u5408\u7c7b\u522b\u4fe1\u606f\uff09\u3001\u805a\u7c7b\u5c3a\u5ea6\u7ea6\u675f\u635f\u5931\uff08\u5747\u5300\u5206\u5e03ID\u4ee4\u724c\uff09\u3001\u5206\u6563\u635f\u5931\uff08\u63d0\u5347\u91cd\u6784\u6587\u6863\u533a\u5206\u5ea6\uff09\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\u6a21\u7cca\u610f\u56fe\u67e5\u8be2\u7684\u5343\u7528\u6237\u5e73\u5747\u8ba2\u5355\u6570\u63d0\u53470.33%\uff0c\u957f\u5c3e\u67e5\u8be2\u63d0\u53470.24%\u3002", "conclusion": "CAT-ID\u00b2\u901a\u8fc7\u6574\u5408\u7c7b\u522b\u4fe1\u606f\u6210\u529f\u63d0\u5347\u4e86\u6587\u6863\u8bed\u4e49\u6807\u8bc6\u7b26\u7684\u8868\u5f81\u80fd\u529b\uff0c\u5728\u7535\u5546\u68c0\u7d22\u573a\u666f\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u63d0\u5347\u3002"}}
{"id": "2511.01857", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01857", "abs": "https://arxiv.org/abs/2511.01857", "authors": ["Reza Esfandiarpoor", "Max Zuo", "Stephen H. Bach"], "title": "Trove: A Flexible Toolkit for Dense Retrieval", "comment": null, "summary": "We introduce Trove, an easy-to-use open-source retrieval toolkit that\nsimplifies research experiments without sacrificing flexibility or speed. For\nthe first time, we introduce efficient data management features that load and\nprocess (filter, select, transform, and combine) retrieval datasets on the fly,\nwith just a few lines of code. This gives users the flexibility to easily\nexperiment with different dataset configurations without the need to compute\nand store multiple copies of large datasets. Trove is highly customizable: in\naddition to many built-in options, it allows users to freely modify existing\ncomponents or replace them entirely with user-defined objects. It also provides\na low-code and unified pipeline for evaluation and hard negative mining, which\nsupports multi-node execution without any code changes. Trove's data management\nfeatures reduce memory consumption by a factor of 2.6. Moreover, Trove's\neasy-to-use inference pipeline incurs no overhead, and inference times decrease\nlinearly with the number of available nodes. Most importantly, we demonstrate\nhow Trove simplifies retrieval experiments and allows for arbitrary\ncustomizations, thus facilitating exploratory research.", "AI": {"tldr": "Trove\u662f\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u5f00\u6e90\u68c0\u7d22\u5de5\u5177\u5305\uff0c\u7b80\u5316\u7814\u7a76\u5b9e\u9a8c\u800c\u4e0d\u727a\u7272\u7075\u6d3b\u6027\u6216\u901f\u5ea6\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u6570\u636e\u7ba1\u7406\u529f\u80fd\u548c\u9ad8\u5ea6\u53ef\u5b9a\u5236\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u68c0\u7d22\u5b9e\u9a8c\u4e2d\u6570\u636e\u7ba1\u7406\u590d\u6742\u3001\u5185\u5b58\u6d88\u8017\u5927\u3001\u7f3a\u4e4f\u7075\u6d3b\u6027\u7b49\u95ee\u9898\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u8f7b\u677e\u8fdb\u884c\u5b9e\u9a8c\u548c\u63a2\u7d22\u6027\u7814\u7a76\u3002", "method": "\u5f15\u5165\u52a8\u6001\u6570\u636e\u7ba1\u7406\u529f\u80fd\uff0c\u652f\u6301\u8fc7\u6ee4\u3001\u9009\u62e9\u3001\u8f6c\u6362\u548c\u7ec4\u5408\u68c0\u7d22\u6570\u636e\u96c6\uff1b\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u5b9a\u5236\u7684\u7ec4\u4ef6\u548c\u4f4e\u4ee3\u7801\u7edf\u4e00\u8bc4\u4f30\u6d41\u7a0b\uff1b\u652f\u6301\u591a\u8282\u70b9\u6267\u884c\u3002", "result": "\u6570\u636e\u7ba1\u7406\u529f\u80fd\u5c06\u5185\u5b58\u6d88\u8017\u51cf\u5c112.6\u500d\uff1b\u63a8\u7406\u7ba1\u9053\u65e0\u5f00\u9500\u4e14\u63a8\u7406\u65f6\u95f4\u968f\u8282\u70b9\u6570\u7ebf\u6027\u51cf\u5c11\uff1b\u7b80\u5316\u4e86\u68c0\u7d22\u5b9e\u9a8c\u5e76\u652f\u6301\u4efb\u610f\u5b9a\u5236\u3002", "conclusion": "Trove\u901a\u8fc7\u7b80\u5316\u5b9e\u9a8c\u6d41\u7a0b\u548c\u63d0\u4f9b\u9ad8\u5ea6\u5b9a\u5236\u80fd\u529b\uff0c\u6709\u6548\u4fc3\u8fdb\u4e86\u68c0\u7d22\u9886\u57df\u7684\u63a2\u7d22\u6027\u7814\u7a76\u3002"}}
