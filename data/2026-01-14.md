<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [A survey: Information search time optimization based on RAG (Retrieval Augmentation Generation) chatbot](https://arxiv.org/abs/2601.07838)
*Jinesh Patel,Arpit Malhotra,Ajay Pande,Prateek Caire*

Main category: cs.IR

TL;DR: RAG聊天机器人相比传统搜索方法在组织内信息检索中平均节省80-95%的时间


<details>
  <summary>Details</summary>
Motivation: 研究RAG聊天机器人在组织内部复杂信息检索中的效率，与传统搜索方法进行对比，评估其时间节省效果

Method: 在"X Systems"公司进行调研，对105名跨部门员工进行实验，比较相同查询下传统搜索方法与RAG聊天机器人的信息检索时间

Result: RAG聊天机器人相比传统搜索方法平均节省80-95%的检索时间，显著优化搜索流程

Conclusion: RAG聊天机器人不仅节省信息检索时间，还能有效优化搜索过程，在组织内部信息检索中具有显著优势

Abstract: Retrieval-Augmented Generation (RAG) based chatbots are not only useful for information retrieval through questionanswering but also for making complex decisions based on injected private data.we present a survey on how much search time can be saved when retrieving complex information within an organization called "X Systems"(a stealth mode company) by using a RAG-based chatbot compared to traditional search methods. We compare the information retrieval time using standard search techniques versus the RAG-based chatbot for the same queries. Our results conclude that RAG-based chatbots not only save time in information retrieval but also optimize the search process effectively. This survey was conducted with a sample of 105 employees across departments, average time spending on information retrieval per query was taken as metric. Comparison shows us, there are average 80-95% improvement on search when use RAG based chatbot than using standard search.

</details>


### [2] [Cost and accuracy of long-term graph memory in distributed LLM-based multi-agent systems](https://arxiv.org/abs/2601.07978)
*Benedict Wolff,Jacopo Bennati*

Main category: cs.IR

TL;DR: 该研究比较了分布式多智能体系统中两种长期记忆框架：向量记忆框架mem0和图知识图谱Graphiti，发现mem0在效率上显著优于Graphiti，而准确性差异不显著，mem0成为成本与准确性平衡的最优选择。


<details>
  <summary>Details</summary>
Motivation: 分布式多智能体系统使用大语言模型实现协作智能同时保护隐私，但在网络约束下对长期记忆的系统性评估仍然有限。需要比较不同记忆框架在实际网络条件下的性能表现。

Method: 研究创建了一个灵活测试平台，使用LOCOMO长上下文基准测试，比较向量记忆框架mem0和图知识图谱Graphiti。实验在无约束和约束网络条件下进行，测量计算、财务和准确性指标。

Result: mem0在效率方面显著优于Graphiti，具有更快的加载时间、更低的资源消耗和最小的网络开销。准确性差异在统计上不显著。应用统计帕累托效率框架分析，mem0被确定为在分布式多智能体系统中平衡成本和准确性的最优选择。

Conclusion: mem0作为向量记忆框架在分布式多智能体系统中表现出更好的效率优势，而准确性相当，是实际部署中平衡成本和性能的优选方案。这为分布式AI系统的记忆架构选择提供了实证依据。

Abstract: Distributed multi-agent systems use large language models to enable collaborative intelligence while preserving privacy, yet systematic evaluations of long-term memory under network constraints remain limited. This study presents a flexible testbed comparing mem0, a vector-based memory framework, and Graphiti, a graph-based knowledge graph, using the LOCOMO long-context benchmark. Experiments were conducted under unconstrained and constrained network conditions, measuring computational, financial, and accuracy metrics. Results indicate that mem0 significantly outperforms Graphiti in efficiency, with faster loading times, lower resource consumption, and minimal network overhead, while accuracy differences are not statistically significant. Applying a statistical pareto efficiency framework, mem0 is identified as the optimal choice that balances cost and accuracy in DMAS.

</details>


### [3] [Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models](https://arxiv.org/abs/2601.08148)
*Seokho Ahn,Sungbok Shin,Young-Duk Seo*

Main category: cs.IR

TL;DR: SPiKE模型结合LLMs和KGs构建用户画像，通过LLMs从多样知识源提取压缩推理，KGs传播画像扩展覆盖，在推荐任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统中缺乏构建和利用用户画像的共识方法，需要更丰富的信息化画像来提升推荐质量。LLMs擅长从多样知识源提取压缩推理，而KGs更适合传播这些画像扩展覆盖范围。

Method: 提出SPiKE模型，包含三个核心组件：1) 实体画像生成：使用LLMs为所有KG实体生成语义画像；2) 画像感知的KG聚合：将这些画像整合到KG中；3) 成对画像偏好匹配：在训练中对齐LLM和KG的表示。

Result: 实验表明SPiKE在真实场景中持续优于最先进的基于KG和LLM的推荐方法。

Conclusion: 通过结合LLMs的推理提取能力和KGs的传播能力，SPiKE为构建和利用用户画像提供了一种有效方法，显著提升了推荐系统的性能。

Abstract: Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is still no consensus on how best to construct and utilize such profiles. To address this, we revisit recent profiling-based approaches in recommender systems along four dimensions: 1) knowledge base, 2) preference indicator, 3) impact range, and 4) subject. We argue that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. Building on this insight, we propose a new recommendation model, called SPiKE. SPiKE consists of three core components: i) Entity profile generation, which uses LLMs to generate semantic profiles for all KG entities; ii) Profile-aware KG aggregation, which integrates these profiles into the KG; and iii) Pairwise profile preference matching, which aligns LLM- and KG-based representations during training. In experiments, we demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.

</details>


### [4] [Markovian Pre-Trained Transformer for Next-Item Recommendation](https://arxiv.org/abs/2601.08275)
*Cong Xu,Guoliang Li,Jun Wang,Wei Zhang*

Main category: cs.IR

TL;DR: MPT模型通过合成马尔可夫链预训练，仅需微调轻量适配器就能在推荐任务中达到SOTA性能，揭示了序列推荐中的"马尔可夫性"本质。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐模型虽然复杂，但本质上都依赖最新交互进行预测，历史交互仅作为辅助线索推断用户身份。这促使开发能够有效总结用户序列、特别关注最新交互的通用推荐模型。

Method: 提出马尔可夫预训练变换器（MPT），在合成马尔可夫链上进行完全预训练，学习从上下文估计转移概率并关注最后状态的能力。预训练后仅需微调轻量适配器即可应用于实际推荐任务。

Result: 在三个不同平台的五个公开数据集上验证了MPT的优越性，表明马尔可夫预训练优于传统推荐预训练和最近的语言预训练范式。

Conclusion: MPT展示了通过可控的合成马尔可夫链预训练可以构建通用且可迁移的推荐模型，揭示了序列推荐中的马尔可夫本质，为推荐系统预训练提供了新思路。

Abstract: We introduce the Markovian Pre-trained Transformer (MPT) for next-item recommendation, a transferable model fully pre-trained on synthetic Markov chains, yet capable of achieving state-of-the-art performance by fine-tuning a lightweight adaptor. This counterintuitive success stems from the observation of the `Markovian' nature: advanced sequential recommenders coincidentally rely on the latest interaction to make predictions, while the historical interactions serve mainly as auxiliary cues for inferring the user's general, non-sequential identity. This characteristic necessitates the capabilities of a universal recommendation model to effectively summarize the user sequence, with particular emphasis on the latest interaction. MPT inherently has the potential to be universal and transferable. On the one hand, when trained to predict the next state of Markov chains, it acquires the capabilities to estimate transition probabilities from the context (one adaptive manner for summarizing sequences) and attend to the last state to ensure accurate state transitions. On the other hand, unlike the heterogeneous interaction data, an unlimited amount of controllable Markov chains is available to boost the model capacity. We conduct extensive experiments on five public datasets from three distinct platforms to validate the superiority of Markovian pre-training over traditional recommendation pre-training and recent language pre-training paradigms.

</details>


### [5] [AgriLens: Semantic Retrieval in Agricultural Texts Using Topic Modeling and Language Models](https://arxiv.org/abs/2601.08283)
*Heba Shakeel,Tanvir Ahmad,Tanya Liyaqat,Chandni Saxena*

Main category: cs.IR

TL;DR: 提出一个统一框架，用于可解释的主题建模、零样本主题标注和主题引导的语义检索，特别针对农业文本语料库


<details>
  <summary>Details</summary>
Motivation: 随着各领域非结构化文本数据快速增长，需要可扩展的方法来实现可解释的信息组织、摘要和检索，特别是在标注数据有限的专门领域

Method: 使用BERTopic提取语义连贯的主题，将每个主题转换为结构化提示，让语言模型以零样本方式生成有意义的主题标签和摘要，通过密集嵌入和向量搜索支持查询和文档探索，并包含专门的评估模块

Result: 该框架支持在标注数据有限的专门领域进行可扩展且可解释的信息访问，能够有效组织、总结和检索农业文本信息

Conclusion: 提出的统一框架为专门领域（如农业）提供了可扩展、可解释的主题建模、标注和检索解决方案，解决了标注数据有限的问题

Abstract: As the volume of unstructured text continues to grow across domains, there is an urgent need for scalable methods that enable interpretable organization, summarization, and retrieval of information. This work presents a unified framework for interpretable topic modeling, zero-shot topic labeling, and topic-guided semantic retrieval over large agricultural text corpora. Leveraging BERTopic, we extract semantically coherent topics. Each topic is converted into a structured prompt, enabling a language model to generate meaningful topic labels and summaries in a zero-shot manner. Querying and document exploration are supported via dense embeddings and vector search, while a dedicated evaluation module assesses topical coherence and bias. This framework supports scalable and interpretable information access in specialized domains where labeled data is limited.

</details>


### [6] [MLPlatt: Simple Calibration Framework for Ranking Models](https://arxiv.org/abs/2601.08345)
*Piotr Bajger,Roman Dusek,Krzysztof Galias,Paweł Młyniec,Aleksander Wawer,Paweł Zawistowski*

Main category: cs.IR

TL;DR: MLPlatt：一种简单有效的排序模型后校准方法，在保持排序顺序的同时将输出转换为可解释的CTR概率，实现上下文感知的校准


<details>
  <summary>Details</summary>
Motivation: 电商排序模型通常存在可解释性差和尺度未校准的问题，特别是使用典型排序损失函数训练时，需要后校准方法将排序输出转换为可解释的概率

Method: 提出MLPlatt方法，这是一种上下文感知的排序模型校准方法，保持项目排序顺序，将排序器输出转换为可用于下游任务的CTR概率

Result: 在两个数据集上优于现有方法，F-ECE（场期望校准误差）改进超过10%，且在不影响排序质量的情况下实现高质量校准

Conclusion: MLPlatt是一种有效的排序模型后校准方法，能够实现高质量的上下文感知校准，同时保持排序性能，对电商平台具有重要商业价值

Abstract: Ranking models are extensively used in e-commerce for relevance estimation. These models often suffer from poor interpretability and no scale calibration, particularly when trained with typical ranking loss functions. This paper addresses the problem of post-hoc calibration of ranking models. We introduce MLPlatt: a simple yet effective ranking model calibration method that preserves the item ordering and converts ranker outputs to interpretable click-through rate (CTR) probabilities usable in downstream tasks. The method is context-aware by design and achieves good calibration metrics globally, and within strata corresponding to different values of a selected categorical field (such as user country or device), which is often important from a business perspective of an E-commerce platform. We demonstrate the superiority of MLPlatt over existing approaches on two datasets, achieving an improvement of over 10\% in F-ECE (Field Expected Calibration Error) compared to other methods. Most importantly, we show that high-quality calibration can be achieved without compromising the ranking quality.

</details>


### [7] [Scalable Sequential Recommendation under Latency and Memory Constraints](https://arxiv.org/abs/2601.08360)
*Adithya Parthasarathy,Aswathnarayan Muthukrishnan Kirubakaran,Vinoth Punniyamoorthy,Nachiappan Chockalingam,Lokesh Butra,Kabilan Kannan,Abhirup Mazumder,Sumit Saha*

Main category: cs.IR

TL;DR: HoloMambaRec：结合全息降维表示和选择性状态空间编码的轻量级序列推荐架构，实现线性时间处理，在有限训练预算下超越SASRec，与GRU4Rec竞争，同时保持更低内存复杂度。


<details>
  <summary>Details</summary>
Motivation: 序列推荐系统需要在严格内存和延迟约束下建模长范围用户行为。现有Transformer方法虽然准确但存在二次注意力复杂度问题，需要截断用户历史记录，限制了长时域建模的实用性。

Method: 结合全息降维表示进行属性感知嵌入，使用选择性状态空间编码器进行线性时间序列处理。通过循环卷积绑定项目和属性信息，保持嵌入维度同时编码结构化元数据。采用受Mamba风格模型启发的浅层选择性状态空间骨干，实现高效训练和恒定时间循环推理。

Result: 在Amazon Beauty和MovieLens-1M数据集上的实验表明，在10个epoch的受限训练预算下，HoloMambaRec始终优于SASRec，与GRU4Rec竞争，同时保持显著更低的内存复杂度。

Conclusion: HoloMambaRec为可扩展、元数据感知的序列推荐提供了一个实用且可扩展的替代方案，设计包含时间捆绑和推理时压缩的前向兼容机制。

Abstract: Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.

</details>


### [8] [PosIR: Position-Aware Heterogeneous Information Retrieval Benchmark](https://arxiv.org/abs/2601.08363)
*Ziyang Zeng,Dun Zhang,Yu Yan,Xu Sun,Yudong Zhou,Yuqing Yang*

Main category: cs.IR

TL;DR: PosIR是一个用于诊断检索模型中位置偏见的基准测试，包含310个数据集、10种语言、31个领域，通过将相关性与精确参考片段绑定来严格解耦文档长度与信息位置。


<details>
  <summary>Details</summary>
Motivation: 现有检索模型评估通常使用位置无关的相关性标签，混淆了处理长上下文的挑战与对特定证据位置的偏见。需要专门工具来诊断检索模型中的位置偏见问题。

Method: 构建PosIR基准测试，包含310个数据集，涵盖10种语言和31个领域。通过严格流程将相关性与精确参考片段绑定，从而分离文档长度与信息位置的影响。使用10个最先进的嵌入模型进行实验，并进行梯度显著性分析。

Result: 1) PosIR在长上下文设置下的性能与MMTEB基准相关性差，暴露了当前短文本基准的局限性；2) 位置偏见普遍存在且随文档长度加剧，大多数模型表现出首因偏见，某些模型显示近因偏见；3) 梯度显著性分析揭示了驱动这些位置偏好的不同内部注意力机制。

Conclusion: PosIR作为一个有价值的诊断框架，有助于促进开发位置鲁棒的检索系统，揭示了当前检索模型中普遍存在的位置偏见问题。

Abstract: While dense retrieval models have achieved remarkable success, rigorous evaluation of their sensitivity to the position of relevant information (i.e., position bias) remains largely unexplored. Existing benchmarks typically employ position-agnostic relevance labels, conflating the challenge of processing long contexts with the bias against specific evidence locations. To address this challenge, we introduce PosIR (Position-Aware Information Retrieval), a comprehensive benchmark designed to diagnose position bias in diverse retrieval scenarios. PosIR comprises 310 datasets spanning 10 languages and 31 domains, constructed through a rigorous pipeline that ties relevance to precise reference spans, enabling the strict disentanglement of document length from information position. Extensive experiments with 10 state-of-the-art embedding models reveal that: (1) Performance on PosIR in long-context settings correlates poorly with the MMTEB benchmark, exposing limitations in current short-text benchmarks; (2) Position bias is pervasive and intensifies with document length, with most models exhibiting primacy bias while certain models show unexpected recency bias; (3) Gradient-based saliency analysis further uncovers the distinct internal attention mechanisms driving these positional preferences. In summary, PosIR serves as a valuable diagnostic framework to foster the development of position-robust retrieval systems.

</details>


### [9] [GraphFusionSBR: Denoising Multi-Channel Graphs for Session-Based Recommendation](https://arxiv.org/abs/2601.08497)
*Jia-Xin He,Hung-Hsuan Chen*

Main category: cs.IR

TL;DR: 提出多通道推荐模型DSR-HK，通过知识图谱、超图和线图三个通道从多源信息中捕获用户意图，解决项目交互主导和噪声会话问题。


<details>
  <summary>Details</summary>
Motivation: 现有会话推荐模型存在项目交互主导和噪声会话问题，需要从多源信息中更准确地捕获用户隐式意图。

Method: 设计三通道模型：1) 知识图谱通道自适应去除冗余边降噪；2) 超图通道与知识图谱表示协作缓解项目主导；3) 线图通道与超图通道通过最大化互信息作为辅助任务；4) 生成会话内注意力进一步降噪。

Result: 实验表明该方法在电子商务和多媒体推荐等多种推荐场景中提升了准确性，代码已开源。

Conclusion: 多通道方法能有效解决会话推荐中的项目主导和噪声问题，通过多源信息融合提升推荐性能。

Abstract: Session-based recommendation systems must capture implicit user intents from sessions. However, existing models suffer from issues such as item interaction dominance and noisy sessions. We propose a multi-channel recommendation model, including a knowledge graph channel, a session hypergraph channel, and a session line graph channel, to capture information from multiple sources. Our model adaptively removes redundant edges in the knowledge graph channel to reduce noise. Knowledge graph representations cooperate with hypergraph representations for prediction to alleviate item dominance. We also generate in-session attention for denoising. Finally, we maximize mutual information between the hypergraph and line graph channels as an auxiliary task. Experiments demonstrate that our method enhances the accuracy of various recommendations, including e-commerce and multimedia recommendations. We release the code on GitHub for reproducibility.\footnote{https://github.com/hohehohe0509/DSR-HK}

</details>


### [10] [VeriTaS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking](https://arxiv.org/abs/2601.08611)
*Mark Rothermel,Marcus Kornmann,Marcus Rohrbach,Anna Rohrbach*

Main category: cs.IR

TL;DR: VeriTaS是首个动态多模态自动事实核查基准，包含24,000个真实世界声明，覆盖54种语言，通过自动化流程定期更新，以解决现有基准的数据泄露问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查基准存在多方面限制：任务范围窄、模态单一、领域有限、语言多样性不足、真实性不够、虚假信息类型覆盖不全。最关键的是，这些基准是静态的，随着声明进入LLM预训练语料库，会出现数据泄露问题，导致基准性能无法可靠反映实际核查能力。

Method: 开发了VeriTaS动态基准，包含24,000个来自108个专业事实核查组织的真实声明，覆盖54种语言和文本/视听内容。采用全自动七阶段流程：声明表述规范化、原始媒体检索、异构专家裁决映射到新颖的标准化解耦评分方案（含文本理由）。每季度自动更新声明。

Result: 通过人工评估验证，自动化标注与人工判断高度匹配。VeriTaS建立了抗泄露基准，支持在基础模型快速演进时代进行有意义的自动事实核查评估。代码和数据将公开提供。

Conclusion: VeriTaS是首个动态多模态自动事实核查基准，通过定期更新和标准化流程解决了现有静态基准的数据泄露问题，为评估基础模型的事实核查能力提供了可靠工具。

Abstract: The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems, however, are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Theses and Statements (VeriTaS), the first dynamic benchmark for multimodal AFC, designed to remain robust under ongoing large-scale pretraining of foundation models. VeriTaS currently comprises 24,000 real-world claims from 108 professional fact-checking organizations across 54 languages, covering textual and audiovisual content. Claims are added quarterly via a fully automated seven-stage pipeline that normalizes claim formulation, retrieves original media, and maps heterogeneous expert verdicts to a novel, standardized, and disentangled scoring scheme with textual justifications. Through human evaluation, we demonstrate that the automated annotations closely match human judgments. We commit to update VeriTaS in the future, establishing a leakage-resistant benchmark, supporting meaningful AFC evaluation in the era of rapidly evolving foundation models. We will make the code and data publicly available.

</details>


### [11] [RMBRec: Robust Multi-Behavior Recommendation towards Target Behaviors](https://arxiv.org/abs/2601.08705)
*Miaomiao Cai,Zhijie Zhang,Junfeng Fang,Zhiyong Cheng,Xiang Wang,Meng Wang*

Main category: cs.IR

TL;DR: 提出RMBRec框架，通过信息论原则解决多行为推荐中辅助行为与目标行为不一致导致的噪声和偏差问题，结合局部语义一致性和全局稳定性优化。


<details>
  <summary>Details</summary>
Motivation: 多行为推荐面临辅助行为（如点击、加购）与目标行为（如购买）不一致的问题，这些辅助行为可能存在噪声、弱相关性或语义不对齐，导致偏好学习偏差和性能下降。现有方法缺乏处理这种行为不一致性的鲁棒机制。

Method: 提出RMBRec框架，基于信息论鲁棒性原则：最大化预测信息同时最小化其在异构行为环境中的方差。包含两个模块：1) 表示鲁棒性模块(RRM)：通过最大化用户辅助行为与目标行为表示之间的互信息来增强局部语义一致性；2) 优化鲁棒性模块(ORM)：通过最小化跨行为预测风险的方差来强制全局稳定性，这是对不变风险最小化的高效近似。

Result: 在三个真实世界数据集上的实验表明，RMBRec不仅在准确性上优于现有最先进方法，而且在各种噪声扰动下保持显著的稳定性。

Conclusion: RMBRec通过局部-全局协作，以理论一致的方式桥接了表示纯化和优化不变性，为解决多行为推荐中的行为不一致问题提供了鲁棒的解决方案。

Abstract: Multi-behavior recommendation faces a critical challenge in practice: auxiliary behaviors (e.g., clicks, carts) are often noisy, weakly correlated, or semantically misaligned with the target behavior (e.g., purchase), which leads to biased preference learning and suboptimal performance. While existing methods attempt to fuse these heterogeneous signals, they inherently lack a principled mechanism to ensure robustness against such behavioral inconsistency.
  In this work, we propose Robust Multi-Behavior Recommendation towards Target Behaviors (RMBRec), a robust multi-behavior recommendation framework grounded in an information-theoretic robustness principle. We interpret robustness as a joint process of maximizing predictive information while minimizing its variance across heterogeneous behavioral environments. Under this perspective, the Representation Robustness Module (RRM) enhances local semantic consistency by maximizing the mutual information between users' auxiliary and target representations, whereas the Optimization Robustness Module (ORM) enforces global stability by minimizing the variance of predictive risks across behaviors, which is an efficient approximation to invariant risk minimization. This local-global collaboration bridges representation purification and optimization invariance in a theoretically coherent way. Extensive experiments on three real-world datasets demonstrate that RMBRec not only outperforms state-of-the-art methods in accuracy but also maintains remarkable stability under various noise perturbations. For reproducibility, our code is available at https://github.com/miaomiao-cai2/RMBRec/.

</details>


### [12] [FusID: Modality-Fused Semantic IDs for Generative Music Recommendation](https://arxiv.org/abs/2601.08764)
*Haven Kim,Yupeng Hou,Julian McAuley*

Main category: cs.IR

TL;DR: FusID提出了一种多模态融合的语义ID框架，通过联合编码跨模态信息、学习统一表示并采用产品量化，解决了现有方法中的模态冗余和跨模态交互缺失问题，在音乐推荐任务中实现了零ID冲突和更好的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐系统使用语义ID表示物品，但独立标记化每个模态存在两个关键限制：1）跨模态冗余降低了效率；2）无法捕捉模态间交互限制了物品表示能力。

Method: FusID包含三个核心组件：1）多模态融合，通过联合编码跨模态信息学习统一表示；2）表示学习，使频繁共现的物品嵌入更接近，同时保持区分性并防止特征冗余；3）产品量化，将融合的连续嵌入转换为多个离散标记以缓解ID冲突。

Result: 在多模态下一首歌曲推荐（播放列表延续）基准测试中，FusID实现了零ID冲突（确保每个标记序列精确映射到一首歌曲），缓解了码本利用不足问题，在MRR和Recall@k（k=1,5,10,20）指标上优于基线方法。

Conclusion: FusID通过模态融合的语义ID框架有效解决了现有方法的局限性，在推荐系统中实现了更好的物品表示和推荐性能，为零冲突的多模态推荐提供了有效解决方案。

Abstract: Generative recommendation systems have achieved significant advances by leveraging semantic IDs to represent items. However, existing approaches that tokenize each modality independently face two critical limitations: (1) redundancy across modalities that reduces efficiency, and (2) failure to capture inter-modal interactions that limits item representation. We introduce FusID, a modality-fused semantic ID framework that addresses these limitations through three key components: (i) multimodal fusion that learns unified representations by jointly encoding information across modalities, (ii) representation learning that brings frequently co-occurring item embeddings closer while maintaining distinctiveness and preventing feature redundancy, and (iii) product quantization that converts the fused continuous embeddings into multiple discrete tokens to mitigate ID conflict. Evaluated on a multimodal next-song recommendation (i.e., playlist continuation) benchmark, FusID achieves zero ID conflicts, ensuring that each token sequence maps to exactly one song, mitigates codebook underutilization, and outperforms baselines in terms of MRR and Recall@k (k = 1, 5, 10, 20).

</details>


### [13] [MemRec: Collaborative Memory-Augmented Agentic Recommender System](https://arxiv.org/abs/2601.08816)
*Weixin Chen,Yuhan Zhao,Jingyuan Huang,Zihe Ye,Clark Mingxuan Ju,Tong Zhao,Neil Shah,Li Chen,Yongfeng Zhang*

Main category: cs.IR

TL;DR: MemRec是一个解耦推理与记忆管理的推荐系统框架，通过专门的LM_Mem管理动态协作记忆图，为下游LLM_Rec提供高信号上下文，实现高效协作增强。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统代理依赖孤立记忆，忽略了关键的协作信号。现有方法面临两大挑战：如何从庞大图上下文中提取信息而不增加推理代理的认知负担，以及如何高效演化协作记忆而不产生过高计算成本。

Method: 提出MemRec框架，架构上将推理与记忆管理解耦。引入专门的LM_Mem管理动态协作记忆图，通过高效检索和成本效益高的异步图传播管道，为下游LLM_Rec提供合成的、高信号上下文。

Result: 在四个基准测试上的广泛实验表明，MemRec实现了最先进的性能。架构分析确认了其灵活性，建立了平衡推理质量、成本和隐私的新帕累托前沿，支持包括本地开源模型在内的多样化部署。

Conclusion: MemRec通过解耦推理与记忆管理，有效解决了协作信号整合的挑战，为推荐系统提供了高效、灵活且成本效益高的解决方案，支持多样化部署场景。

Abstract: The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurring prohibitive computational costs. To address this, we propose MemRec, a framework that architecturally decouples reasoning from memory management to enable efficient collaborative augmentation. MemRec introduces a dedicated, cost-effective LM_Mem to manage a dynamic collaborative memory graph, serving synthesized, high-signal context to a downstream LLM_Rec. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation that evolves memory in the background. Extensive experiments on four benchmarks demonstrate that MemRec achieves state-of-the-art performance. Furthermore, architectural analysis confirms its flexibility, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy through support for diverse deployments, including local open-source models. Code:https://github.com/rutgerswiselab/memrec and Homepage: https://memrec.weixinchen.com

</details>
