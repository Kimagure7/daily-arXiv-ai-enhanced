<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [The Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q&A](https://arxiv.org/abs/2512.04343)
*Satyajit Movidi,Stephen Russell*

Main category: cs.IR

TL;DR: 个性化AI顾问系统在提升推理质量的同时，会降低语义相似度得分，揭示当前LLM评估方法不适合评估个性化响应


<details>
  <summary>Details</summary>
Motivation: 研究个性化如何影响AI学生顾问系统的性能，探索当前评估方法是否适合评估个性化响应

Method: 使用AIVisor系统，比较10种个性化与非个性化配置，通过线性混合效应模型分析BLEU、ROUGE-L、METEOR、BERTScore和RAGAS等多维度指标

Result: 个性化可靠地提高了推理质量和基础性，但显著降低了语义相似度得分，这种负面交互是由于当前评估指标惩罚有意义的个性化偏离，而非答案质量下降

Conclusion: 个性化产生指标依赖的性能变化而非统一改进，揭示了当前LLM评估方法的结构性缺陷，为更透明和鲁棒的个性化AI提供了方法论基础

Abstract: AIVisor, an agentic retrieval-augmented LLM for student advising, was used to examine how personalization affects system performance across multiple evaluation dimensions. Using twelve authentic advising questions intentionally designed to stress lexical precision, we compared ten personalized and non-personalized system configurations and analyzed outcomes with a Linear Mixed-Effects Model across lexical (BLEU, ROUGE-L), semantic (METEOR, BERTScore), and grounding (RAGAS) metrics. Results showed a consistent trade-off: personalization reliably improved reasoning quality and grounding, yet introduced a significant negative interaction on semantic similarity, driven not by poorer answers but by the limits of current metrics, which penalize meaningful personalized deviations from generic reference texts. This reveals a structural flaw in prevailing LLM evaluation methods, which are ill-suited for assessing user-specific responses. The fully integrated personalized configuration produced the highest overall gains, suggesting that personalization can enhance system effectiveness when evaluated with appropriate multidimensional metrics. Overall, the study demonstrates that personalization produces metric-dependent shifts rather than uniform improvements and provides a methodological foundation for more transparent and robust personalization in agentic AI.

</details>


### [2] [UserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems](https://arxiv.org/abs/2512.04588)
*Nolwenn Bernard,Krisztian Balog*

Main category: cs.IR

TL;DR: UserSimCRS v2是对话推荐系统评估工具包的升级版，增加了基于大语言模型的模拟器、增强的用户模拟器、更广泛的系统集成和新的评估工具。


<details>
  <summary>Details</summary>
Motivation: 对话推荐系统（CRS）的仿真评估资源稀缺，需要更好的工具来支持该领域的研究和发展。

Method: 开发UserSimCRS v2工具包，包含增强的议程式用户模拟器、大语言模型模拟器、更广泛的CRS和数据集集成，以及新的LLM-as-a-judge评估工具。

Result: 通过案例研究展示了这些扩展功能，提供了更先进、更全面的对话推荐系统仿真评估工具。

Conclusion: UserSimCRS v2显著提升了对话推荐系统仿真评估的能力，与最新研究进展保持一致，为领域研究提供了重要工具支持。

Abstract: Resources for simulation-based evaluation of conversational recommender systems (CRSs) are scarce. The UserSimCRS toolkit was introduced to address this gap. In this work, we present UserSimCRS v2, a significant upgrade aligning the toolkit with state-of-the-art research. Key extensions include an enhanced agenda-based user simulator, introduction of large language model-based simulators, integration for a wider range of CRSs and datasets, and new LLM-as-a-judge evaluation utilities. We demonstrate these extensions in a case study.

</details>


### [3] [Spatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery](https://arxiv.org/abs/2512.04790)
*Maddalena Amendola,Chiara Pugliese,Raffaele Perego,Chiara Renso*

Main category: cs.IR

TL;DR: WalkRAG是一个基于空间检索增强生成(RAG)的框架，通过对话界面推荐可步行的城市路线，结合信息检索、空间推理和LLMs支持城市探索。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)在空间检索和推理方面存在局限性，容易产生幻觉，需要新的解决方案来支持城市系统和旅游推荐等应用。

Method: 提出WalkRAG框架，基于空间RAG方法，结合对话界面，允许用户指定空间约束和偏好，交互式检索路径信息和兴趣点(POIs)。

Result: 初步结果显示，结合信息检索、空间推理和LLMs的方法能有效支持城市探索。

Conclusion: WalkRAG展示了空间RAG在增强LLMs进行城市路线推荐方面的潜力，为克服LLMs在空间任务中的局限性提供了有前景的解决方案。

Abstract: Large Language Models (LLMs) have become foundational tools in artificial intelligence, supporting a wide range of applications beyond traditional natural language processing, including urban systems and tourist recommendations. However, their tendency to hallucinate and their limitations in spatial retrieval and reasoning are well known, pointing to the need for novel solutions. Retrieval-augmented generation (RAG) has recently emerged as a promising way to enhance LLMs with accurate, domain-specific, and timely information. Spatial RAG extends this approach to tasks involving geographic understanding. In this work, we introduce WalkRAG, a spatial RAG-based framework with a conversational interface for recommending walkable urban itineraries. Users can request routes that meet specific spatial constraints and preferences while interactively retrieving information about the path and points of interest (POIs) along the way. Preliminary results show the effectiveness of combining information retrieval, spatial reasoning, and LLMs to support urban discovery.

</details>


### [4] [Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs](https://arxiv.org/abs/2512.04852)
*Mauro Dalle Lucca Tosi,Jordi Cabot*

Main category: cs.IR

TL;DR: 提出一种隐私感知的查询生成方法，在知识图谱查询中保护敏感数据，同时保持查询质量


<details>
  <summary>Details</summary>
Motivation: 当知识图谱包含敏感数据且用户无法部署本地生成式大语言模型时，现有方法无法保护隐私，需要解决敏感信息泄露问题

Method: 基于知识图谱结构识别敏感信息，在请求大语言模型将自然语言问题转换为Cypher查询前省略敏感值

Result: 实验结果表明，该方法在防止敏感数据传输到第三方服务的同时，保持了生成的查询质量

Conclusion: 提出的隐私感知查询生成方法有效解决了知识图谱查询中的隐私保护问题，平衡了查询质量与数据安全

Abstract: Large Language Models (LLMs) are increasingly used to query knowledge graphs (KGs) due to their strong semantic understanding and extrapolation capabilities compared to traditional approaches. However, these methods cannot be applied when the KG contains sensitive data and the user lacks the resources to deploy a local generative LLM. To address this issue, we propose a privacy-aware query generation approach for KGs. Our method identifies sensitive information in the graph based on its structure and omits such values before requesting the LLM to translate natural language questions into Cypher queries. Experimental results show that our approach preserves the quality of the generated queries while preventing sensitive data from being transmitted to third-party services.

</details>
