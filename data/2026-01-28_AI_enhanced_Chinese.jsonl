{"id": "2601.18886", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18886", "abs": "https://arxiv.org/abs/2601.18886", "authors": ["Youssef Mohamed", "Mohamed Elhoseiny", "Thibault Formal", "Nadezhda Chirkova"], "title": "XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation", "comment": "Accepted to ECIR 2026", "summary": "This paper introduces XProvence, a multilingual zero-cost context pruning model for retrieval-augmented generation (RAG), trained on 16 languages and supporting 100+ languages through effective cross-lingual transfer. Motivated by the growing use of RAG systems across diverse languages, we explore several strategies to generalize the Provence framework-which first integrated efficient zero-cost context pruning directly into the re-ranking model-beyond English. Across four multilingual question answering benchmarks, we show how XProvence can prune RAG contexts with minimal-to-no performance degradation and outperforms strong baselines. Our model is available at https://huggingface.co/naver/xprovence-reranker-bgem3-v2.", "AI": {"tldr": "XProvence\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u96f6\u6210\u672c\u4e0a\u4e0b\u6587\u526a\u679d\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\uff0c\u652f\u6301100+\u8bed\u8a00\uff0c\u572816\u79cd\u8bed\u8a00\u4e0a\u8bad\u7ec3\uff0c\u901a\u8fc7\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b9e\u73b0\u591a\u8bed\u8a00\u6269\u5c55\u3002", "motivation": "\u968f\u7740RAG\u7cfb\u7edf\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u5c06\u539f\u672c\u4ec5\u652f\u6301\u82f1\u8bed\u7684Provence\u6846\u67b6\u6269\u5c55\u5230\u591a\u8bed\u8a00\u73af\u5883\uff0c\u4ee5\u652f\u6301\u5168\u7403\u8303\u56f4\u5185\u7684\u591a\u8bed\u8a00RAG\u5e94\u7528\u3002", "method": "\u57fa\u4e8eProvence\u6846\u67b6\uff0c\u63a2\u7d22\u4e86\u591a\u79cd\u7b56\u7565\u5c06\u5176\u6269\u5c55\u5230\u591a\u8bed\u8a00\uff0c\u572816\u79cd\u8bed\u8a00\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u6709\u6548\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u652f\u6301100+\u79cd\u8bed\u8a00\uff0c\u5c06\u9ad8\u6548\u7684\u96f6\u6210\u672c\u4e0a\u4e0b\u6587\u526a\u679d\u76f4\u63a5\u96c6\u6210\u5230\u91cd\u6392\u5e8f\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u56db\u4e2a\u591a\u8bed\u8a00\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cXProvence\u80fd\u591f\u4ee5\u6700\u5c0f\u5230\u65e0\u6027\u80fd\u635f\u5931\u7684\u65b9\u5f0f\u526a\u679dRAG\u4e0a\u4e0b\u6587\uff0c\u5e76\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "XProvence\u6210\u529f\u5c06\u96f6\u6210\u672c\u4e0a\u4e0b\u6587\u526a\u679d\u6280\u672f\u6269\u5c55\u5230\u591a\u8bed\u8a00\u73af\u5883\uff0c\u4e3a\u591a\u8bed\u8a00RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u6a21\u578b\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2601.19005", "categories": ["cs.IR", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19005", "abs": "https://arxiv.org/abs/2601.19005", "authors": ["Xuan Bi", "Yaqiong Wang", "Gediminas Adomavicius", "Shawn Curley"], "title": "Recommending Composite Items Using Multi-Level Preference Information: A Joint Interaction Modeling Approach", "comment": null, "summary": "With the advancement of machine learning and artificial intelligence technologies, recommender systems have been increasingly used across a vast variety of platforms to efficiently and effectively match users with items. As application contexts become more diverse and complex, there is a growing need for more sophisticated recommendation techniques. One example is the composite item (for example, fashion outfit) recommendation where multiple levels of user preference information might be available and relevant. In this study, we propose JIMA, a joint interaction modeling approach that uses a single model to take advantage of all data from different levels of granularity and incorporate interactions to learn the complex relationships among lower-order (atomic item) and higher-order (composite item) user preferences as well as domain expertise (e.g., on the stylistic fit). We comprehensively evaluate the proposed method and compare it with advanced baselines through multiple simulation studies as well as with real data in both offline and online settings. The results consistently demonstrate the superior performance of the proposed approach.", "AI": {"tldr": "JIMA\u662f\u4e00\u4e2a\u8054\u5408\u4ea4\u4e92\u5efa\u6a21\u65b9\u6cd5\uff0c\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u6574\u5408\u4e0d\u540c\u7c92\u5ea6\u7ea7\u522b\u7684\u6570\u636e\uff0c\u5b66\u4e60\u539f\u5b50\u7269\u54c1\u548c\u7ec4\u5408\u7269\u54c1\u7684\u7528\u6237\u504f\u597d\u4ee5\u53ca\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002", "motivation": "\u968f\u7740\u63a8\u8350\u7cfb\u7edf\u5e94\u7528\u573a\u666f\u53d8\u5f97\u66f4\u52a0\u591a\u6837\u548c\u590d\u6742\uff0c\u9700\u8981\u66f4\u590d\u6742\u7684\u63a8\u8350\u6280\u672f\u3002\u7279\u522b\u662f\u5728\u7ec4\u5408\u7269\u54c1\u63a8\u8350\uff08\u5982\u65f6\u5c1a\u642d\u914d\uff09\u4e2d\uff0c\u7528\u6237\u504f\u597d\u4fe1\u606f\u53ef\u80fd\u5728\u4e0d\u540c\u7c92\u5ea6\u7ea7\u522b\u4e0a\u53ef\u7528\u4e14\u76f8\u5173\u3002", "method": "\u63d0\u51faJIMA\u65b9\u6cd5\uff0c\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u6574\u5408\u6240\u6709\u4e0d\u540c\u7c92\u5ea6\u7684\u6570\u636e\uff0c\u901a\u8fc7\u4ea4\u4e92\u5efa\u6a21\u5b66\u4e60\u4f4e\u9636\uff08\u539f\u5b50\u7269\u54c1\uff09\u548c\u9ad8\u9636\uff08\u7ec4\u5408\u7269\u54c1\uff09\u7528\u6237\u504f\u597d\u4ee5\u53ca\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff08\u5982\u98ce\u683c\u5339\u914d\uff09\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6a21\u62df\u7814\u7a76\u548c\u771f\u5b9e\u6570\u636e\u7684\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8bc4\u4f30\uff0c\u4e0e\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0c\u7ed3\u679c\u4e00\u81f4\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "JIMA\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u591a\u7c92\u5ea6\u7528\u6237\u504f\u597d\u4fe1\u606f\uff0c\u5728\u7ec4\u5408\u7269\u54c1\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u590d\u6742\u63a8\u8350\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19120", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19120", "abs": "https://arxiv.org/abs/2601.19120", "authors": ["Guilin Zhang", "Kai Zhao", "Jeffrey Friedman", "Xu Chu"], "title": "RobustExplain: Evaluating Robustness of LLM-Based Explanation Agents for Recommendation", "comment": "8 pages, 4 figures", "summary": "Large Language Models (LLMs) are increasingly used to generate natural-language explanations in recommender systems, acting as explanation agents that reason over user behavior histories. While prior work has focused on explanation fluency and relevance under fixed inputs, the robustness of LLM-generated explanations to realistic user behavior noise remains largely unexplored. In real-world web platforms, interaction histories are inherently noisy due to accidental clicks, temporal inconsistencies, missing values, and evolving preferences, raising concerns about explanation stability and user trust. We present RobustExplain, the first systematic evaluation framework for measuring the robustness of LLM-generated recommendation explanations. RobustExplain introduces five realistic user behavior perturbations evaluated across multiple severity levels and a multi-dimensional robustness metric capturing semantic, keyword, structural, and length consistency. Our goal is to establish a principled, task-level evaluation framework and initial robustness baselines, rather than to provide a comprehensive leaderboard across all available LLMs. Experiments on four representative LLMs (7B--70B) show that current models exhibit only moderate robustness, with larger models achieving up to 8% higher stability. Our results establish the first robustness benchmarks for explanation agents and highlight robustness as a critical dimension for trustworthy, agent-driven recommender systems at web scale.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86RobustExplain\u6846\u67b6\uff0c\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30LLM\u751f\u6210\u63a8\u8350\u89e3\u91ca\u5728\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u566a\u58f0\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u4ec5\u5177\u4e2d\u7b49\u9c81\u68d2\u6027\uff0c\u5927\u6a21\u578b\u7a33\u5b9a\u6027\u63d0\u5347\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLM\u751f\u6210\u63a8\u8350\u89e3\u91ca\u7684\u6d41\u7545\u6027\u548c\u76f8\u5173\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u566a\u58f0\uff08\u5982\u8bef\u70b9\u51fb\u3001\u65f6\u95f4\u4e0d\u4e00\u81f4\u3001\u7f3a\u5931\u503c\u3001\u504f\u597d\u53d8\u5316\uff09\u5bf9\u89e3\u91ca\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u8fd9\u5173\u7cfb\u5230\u7528\u6237\u4fe1\u4efb\u548c\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faRobustExplain\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e94\u79cd\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u6270\u52a8\uff08\u5728\u4e0d\u540c\u4e25\u91cd\u7ea7\u522b\u4e0b\u8bc4\u4f30\uff09\u548c\u591a\u7ef4\u5ea6\u9c81\u68d2\u6027\u6307\u6807\uff08\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u5173\u952e\u8bcd\u4e00\u81f4\u6027\u3001\u7ed3\u6784\u4e00\u81f4\u6027\u3001\u957f\u5ea6\u4e00\u81f4\u6027\uff09\u3002\u5728\u56db\u4e2a\u4ee3\u8868\u6027LLM\uff087B-70B\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5f53\u524d\u6a21\u578b\u4ec5\u8868\u73b0\u51fa\u4e2d\u7b49\u9c81\u68d2\u6027\uff0c\u5927\u6a21\u578b\uff0870B\uff09\u6bd4\u5c0f\u6a21\u578b\uff087B\uff09\u7a33\u5b9a\u6027\u63d0\u5347\u6700\u591a8%\u3002\u5efa\u7acb\u4e86\u9996\u4e2a\u89e3\u91ca\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u9c81\u68d2\u6027\u4f5c\u4e3a\u53ef\u4fe1\u63a8\u8350\u7cfb\u7edf\u5173\u952e\u7ef4\u5ea6\u7684\u73b0\u72b6\u3002", "conclusion": "\u9c81\u68d2\u6027\u662f\u53ef\u4fe1\u3001\u4ee3\u7406\u9a71\u52a8\u7684\u63a8\u8350\u7cfb\u7edf\u5728Web\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u5173\u952e\u7ef4\u5ea6\uff0cRobustExplain\u4e3a\u7cfb\u7edf\u8bc4\u4f30LLM\u751f\u6210\u89e3\u91ca\u7684\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\u548c\u57fa\u51c6\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u5bf9\u7528\u6237\u884c\u4e3a\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.19121", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.19121", "abs": "https://arxiv.org/abs/2601.19121", "authors": ["Guilin Zhang", "Kai Zhao", "Jeffrey Friedman", "Xu Chu"], "title": "LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems", "comment": "8 pages, 5 figures", "summary": "Recommendation systems must optimize multiple objectives while satisfying hard business constraints such as fairness and coverage. For example, an e-commerce platform may require every recommendation list to include items from multiple sellers and at least one newly listed product; violating such constraints--even once--is unacceptable in production. Prior work on multi-objective recommendation and recent LLM-based recommender agents largely treat constraints as soft penalties or focus on item scoring and interaction, leading to frequent violations in real-world deployments. How to leverage LLMs for coordinating constrained optimization in recommendation systems remains underexplored. We propose DualAgent-Rec, an LLM-coordinated dual-agent framework for constrained multi-objective e-commerce recommendation. The framework separates optimization into an Exploitation Agent that prioritizes accuracy under hard constraints and an Exploration Agent that promotes diversity through unconstrained Pareto search. An LLM-based coordinator adaptively allocates resources between agents based on optimization progress and constraint satisfaction, while an adaptive epsilon-relaxation mechanism guarantees feasibility of final solutions. Experiments on the Amazon Reviews 2023 dataset demonstrate that DualAgent-Rec achieves 100% constraint satisfaction and improves Pareto hypervolume by 4-6% over strong baselines, while maintaining competitive accuracy-diversity trade-offs. These results indicate that LLMs can act as effective orchestration agents for deployable and constraint-compliant recommendation systems.", "AI": {"tldr": "DualAgent-Rec\uff1a\u57fa\u4e8eLLM\u534f\u8c03\u7684\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u7ea6\u675f\u591a\u76ee\u6807\u7535\u5546\u63a8\u8350\uff0c\u5b9e\u73b0100%\u7ea6\u675f\u6ee1\u8db3\u548c4-6%\u7684\u5e15\u7d2f\u6258\u8d85\u4f53\u79ef\u63d0\u5347", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u5728\u5904\u7406\u786c\u4e1a\u52a1\u7ea6\u675f\uff08\u5982\u516c\u5e73\u6027\u3001\u8986\u76d6\u7387\uff09\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u4f20\u7edf\u65b9\u6cd5\u5c06\u7ea6\u675f\u89c6\u4e3a\u8f6f\u60e9\u7f5a\uff0c\u5bfc\u81f4\u5b9e\u9645\u90e8\u7f72\u4e2d\u9891\u7e41\u8fdd\u53cd\u7ea6\u675f\u3002LLM\u5728\u63a8\u8350\u7cfb\u7edf\u7ea6\u675f\u534f\u8c03\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faDualAgent-Rec\u6846\u67b6\uff1a1\uff09\u5229\u7528\u667a\u80fd\u4f53\u8d1f\u8d23\u5728\u786c\u7ea6\u675f\u4e0b\u4f18\u5148\u8003\u8651\u51c6\u786e\u6027\uff1b2\uff09\u63a2\u7d22\u667a\u80fd\u4f53\u901a\u8fc7\u65e0\u7ea6\u675f\u5e15\u7d2f\u6258\u641c\u7d22\u4fc3\u8fdb\u591a\u6837\u6027\uff1b3\uff09\u57fa\u4e8eLLM\u7684\u534f\u8c03\u5668\u6839\u636e\u4f18\u5316\u8fdb\u5ea6\u548c\u7ea6\u675f\u6ee1\u8db3\u60c5\u51b5\u81ea\u9002\u5e94\u5206\u914d\u8d44\u6e90\uff1b4\uff09\u81ea\u9002\u5e94epsilon\u677e\u5f1b\u673a\u5236\u4fdd\u8bc1\u6700\u7ec8\u89e3\u7684\u53ef\u884c\u6027\u3002", "result": "\u5728Amazon Reviews 2023\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1aDualAgent-Rec\u5b9e\u73b0\u4e86100%\u7684\u7ea6\u675f\u6ee1\u8db3\u7387\uff0c\u5e15\u7d2f\u6258\u8d85\u4f53\u79ef\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u53474-6%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027-\u591a\u6837\u6027\u6743\u8861\u3002", "conclusion": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u7f16\u6392\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u53ef\u90e8\u7f72\u4e14\u7b26\u5408\u7ea6\u675f\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u4e3a\u89e3\u51b3\u5b9e\u9645\u751f\u4ea7\u4e2d\u7684\u786c\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.19158", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19158", "abs": "https://arxiv.org/abs/2601.19158", "authors": ["Qijiong Liu", "Lu Fan", "Zhongzhou Liu", "Xiaoyu Dong", "Yuankai Luo", "Guoyuan An", "Nuo Chen", "Wei Guo", "Yong Liu", "Xiao-Ming Wu"], "title": "Accelerating Generative Recommendation via Simple Categorical User Sequence Compression", "comment": "WSDM'26 Accepted Paper", "summary": "Although generative recommenders demonstrate improved performance with longer sequences, their real-time deployment is hindered by substantial computational costs. To address this challenge, we propose a simple yet effective method for compressing long-term user histories by leveraging inherent item categorical features, thereby preserving user interests while enhancing efficiency. Experiments on two large-scale datasets demonstrate that, compared to the influential HSTU model, our approach achieves up to a 6x reduction in computational cost and up to 39% higher accuracy at comparable cost (i.e., similar sequence length).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7269\u54c1\u7c7b\u522b\u7279\u5f81\u538b\u7f29\u957f\u5e8f\u5217\u7528\u6237\u5386\u53f2\u7684\u65b9\u6cd5\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u957f\u5e8f\u5217\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u6548\u7684\u5e8f\u5217\u538b\u7f29\u65b9\u6cd5", "method": "\u5229\u7528\u7269\u54c1\u56fa\u6709\u7684\u7c7b\u522b\u7279\u5f81\u6765\u538b\u7f29\u957f\u671f\u7528\u6237\u5386\u53f2\uff0c\u5728\u4fdd\u6301\u7528\u6237\u5174\u8da3\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387", "result": "\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4HSTU\u6a21\u578b\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e6\u500d\uff0c\u5728\u76f8\u4f3c\u5e8f\u5217\u957f\u5ea6\u4e0b\u51c6\u786e\u7387\u63d0\u534739%", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5b9e\u65f6\u90e8\u7f72\u7684\u74f6\u9888"}}
{"id": "2601.19197", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19197", "abs": "https://arxiv.org/abs/2601.19197", "authors": ["Sushant Mehta"], "title": "HELM: A Human-Centered Evaluation Framework for LLM-Powered Recommender Systems", "comment": null, "summary": "The integration of Large Language Models (LLMs) into recommendation systems has introduced unprecedented capabilities for natural language understanding, explanation generation, and conversational interactions. However, existing evaluation methodologies focus predominantly on traditional accuracy metrics, failing to capture the multifaceted human-centered qualities that determine the real-world user experience. We introduce \\framework{} (\\textbf{H}uman-centered \\textbf{E}valuation for \\textbf{L}LM-powered reco\\textbf{M}menders), a comprehensive evaluation framework that systematically assesses LLM-powered recommender systems across five human-centered dimensions: \\textit{Intent Alignment}, \\textit{Explanation Quality}, \\textit{Interaction Naturalness}, \\textit{Trust \\& Transparency}, and \\textit{Fairness \\& Diversity}. Through extensive experiments involving three state-of-the-art LLM-based recommenders (GPT-4, LLaMA-3.1, and P5) across three domains (movies, books, and restaurants), and rigorous evaluation by 12 domain experts using 847 recommendation scenarios, we demonstrate that \\framework{} reveals critical quality dimensions invisible to traditional metrics. Our results show that while GPT-4 achieves superior explanation quality (4.21/5.0) and interaction naturalness (4.35/5.0), it exhibits a significant popularity bias (Gini coefficient 0.73) compared to traditional collaborative filtering (0.58). We release \\framework{} as an open-source toolkit to advance human-centered evaluation practices in the recommender systems community.", "AI": {"tldr": "\u63d0\u51fa\u4e86HELM\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLM\u63a8\u8350\u7cfb\u7edf\u5728\u4e94\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u5f25\u8865\u4f20\u7edf\u51c6\u786e\u6027\u6307\u6807\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4f20\u7edf\u51c6\u786e\u6027\u6307\u6807\uff0c\u65e0\u6cd5\u6355\u6349\u51b3\u5b9a\u771f\u5b9e\u7528\u6237\u4f53\u9a8c\u7684\u591a\u65b9\u9762\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u54c1\u8d28\u3002LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u80fd\u529b\uff0c\u4f46\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faHELM\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u63a8\u8350\u7cfb\u7edf\u5728\u4e94\u4e2a\u7ef4\u5ea6\uff1a\u610f\u56fe\u5bf9\u9f50\u3001\u89e3\u91ca\u8d28\u91cf\u3001\u4ea4\u4e92\u81ea\u7136\u6027\u3001\u4fe1\u4efb\u4e0e\u900f\u660e\u5ea6\u3001\u516c\u5e73\u6027\u4e0e\u591a\u6837\u6027\u3002\u4f7f\u7528\u4e09\u4e2a\u6700\u5148\u8fdb\u7684LLM\u63a8\u8350\u7cfb\u7edf\uff08GPT-4\u3001LLaMA-3.1\u3001P5\uff09\u5728\u4e09\u4e2a\u9886\u57df\uff08\u7535\u5f71\u3001\u4e66\u7c4d\u3001\u9910\u5385\uff09\u8fdb\u884c\u5b9e\u9a8c\uff0c\u753112\u4f4d\u9886\u57df\u4e13\u5bb6\u5bf9847\u4e2a\u63a8\u8350\u573a\u666f\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "result": "HELM\u63ed\u793a\u4e86\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u770b\u5230\u7684\u6279\u5224\u6027\u8d28\u91cf\u7ef4\u5ea6\u3002GPT-4\u5728\u89e3\u91ca\u8d28\u91cf\uff084.21/5.0\uff09\u548c\u4ea4\u4e92\u81ea\u7136\u6027\uff084.35/5.0\uff09\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8868\u73b0\u51fa\u663e\u8457\u7684\u70ed\u95e8\u504f\u89c1\uff08\u57fa\u5c3c\u7cfb\u65700.73\uff09\uff0c\u800c\u4f20\u7edf\u534f\u540c\u8fc7\u6ee4\u4e3a0.58\u3002", "conclusion": "HELM\u6846\u67b6\u4e3a\u63a8\u8350\u7cfb\u7edf\u793e\u533a\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u5de5\u5177\u5305\u53d1\u5e03\u4ee5\u63a8\u8fdb\u8be5\u9886\u57df\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002"}}
{"id": "2601.19198", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19198", "abs": "https://arxiv.org/abs/2601.19198", "authors": ["Xinzhuo Wu", "Hongbo Wang", "Yuan Lin", "Kan Xu", "Liang Yang", "Hongfei Lin"], "title": "Propagating Similarity, Mitigating Uncertainty: Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation", "comment": "Accepted by ICASSP2026", "summary": "Multimodal Recommendation (MMR) systems are crucial for modern platforms but are often hampered by inherent noise and uncertainty in modal features, such as blurry images, diverse visual appearances, or ambiguous text. Existing methods often overlook this modality-specific uncertainty, leading to ineffective feature fusion. Furthermore, they fail to leverage rich similarity patterns among users and items to refine representations and their corresponding uncertainty estimates. To address these challenges, we propose a novel framework, Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation (SPUMR). SPUMR explicitly models and mitigates uncertainty by first constructing the Modality Similarity Graph and the Collaborative Similarity Graph to refine representations from both content and behavioral perspectives. The Uncertainty-aware Preference Aggregation module then adaptively fuses the refined multimodal features, assigning greater weight to more reliable modalities. Extensive experiments on three benchmark datasets demonstrate that SPUMR achieves significant improvements over existing leading methods.", "AI": {"tldr": "SPUMR\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u76f8\u4f3c\u6027\u4f20\u64ad\u589e\u5f3a\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u6765\u6539\u8fdb\u63a8\u8350\u6548\u679c\uff0c\u89e3\u51b3\u4e86\u6a21\u6001\u7279\u5f81\u4e2d\u7684\u566a\u58f0\u548c\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u6a21\u6001\u7279\u5f81\u56fa\u6709\u7684\u566a\u58f0\u548c\u4e0d\u786e\u5b9a\u6027\uff08\u5982\u6a21\u7cca\u56fe\u50cf\u3001\u591a\u6837\u89c6\u89c9\u5916\u89c2\u3001\u6a21\u7cca\u6587\u672c\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u6a21\u6001\u7279\u5b9a\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u7279\u5f81\u878d\u5408\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u672a\u80fd\u5229\u7528\u7528\u6237\u548c\u7269\u54c1\u95f4\u7684\u4e30\u5bcc\u76f8\u4f3c\u6027\u6a21\u5f0f\u6765\u4f18\u5316\u8868\u793a\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "SPUMR\u9996\u5148\u6784\u5efa\u6a21\u6001\u76f8\u4f3c\u6027\u56fe\u548c\u534f\u540c\u76f8\u4f3c\u6027\u56fe\uff0c\u4ece\u5185\u5bb9\u548c\u884c\u4e3a\u89d2\u5ea6\u4f18\u5316\u8868\u793a\uff1b\u7136\u540e\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u504f\u597d\u805a\u5408\u6a21\u5757\u81ea\u9002\u5e94\u878d\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u4e3a\u66f4\u53ef\u9760\u7684\u6a21\u6001\u5206\u914d\u66f4\u5927\u6743\u91cd\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSPUMR\u76f8\u6bd4\u73b0\u6709\u9886\u5148\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "SPUMR\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u548c\u7f13\u89e3\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5229\u7528\u76f8\u4f3c\u6027\u4f20\u64ad\u6765\u4f18\u5316\u8868\u793a\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2601.19244", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19244", "abs": "https://arxiv.org/abs/2601.19244", "authors": ["Chayan Banerjee"], "title": "Physics-Informed Neuro-Symbolic Recommender System: A Dual-Physics Approach for Personalized Nutrition", "comment": null, "summary": "Traditional e-commerce recommender systems primarily optimize for user engagement and purchase likelihood, often neglecting the rigid physiological constraints required for human health. Standard collaborative filtering algorithms are structurally blind to these hard limits, frequently suggesting bundles that fail to meet specific total daily energy expenditure and macronutrient balance requirements. To address this disconnect, this paper introduces a Physics-Informed Neuro-Symbolic Recommender System that integrates nutritional science directly into the recommendation pipeline via a dual-layer architecture. The framework begins by constructing a semantic knowledge graph using sentence-level encoders to strictly align commercial products with authoritative nutritional data. During the training phase, an implicit physics regularizer applies a differentiable thermodynamic loss function, ensuring that learned latent embeddings reflect nutritional plausibility rather than simple popularity. Subsequently, during the inference phase, an explicit physics optimizer employs simulated annealing and elastic quantity optimization to generate discrete grocery bundles that strictly adhere to the user's protein and caloric targets.", "AI": {"tldr": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7b26\u53f7\u63a8\u8350\u7cfb\u7edf\uff0c\u5c06\u8425\u517b\u79d1\u5b66\u878d\u5165\u63a8\u8350\u6d41\u7a0b\uff0c\u786e\u4fdd\u98df\u54c1\u63a8\u8350\u7b26\u5408\u7528\u6237\u80fd\u91cf\u548c\u8425\u517b\u9700\u6c42", "motivation": "\u4f20\u7edf\u7535\u5546\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u4f18\u5316\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u8d2d\u4e70\u53ef\u80fd\u6027\uff0c\u5ffd\u89c6\u4eba\u7c7b\u5065\u5eb7\u6240\u9700\u7684\u521a\u6027\u751f\u7406\u7ea6\u675f\u3002\u6807\u51c6\u534f\u540c\u8fc7\u6ee4\u7b97\u6cd5\u5728\u7ed3\u6784\u4e0a\u65e0\u89c6\u8fd9\u4e9b\u786c\u6027\u9650\u5236\uff0c\u7ecf\u5e38\u63a8\u8350\u4e0d\u7b26\u5408\u6bcf\u65e5\u603b\u80fd\u91cf\u6d88\u8017\u548c\u5b8f\u91cf\u8425\u517b\u7d20\u5e73\u8861\u8981\u6c42\u7684\u98df\u54c1\u7ec4\u5408\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u6b21\u67b6\u6784\uff1a1) \u4f7f\u7528\u53e5\u5b50\u7ea7\u7f16\u7801\u5668\u6784\u5efa\u8bed\u4e49\u77e5\u8bc6\u56fe\u8c31\uff0c\u5c06\u5546\u4e1a\u4ea7\u54c1\u4e0e\u6743\u5a01\u8425\u517b\u6570\u636e\u4e25\u683c\u5bf9\u9f50\uff1b2) \u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u9690\u5f0f\u7269\u7406\u6b63\u5219\u5316\u5668\uff0c\u5e94\u7528\u53ef\u5fae\u5206\u70ed\u529b\u5b66\u635f\u5931\u51fd\u6570\uff0c\u786e\u4fdd\u5b66\u4e60\u7684\u6f5c\u5728\u5d4c\u5165\u53cd\u6620\u8425\u517b\u5408\u7406\u6027\u800c\u975e\u7b80\u5355\u6d41\u884c\u5ea6\uff1b3) \u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u663e\u5f0f\u7269\u7406\u4f18\u5316\u5668\uff0c\u91c7\u7528\u6a21\u62df\u9000\u706b\u548c\u5f39\u6027\u6570\u91cf\u4f18\u5316\u751f\u6210\u4e25\u683c\u7b26\u5408\u7528\u6237\u86cb\u767d\u8d28\u548c\u70ed\u91cf\u76ee\u6807\u7684\u79bb\u6563\u98df\u54c1\u7ec4\u5408\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u7b26\u5408\u8425\u517b\u7ea6\u675f\u7684\u98df\u54c1\u63a8\u8350\u6846\u67b6\uff0c\u4f46\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u6570\u636e\u3002", "conclusion": "\u8be5\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7b26\u53f7\u63a8\u8350\u7cfb\u7edf\u6210\u529f\u5c06\u8425\u517b\u79d1\u5b66\u76f4\u63a5\u6574\u5408\u5230\u63a8\u8350\u6d41\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u5ffd\u89c6\u5065\u5eb7\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u80fd\u591f\u751f\u6210\u4e25\u683c\u7b26\u5408\u7528\u6237\u751f\u7406\u9700\u6c42\u7684\u98df\u54c1\u7ec4\u5408\u3002"}}
{"id": "2601.19276", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19276", "abs": "https://arxiv.org/abs/2601.19276", "authors": ["Shengjia Zhang", "Weiqin Yang", "Jiawei Chen", "Peng Wu", "Yuegang Sun", "Gang Wang", "Qihao Shi", "Can Wang"], "title": "Talos: Optimizing Top-$K$ Accuracy in Recommender Systems", "comment": "Accepted by WWW'26", "summary": "Recommender systems (RS) aim to retrieve a small set of items that best match individual user preferences. Naturally, RS place primary emphasis on the quality of the Top-$K$ results rather than performance across the entire item set. However, estimating Top-$K$ accuracy (e.g., Precision@$K$, Recall@$K$) requires determining the ranking positions of items, which imposes substantial computational overhead and poses significant challenges for optimization. In addition, RS often suffer from distribution shifts due to evolving user preferences or data biases, further complicating the task.\n  To address these issues, we propose Talos, a loss function that is specifically designed to optimize the Talos recommendation accuracy. Talos leverages a quantile technique that replaces the complex ranking-dependent operations into simpler comparisons between predicted scores and learned score thresholds. We further develop a sampling-based regression algorithm for efficient and accurate threshold estimation, and introduce a constraint term to maintain optimization stability by preventing score inflation. Additionally, we incorporate a tailored surrogate function to address discontinuity and enhance robustness against distribution shifts. Comprehensive theoretical analyzes and empirical experiments are conducted to demonstrate the effectiveness, efficiency, convergence, and distributional robustness of Talos. The code is available at https://github.com/cynthia-shengjia/WWW-2026-Talos.", "AI": {"tldr": "Talos\u662f\u4e00\u79cd\u4e13\u95e8\u4f18\u5316Top-K\u63a8\u8350\u51c6\u786e\u6027\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u5206\u4f4d\u6570\u6280\u672f\u5c06\u590d\u6742\u7684\u6392\u540d\u76f8\u5173\u64cd\u4f5c\u7b80\u5316\u4e3a\u9884\u6d4b\u5206\u6570\u4e0e\u5b66\u4e60\u9608\u503c\u4e4b\u95f4\u7684\u6bd4\u8f83\uff0c\u5e76\u901a\u8fc7\u91c7\u6837\u56de\u5f52\u7b97\u6cd5\u3001\u7ea6\u675f\u9879\u548c\u4ee3\u7406\u51fd\u6570\u63d0\u9ad8\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8Top-K\u7ed3\u679c\u8d28\u91cf\uff0c\u4f46\u8bc4\u4f30Top-K\u51c6\u786e\u6027\u9700\u8981\u786e\u5b9a\u7269\u54c1\u7684\u6392\u540d\u4f4d\u7f6e\uff0c\u8fd9\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u4f18\u5316\u6311\u6218\u3002\u6b64\u5916\uff0c\u63a8\u8350\u7cfb\u7edf\u5e38\u9762\u4e34\u7528\u6237\u504f\u597d\u6f14\u53d8\u6216\u6570\u636e\u504f\u5dee\u5bfc\u81f4\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51faTalos\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u5206\u4f4d\u6570\u6280\u672f\u5c06\u6392\u540d\u76f8\u5173\u64cd\u4f5c\u8f6c\u6362\u4e3a\u9884\u6d4b\u5206\u6570\u4e0e\u5b66\u4e60\u9608\u503c\u4e4b\u95f4\u7684\u6bd4\u8f83\uff1b\u5f00\u53d1\u91c7\u6837\u56de\u5f52\u7b97\u6cd5\u8fdb\u884c\u9ad8\u6548\u51c6\u786e\u7684\u9608\u503c\u4f30\u8ba1\uff1b\u5f15\u5165\u7ea6\u675f\u9879\u9632\u6b62\u5206\u6570\u81a8\u80c0\uff1b\u8bbe\u8ba1\u5b9a\u5236\u4ee3\u7406\u51fd\u6570\u5904\u7406\u4e0d\u8fde\u7eed\u6027\u548c\u589e\u5f3a\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86Talos\u5728\u6709\u6548\u6027\u3001\u6548\u7387\u3001\u6536\u655b\u6027\u548c\u5206\u5e03\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "Talos\u80fd\u591f\u6709\u6548\u4f18\u5316Top-K\u63a8\u8350\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u6027\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.19423", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19423", "abs": "https://arxiv.org/abs/2601.19423", "authors": ["Zijie Lei", "Tao Feng", "Zhigang Hua", "Yan Xie", "Guanyu Lin", "Shuang Yang", "Ge Liu", "Jiaxuan You"], "title": "UniRec: Unified Multimodal Encoding for LLM-Based Recommendations", "comment": null, "summary": "Large language models have recently shown promise for multimodal recommendation, particularly with text and image inputs. Yet real-world recommendation signals extend far beyond these modalities. To reflect this, we formalize recommendation features into four modalities: text, images, categorical features, and numerical attributes, and highlight the unique challenges this heterogeneity poses for LLMs in understanding multimodal information. In particular, these challenges arise not only across modalities but also within them, as attributes such as price, rating, and time may all be numeric yet carry distinct semantic meanings. Beyond this intra-modality ambiguity, another major challenge is the nested structure of recommendation signals, where user histories are sequences of items, each associated with multiple attributes. To address these challenges, we propose UniRec, a unified multimodal encoder for LLM-based recommendation. UniRec first employs modality-specific encoders to produce consistent embeddings across heterogeneous signals. It then adopts a triplet representation, comprising attribute name, type, and value, to separate schema from raw inputs and preserve semantic distinctions. Finally, a hierarchical Q-Former models the nested structure of user interactions while maintaining their layered organization. Across multiple real-world benchmarks, UniRec outperforms state-of-the-art multimodal and LLM-based recommenders by up to 15%, and extensive ablation studies further validate the contributions of each component.", "AI": {"tldr": "UniRec\u662f\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u591a\u6a21\u6001\u63a8\u8350\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u3001\u4e09\u5143\u7ec4\u8868\u793a\u548c\u5206\u5c42Q-Former\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf\u3001\u5206\u7c7b\u548c\u6570\u503c\u56db\u79cd\u6a21\u6001\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u5f02\u8d28\u6027\u548c\u5d4c\u5957\u7ed3\u6784\u6311\u6218\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd515%\u3002", "motivation": "\u73b0\u6709LLM\u591a\u6a21\u6001\u63a8\u8350\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u548c\u56fe\u50cf\uff0c\u4f46\u771f\u5b9e\u63a8\u8350\u4fe1\u53f7\u5305\u542b\u66f4\u591a\u6a21\u6001\uff08\u5206\u7c7b\u7279\u5f81\u548c\u6570\u503c\u5c5e\u6027\uff09\u3002\u591a\u6a21\u6001\u5f02\u8d28\u6027\u5e26\u6765\u8de8\u6a21\u6001\u548c\u6a21\u6001\u5185\u6311\u6218\uff0c\u7279\u522b\u662f\u6570\u503c\u5c5e\u6027\uff08\u5982\u4ef7\u683c\u3001\u8bc4\u5206\u3001\u65f6\u95f4\uff09\u5177\u6709\u4e0d\u540c\u8bed\u4e49\u542b\u4e49\u3002\u6b64\u5916\uff0c\u63a8\u8350\u4fe1\u53f7\u5177\u6709\u5d4c\u5957\u7ed3\u6784\uff08\u7528\u6237\u5386\u53f2\u662f\u9879\u76ee\u5e8f\u5217\uff0c\u6bcf\u4e2a\u9879\u76ee\u6709\u591a\u4e2a\u5c5e\u6027\uff09\uff0c\u8fd9\u7ed9LLM\u7406\u89e3\u591a\u6a21\u6001\u4fe1\u606f\u5e26\u6765\u72ec\u7279\u6311\u6218\u3002", "method": "UniRec\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u4e3a\u5f02\u8d28\u4fe1\u53f7\u751f\u6210\u4e00\u81f4\u5d4c\u5165\uff1b2) \u91c7\u7528\u4e09\u5143\u7ec4\u8868\u793a\uff08\u5c5e\u6027\u540d\u3001\u7c7b\u578b\u3001\u503c\uff09\u5206\u79bb\u6a21\u5f0f\u4e0e\u539f\u59cb\u8f93\u5165\uff0c\u4fdd\u6301\u8bed\u4e49\u533a\u5206\uff1b3) \u4f7f\u7528\u5206\u5c42Q-Former\u5efa\u6a21\u7528\u6237\u4ea4\u4e92\u7684\u5d4c\u5957\u7ed3\u6784\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u5c42\u7ec4\u7ec7\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUniRec\u6bd4\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u548cLLM\u63a8\u8350\u5668\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe15%\u3002\u5e7f\u6cdb\u7684\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u6bcf\u4e2a\u7ec4\u4ef6\u7684\u8d21\u732e\u3002", "conclusion": "UniRec\u901a\u8fc7\u7edf\u4e00\u7684\u7f16\u7801\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7684\u5f02\u8d28\u6027\u548c\u5d4c\u5957\u7ed3\u6784\u6311\u6218\uff0c\u8bc1\u660e\u4e86\u5728LLM\u63a8\u8350\u4e2d\u5168\u9762\u8003\u8651\u591a\u79cd\u6a21\u6001\u548c\u7ed3\u6784\u4fe1\u606f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.19501", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19501", "abs": "https://arxiv.org/abs/2601.19501", "authors": ["Lingyu Mu", "Hao Deng", "Haibo Xing", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "Masked Diffusion Generative Recommendation", "comment": null, "summary": "Generative recommendation (GR) typically first quantizes continuous item embeddings into multi-level semantic IDs (SIDs), and then generates the next item via autoregressive decoding. Although existing methods are already competitive in terms of recommendation performance, directly inheriting the autoregressive decoding paradigm from language models still suffers from three key limitations: (1) autoregressive decoding struggles to jointly capture global dependencies among the multi-dimensional features associated with different positions of SID; (2) using a unified, fixed decoding path for the same item implicitly assumes that all users attend to item attributes in the same order; (3) autoregressive decoding is inefficient at inference time and struggles to meet real-time requirements. To tackle these challenges, we propose MDGR, a Masked Diffusion Generative Recommendation framework that reshapes the GR pipeline from three perspectives: codebook, training, and inference. (1) We adopt a parallel codebook to provide a structural foundation for diffusion-based GR. (2) During training, we adaptively construct masking supervision signals along both the temporal and sample dimensions. (3) During inference, we develop a warm-up-based two-stage parallel decoding strategy for efficient generation of SIDs. Extensive experiments on multiple public and industrial-scale datasets show that MDGR outperforms ten state-of-the-art baselines by up to 10.78%. Furthermore, by deploying MDGR on a large-scale online advertising platform, we achieve a 1.20% increase in revenue, demonstrating its practical value. The code will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51faMDGR\u6846\u67b6\uff0c\u4f7f\u7528\u63a9\u7801\u6269\u6563\u751f\u6210\u63a8\u8350\uff0c\u89e3\u51b3\u4f20\u7edf\u81ea\u56de\u5f52\u89e3\u7801\u7684\u4e09\u4e2a\u9650\u5236\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u5e76\u63d0\u5347\u5728\u7ebf\u5e7f\u544a\u6536\u51651.20%", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u7684\u81ea\u56de\u5f52\u89e3\u7801\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a1) \u96be\u4ee5\u8054\u5408\u6355\u6349SID\u591a\u7ef4\u7279\u5f81\u7684\u5168\u5c40\u4f9d\u8d56\uff1b2) \u56fa\u5b9a\u89e3\u7801\u8def\u5f84\u5047\u8bbe\u6240\u6709\u7528\u6237\u4ee5\u76f8\u540c\u987a\u5e8f\u5173\u6ce8\u9879\u76ee\u5c5e\u6027\uff1b3) \u63a8\u7406\u6548\u7387\u4f4e\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u9700\u6c42", "method": "\u63d0\u51faMDGR\u63a9\u7801\u6269\u6563\u751f\u6210\u63a8\u8350\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u89d2\u5ea6\u91cd\u5851GR\u6d41\u7a0b\uff1a1) \u91c7\u7528\u5e76\u884c\u7801\u672c\u4e3a\u6269\u6563\u57fa\u7840\uff1b2) \u8bad\u7ec3\u65f6\u6cbf\u65f6\u95f4\u548c\u6837\u672c\u7ef4\u5ea6\u81ea\u9002\u5e94\u6784\u5efa\u63a9\u7801\u76d1\u7763\u4fe1\u53f7\uff1b3) \u63a8\u7406\u65f6\u4f7f\u7528\u57fa\u4e8e\u9884\u70ed\u7684\u4e24\u9636\u6bb5\u5e76\u884c\u89e3\u7801\u7b56\u7565", "result": "\u5728\u591a\u4e2a\u516c\u5171\u548c\u5de5\u4e1a\u7ea7\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a10\u4e2aSOTA\u57fa\u7ebf\u8fbe10.78%\uff0c\u5728\u5927\u578b\u5728\u7ebf\u5e7f\u544a\u5e73\u53f0\u90e8\u7f72\u5b9e\u73b0\u6536\u5165\u63d0\u53471.20%", "conclusion": "MDGR\u901a\u8fc7\u63a9\u7801\u6269\u6563\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u56de\u5f52\u89e3\u7801\u7684\u9650\u5236\uff0c\u5728\u63a8\u8350\u6027\u80fd\u548c\u63a8\u7406\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.19513", "categories": ["cs.IR", "cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2601.19513", "abs": "https://arxiv.org/abs/2601.19513", "authors": ["Haixu Xi", "Heng Zhang", "Chengzhi Zhang"], "title": "Enhancing Academic Paper Recommendations Using Fine-Grained Knowledge Entities and Multifaceted Document Embeddings", "comment": null, "summary": "In the era of explosive growth in academic literature, the burden of literature review on scholars are increasing. Proactively recommending academic papers that align with scholars' literature needs in the research process has become one of the crucial pathways to enhance research efficiency and stimulate innovative thinking. Current academic paper recommendation systems primarily focus on broad and coarse-grained suggestions based on general topic or field similarities. While these systems effectively identify related literature, they fall short in addressing scholars' more specific and fine-grained needs, such as locating papers that utilize particular research methods, or tackle distinct research tasks within the same topic. To meet the diverse and specific literature needs of scholars in the research process, this paper proposes a novel academic paper recommendation method. This approach embeds multidimensional information by integrating new types of fine-grained knowledge entities, title and abstract of document, and citation data. Recommendations are then generated by calculating the similarity between combined paper vectors. The proposed recommendation method was evaluated using the STM-KG dataset, a knowledge graph that incorporates scientific concepts derived from papers across ten distinct domains. The experimental results indicate that our method outperforms baseline models, achieving an average precision of 27.3% among the top 50 recommendations. This represents an improvement of 6.7% over existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5b66\u672f\u8bba\u6587\u63a8\u8350\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u5b9e\u4f53\u3001\u6587\u6863\u6807\u9898\u6458\u8981\u548c\u5f15\u7528\u6570\u636e\u6765\u5d4c\u5165\u591a\u7ef4\u4fe1\u606f\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u4e8e\u4e3b\u9898\u76f8\u4f3c\u6027\u7684\u7c97\u7c92\u5ea6\u63a8\u8350\u7cfb\u7edf\uff0c\u80fd\u66f4\u597d\u5730\u6ee1\u8db3\u5b66\u8005\u5bf9\u7279\u5b9a\u7814\u7a76\u65b9\u6cd5\u6216\u4efb\u52a1\u7684\u6587\u732e\u9700\u6c42\u3002", "motivation": "\u5b66\u672f\u6587\u732e\u7206\u70b8\u5f0f\u589e\u957f\u589e\u52a0\u4e86\u5b66\u8005\u7684\u6587\u732e\u7efc\u8ff0\u8d1f\u62c5\u3002\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u57fa\u4e8e\u5bbd\u6cdb\u7684\u4e3b\u9898\u76f8\u4f3c\u6027\u8fdb\u884c\u7c97\u7c92\u5ea6\u63a8\u8350\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b66\u8005\u5728\u7814\u7a76\u8fc7\u7a0b\u4e2d\u5bf9\u7279\u5b9a\u7814\u7a76\u65b9\u6cd5\u3001\u4efb\u52a1\u7b49\u7ec6\u7c92\u5ea6\u6587\u732e\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5b66\u672f\u8bba\u6587\u63a8\u8350\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u5b9e\u4f53\u3001\u6587\u6863\u6807\u9898\u6458\u8981\u548c\u5f15\u7528\u6570\u636e\u6765\u5d4c\u5165\u591a\u7ef4\u4fe1\u606f\uff0c\u7136\u540e\u901a\u8fc7\u8ba1\u7b97\u7ec4\u5408\u8bba\u6587\u5411\u91cf\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6765\u751f\u6210\u63a8\u8350\u3002", "result": "\u5728STM-KG\u6570\u636e\u96c6\uff08\u5305\u542b\u5341\u4e2a\u4e0d\u540c\u9886\u57df\u79d1\u5b66\u6982\u5ff5\u7684\u77e5\u8bc6\u56fe\u8c31\uff09\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u524d50\u4e2a\u63a8\u8350\u4e2d\u5e73\u5747\u7cbe\u5ea6\u8fbe\u523027.3%\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e866.7%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u6ee1\u8db3\u5b66\u8005\u5728\u7814\u7a76\u8fc7\u7a0b\u4e2d\u7684\u591a\u6837\u5316\u548c\u5177\u4f53\u5316\u6587\u732e\u9700\u6c42\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u5b9e\u4f53\u6574\u5408\u548c\u591a\u7ef4\u4fe1\u606f\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u672f\u8bba\u6587\u63a8\u8350\u7684\u7cbe\u5ea6\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.19535", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19535", "abs": "https://arxiv.org/abs/2601.19535", "authors": ["Manish Chandra", "Debasis Ganguly", "Iadh Ounis"], "title": "LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG", "comment": null, "summary": "Most conventional Retrieval-Augmented Generation (RAG) pipelines rely on relevance-based retrieval, which often misaligns with utility -- that is, whether the retrieved passages actually improve the quality of the generated text specific to a downstream task such as question answering or query-based summarization. The limitations of existing utility-driven retrieval approaches for RAG are that, firstly, they are resource-intensive typically requiring query encoding, and that secondly, they do not involve listwise ranking loss during training. The latter limitation is particularly critical, as the relative order between documents directly affects generation in RAG. To address this gap, we propose Lightweight Utility-driven Reranking for Efficient RAG (LURE-RAG), a framework that augments any black-box retriever with an efficient LambdaMART-based reranker. Unlike prior methods, LURE-RAG trains the reranker with a listwise ranking loss guided by LLM utility, thereby directly optimizing the ordering of retrieved documents. Experiments on two standard datasets demonstrate that LURE-RAG achieves competitive performance, reaching 97-98% of the state-of-the-art dense neural baseline, while remaining efficient in both training and inference. Moreover, its dense variant, UR-RAG, significantly outperforms the best existing baseline by up to 3%.", "AI": {"tldr": "LURE-RAG\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6548\u7528\u9a71\u52a8\u7684\u91cd\u6392\u5e8f\u6846\u67b6\uff0c\u901a\u8fc7LambdaMART\u91cd\u6392\u5e8f\u5668\u548c\u5217\u8868\u6392\u5e8f\u635f\u5931\u4f18\u5316\u68c0\u7d22\u6587\u6863\u7684\u6392\u5e8f\uff0c\u63d0\u5347RAG\u751f\u6210\u8d28\u91cf\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u8fbe\u5230\u63a5\u8fd1SOTA\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfRAG\u7ba1\u9053\u4f9d\u8d56\u76f8\u5173\u6027\u68c0\u7d22\uff0c\u4f46\u76f8\u5173\u6027\u5e38\u4e0e\u6548\u7528\uff08\u5373\u68c0\u7d22\u5230\u7684\u6bb5\u843d\u662f\u5426\u771f\u6b63\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u751f\u6210\u8d28\u91cf\uff09\u4e0d\u5339\u914d\u3002\u73b0\u6709\u6548\u7528\u9a71\u52a8\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5c40\u9650\uff1a1) \u9700\u8981\u67e5\u8be2\u7f16\u7801\uff0c\u8d44\u6e90\u5bc6\u96c6\uff1b2) \u8bad\u7ec3\u4e2d\u672a\u4f7f\u7528\u5217\u8868\u6392\u5e8f\u635f\u5931\uff0c\u800c\u6587\u6863\u76f8\u5bf9\u987a\u5e8f\u76f4\u63a5\u5f71\u54cdRAG\u751f\u6210\u6548\u679c\u3002", "method": "\u63d0\u51faLURE-RAG\u6846\u67b6\uff0c\u4e3a\u4efb\u4f55\u9ed1\u76d2\u68c0\u7d22\u5668\u6dfb\u52a0\u9ad8\u6548\u7684LambdaMART\u91cd\u6392\u5e8f\u5668\u3002\u4e0e\u5148\u524d\u65b9\u6cd5\u4e0d\u540c\uff0cLURE-RAG\u4f7f\u7528LLM\u6548\u7528\u6307\u5bfc\u7684\u5217\u8868\u6392\u5e8f\u635f\u5931\u8bad\u7ec3\u91cd\u6392\u5e8f\u5668\uff0c\u76f4\u63a5\u4f18\u5316\u68c0\u7d22\u6587\u6863\u7684\u6392\u5e8f\u3002\u8fd8\u63d0\u51fa\u4e86\u5176\u5bc6\u96c6\u53d8\u4f53UR-RAG\u3002", "result": "\u5728\u4e24\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLURE-RAG\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u5bc6\u96c6\u795e\u7ecf\u57fa\u7ebf\u768497-98%\uff0c\u540c\u65f6\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\u4fdd\u6301\u9ad8\u6548\u3002\u5176\u5bc6\u96c6\u53d8\u4f53UR-RAG\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\uff0c\u63d0\u5347\u9ad8\u8fbe3%\u3002", "conclusion": "LURE-RAG\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6548\u7528\u9a71\u52a8\u91cd\u6392\u5e8f\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u4e2d\u68c0\u7d22\u4e0e\u6548\u7528\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf\uff0c\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.19559", "categories": ["cs.IR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.19559", "abs": "https://arxiv.org/abs/2601.19559", "authors": ["Mark Green", "Maura Halstead", "Caroline Jay", "Richard Kingston", "Alex Singleton", "David Topping"], "title": "Comparing how Large Language Models perform against keyword-based searches for social science research data discovery", "comment": null, "summary": "This paper evaluates the performance of a large language model (LLM) based semantic search tool relative to a traditional keyword-based search for data discovery. Using real-world search behaviour, we compare outputs from a bespoke semantic search system applied to UKRI data services with the Consumer Data Research Centre (CDRC) keyword search. Analysis is based on 131 of the most frequently used search terms extracted from CDRC search logs between December 2023 and October 2024. We assess differences in the volume, overlap, ranking, and relevance of returned datasets using descriptive statistics, qualitative inspection, and quantitative similarity measures, including exact dataset overlap, Jaccard similarity, and cosine similarity derived from BERT embeddings. Results show that the semantic search consistently returns a larger number of results than the keyword search and performs particularly well for place based, misspelled, obscure, or complex queries. While the semantic search does not capture all keyword based results, the datasets returned are overwhelmingly semantically similar, with high cosine similarity scores despite lower exact overlap. Rankings of the most relevant results differ substantially between tools, reflecting contrasting prioritisation strategies. Case studies demonstrate that the LLM based tool is robust to spelling errors, interprets geographic and contextual relevance effectively, and supports natural-language queries that keyword search fails to resolve. Overall, the findings suggest that LLM driven semantic search offers a substantial improvement for data discovery, complementing rather than fully replacing traditional keyword-based approaches.", "AI": {"tldr": "\u6bd4\u8f83\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u641c\u7d22\u4e0e\u4f20\u7edf\u5173\u952e\u8bcd\u641c\u7d22\u5728\u6570\u636e\u53d1\u73b0\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u8bed\u4e49\u641c\u7d22\u5728\u7ed3\u679c\u6570\u91cf\u3001\u5904\u7406\u590d\u6742\u67e5\u8be2\u548c\u5bb9\u9519\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u4e24\u8005\u6392\u540d\u7b56\u7565\u4e0d\u540c\uff0c\u5efa\u8bae\u4e92\u8865\u4f7f\u7528\u3002", "motivation": "\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bed\u4e49\u641c\u7d22\u5de5\u5177\u76f8\u5bf9\u4e8e\u4f20\u7edf\u5173\u952e\u8bcd\u641c\u7d22\u5728\u6570\u636e\u53d1\u73b0\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u63a2\u7d22\u8bed\u4e49\u641c\u7d22\u662f\u5426\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u641c\u7d22\u4f53\u9a8c\u548c\u7ed3\u679c\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u82f1\u56fd\u7814\u7a76\u521b\u65b0\u7f72\uff08UKRI\uff09\u6570\u636e\u670d\u52a1\u7684\u771f\u5b9e\u641c\u7d22\u884c\u4e3a\uff0c\u6bd4\u8f83\u5b9a\u5236\u8bed\u4e49\u641c\u7d22\u7cfb\u7edf\u4e0e\u6d88\u8d39\u8005\u6570\u636e\u7814\u7a76\u4e2d\u5fc3\uff08CDRC\uff09\u5173\u952e\u8bcd\u641c\u7d22\u3002\u57fa\u4e8e2023\u5e7412\u6708\u81f32024\u5e7410\u6708CDRC\u641c\u7d22\u65e5\u5fd7\u4e2d\u63d0\u53d6\u7684131\u4e2a\u6700\u5e38\u7528\u641c\u7d22\u8bcd\uff0c\u901a\u8fc7\u63cf\u8ff0\u6027\u7edf\u8ba1\u3001\u5b9a\u6027\u68c0\u67e5\u548c\u5b9a\u91cf\u76f8\u4f3c\u6027\u5ea6\u91cf\uff08\u5305\u62ec\u7cbe\u786e\u6570\u636e\u96c6\u91cd\u53e0\u3001Jaccard\u76f8\u4f3c\u6027\u548cBERT\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\uff09\u8bc4\u4f30\u8fd4\u56de\u6570\u636e\u96c6\u7684\u5dee\u5f02\u3002", "result": "\u8bed\u4e49\u641c\u7d22\u59cb\u7ec8\u8fd4\u56de\u6bd4\u5173\u952e\u8bcd\u641c\u7d22\u66f4\u591a\u7684\u7ed3\u679c\uff0c\u5728\u5904\u7406\u57fa\u4e8e\u5730\u70b9\u3001\u62fc\u5199\u9519\u8bef\u3001\u6a21\u7cca\u6216\u590d\u6742\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u5c24\u4e3a\u51fa\u8272\u3002\u867d\u7136\u8bed\u4e49\u641c\u7d22\u672a\u80fd\u6355\u83b7\u6240\u6709\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u7ed3\u679c\uff0c\u4f46\u8fd4\u56de\u7684\u6570\u636e\u96c6\u5728\u8bed\u4e49\u4e0a\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u4f59\u5f26\u76f8\u4f3c\u6027\u5f97\u5206\u9ad8\u800c\u7cbe\u786e\u91cd\u53e0\u7387\u8f83\u4f4e\u3002\u4e24\u79cd\u5de5\u5177\u7684\u6392\u540d\u7b56\u7565\u5dee\u5f02\u663e\u8457\u3002\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eLLM\u7684\u5de5\u5177\u5bf9\u62fc\u5199\u9519\u8bef\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u6709\u6548\u89e3\u91ca\u5730\u7406\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u5e76\u652f\u6301\u5173\u952e\u8bcd\u641c\u7d22\u65e0\u6cd5\u89e3\u51b3\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u641c\u7d22\u4e3a\u6570\u636e\u53d1\u73b0\u63d0\u4f9b\u4e86\u5b9e\u8d28\u6027\u6539\u8fdb\uff0c\u4f46\u5e76\u975e\u5b8c\u5168\u53d6\u4ee3\u4f20\u7edf\u5173\u952e\u8bcd\u641c\u7d22\u65b9\u6cd5\uff0c\u800c\u662f\u4f5c\u4e3a\u4e92\u8865\u5de5\u5177\u4f7f\u7528\u3002"}}
{"id": "2601.19585", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19585", "abs": "https://arxiv.org/abs/2601.19585", "authors": ["Chongjun Xia", "Yanchun Peng", "Xianzhi Wang"], "title": "LLM-Enhanced Reinforcement Learning for Long-Term User Satisfaction in Interactive Recommendation", "comment": null, "summary": "Interactive recommender systems can dynamically adapt to user feedback, but often suffer from content homogeneity and filter bubble effects due to overfitting short-term user preferences. While recent efforts aim to improve content diversity, they predominantly operate in static or one-shot settings, neglecting the long-term evolution of user interests. Reinforcement learning provides a principled framework for optimizing long-term user satisfaction by modeling sequential decision-making processes. However, its application in recommendation is hindered by sparse, long-tailed user-item interactions and limited semantic planning capabilities. In this work, we propose LLM-Enhanced Reinforcement Learning (LERL), a novel hierarchical recommendation framework that integrates the semantic planning power of LLM with the fine-grained adaptability of RL. LERL consists of a high-level LLM-based planner that selects semantically diverse content categories, and a low-level RL policy that recommends personalized items within the selected semantic space. This hierarchical design narrows the action space, enhances planning efficiency, and mitigates overexposure to redundant content. Extensive experiments on real-world datasets demonstrate that LERL significantly improves long-term user satisfaction when compared with state-of-the-art baselines. The implementation of LERL is available at https://anonymous.4open.science/r/code3-18D3/.", "AI": {"tldr": "\u63d0\u51faLLM\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6LERL\uff0c\u901a\u8fc7LLM\u8fdb\u884c\u9ad8\u5c42\u8bed\u4e49\u89c4\u5212\u9009\u62e9\u591a\u6837\u5185\u5bb9\u7c7b\u522b\uff0cRL\u8fdb\u884c\u4f4e\u5c42\u4e2a\u6027\u5316\u63a8\u8350\uff0c\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5185\u5bb9\u540c\u8d28\u5316\u548c\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\u95ee\u9898\u3002", "motivation": "\u4ea4\u4e92\u5f0f\u63a8\u8350\u7cfb\u7edf\u5bb9\u6613\u56e0\u8fc7\u5ea6\u62df\u5408\u77ed\u671f\u7528\u6237\u504f\u597d\u800c\u5bfc\u81f4\u5185\u5bb9\u540c\u8d28\u5316\u548c\u8fc7\u6ee4\u6c14\u6ce1\u6548\u5e94\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u5728\u9759\u6001\u6216\u4e00\u6b21\u6027\u8bbe\u7f6e\u4e2d\u8fd0\u4f5c\uff0c\u5ffd\u89c6\u4e86\u7528\u6237\u5174\u8da3\u7684\u957f\u671f\u6f14\u5316\u3002\u5f3a\u5316\u5b66\u4e60\u867d\u80fd\u4f18\u5316\u957f\u671f\u6ee1\u610f\u5ea6\uff0c\u4f46\u53d7\u9650\u4e8e\u7a00\u758f\u7684\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u548c\u6709\u9650\u7684\u8bed\u4e49\u89c4\u5212\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u63a8\u8350\u6846\u67b6LERL\uff1a\u9ad8\u5c42\u4f7f\u7528LLM\u4f5c\u4e3a\u89c4\u5212\u5668\u9009\u62e9\u8bed\u4e49\u591a\u6837\u7684\u5185\u5bb9\u7c7b\u522b\uff0c\u4f4e\u5c42\u4f7f\u7528RL\u7b56\u7565\u5728\u9009\u5b9a\u8bed\u4e49\u7a7a\u95f4\u5185\u63a8\u8350\u4e2a\u6027\u5316\u7269\u54c1\u3002\u8fd9\u79cd\u5206\u5c42\u8bbe\u8ba1\u7f29\u5c0f\u4e86\u52a8\u4f5c\u7a7a\u95f4\uff0c\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\uff0c\u5e76\u51cf\u5c11\u4e86\u5197\u4f59\u5185\u5bb9\u7684\u8fc7\u5ea6\u66dd\u5149\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cLERL\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "conclusion": "LERL\u6210\u529f\u5730\u5c06LLM\u7684\u8bed\u4e49\u89c4\u5212\u80fd\u529b\u4e0eRL\u7684\u7ec6\u7c92\u5ea6\u9002\u5e94\u6027\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5185\u5bb9\u591a\u6837\u6027\u95ee\u9898\u548c\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\u4f18\u5316\u6311\u6218\u3002"}}
{"id": "2601.19711", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19711", "abs": "https://arxiv.org/abs/2601.19711", "authors": ["Junchen Fu", "Xuri Ge", "Alexandros Karatzoglou", "Ioannis Arapakis", "Suzan Verberne", "Joemon M. Jose", "Zhaochun Ren"], "title": "Differentiable Semantic ID for Generative Recommendation", "comment": null, "summary": "Generative recommendation provides a novel paradigm in which each item is represented by a discrete semantic ID (SID) learned from rich content. Most existing methods treat SIDs as predefined and train recommenders under static indexing. In practice, SIDs are typically optimized only for content reconstruction rather than recommendation accuracy. This leads to an objective mismatch: the system optimizes an indexing loss to learn the SID and a recommendation loss for interaction prediction, but because the tokenizer is trained independently, the recommendation loss cannot update it. A natural approach is to make semantic indexing differentiable so that recommendation gradients can directly influence SID learning, but this often causes codebook collapse, where only a few codes are used. We attribute this issue to early deterministic assignments that limit codebook exploration, resulting in imbalance and unstable optimization.\n  In this paper, we propose DIGER (Differentiable Semantic ID for Generative Recommendation), a first step toward effective differentiable semantic IDs for generative recommendation. DIGER introduces Gumbel noise to explicitly encourage early-stage exploration over codes, mitigating codebook collapse and improving code utilization. To balance exploration and convergence, we further design two uncertainty decay strategies that gradually reduce the Gumbel noise, enabling a smooth transition from early exploration to exploitation of learned SIDs. Extensive experiments on multiple public datasets demonstrate consistent improvements from differentiable semantic IDs. These results confirm the effectiveness of aligning indexing and recommendation objectives through differentiable SIDs and highlight differentiable semantic indexing as a promising research direction.", "AI": {"tldr": "\u63d0\u51faDIGER\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u8bed\u4e49ID\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7d22\u5f15\u4e0e\u63a8\u8350\u76ee\u6807\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4f7f\u7528Gumbel\u566a\u58f0\u4fc3\u8fdb\u65e9\u671f\u4ee3\u7801\u63a2\u7d22\uff0c\u9632\u6b62\u7801\u672c\u5d29\u6e83", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u5c06\u8bed\u4e49ID\u89c6\u4e3a\u9884\u5b9a\u4e49\uff0c\u72ec\u7acb\u8bad\u7ec3\u5206\u8bcd\u5668\u7528\u4e8e\u5185\u5bb9\u91cd\u5efa\u800c\u975e\u63a8\u8350\u51c6\u786e\u6027\uff0c\u5bfc\u81f4\u7d22\u5f15\u635f\u5931\u4e0e\u63a8\u8350\u635f\u5931\u76ee\u6807\u4e0d\u5339\u914d\uff0c\u4e14\u63a8\u8350\u68af\u5ea6\u65e0\u6cd5\u66f4\u65b0\u5206\u8bcd\u5668", "method": "\u63d0\u51faDIGER\u65b9\u6cd5\uff1a1) \u5f15\u5165Gumbel\u566a\u58f0\u4fc3\u8fdb\u65e9\u671f\u4ee3\u7801\u63a2\u7d22\uff0c\u9632\u6b62\u7801\u672c\u5d29\u6e83\uff1b2) \u8bbe\u8ba1\u4e24\u79cd\u4e0d\u786e\u5b9a\u6027\u8870\u51cf\u7b56\u7565\uff0c\u9010\u6b65\u51cf\u5c11Gumbel\u566a\u58f0\uff0c\u5b9e\u73b0\u4ece\u63a2\u7d22\u5230\u5229\u7528\u7684\u5e73\u6ed1\u8fc7\u6e21", "result": "\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u53ef\u5fae\u5206\u8bed\u4e49ID\u5e26\u6765\u4e00\u81f4\u6539\u8fdb\uff0c\u9a8c\u8bc1\u4e86\u901a\u8fc7\u53ef\u5fae\u5206\u8bed\u4e49ID\u5bf9\u9f50\u7d22\u5f15\u4e0e\u63a8\u8350\u76ee\u6807\u7684\u6709\u6548\u6027", "conclusion": "\u53ef\u5fae\u5206\u8bed\u4e49\u7d22\u5f15\u662f\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\uff0cDIGER\u901a\u8fc7\u4fc3\u8fdb\u65e9\u671f\u63a2\u7d22\u548c\u5e73\u8861\u63a2\u7d22-\u5229\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7801\u672c\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u5229\u7528\u7387"}}
