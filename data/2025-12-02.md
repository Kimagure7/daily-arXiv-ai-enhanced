<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Enhancing Talent Search Ranking with Role-Aware Expert Mixtures and LLM-based Fine-Grained Job Descriptions](https://arxiv.org/abs/2512.00004)
*Jihang Li,Bing Xu,Zulong Chen,Chuanfei Xu,Minping Chen,Suyu Liu,Ying Zhou,Zeyi Wen*

Main category: cs.IR

TL;DR: 提出一个基于LLM和角色感知MoE网络的人才搜索框架，通过多任务学习优化招聘效果，实现显著业务价值


<details>
  <summary>Details</summary>
Motivation: 现有人才搜索方法难以捕捉细粒度的职位偏好、建模招聘人员行为差异，以及减少主观判断带来的噪声

Method: 1) 利用LLM从职位描述和历史招聘数据提取细粒度招聘信号；2) 采用角色感知多门MoE网络捕捉不同招聘角色的行为差异；3) 引入多任务学习模块联合优化CTR、CVR和简历匹配相关性

Result: 在真实招聘数据和在线A/B测试中，CTR相对AUC提升1.70%，CVR提升5.97%，点击转化率提升17.29%，预计每年节省数百万元人民币成本

Conclusion: 该框架显著提升人才搜索效果，减少对外部招聘渠道的依赖，具有重要商业价值

Abstract: Talent search is a cornerstone of modern recruitment systems, yet existing approaches often struggle to capture nuanced job-specific preferences, model recruiter behavior at a fine-grained level, and mitigate noise from subjective human judgments. We present a novel framework that enhances talent search effectiveness and delivers substantial business value through two key innovations: (i) leveraging LLMs to extract fine-grained recruitment signals from job descriptions and historical hiring data, and (ii) employing a role-aware multi-gate MoE network to capture behavioral differences across recruiter roles. To further reduce noise, we introduce a multi-task learning module that jointly optimizes click-through rate (CTR), conversion rate (CVR), and resume matching relevance. Experiments on real-world recruitment data and online A/B testing show relative AUC gains of 1.70% (CTR) and 5.97% (CVR), and a 17.29% lift in click-through conversion rate. These improvements reduce dependence on external sourcing channels, enabling an estimated annual cost saving of millions of CNY.

</details>


### [2] [Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking](https://arxiv.org/abs/2512.00007)
*Jingyi Huang,Yuyi Yang,Mengmeng Ji,Charles Alba,Sheng Zhang,Ruopeng An*

Main category: cs.IR

TL;DR: SAFE是一个结合大语言模型与检索增强生成(RAG)的智能体系统，用于准确核查长篇幅COVID-19虚假信息，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: COVID-19信息疫情需要可扩展的事实核查解决方案，以准确可靠地处理长篇虚假信息。现有大语言模型在一致性和可解释性方面存在局限性。

Method: SAFE系统包含两个智能体：一个用于声明提取，另一个使用LOTR-RAG进行声明验证，后者基于13万份COVID-19研究文档。增强变体SAFE (LOTR-RAG + SRAG)加入Self-RAG通过查询重写优化检索。

Result: 在50篇假新闻文章（包含246个标注声明）上评估，SAFE系统在所有指标上显著优于基线LLMs（p < 0.001）。SAFE (LOTR-RAG)在一致性（0.629）、有用性（3.640）、清晰度（3.800）和真实性（3.526）方面表现最佳。添加SRAG略微降低整体性能。

Conclusion: SAFE通过解决LLM在一致性和可解释性方面的局限性，显著提升了长篇COVID-19事实核查能力。核心LOTR-RAG设计比SRAG增强变体更有效，为可扩展的虚假信息缓解提供了坚实基础。

Abstract: The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability. This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation. SAFE includes two agents - one for claim extraction and another for claim verification using LOTR-RAG, which leverages a 130,000-document COVID-19 research corpus. An enhanced variant, SAFE (LOTR-RAG + SRAG), incorporates Self-RAG to refine retrieval via query rewriting. We evaluated both systems on 50 fake news articles (2-17 pages) containing 246 annotated claims (M = 4.922, SD = 3.186), labeled as true (14.1%), partly true (14.4%), false (27.0%), partly false (2.2%), and misleading (21.0%) by public health professionals. SAFE systems significantly outperformed baseline LLMs in all metrics (p < 0.001). For consistency (0-1 scale), SAFE (LOTR-RAG) scored 0.629, exceeding both SAFE (+SRAG) (0.577) and the baseline (0.279). In subjective evaluations (0-4 Likert scale), SAFE (LOTR-RAG) also achieved the highest average ratings in usefulness (3.640), clearness (3.800), and authenticity (3.526). Adding SRAG slightly reduced overall performance, except for a minor gain in clearness. SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability. The core LOTR-RAG design proved more effective than its SRAG-augmented variant, offering a strong foundation for scalable misinformation mitigation.

</details>


### [3] [Evolving Paradigms in Task-Based Search and Learning: A Comparative Analysis of Traditional Search Engine with LLM-Enhanced Conversational Search System](https://arxiv.org/abs/2512.00313)
*Zhitong Guan,Yi Wang*

Main category: cs.IR

TL;DR: 比较传统搜索引擎与LLM驱动搜索系统在搜索行为和学习效果上的差异，研究生成式AI如何影响信息检索过程


<details>
  <summary>Details</summary>
Motivation: 大型语言模型正在重塑信息检索，但传统关键词搜索在多步推理和探索性学习任务中存在局限，需要实证研究LLM如何影响用户的搜索行为和知识构建

Method: 比较研究法：在标准搜索引擎和LLM驱动的搜索系统两种环境中，分析用户的搜索策略、查询构建和评估行为，以及搜索学习任务中的理解、知识整合和批判性思维

Result: 研究发现揭示了LLM使用对搜索行为和认知过程的具体影响，为理解生成式AI如何塑造信息寻求过程提供了实证依据

Conclusion: 研究结果为信息检索、人机交互和技术支持学习领域的讨论提供了重要见解，有助于理解生成式AI在信息搜索中的实际影响

Abstract: Large Language Models (LLMs) are rapidly reshaping information retrieval by enabling interactive, generative, and inference-driven search. While traditional keyword-based search remains central to web and academic information access, it often struggles to support multi-step reasoning and exploratory learning tasks. LLM-powered search interfaces, such as ChatGPT and Claude, introduce new capabilities that may influence how users formulate queries, navigate information, and construct knowledge. However, empirical understanding of these effects is still limited. This study compares search behavior and learning outcomes in two environments: a standard search engine and an LLM-powered search system. We investigate (1) how search strategies, query formulation, and evaluation behaviors differ across systems, and (2) how LLM use affects comprehension, knowledge integration, and critical thinking during search-based learning tasks. Findings offer insight into how generative AI shapes information-seeking processes and contribute to ongoing discussions in information retrieval, human-AI interaction, and technology-supported learning.

</details>


### [4] [Breaking It Down: Domain-Aware Semantic Segmentation for Retrieval Augmented Generation](https://arxiv.org/abs/2512.00367)
*Aparajitha Allamraju,Maitreya Prafulla Chitale,Hiranmai Sri Adibhatla,Rahul Mishra,Manish Shrivastava*

Main category: cs.IR

TL;DR: 论文提出两种高效的语义分块方法PSC和MFC，通过PubMed数据训练，显著提升RAG系统的检索和生成质量


<details>
  <summary>Details</summary>
Motivation: 传统固定长度和递归分块方法会产生任意、不连贯的片段，无法保留语义结构，而语义分块对生成质量的影响尚未充分探索

Method: 提出投影相似度分块(PSC)和度量融合分块(MFC)两种语义分块方法，在PubMed数据上使用三种嵌入模型训练，并建立评估框架测量分块对检索和生成的影响

Result: PSC在MRR上实现24倍检索改进，在PubMedQA上获得更高的Hits@k，尽管在单一领域训练，PSC和MFC在多个数据集上表现出良好的跨领域泛化能力

Conclusion: 语义分块器特别是PSC能持续提供优越性能，证实语义分块对RAG系统检索和生成质量有显著积极影响

Abstract: Document chunking is a crucial component of Retrieval-Augmented Generation (RAG), as it directly affects the retrieval of relevant and precise context. Conventional fixed-length and recursive splitters often produce arbitrary, incoherent segments that fail to preserve semantic structure. Although semantic chunking has gained traction, its influence on generation quality remains underexplored. This paper introduces two efficient semantic chunking methods, Projected Similarity Chunking (PSC) and Metric Fusion Chunking (MFC), trained on PubMed data using three different embedding models. We further present an evaluation framework that measures the effect of chunking on both retrieval and generation by augmenting PubMedQA with full-text PubMed Central articles. Our results show substantial retrieval improvements (24x with PSC) in MRR and higher Hits@k on PubMedQA. We provide a comprehensive analysis, including statistical significance and response-time comparisons with common chunking libraries. Despite being trained on a single domain, PSC and MFC also generalize well, achieving strong out-of-domain generation performance across multiple datasets. Overall, our findings confirm that our semantic chunkers, especially PSC, consistently deliver superior performance.

</details>


### [5] [PEOAT: Personalization-Guided Evolutionary Question Assembly for One-Shot Adaptive Testing](https://arxiv.org/abs/2512.00439)
*Xiaoshan Yu,Ziwei Huang,Shangshang Yang,Ziwen Wang,Haiping Ma,Xingyi Zhang*

Main category: cs.IR

TL;DR: 提出PEOAT框架，用于一次性自适应测试任务，通过个性化引导的进化算法优化试题组合选择


<details>
  <summary>Details</summary>
Motivation: 传统计算机自适应测试(CAT)在实时性和顺序性方面存在局限，特别是在大规模评估或敏感领域（如心理评估）中，交互成本高且需要最小化噪声干扰。这些限制使得传统CAT方法在时间敏感或资源受限环境中的应用受到约束。

Method: 提出PEOAT框架：1) 设计个性化感知初始化策略，整合考生能力与试题难度差异，使用多策略采样构建多样化的初始种群；2) 提出认知增强的进化框架，包含模式保留交叉和认知引导变异；3) 引入多样性感知的环境选择机制，在不损害适应度的情况下保持多样性。

Result: 在两个数据集上进行了广泛实验验证PEOAT的有效性，并通过案例研究揭示了有价值的见解。

Conclusion: PEOAT框架成功解决了传统CAT在实时性和资源约束环境中的局限性，为一次性自适应测试提供了有效的解决方案，通过进化算法优化试题组合选择，提高了评估效率和准确性。

Abstract: With the rapid advancement of intelligent education, Computerized Adaptive Testing (CAT) has attracted increasing attention by integrating educational psychology with deep learning technologies. Unlike traditional paper-and-pencil testing, CAT aims to efficiently and accurately assess examinee abilities by adaptively selecting the most suitable items during the assessment process. However, its real-time and sequential nature presents limitations in practical scenarios, particularly in large-scale assessments where interaction costs are high, or in sensitive domains such as psychological evaluations where minimizing noise and interference is essential. These challenges constrain the applicability of conventional CAT methods in time-sensitive or resourceconstrained environments. To this end, we first introduce a novel task called one-shot adaptive testing (OAT), which aims to select a fixed set of optimal items for each test-taker in a one-time selection. Meanwhile, we propose PEOAT, a Personalization-guided Evolutionary question assembly framework for One-shot Adaptive Testing from the perspective of combinatorial optimization. Specifically, we began by designing a personalization-aware initialization strategy that integrates differences between examinee ability and exercise difficulty, using multi-strategy sampling to construct a diverse and informative initial population. Building on this, we proposed a cognitive-enhanced evolutionary framework incorporating schema-preserving crossover and cognitively guided mutation to enable efficient exploration through informative signals. To maintain diversity without compromising fitness, we further introduced a diversity-aware environmental selection mechanism. The effectiveness of PEOAT is validated through extensive experiments on two datasets, complemented by case studies that uncovered valuable insights.

</details>


### [6] [DLRREC: Denoising Latent Representations via Multi-Modal Knowledge Fusion in Deep Recommender Systems](https://arxiv.org/abs/2512.00596)
*Jiahao Tian,Zhenkai Wang*

Main category: cs.IR

TL;DR: 提出一种新框架，通过深度融合多模态和协同知识进行表示去噪，解决LLM生成特征在推荐系统中的有效利用问题


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统难以有效利用LLM生成的高维、噪声丰富的多模态特征，将这些特征作为静态输入会使其与核心推荐任务脱节

Method: 1) 将降维直接集成到推荐模型中，实现端到端协同训练；2) 引入对比学习目标，将协同过滤信号显式纳入潜在空间

Result: 大量实验证实该方法具有优越的判别能力，证明这种集成融合和去噪策略对于实现最先进性能至关重要

Conclusion: 该工作为在推荐系统中有效利用LLM提供了一个基础范式

Abstract: Modern recommender systems struggle to effectively utilize the rich, yet high-dimensional and noisy, multi-modal features generated by Large Language Models (LLMs). Treating these features as static inputs decouples them from the core recommendation task. We address this limitation with a novel framework built on a key insight: deeply fusing multi-modal and collaborative knowledge for representation denoising. Our unified architecture introduces two primary technical innovations. First, we integrate dimensionality reduction directly into the recommendation model, enabling end-to-end co-training that makes the reduction process aware of the final ranking objective. Second, we introduce a contrastive learning objective that explicitly incorporates the collaborative filtering signal into the latent space. This synergistic process refines raw LLM embeddings, filtering noise while amplifying task-relevant signals. Extensive experiments confirm our method's superior discriminative power, proving that this integrated fusion and denoising strategy is critical for achieving state-of-the-art performance. Our work provides a foundational paradigm for effectively harnessing LLMs in recommender systems.

</details>


### [7] [ProEx: A Unified Framework Leveraging Large Language Model with Profile Extrapolation for Recommendation](https://arxiv.org/abs/2512.00679)
*Yi Zhang,Yiwen Zhang,Yu Wang,Tong Chen,Hongzhi Yin*

Main category: cs.IR

TL;DR: ProEx框架通过多角度用户/物品画像外推和环境概念，提升基于大语言模型的推荐系统性能


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的推荐方法通常为每个用户或物品生成单一画像，这不足以全面捕捉复杂的用户意图。此外，大语言模型的不稳定性可能导致有偏或误解的画像，反而损害推荐性能。

Method: 提出多角度画像外推框架ProEx：1）利用思维链推理为每个用户和物品构建多个不同角度的画像；2）将这些新画像映射到语义向量，从原始画像位置外推以探索更广的语言空间区域；3）引入环境概念，每个环境代表所有画像的可能线性组合，通过最小化环境间差异来揭示用户偏好的内在不变性。

Result: 在三个数据集上对三种判别式方法和三种生成式方法进行广泛实验，结果表明ProEx显著提升了这些基础推荐模型的性能。

Conclusion: 多角度画像外推框架ProEx通过构建多个不同角度的用户/物品画像，并利用环境概念捕捉用户偏好的不变性，能够有效提升基于大语言模型的推荐系统性能。

Abstract: The powerful text understanding and generation capabilities of large language models (LLMs) have brought new vitality to general recommendation with implicit feedback. One possible strategy involves generating a unique user (or item) profile from historical interaction data, which is then mapped to a semantic representation in the language space. However, a single-instance profile may be insufficient to comprehensively capture the complex intentions behind a user's interacted items. Moreover, due to the inherent instability of LLMs, a biased or misinterpreted profile could even undermine the original recommendation performance. Consequently, an intuitive solution is to generate multiple profiles for each user (or item), each reflecting a distinct aspect of their characteristics. In light of this, we propose a unified recommendation framework with multi-faceted profile extrapolation (ProEx) in this paper. By leveraging chain-of-thought reasoning, we construct multiple distinct profiles for each user and item. These new profiles are subsequently mapped into semantic vectors, extrapolating from the position of the original profile to explore a broader region of the language space. Subsequently, we introduce the concept of environments, where each environment represents a possible linear combination of all profiles. The differences across environments are minimized to reveal the inherent invariance of user preferences. We apply ProEx to three discriminative methods and three generative methods, and conduct extensive experiments on three datasets. The experimental results demonstrate that ProEx significantly enhances the performance of these base recommendation models.

</details>


### [8] [SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG](https://arxiv.org/abs/2512.00772)
*Hyunseok Ryu,Wonjune Shin,Hyun Park*

Main category: cs.IR

TL;DR: SHRAG是一个结合信息检索与检索增强生成的新框架，利用LLM作为查询策略师将自然语言查询转换为结构化搜索查询，通过布尔检索和多语言扩展提升跨语言问答性能。


<details>
  <summary>Details</summary>
Motivation: RAG虽然能减少LLM幻觉并整合最新信息，但构建高质量检索系统需要专业知识，且处理速度比传统检索系统慢。需要一种能无缝集成信息检索与RAG，同时保证精确检索性能的解决方案。

Method: SHRAG使用大型语言模型作为查询策略师，自动将非结构化自然语言查询转换为逻辑结构化搜索查询，然后执行布尔检索来模拟专家搜索过程。还结合多语言查询扩展和多语言嵌入模型，在ScienceON Challenge的多语言数据集环境中实现高效跨语言问答。

Result: 实验结果表明，结合逻辑检索能力和生成推理的SHRAG方法能显著提高RAG系统的准确性和可靠性。超越了传统的以文档为中心的检索方法，展示了提供直接可靠查询响应的新搜索范式潜力。

Conclusion: SHRAG框架成功地将信息检索与RAG无缝集成，通过LLM驱动的查询策略和布尔检索实现了精确的检索性能，为下一代信息检索系统提供了新的方向。

Abstract: Retrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language
  Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to
  construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing
  speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages.
  Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of
  Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a
  Large Language Model as a Query Strategist to automatically transform unstructured natural language queries
  into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process
  of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual
  embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual
  dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method,
  combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and
  reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods,
  presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.

</details>


### [9] [Optimizing Generative Ranking Relevance via Reinforcement Learning in Xiaohongshu Search](https://arxiv.org/abs/2512.00968)
*Ziyang Zeng,Heming Jing,Jindong Chen,Xiangli Li,Hongyu Liu,Yixuan He,Zhengyu Li,Yige Sun,Zheyong Xie,Yuqing Yang,Shaosheng Cao,Jun Fan,Yi Wu,Yao Hu*

Main category: cs.IR

TL;DR: 该论文提出了一种基于强化学习的推理增强生成相关性模型，通过多步推理提示和过程监督策略提升搜索相关性建模的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统相关性模型通常产生标量分数或直接预测相关性标签，限制了可解释性和复杂相关性信号的建模能力。现有的基于推理的生成相关性模型主要依赖大量人工标注或合成推理数据进行监督微调，泛化能力有限，且领域无关的自由形式推理过于通用，难以处理开放域搜索中的多样性和模糊性案例。

Method: 将小红书搜索中的相关性建模重新定义为推理任务，引入基于强化学习的训练框架。具体包括：1）将实际业务特定的相关性标准融入多步推理提示设计；2）提出Stepwise Advantage Masking（SAM）轻量级过程监督策略，通过改进信用分配促进有效学习；3）将大规模RL调优模型蒸馏为适合实际搜索系统的轻量版本。

Result: 在工业数据集上的大量实验以及在线A/B测试证明了该方法的有效性。

Conclusion: 通过强化学习框架增强生成相关性模型的推理能力，能够显著提升搜索相关性建模的性能和可解释性，同时通过模型蒸馏实现了工业部署的可行性。

Abstract: Ranking relevance is a fundamental task in search engines, aiming to identify the items most relevant to a given user query. Traditional relevance models typically produce scalar scores or directly predict relevance labels, limiting both interpretability and the modeling of complex relevance signals. Inspired by recent advances in Chain-of-Thought (CoT) reasoning for complex tasks, we investigate whether explicit reasoning can enhance both interpretability and performance in relevance modeling. However, existing reasoning-based Generative Relevance Models (GRMs) primarily rely on supervised fine-tuning on large amounts of human-annotated or synthetic CoT data, which often leads to limited generalization. Moreover, domain-agnostic, free-form reasoning tends to be overly generic and insufficiently grounded, limiting its potential to handle the diverse and ambiguous cases prevalent in open-domain search. In this work, we formulate relevance modeling in Xiaohongshu search as a reasoning task and introduce a Reinforcement Learning (RL)-based training framework to enhance the grounded reasoning capabilities of GRMs. Specifically, we incorporate practical business-specific relevance criteria into the multi-step reasoning prompt design and propose Stepwise Advantage Masking (SAM), a lightweight process-supervision strategy which facilitates effective learning of these criteria through improved credit assignment. To enable industrial deployment, we further distill the large-scale RL-tuned model to a lightweight version suitable for real-world search systems. Extensive experiments on industrial datasets, along with online A/B tests, demonstrate the effectiveness of our approach.

</details>


### [10] [Conversion rate prediction in online advertising: modeling techniques, performance evaluation and future directions](https://arxiv.org/abs/2512.01171)
*Tao Xue,Yanwu Yang,Panyu Zhai*

Main category: cs.IR

TL;DR: 本文对在线广告中的转化率预测进行了全面的文献综述，将现有模型分为六类，分析了技术演进关系，总结了性能表现，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 虽然过去几十年研究者开发了许多转化率预测模型，但技术方法的演进和不同技术之间的关系尚未得到系统梳理。本文旨在填补这一空白，为研究者和从业者提供有价值的参考。

Method: 对在线广告中的CVR预测文献进行全面综述，将现有模型按底层技术分为六类，分析各类技术的框架、优缺点及其在CVR预测中的应用，并总结在公开和专有数据集上的性能表现。

Result: 发现先前研究中报告的性能评估结果并不一致；识别出语义增强、归因增强、去偏的CVR预测以及联合建模CTR和CVR预测是未来有前景的研究方向。

Conclusion: 本文为在线广告转化率预测领域提供了系统的文献综述，明确了技术分类和演进关系，指出了当前挑战和未来研究方向，为研究者和从业者提供了有价值的参考和见解。

Abstract: Conversion and conversion rate (CVR) prediction play a critical role in efficient advertising decision-making. In past decades, although researchers have developed plenty of models for CVR prediction, the methodological evolution and relationships between different techniques have been precluded. In this paper, we conduct a comprehensive literature review on CVR prediction in online advertising, and classify state-of-the-art CVR prediction models into six categories with respect to the underlying techniques and elaborate on connections between these techniques. For each category of models, we present the framework of underlying techniques, their advantages and disadvantages, and discuss how they are utilized for CVR prediction. Moreover, we summarize the performance of various CVR prediction models on public and proprietary datasets. Finally, we identify research trends, major challenges, and promising future directions. We observe that results of performance evaluation reported in prior studies are not unanimous; semantics-enriched, attribution-enhanced, debiased CVR prediction and jointly modeling CTR and CVR prediction would be promising directions to explore in the future. This review is expected to provide valuable references and insights for future researchers and practitioners in this area.

</details>


### [11] [Toward a benchmark for CTR prediction in online advertising: datasets, evaluation protocols and perspectives](https://arxiv.org/abs/2512.01179)
*Shan Gao,Yanwu Yang*

Main category: cs.IR

TL;DR: Bench-CTR是一个统一的CTR预测基准平台，提供灵活的数据集和模型组件接口，包含全面的评估协议，并对传统统计模型到现代LLM模型进行了比较研究。


<details>
  <summary>Details</summary>
Motivation: 为了解决CTR预测领域缺乏统一评估标准和基准平台的问题，促进模型开发和评估，增强从业者对模型机制的理解。

Method: 设计统一的CTR预测基准平台架构，构建包含真实和合成数据集、指标分类、标准化流程和实验指南的综合评估系统，并在三个公共数据集和两个合成数据集上对多种SOTA模型进行比较研究。

Result: 实验发现：(1)高阶模型普遍优于低阶模型，但优势因指标和数据集而异；(2)LLM模型具有显著的数据效率，仅用2%训练数据即可达到其他模型相当性能；(3)CTR预测模型性能在2015-2016年显著提升，之后进入缓慢进展阶段。

Conclusion: Bench-CTR基准平台将促进CTR预测领域的模型开发和评估，帮助从业者更好地理解模型机制，代码已开源。

Abstract: This research designs a unified architecture of CTR prediction benchmark (Bench-CTR) platform that offers flexible interfaces with datasets and components of a wide range of CTR prediction models. Moreover, we construct a comprehensive system of evaluation protocols encompassing real-world and synthetic datasets, a taxonomy of metrics, standardized procedures and experimental guidelines for calibrating the performance of CTR prediction models. Furthermore, we implement the proposed benchmark platform and conduct a comparative study to evaluate a wide range of state-of-the-art models from traditional multivariate statistical to modern large language model (LLM)-based approaches on three public datasets and two synthetic datasets. Experimental results reveal that, (1) high-order models largely outperform low-order models, though such advantage varies in terms of metrics and on different datasets; (2) LLM-based models demonstrate a remarkable data efficiency, i.e., achieving the comparable performance to other models while using only 2% of the training data; (3) the performance of CTR prediction models has achieved significant improvements from 2015 to 2016, then reached a stage with slow progress, which is consistent across various datasets. This benchmark is expected to facilitate model development and evaluation and enhance practitioners' understanding of the underlying mechanisms of models in the area of CTR prediction. Code is available at https://github.com/NuriaNinja/Bench-CTR.

</details>


### [12] [Structured Spectral Reasoning for Frequency-Adaptive Multimodal Recommendation](https://arxiv.org/abs/2512.01372)
*Wei Yang,Rui Zhong,Yiqun Chen,Chi Lu,Peng Jiang*

Main category: cs.IR

TL;DR: 提出SSR框架，通过结构化谱推理进行频率感知的多模态推荐，解决模态噪声、语义不一致和图传播不稳定问题


<details>
  <summary>Details</summary>
Motivation: 多模态推荐面临模态特定噪声、语义不一致和图传播不稳定等问题，现有方法依赖静态滤波或重加权，缺乏对谱结构的推理能力和模态特定可靠性的自适应能力

Method: 四阶段框架：1) 图引导变换分解多模态信号为谱带；2) 谱带掩码调制带级可靠性；3) 低秩跨带交互的谱推理融合频率线索；4) 对比正则化对齐模态特定谱特征

Result: 在三个真实基准测试中优于强基线，尤其在稀疏和冷启动场景下表现突出，分析显示结构化谱建模提高了鲁棒性并提供了清晰的频带贡献诊断

Conclusion: SSR框架通过结构化谱推理有效解决了多模态推荐中的噪声、不一致和传播问题，为频率感知的多模态推荐提供了新思路

Abstract: Multimodal recommendation aims to integrate collaborative signals with heterogeneous content such as visual and textual information, but remains challenged by modality-specific noise, semantic inconsistency, and unstable propagation over user-item graphs. These issues are often exacerbated by naive fusion or shallow modeling strategies, leading to degraded generalization and poor robustness. While recent work has explored the frequency domain as a lens to separate stable from noisy signals, most methods rely on static filtering or reweighting, lacking the ability to reason over spectral structure or adapt to modality-specific reliability. To address these challenges, we propose a Structured Spectral Reasoning (SSR) framework for frequency-aware multimodal recommendation. Our method follows a four-stage pipeline: (i) Decompose graph-based multimodal signals into spectral bands via graph-guided transformations to isolate semantic granularity; (ii) Modulate band-level reliability with spectral band masking, a training-time masking with a prediction-consistency objective that suppresses brittle frequency components; (iii) Fuse complementary frequency cues using hyperspectral reasoning with low-rank cross-band interaction; and (iv) Align modality-specific spectral features via contrastive regularization to promote semantic and structural consistency. Experiments on three real-world benchmarks show consistent gains over strong baselines, particularly under sparse and cold-start settings. Additional analyses indicate that structured spectral modeling improves robustness and provides clearer diagnostics of how different bands contribute to performance.

</details>
