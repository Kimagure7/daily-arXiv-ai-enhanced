<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [BiCoRec: Bias-Mitigated Context-Aware Sequential Recommendation Model](https://arxiv.org/abs/2512.13848)
*Mufhumudzi Muthivhi,Terence L van Zyl,Hairong Wang*

Main category: cs.IR

TL;DR: BiCoRec是一个新颖的序列推荐框架，通过自适应处理用户对热门和冷门物品的偏好变化，解决了现有模型的流行度偏差问题，显著提升了偏好冷门物品用户的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的序列推荐模型存在固有的流行度偏差问题，无法很好地适应用户对热门和冷门物品偏好的动态变化，特别是对于偏好冷门物品的用户推荐效果不佳。

Method: 提出BiCoRec框架：1）使用协同注意力机制获取流行度加权的用户序列表示；2）引入新的训练方案，通过一致性损失函数从未来偏好中学习；3）自适应地处理用户对热门和冷门物品的偏好变化。

Result: 对于偏好冷门物品的用户，BiCoRec在NDCG@10指标上相比最先进的基线方法平均提升了26.00%。在完整物品集合上的排名性能：Movies数据集NDCG@10为0.0102，Fashion为0.0047，Games为0.0021，Music为0.0005。

Conclusion: BiCoRec通过自适应处理流行度偏差，有效提升了序列推荐性能，特别是在偏好冷门物品的用户群体中取得了显著改进，为解决推荐系统中的流行度偏差问题提供了有效方案。

Abstract: Sequential recommendation models aim to learn from users evolving preferences. However, current state-of-the-art models suffer from an inherent popularity bias. This study developed a novel framework, BiCoRec, that adaptively accommodates users changing preferences for popular and niche items. Our approach leverages a co-attention mechanism to obtain a popularity-weighted user sequence representation, facilitating more accurate predictions. We then present a new training scheme that learns from future preferences using a consistency loss function. BiCoRec aimed to improve the recommendation performance of users who preferred niche items. For these users, BiCoRec achieves a 26.00% average improvement in NDCG@10 over state-of-the-art baselines. When ranking the relevant item against the entire collection, BiCoRec achieves NDCG@10 scores of 0.0102, 0.0047, 0.0021, and 0.0005 for the Movies, Fashion, Games and Music datasets.

</details>


### [2] [Intent-Guided Reasoning for Sequential Recommendation](https://arxiv.org/abs/2512.14034)
*Yifan Shao,Peilin Zhou*

Main category: cs.IR

TL;DR: IGR-SR：一种基于意图引导推理的序列推荐框架，通过显式提取高层意图解决现有推理增强方法中的推理不稳定性和浅层推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于推理增强的序列推荐方法仅以下一个目标物品作为监督，导致两个关键问题：1) 推理不稳定性——过程对近期行为和偶然点击等虚假交互过于敏感；2) 浅层推理——模型仅记忆物品间转移而非理解内在行为模式。

Method: 提出IGR-SR框架，包含三个核心组件：1) 潜在意图蒸馏器(LID)，使用冻结编码器和可学习令牌高效提取多层面意图；2) 意图感知审慎推理器(IDR)，通过双重注意力架构将推理解耦为意图审慎和决策制定；3) 意图一致性正则化(ICR)，通过强制不同意图视图间表示一致性确保鲁棒性。

Result: 在三个公开数据集上，IGR-SR相比最先进基线平均提升7.13%。在20%行为噪声下，IGR-SR仅下降10.4%，而竞争方法分别下降16.2%和18.6%，验证了意图引导推理的有效性和鲁棒性。

Conclusion: IGR-SR通过显式提取和利用高层意图，有效解决了序列推荐中推理不稳定和浅层推理的问题，显著提升了推荐性能和鲁棒性，为推理增强的推荐系统提供了新思路。

Abstract: Sequential recommendation systems aim to capture users' evolving preferences from their interaction histories. Recent reasoningenhanced methods have shown promise by introducing deliberate, chain-of-thought-like processes with intermediate reasoning steps. However, these methods rely solely on the next target item as supervision, leading to two critical issues: (1) reasoning instability--the process becomes overly sensitive to recent behaviors and spurious interactions like accidental clicks, and (2) surface-level reasoning--the model memorizes item-to-item transitions rather than understanding intrinsic behavior patterns. To address these challenges, we propose IGR-SR, an Intent-Guided Reasoning framework for Sequential Recommendation that anchors the reasoning process to explicitly extracted high-level intents. Our framework comprises three key components: (1) a Latent Intent Distiller (LID) that efficiently extracts multi-faceted intents using a frozen encoder with learnable tokens, (2) an Intent-aware Deliberative Reasoner (IDR) that decouples reasoning into intent deliberation and decision-making via a dual-attention architecture, and (3) an Intent Consistency Regularization (ICR) that ensures robustness by enforcing consistent representations across different intent views. Extensive experiments on three public datasets demonstrate that IGR-SR achieves an average 7.13% improvement over state-of-the-art baselines. Critically, under 20% behavioral noise, IGR-SR degrades only 10.4% compared to 16.2% and 18.6% for competing methods, validating the effectiveness and robustness of intent-guided reasoning.

</details>


### [3] [DTRec: Learning Dynamic Reasoning Trajectories for Sequential Recommendation](https://arxiv.org/abs/2512.14036)
*Yifan Shao,Peilin Zhou,Shoujin Wang,Weizhi Zhang,Xu Cai,Sunghun Kim*

Main category: cs.IR

TL;DR: DTRec：一种动态推理轨迹推荐框架，通过分层过程监督和自适应推理停止机制，在推理方向和深度上实现动态调整，显著提升推荐性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有推理增强的顺序推荐方法存在两个关键限制：1）静态推理方向，使用扁平监督信号，与人类分层推理不匹配；2）固定推理深度，对所有用户应用相同计算量，不考虑行为模式复杂性。这些刚性导致性能次优和计算浪费。

Method: 提出DTRec框架，包含两个核心组件：1）分层过程监督（HPS），提供从粗到细的监督信号，模拟人类认知过程的渐进细化；2）自适应推理停止（ARH）机制，通过联合监控三个指标动态调整推理步数。

Result: 在三个真实世界数据集上的实验表明，该方法相比强基线性能提升高达24.5%，同时计算成本降低高达41.6%。

Conclusion: DTRec通过动态调整推理轨迹的方向和深度，有效解决了现有方法的刚性限制，实现了更高效、更准确的顺序推荐。

Abstract: Inspired by advances in LLMs, reasoning-enhanced sequential recommendation performs multi-step deliberation before making final predictions, unlocking greater potential for capturing user preferences. However, current methods are constrained by static reasoning trajectories that are ill-suited for the diverse complexity of user behaviors. They suffer from two key limitations: (1) a static reasoning direction, which uses flat supervision signals misaligned with human-like hierarchical reasoning, and (2) a fixed reasoning depth, which inefficiently applies the same computational effort to all users, regardless of pattern complexity. These rigidity lead to suboptimal performance and significant computational waste. To overcome these challenges, we propose DTRec, a novel and effective framework that explores the Dynamic reasoning Trajectory for Sequential Recommendation along both direction and depth. To guide the direction, we develop Hierarchical Process Supervision (HPS), which provides coarse-to-fine supervisory signals to emulate the natural, progressive refinement of human cognitive processes. To optimize the depth, we introduce the Adaptive Reasoning Halting (ARH) mechanism that dynamically adjusts the number of reasoning steps by jointly monitoring three indicators. Extensive experiments on three real-world datasets demonstrate the superiority of our approach, achieving up to a 24.5% performance improvement over strong baselines while simultaneously reducing computational cost by up to 41.6%.

</details>


### [4] [From Feature Interaction to Feature Generation: A Generative Paradigm of CTR Prediction Models](https://arxiv.org/abs/2512.14041)
*Mingjia Yin,Junwei Pan,Hao Wang,Ximei Wang,Shangyu Zhang,Jie Jiang,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 提出SFG框架，将CTR预测从判别式"特征交互"范式转向生成式"特征生成"范式，通过编码器-解码器结构生成特征嵌入，缓解嵌入维度坍缩和信息冗余问题。


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测模型主要采用判别式范式，过度依赖原始ID嵌入的特征交互，导致嵌入维度坍缩和信息冗余两个关键问题。

Method: 提出监督特征生成(SFG)框架，包含编码器构建特征隐藏嵌入和解码器从隐藏表示重构所有特征嵌入，引入监督损失利用点击信号，可与大多数现有CTR模型集成。

Result: 实验表明SFG能有效缓解嵌入坍缩和减少信息冗余，在各种数据集和基础模型上带来显著性能提升。

Conclusion: SFG框架成功将CTR预测从判别式范式转向生成式范式，解决了现有模型的局限性，具有良好通用性和性能优势。

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems, aims to estimate the probability of users clicking on items. Existing models predominantly follow a discriminative paradigm, which relies heavily on explicit interactions between raw ID embeddings. However, this paradigm inherently renders them susceptible to two critical issues: embedding dimensional collapse and information redundancy, stemming from the over-reliance on feature interactions \emph{over raw ID embeddings}. To address these limitations, we propose a novel \emph{Supervised Feature Generation (SFG)} framework, \emph{shifting the paradigm from discriminative ``feature interaction" to generative ``feature generation"}. Specifically, SFG comprises two key components: an \emph{Encoder} that constructs hidden embeddings for each feature, and a \emph{Decoder} tasked with regenerating the feature embeddings of all features from these hidden representations. Unlike existing generative approaches that adopt self-supervised losses, we introduce a supervised loss to utilize the supervised signal, \ie, click or not, in the CTR prediction task. This framework exhibits strong generalizability: it can be seamlessly integrated with most existing CTR models, reformulating them under the generative paradigm. Extensive experiments demonstrate that SFG consistently mitigates embedding collapse and reduces information redundancy, while yielding substantial performance gains across various datasets and base models. The code is available at https://github.com/USTC-StarTeam/GE4Rec.

</details>


### [5] [AsarRec: Adaptive Sequential Augmentation for Robust Self-supervised Sequential Recommendation](https://arxiv.org/abs/2512.14047)
*Kaike Zhang,Qi Cao,Fei Sun,Xinran Liu*

Main category: cs.IR

TL;DR: 提出AsarRec框架，通过自适应增强解决序列推荐系统中噪声问题，相比静态增强方法能适应不同场景并提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现实用户行为存在噪声（人为错误、不确定性、行为模糊性），传统自监督学习方法依赖预定义的静态增强策略，但最佳增强类型因场景而异，不适当的增强反而会降低推荐性能。

Method: 将现有基本增强操作统一为结构化变换矩阵，提出AsarRec框架：通过编码用户序列为概率转移矩阵，使用可微分Semi-Sinkhorn算法投影为半双随机矩阵来学习变换矩阵，联合优化多样性、语义不变性和信息性三个目标。

Result: 在三个基准数据集和不同噪声水平下的广泛实验验证了AsarRec的有效性，展示了其优越的鲁棒性和一致的性能提升。

Conclusion: AsarRec通过自适应增强策略有效解决了序列推荐中的噪声问题，相比静态增强方法具有更好的适应性和鲁棒性。

Abstract: Sequential recommender systems have demonstrated strong capabilities in modeling users' dynamic preferences and capturing item transition patterns. However, real-world user behaviors are often noisy due to factors such as human errors, uncertainty, and behavioral ambiguity, which can lead to degraded recommendation performance. To address this issue, recent approaches widely adopt self-supervised learning (SSL), particularly contrastive learning, by generating perturbed views of user interaction sequences and maximizing their mutual information to improve model robustness. However, these methods heavily rely on their pre-defined static augmentation strategies~(where the augmentation type remains fixed once chosen) to construct augmented views, leading to two critical challenges: (1) the optimal augmentation type can vary significantly across different scenarios; (2) inappropriate augmentations may even degrade recommendation performance, limiting the effectiveness of SSL. To overcome these limitations, we propose an adaptive augmentation framework. We first unify existing basic augmentation operations into a unified formulation via structured transformation matrices. Building on this, we introduce AsarRec (Adaptive Sequential Augmentation for Robust Sequential Recommendation), which learns to generate transformation matrices by encoding user sequences into probabilistic transition matrices and projecting them into hard semi-doubly stochastic matrices via a differentiable Semi-Sinkhorn algorithm. To ensure that the learned augmentations benefit downstream performance, we jointly optimize three objectives: diversity, semantic invariance, and informativeness. Extensive experiments on three benchmark datasets under varying noise levels validate the effectiveness of AsarRec, demonstrating its superior robustness and consistent improvements.

</details>


### [6] [SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions](https://arxiv.org/abs/2512.14277)
*Panayiotis Smeros,Vincent Emonet,Ruijie Wang,Ana-Claudia Sima,Tarcisio Mendes de Farias*

Main category: cs.IR

TL;DR: SPARQL-LLM：基于轻量级元数据的开源、三元存储无关方法，能够从自然语言生成SPARQL查询，在准确率、速度、成本和联邦查询能力方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型方法主要关注单一数据源的查询准确率，忽略了联邦查询能力、生成时间和成本等生产部署所需的关键指标，导致难以在实际分布式知识图谱中部署。

Method: 扩展先前工作，提出SPARQL-LLM架构，包含元数据索引、提示构建、查询生成与执行三个核心组件，采用轻量级元数据实现三元存储无关性。

Result: 在最新挑战中F1分数提升24%，支持英语和西班牙语等资源丰富语言，能生成复杂联邦生物信息学查询，比同类系统快36倍，每问题成本最高仅0.01美元。

Conclusion: SPARQL-LLM在准确率、速度、成本和联邦查询能力方面均有显著优势，适合实时低成本文本到SPARQL应用，已在实际分散知识图谱中部署应用。

Abstract: The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.

</details>


### [7] [Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias](https://arxiv.org/abs/2512.14313)
*Malika Iratni,Mohand Boughanem,Taoufiq Dkaki*

Main category: cs.IR

TL;DR: 本文系统分析了RAG系统中干扰文档对生成质量的影响，研究了相关文档在上下文中的位置效应，并提出了一种基于查询的动态文档检索数量预测方法，显著提升了RAG性能。


<details>
  <summary>Details</summary>
Motivation: 标准RAG系统使用固定的top-k检索策略存在两个问题：1) 可能错过相关信息或引入语义不相关的干扰文档，降低输出质量；2) 检索到的文档在输入上下文中的位置会影响模型注意力，存在"中间丢失"现象。需要系统分析这些因素对生成质量的影响并改进检索策略。

Method: 首先系统分析干扰文档对生成质量的影响，量化不同条件下的效果；其次研究相关文档在上下文窗口中的位置如何影响生成结果；基于这些分析，提出一个上下文大小分类器，能够根据查询特定的信息需求动态预测最优的检索文档数量；最后将该方法集成到完整的RAG流程中。

Result: 提出的动态文档检索方法在完整RAG流程中表现出色，相比固定k值基线方法取得了更好的性能提升，验证了动态调整检索数量的有效性。

Conclusion: RAG系统中干扰文档和文档位置对生成质量有显著影响，通过动态预测最优检索文档数量可以有效提升RAG性能，这为改进检索增强生成系统提供了重要见解和方法。

Abstract: Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the "lost in the middle" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.

</details>


### [8] [PushGen: Push Notifications Generation with LLM](https://arxiv.org/abs/2512.14490)
*Shifu Bie,Jiangxia Cao,Zixiao Luo,Yichuan Zou,Lei Liang,Lu Zhang,Linxun Chen,Zhaojie Liu,Xuanping Li,Guorui Zhou,Kaiqiao Zhan,Kun Gai*

Main category: cs.IR

TL;DR: PushGen是一个自动生成高质量推送通知的框架，通过可控类别提示和奖励模型确保内容质量，已在大规模工业应用中部署


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的发展，利用LLM生成推送内容变得普遍，但保持风格控制和可靠质量评估仍然具有挑战性，这两者直接影响用户参与度

Method: PushGen结合两个关键组件：(1) 可控类别提示技术，引导LLM输出符合期望风格；(2) 奖励模型，对生成的候选内容进行排名和选择

Result: 广泛的离线和在线实验证明了其有效性，已在大型工业应用中部署，每天为数亿用户提供服务

Conclusion: PushGen框架成功解决了LLM生成推送内容时的风格控制和质量评估问题，实现了高质量、可扩展的推送通知生成

Abstract: We present PushGen, an automated framework for generating high-quality push notifications comparable to human-crafted content. With the rise of generative models, there is growing interest in leveraging LLMs for push content generation. Although LLMs make content generation straightforward and cost-effective, maintaining stylistic control and reliable quality assessment remains challenging, as both directly impact user engagement. To address these issues, PushGen combines two key components: (1) a controllable category prompt technique to guide LLM outputs toward desired styles, and (2) a reward model that ranks and selects generated candidates. Extensive offline and online experiments demonstrate its effectiveness, which has been deployed in large-scale industrial applications, serving hundreds of millions of users daily.

</details>


### [9] [RecGPT-V2 Technical Report](https://arxiv.org/abs/2512.14503)
*Chao Yi,Dian Chen,Gaoyang Guo,Jiakai Tang,Jian Wu,Jing Yu,Mao Zhang,Wen Chen,Wenjun Yang,Yujie Luo,Yuning Jiang,Zhujin Gao,Bo Zheng,Binbin Cao,Changfa Wu,Dixuan Wang,Han Wu,Haoyi Hu,Kewei Zhu,Lang Tian,Lin Yang,Qiqi Huang,Siqi Yang,Wenbo Su,Xiaoxiao He,Xin Tong,Xu Chen,Xunke Xi,Xiaowei Huang,Yaxuan Wu,Yeqiu Yang,Yi Hu,Yujin Yuan,Yuliang Yan,Zile Zhou*

Main category: cs.IR

TL;DR: RecGPT-V2通过分层多智能体系统、元提示框架、约束强化学习和智能体即法官评估框架，解决了V1版本的计算效率、解释多样性、泛化能力和评估标准问题，显著提升了推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然RecGPT-V1成功将LLM推理引入推荐系统，但存在四个根本限制：计算效率低下和认知冗余；解释多样性不足；监督学习范式下泛化能力有限；评估标准过于简单无法匹配人类标准。

Method: 1. 分层多智能体系统协调协作重构意图推理，消除认知重复；2. 混合表示推理压缩用户行为上下文；3. 元提示框架动态生成上下文自适应提示；4. 约束强化学习缓解多奖励冲突；5. 智能体即法官框架将评估分解为多步推理。

Result: GPU消耗减少60%，独占召回率从9.39%提升至10.99%；解释多样性提升7.3%；标签预测提升24.1%，解释接受度提升13.0%；淘宝在线A/B测试显示CTR提升2.98%，IPV提升3.71%，TV提升2.19%，NER提升11.46%。

Conclusion: RecGPT-V2证明了在大规模部署LLM驱动的意图推理的技术可行性和商业可行性，弥合了认知探索与工业效用之间的差距。

Abstract: Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.
  To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.

</details>


### [10] [Pairwise Comparison for Bias Identification and Quantification](https://arxiv.org/abs/2512.14565)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 该研究提出使用成对比较法来标注语言偏见，通过模拟环境评估不同评分技术和成本感知替代方案，为创建高质量基准数据集提供基础。


<details>
  <summary>Details</summary>
Motivation: 在线新闻和社交媒体中的语言偏见普遍存在但难以测量，主要挑战包括主观性、上下文依赖性和高质量标注数据集的稀缺。传统标注方法成本高昂，需要更高效的标注方法。

Method: 采用成对比较法进行偏见标注，通过模拟环境评估不同评分技术和三种成本感知替代方案的参数。模拟包括潜在严重性分布、距离校准噪声和合成标注者偏见。在人类标注的偏见基准数据集上评估最有前景的设置，并与大语言模型直接评估和未修改的成对比较标签作为基线进行比较。

Result: 研究支持使用成对比较作为量化主观语言方面的实用基础，能够实现可重复的偏见分析。优化了比较和匹配组件，进行了端到端评估（包括模拟和实际数据应用），并提供了成本感知大规模标注的实现蓝图。

Conclusion: 成对比较法为量化语言偏见和其他主观语言方面提供了实用且可扩展的方法，通过优化标注流程能够显著降低标注成本，同时保持高质量的数据标注，为创建大规模基准数据集提供了可行方案。

Abstract: Linguistic bias in online news and social media is widespread but difficult to measure. Yet, its identification and quantification remain difficult due to subjectivity, context dependence, and the scarcity of high-quality gold-label datasets. We aim to reduce annotation effort by leveraging pairwise comparison for bias annotation. To overcome the costliness of the approach, we evaluate more efficient implementations of pairwise comparison-based rating. We achieve this by investigating the effects of various rating techniques and the parameters of three cost-aware alternatives in a simulation environment. Since the approach can in principle be applied to both human and large language model annotation, our work provides a basis for creating high-quality benchmark datasets and for quantifying biases and other subjective linguistic aspects.
  The controlled simulations include latent severity distributions, distance-calibrated noise, and synthetic annotator bias to probe robustness and cost-quality trade-offs. In applying the approach to human-labeled bias benchmark datasets, we then evaluate the most promising setups and compare them to direct assessment by large language models and unmodified pairwise comparison labels as baselines. Our findings support the use of pairwise comparison as a practical foundation for quantifying subjective linguistic aspects, enabling reproducible bias analysis. We contribute an optimization of comparison and matchmaking components, an end-to-end evaluation including simulation and real-data application, and an implementation blueprint for cost-aware large-scale annotation

</details>
