<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Soft Filtering: Guiding Zero-shot Composed Image Retrieval with Prescriptive and Proscriptive Constraints](https://arxiv.org/abs/2512.20781)
*Youjin Jung,Seongwoo Cho,Hyun-seok Min,Sungchul Choi*

Main category: cs.IR

TL;DR: SoFT是一个用于零样本组合图像检索的训练免费插件过滤模块，通过提取规定性和禁止性约束来重新排序结果，无需修改基础检索模型或添加监督。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合图像检索方法存在两个问题：1）使用单一融合查询会稀释关键信息，无法区分用户想要什么和避免什么；2）现有基准假设每个查询只有一个正确答案，忽略了修改文本的模糊性。

Method: 提出SoFT（Soft Filtering with Textual constraints），利用多模态大语言模型从参考图像-修改文本对中提取两种互补约束：规定性（必须有）和禁止性（必须避免）约束，作为语义过滤器对候选图像进行奖励或惩罚来重新排序。同时构建两阶段数据集管道，首先识别每个查询的多个可能目标构建多目标三元组，然后引导多模态LLM重写修改文本以专注于一个目标。

Result: 在CIReVL检索器基础上应用SoFT，在CIRR上将R@5提升到65.25（+12.94），在CIRCO上将mAP@50提升到27.93（+6.13），在FashionIQ上将R@50提升到58.44（+4.59），显示出广泛的有效性。

Conclusion: SoFT通过提取互补的语义约束和构建更全面的评估数据集，有效解决了零样本组合图像检索中的信息稀释和模糊性问题，显著提升了检索性能。

Abstract: Composed Image Retrieval (CIR) aims to find a target image that aligns with user intent, expressed through a reference image and a modification text. While Zero-shot CIR (ZS-CIR) methods sidestep the need for labeled training data by leveraging pretrained vision-language models, they often rely on a single fused query that merges all descriptive cues of what the user wants, tending to dilute key information and failing to account for what they wish to avoid. Moreover, current CIR benchmarks assume a single correct target per query, overlooking the ambiguity in modification texts. To address these challenges, we propose Soft Filtering with Textual constraints (SoFT), a training-free, plug-and-play filtering module for ZS-CIR. SoFT leverages multimodal large language models (LLMs) to extract two complementary constraints from the reference-modification pair: prescriptive (must-have) and proscriptive (must-avoid) constraints. These serve as semantic filters that reward or penalize candidate images to re-rank results, without modifying the base retrieval model or adding supervision. In addition, we construct a two-stage dataset pipeline that refines CIR benchmarks. We first identify multiple plausible targets per query to construct multi-target triplets, capturing the open-ended nature of user intent. Then guide multimodal LLMs to rewrite the modification text to focus on one target, while referencing contrastive distractors to ensure precision. This enables more comprehensive and reliable evaluation under varying ambiguity levels. Applied on top of CIReVL, a ZS-CIR retriever, SoFT raises R@5 to 65.25 on CIRR (+12.94), mAP@50 to 27.93 on CIRCO (+6.13), and R@50 to 58.44 on FashionIQ (+4.59), demonstrating broad effectiveness.

</details>


### [2] [Accurate and Diverse Recommendations via Propensity-Weighted Linear Autoencoders](https://arxiv.org/abs/2512.20896)
*Kazuma Onishi,Katsuhiko Hayashi,Hidetaka Kamigaito*

Main category: cs.IR

TL;DR: 提出新的倾向性评分方法，使用sigmoid函数调整项目观测频率，在保持推荐准确性的同时提高多样性


<details>
  <summary>Details</summary>
Motivation: 现实推荐系统中用户-项目交互存在MNAR问题，流行项目被过度观测，导致推荐偏向流行项目而降低多样性。现有基于幂律函数的IPS方法过度惩罚流行项目，损害其推荐性能

Method: 重新定义倾向性评分，将项目观测频率的对数通过sigmoid函数处理，保持幂律评分的简单性同时允许更灵活的调整。将新评分方法集成到线性自编码器模型中

Result: 实验结果显示，该方法显著提高了推荐列表中项目的多样性，同时没有牺牲推荐准确性

Conclusion: 提出的sigmoid-based倾向性评分方法有效解决了MNAR问题，在保持准确性的同时提高了推荐多样性，避免了过度惩罚流行项目的问题

Abstract: In real-world recommender systems, user-item interactions are Missing Not At Random (MNAR), as interactions with popular items are more frequently observed than those with less popular ones. Missing observations shift recommendations toward frequently interacted items, which reduces the diversity of the recommendation list. To alleviate this problem, Inverse Propensity Scoring (IPS) is widely used and commonly models propensities based on a power-law function of item interaction frequency. However, we found that such power-law-based correction overly penalizes popular items and harms their recommendation performance. We address this issue by redefining the propensity score to allow broader item recommendation without excessively penalizing popular items. The proposed score is formulated by applying a sigmoid function to the logarithm of the item observation frequency, maintaining the simplicity of power-law scoring while allowing for more flexible adjustment. Furthermore, we incorporate the redefined propensity score into a linear autoencoder model, which tends to favor popular items, and evaluate its effectiveness. Experimental results revealed that our method substantially improves the diversity of items in the recommendation list without sacrificing recommendation accuracy.

</details>


### [3] [MMSRARec: Summarization and Retrieval Augumented Sequential Recommendation Based on Multimodal Large Language Model](https://arxiv.org/abs/2512.20916)
*Haoyu Wang,Yitong Wang,Jining Wang*

Main category: cs.IR

TL;DR: 本文提出MMSRARec方法，通过多模态大语言模型总结物品为关键词，结合协同信号，实现高效可解释的多模态序列推荐。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在推荐系统应用中存在三个主要问题：1）现有方法主要利用预训练MLLM生成物品嵌入或语义ID，但表示可解释性有限且难以迁移到基于语言模型的推荐系统；2）将用户行为序列转换为图像-文本对进行多次MLLM推理，计算和时间成本过高；3）当前MLLM推荐系统普遍忽视协同信号的整合。

Method: 提出多模态总结与检索增强序列推荐（MMSRARec）：1）使用MLLM将物品总结为简洁关键词，通过包含总结长度、信息损失和重建难度的奖励进行微调，实现自适应总结策略；2）受检索增强生成启发，将协同信号转换为相应关键词作为补充上下文；3）应用监督微调与多任务学习，使MLLM与多模态序列推荐对齐。

Result: 在常见推荐数据集上的广泛评估证明了MMSRARec的有效性，展示了其能够高效且可解释地理解用户行为历史和物品信息，实现准确推荐。

Conclusion: MMSRARec在推荐性能、可解释性和计算成本之间取得了良好平衡，解决了现有MLLM推荐方法的局限性，为多模态序列推荐提供了新的有效解决方案。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant potential in recommendation systems. However, the effective application of MLLMs to multimodal sequential recommendation remains unexplored: A) Existing methods primarily leverage the multimodal semantic understanding capabilities of pre-trained MLLMs to generate item embeddings or semantic IDs, thereby enhancing traditional recommendation models. These approaches generate item representations that exhibit limited interpretability, and pose challenges when transferring to language model-based recommendation systems. B) Other approaches convert user behavior sequence into image-text pairs and perform recommendation through multiple MLLM inference, incurring prohibitive computational and time costs. C) Current MLLM-based recommendation systems generally neglect the integration of collaborative signals. To address these limitations while balancing recommendation performance, interpretability, and computational cost, this paper proposes MultiModal Summarization-and-Retrieval-Augmented Sequential Recommendation. Specifically, we first employ MLLM to summarize items into concise keywords and fine-tune the model using rewards that incorporate summary length, information loss, and reconstruction difficulty, thereby enabling adaptive adjustment of the summarization policy. Inspired by retrieval-augmented generation, we then transform collaborative signals into corresponding keywords and integrate them as supplementary context. Finally, we apply supervised fine-tuning with multi-task learning to align the MLLM with the multimodal sequential recommendation. Extensive evaluations on common recommendation datasets demonstrate the effectiveness of MMSRARec, showcasing its capability to efficiently and interpretably understand user behavior histories and item information for accurate recommendations.

</details>


### [4] [Towards Better Search with Domain-Aware Text Embeddings for C2C Marketplaces](https://arxiv.org/abs/2512.21021)
*Andre Rusli,Miao Cao,Shoma Ishimoto,Sho Akiyama,Max Frenzel*

Main category: cs.IR

TL;DR: 该论文通过在Mercari平台开发领域感知的日语文本嵌入方法，解决了C2C市场中的搜索挑战，包括短查询、噪声列表和生产约束，通过微调和Matryoshka表示学习实现了搜索质量和效率的显著提升。


<details>
  <summary>Details</summary>
Motivation: C2C市场面临独特的检索挑战：简短模糊的查询、用户生成的噪声列表、严格的生产约束。需要为日本最大的C2C平台Mercari开发专门的文本嵌入方法，以提升搜索质量。

Method: 1) 在购买驱动的查询-标题对上微调模型；2) 使用角色特定前缀建模查询-商品不对称性；3) 应用Matryoshka表示学习获得紧凑、截断鲁棒的嵌入；4) 用Matryoshka截断替换PCA压缩。

Result: 离线评估显示相比通用编码器有持续提升，Matryoshka截断替代PCA压缩带来特别大的改进。人工评估显示在处理专有名词、市场特定语义和术语重要性对齐方面表现更好。在线A/B测试显示用户收入和搜索流效率有统计显著提升，交易频率保持稳定。

Conclusion: 领域感知嵌入能够在大规模下提升相关性和效率，为更丰富的LLM时代搜索体验奠定了实用基础，证明了针对特定领域优化嵌入方法的价值。

Abstract: Consumer-to-consumer (C2C) marketplaces pose distinct retrieval challenges: short, ambiguous queries; noisy, user-generated listings; and strict production constraints. This paper reports our experiment to build a domain-aware Japanese text-embedding approach to improve the quality of search at Mercari, Japan's largest C2C marketplace. We experimented with fine-tuning on purchase-driven query-title pairs, using role-specific prefixes to model query-item asymmetry. To meet production constraints, we apply Matryoshka Representation Learning to obtain compact, truncation-robust embeddings. Offline evaluation on historical search logs shows consistent gains over a strong generic encoder, with particularly large improvements when replacing PCA compression with Matryoshka truncation. A manual assessment further highlights better handling of proper nouns, marketplace-specific semantics, and term-importance alignment. Additionally, an initial online A/B test demonstrates statistically significant improvements in revenue per user and search-flow efficiency, with transaction frequency maintained. Results show that domain-aware embeddings improve relevance and efficiency at scale and form a practical foundation for richer LLM-era search experiences.

</details>


### [5] [Agentic Multi-Persona Framework for Evidence-Aware Fake News Detection](https://arxiv.org/abs/2512.21039)
*Roopa Bukke,Soumya Pandey,Suraj Kumar,Soumi Chattopadhyay,Chandranath Adak*

Main category: cs.IR

TL;DR: AMPEND-LS：一个基于LLM-SLM协同的多模态假新闻检测框架，通过多角色证据推理和可信度融合机制，在准确性、鲁棒性和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线虚假信息的快速传播对公众信任、政策和安全构成重大风险，需要可靠的自动化假新闻检测。现有方法在多模态内容处理、领域泛化和可解释性方面存在不足。

Method: 提出AMPEND-LS框架，整合文本、视觉和上下文信号，通过LLM驱动的结构化推理流程，结合反向图像搜索、知识图谱路径和说服策略分析。引入可信度融合机制（语义相似度、领域可信度、时间上下文）和互补的SLM分类器来缓解LLM的不确定性和幻觉。

Result: 在三个基准数据集上的广泛实验表明，AMPEND-LS在准确性、F1分数和鲁棒性方面始终优于最先进的基线方法。定性案例研究进一步突出了其透明的推理能力和对不断演变的虚假信息的韧性。

Conclusion: 这项工作推动了自适应、可解释和证据感知系统的发展，用于保护在线信息完整性，为多模态假新闻检测提供了有效的解决方案。

Abstract: The rapid proliferation of online misinformation poses significant risks to public trust, policy, and safety, necessitating reliable automated fake news detection. Existing methods often struggle with multimodal content, domain generalization, and explainability. We propose AMPEND-LS, an agentic multi-persona evidence-grounded framework with LLM-SLM synergy for multimodal fake news detection. AMPEND-LS integrates textual, visual, and contextual signals through a structured reasoning pipeline powered by LLMs, augmented with reverse image search, knowledge graph paths, and persuasion strategy analysis. To improve reliability, we introduce a credibility fusion mechanism combining semantic similarity, domain trustworthiness, and temporal context, and a complementary SLM classifier to mitigate LLM uncertainty and hallucinations. Extensive experiments across three benchmark datasets demonstrate that AMPEND-LS consistently outperformed state-of-the-art baselines in accuracy, F1 score, and robustness. Qualitative case studies further highlight its transparent reasoning and resilience against evolving misinformation. This work advances the development of adaptive, explainable, and evidence-aware systems for safeguarding online information integrity.

</details>


### [6] [Blurb-Refined Inference from Crowdsourced Book Reviews using Hierarchical Genre Mining with Dual-Path Graph Convolutions](https://arxiv.org/abs/2512.21076)
*Suraj Kumar,Utsav Kumar Nareti,Soumi Chattopadhyay,Chandranath Adak,Prolay Mallick*

Main category: cs.IR

TL;DR: HiGeMine：一个两阶段层次化图书流派挖掘框架，通过零样本语义对齐过滤用户评论噪声，结合双路径图分类架构，在层次化流派分类任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图书流派分类方法通常将其建模为扁平的单标签任务，忽略了层次化流派结构，并且过度依赖嘈杂、主观的用户评论，导致分类可靠性下降。需要一种能够整合权威书籍简介和用户评论的鲁棒性层次化分类框架。

Method: 提出HiGeMine两阶段框架：第一阶段使用零样本语义对齐策略过滤用户评论，只保留与书籍简介语义一致的内容；第二阶段采用双路径两层图分类架构，第一层粗粒度二分类区分虚构/非虚构，第二层细粒度多标签分类预测具体流派，使用标签共现图建模流派间依赖关系，并利用预训练语言模型提取文本表示。

Result: 构建了新的层次化图书流派数据集进行系统评估，实验表明HiGeMine在层次化流派分类任务上持续优于强基线方法，证明了框架的有效性。

Conclusion: HiGeMine为层次化图书流派分析提供了一个原则性且有效的解决方案，能够同时利用结构化和非结构化文本数据，在数字图书馆组织和内容发现中具有应用价值。

Abstract: Accurate book genre classification is fundamental to digital library organization, content discovery, and personalized recommendation. Existing approaches typically model genre prediction as a flat, single-label task, ignoring hierarchical genre structure and relying heavily on noisy, subjective user reviews, which often degrade classification reliability. We propose HiGeMine, a two-phase hierarchical genre mining framework that robustly integrates user reviews with authoritative book blurbs. In the first phase, HiGeMine employs a zero-shot semantic alignment strategy to filter reviews, retaining only those semantically consistent with the corresponding blurb, thereby mitigating noise, bias, and irrelevance. In the second phase, we introduce a dual-path, two-level graph-based classification architecture: a coarse-grained Level-1 binary classifier distinguishes fiction from non-fiction, followed by Level-2 multi-label classifiers for fine-grained genre prediction. Inter-genre dependencies are explicitly modeled using a label co-occurrence graph, while contextual representations are derived from pretrained language models applied to the filtered textual content. To facilitate systematic evaluation, we curate a new hierarchical book genre dataset. Extensive experiments demonstrate that HiGeMine consistently outperformed strong baselines across hierarchical genre classification tasks. The proposed framework offers a principled and effective solution for leveraging both structured and unstructured textual data in hierarchical book genre analysis.

</details>


### [7] [ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling](https://arxiv.org/abs/2512.21257)
*Chuan Wang,Gaoming Yang,Han Wu,Jiakai Tang,Jiahao Yu,Jian Wu,Jianwu Hu,Junjun Zheng,Shuwen Xiao,Yeqiu Yang,Yuning Jiang,Ahjol Nurlanbek,Binbin Cao,Bo Zheng,Fangmei Zhu,Gaoming Zhou,Huimin Yi,Huiping Chu,Jin Huang,Jinzhe Shan,Kenan Cui,Longbin Li,Silu Zhou,Wen Chen,Xia Ming,Xiang Gao,Xin Yao,Xingyu Wen,Yan Zhang,Yiwen Hu,Yulin Wang,Ziheng Bao,Zongyuan Wu*

Main category: cs.IR

TL;DR: ReaSeq是一个推理增强的推荐框架，利用大语言模型的世界知识解决传统日志驱动推荐系统的知识贫乏和系统盲区问题，在淘宝排名系统中显著提升了各项业务指标。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统在日志驱动范式下存在两个根本限制：1）基于ID的物品表示存在知识贫乏，导致数据稀疏下的兴趣建模脆弱；2）系统对日志之外的用户兴趣存在盲区，限制了模型在平台边界内的性能。这些问题源于过度依赖浅层交互统计和闭环反馈，而忽视了大语言模型从海量语料中学到的产品语义和跨领域行为模式的世界知识。

Method: ReaSeq通过显式和隐式推理利用大语言模型的世界知识：1）通过多智能体协作的显式思维链推理，将结构化产品知识提炼成语义丰富的物品表示；2）通过扩散大语言模型进行隐式推理，推断合理的日志之外行为。

Result: 在淘宝服务数亿用户的排名系统中部署ReaSeq后，取得了显著提升：IPV和CTR增长超过6.0%，订单量增长超过2.9%，GMV增长超过2.5%，验证了世界知识增强推理相对于纯日志驱动方法的有效性。

Conclusion: ReaSeq框架通过利用大语言模型的世界知识进行推理，成功解决了工业推荐系统中知识贫乏和系统盲区的问题，显著提升了推荐性能，证明了世界知识增强推理在推荐系统中的重要价值。

Abstract: Industrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance within platform boundaries. These limitations stem from an over-reliance on shallow interaction statistics and close-looped feedback while neglecting the rich world knowledge about product semantics and cross-domain behavioral patterns that Large Language Models have learned from vast corpora.
  To address these challenges, we introduce ReaSeq, a reasoning-enhanced framework that leverages world knowledge in Large Language Models to address both limitations through explicit and implicit reasoning. Specifically, ReaSeq employs explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into semantically enriched item representations, and latent reasoning via Diffusion Large Language Models to infer plausible beyond-log behaviors. Deployed on Taobao's ranking system serving hundreds of millions of users, ReaSeq achieves substantial gains: >6.0% in IPV and CTR, >2.9% in Orders, and >2.5% in GMV, validating the effectiveness of world-knowledge-enhanced reasoning over purely log-driven approaches.

</details>
