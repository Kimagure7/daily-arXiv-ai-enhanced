{"id": "2511.13885", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13885", "abs": "https://arxiv.org/abs/2511.13885", "authors": ["Xingxian Liu", "Dongshuai Li", "Tao Wen", "Jiahui Wan", "Gui Ling", "Fuyu Lv", "Dan Ou", "Haihong Tang"], "title": "TaoSearchEmb: A Multi-Objective Reinforcement Learning Framework for Dense Retrieval in Taobao Search", "comment": null, "summary": "Dense retrieval, as the core component of e-commerce search engines, maps user queries and items into a unified semantic space through pre-trained embedding models to enable large-scale real-time semantic retrieval. Despite the rapid advancement of LLMs gradually replacing traditional BERT architectures for embedding, their training paradigms still adhere to BERT-like supervised fine-tuning and hard negative mining strategies. This approach relies on complex offline hard negative sample construction pipelines, which constrain model iteration efficiency and hinder the evolutionary potential of semantic representation capabilities. Besides, existing multi-task learning frameworks face the seesaw effect when simultaneously optimizing semantic relevance and non-relevance objectives. In this paper, we propose Retrieval-GRPO, a multi-objective reinforcement learning-based dense retrieval framework designed to address these challenges. The method eliminates offline hard negative sample construction by dynamically retrieving Top-K candidate products for each query during training, while introducing a relevance LLM as a reward model to generate real-time feedback. Specifically, the retrieval model dynamically optimizes embedding representations through reinforcement learning, with reward signals combining LLM-generated relevance scores, product quality scores, and multi-way exclusivity metrics to achieve multi-objective user preference alignment and real-time error correction. This mechanism not only removes dependency on hard negatives but also mitigates the seesaw effect through collaborative multi-objective optimization, significantly enhancing the model's semantic generalization capability for complex long-tail queries. Extensive offline and online experiments validate the effectiveness of Retrieval-GRPO, which has been deployed on China's largest e-commerce platform.", "AI": {"tldr": "\u63d0\u51fa\u4e86Retrieval-GRPO\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u4f20\u7edf\u786c\u8d1f\u6837\u672c\u6316\u6398\uff0c\u901a\u8fc7\u52a8\u6001\u68c0\u7d22\u548cLLM\u5956\u52b1\u6a21\u578b\u5b9e\u73b0\u5b9e\u65f6\u53cd\u9988\uff0c\u89e3\u51b3\u4e86\u8bed\u4e49\u68c0\u7d22\u4e2d\u7684\u8fed\u4ee3\u6548\u7387\u548c\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfBERT\u67b6\u6784\u7684\u5bc6\u96c6\u68c0\u7d22\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u79bb\u7ebf\u786c\u8d1f\u6837\u672c\u6784\u5efa\u6d41\u7a0b\uff0c\u9650\u5236\u4e86\u6a21\u578b\u8fed\u4ee3\u6548\u7387\u548c\u8bed\u4e49\u8868\u793a\u80fd\u529b\u7684\u8fdb\u5316\u6f5c\u529b\uff0c\u540c\u65f6\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u5728\u540c\u65f6\u4f18\u5316\u76f8\u5173\u6027\u548c\u975e\u76f8\u5173\u6027\u76ee\u6807\u65f6\u9762\u4e34\u8df7\u8df7\u677f\u6548\u5e94\u3002", "method": "\u4f7f\u7528\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u52a8\u6001\u68c0\u7d22Top-K\u5019\u9009\u5546\u54c1\uff0c\u5f15\u5165\u76f8\u5173\u6027LLM\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u751f\u6210\u5b9e\u65f6\u53cd\u9988\uff0c\u7ed3\u5408LLM\u751f\u6210\u7684\u76f8\u5173\u6027\u5206\u6570\u3001\u5546\u54c1\u8d28\u91cf\u5206\u6570\u548c\u591a\u8def\u6392\u4ed6\u6027\u6307\u6807\u6765\u4f18\u5316\u5d4c\u5165\u8868\u793a\u3002", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5df2\u5728\u4e2d\u56fd\u6700\u5927\u7684\u7535\u5546\u5e73\u53f0\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u957f\u5c3e\u67e5\u8be2\u7684\u8bed\u4e49\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Retrieval-GRPO\u6846\u67b6\u4e0d\u4ec5\u6d88\u9664\u4e86\u5bf9\u786c\u8d1f\u6837\u672c\u7684\u4f9d\u8d56\uff0c\u8fd8\u901a\u8fc7\u534f\u540c\u591a\u76ee\u6807\u4f18\u5316\u7f13\u89e3\u4e86\u8df7\u8df7\u677f\u6548\u5e94\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.14096", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14096", "abs": "https://arxiv.org/abs/2511.14096", "authors": ["Junchen Li", "Rongzheng Wang", "Yihong Huang", "Qizhi Chen", "Jiasheng Zhang", "Shuang Liang"], "title": "NeuroPath: Neurobiology-Inspired Path Tracking and Reflection for Semantically Coherent Retrieval", "comment": "Accepted by NeurIPS 2025", "summary": "Retrieval-augmented generation (RAG) greatly enhances large language models (LLMs) performance in knowledge-intensive tasks. However, naive RAG methods struggle with multi-hop question answering due to their limited capacity to capture complex dependencies across documents. Recent studies employ graph-based RAG to capture document connections. However, these approaches often result in a loss of semantic coherence and introduce irrelevant noise during node matching and subgraph construction. To address these limitations, we propose NeuroPath, an LLM-driven semantic path tracking RAG framework inspired by the path navigational planning of place cells in neurobiology. It consists of two steps: Dynamic Path Tracking and Post-retrieval Completion. Dynamic Path Tracking performs goal-directed semantic path tracking and pruning over the constructed knowledge graph (KG), improving noise reduction and semantic coherence. Post-retrieval Completion further reinforces these benefits by conducting second-stage retrieval using intermediate reasoning and the original query to refine the query goal and complete missing information in the reasoning path. NeuroPath surpasses current state-of-the-art baselines on three multi-hop QA datasets, achieving average improvements of 16.3% on recall@2 and 13.5% on recall@5 over advanced graph-based RAG methods. Moreover, compared to existing iter-based RAG methods, NeuroPath achieves higher accuracy and reduces token consumption by 22.8%. Finally, we demonstrate the robustness of NeuroPath across four smaller LLMs (Llama3.1, GLM4, Mistral0.3, and Gemma3), and further validate its scalability across tasks of varying complexity. Code is available at https://github.com/KennyCaty/NeuroPath.", "AI": {"tldr": "NeuroPath\u662f\u4e00\u4e2a\u53d7\u795e\u7ecf\u751f\u7269\u5b66\u542f\u53d1\u7684\u8bed\u4e49\u8def\u5f84\u8ffd\u8e2aRAG\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u5f84\u8ffd\u8e2a\u548c\u540e\u68c0\u7d22\u8865\u5168\u4e24\u4e2a\u6b65\u9aa4\uff0c\u6709\u6548\u89e3\u51b3\u591a\u8df3\u95ee\u7b54\u4e2d\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u566a\u58f0\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u96be\u4ee5\u6355\u6349\u6587\u6863\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u800c\u73b0\u6709\u7684\u56fe\u57faRAG\u65b9\u6cd5\u5728\u8282\u70b9\u5339\u914d\u548c\u5b50\u56fe\u6784\u5efa\u8fc7\u7a0b\u4e2d\u4f1a\u635f\u5931\u8bed\u4e49\u8fde\u8d2f\u6027\u5e76\u5f15\u5165\u65e0\u5173\u566a\u58f0\u3002", "method": "\u63d0\u51faNeuroPath\u6846\u67b6\uff0c\u5305\u542b\u52a8\u6001\u8def\u5f84\u8ffd\u8e2a\u548c\u540e\u68c0\u7d22\u8865\u5168\u4e24\u4e2a\u6b65\u9aa4\uff1a\u52a8\u6001\u8def\u5f84\u8ffd\u8e2a\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u76ee\u6807\u5bfc\u5411\u7684\u8bed\u4e49\u8def\u5f84\u8ffd\u8e2a\u548c\u526a\u679d\uff1b\u540e\u68c0\u7d22\u8865\u5168\u4f7f\u7528\u4e2d\u95f4\u63a8\u7406\u548c\u539f\u59cb\u67e5\u8be2\u8fdb\u884c\u7b2c\u4e8c\u9636\u6bb5\u68c0\u7d22\uff0c\u5b8c\u5584\u67e5\u8be2\u76ee\u6807\u548c\u8865\u5168\u63a8\u7406\u8def\u5f84\u4e2d\u7684\u7f3a\u5931\u4fe1\u606f\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u8df3QA\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u5f53\u524d\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728recall@2\u548crecall@5\u4e0a\u5206\u522b\u5e73\u5747\u63d0\u534716.3%\u548c13.5%\uff1b\u76f8\u6bd4\u8fed\u4ee3\u5f0fRAG\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u66f4\u9ad8\u4e14token\u6d88\u8017\u51cf\u5c1122.8%\uff1b\u5728\u56db\u4e2a\u5c0f\u578bLLM\u4e0a\u9a8c\u8bc1\u4e86\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "NeuroPath\u901a\u8fc7\u6a21\u62df\u795e\u7ecf\u751f\u7269\u5b66\u4e2d\u7684\u8def\u5f84\u5bfc\u822a\u89c4\u5212\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u566a\u58f0\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.14182", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14182", "abs": "https://arxiv.org/abs/2511.14182", "authors": ["Zihuai Zhao", "Yujuan Ding", "Wenqi Fan", "Qing Li"], "title": "WebRec: Enhancing LLM-based Recommendations with Attention-guided RAG from Web", "comment": null, "summary": "Recommender systems play a vital role in alleviating information overload and enriching users' online experience. In the era of large language models (LLMs), LLM-based recommender systems have emerged as a prevalent paradigm for advancing personalized recommendations. Recently, retrieval-augmented generation (RAG) has drawn growing interest to facilitate the recommendation capability of LLMs, incorporating useful information retrieved from external knowledge bases. However, as a rich source of up-to-date information, the web remains under-explored by existing RAG-based recommendations. In particular, unique challenges are posed from two perspectives: one is to generate effective queries for web retrieval, considering the inherent knowledge gap between web search and recommendations; another challenge lies in harnessing online websites that contain substantial noisy content. To tackle these limitations, we propose WebRec, a novel web-based RAG framework, which takes advantage of the reasoning capability of LLMs to interpret recommendation tasks into queries of user preferences that cater to web retrieval. Moreover, given noisy web-retrieved information, where relevant pieces of evidence are scattered far apart, an insightful MP-Head is designed to enhance LLM attentions between distant tokens of relevant information via message passing. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed web-based RAG methods in recommendation scenarios.", "AI": {"tldr": "WebRec\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f51\u7edc\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u63a8\u8350\u7cfb\u7edf\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u63a8\u7406\u80fd\u529b\u5c06\u63a8\u8350\u4efb\u52a1\u8f6c\u5316\u4e3a\u9002\u5408\u7f51\u7edc\u68c0\u7d22\u7684\u7528\u6237\u504f\u597d\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7MP-Head\u673a\u5236\u5904\u7406\u7f51\u7edc\u68c0\u7d22\u4e2d\u7684\u566a\u58f0\u4fe1\u606f\u3002", "motivation": "\u73b0\u6709\u7684RAG\u63a8\u8350\u7cfb\u7edf\u672a\u80fd\u5145\u5206\u5229\u7528\u7f51\u7edc\u8fd9\u4e00\u4e30\u5bcc\u7684\u5b9e\u65f6\u4fe1\u606f\u6e90\uff0c\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u5982\u4f55\u751f\u6210\u6709\u6548\u7684\u7f51\u7edc\u68c0\u7d22\u67e5\u8be2\uff0c\u4ee5\u53ca\u5982\u4f55\u5904\u7406\u5305\u542b\u5927\u91cf\u566a\u58f0\u5185\u5bb9\u7684\u5728\u7ebf\u7f51\u7ad9\u4fe1\u606f\u3002", "method": "\u63d0\u51faWebRec\u6846\u67b6\uff1a1) \u5229\u7528LLM\u63a8\u7406\u80fd\u529b\u5c06\u63a8\u8350\u4efb\u52a1\u8f6c\u5316\u4e3a\u7528\u6237\u504f\u597d\u67e5\u8be2\uff1b2) \u8bbe\u8ba1MP-Head\u673a\u5236\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u589e\u5f3aLLM\u5bf9\u5206\u6563\u76f8\u5173\u4fe1\u606f\u7684\u6ce8\u610f\u529b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u7f51\u7edc\u7684RAG\u65b9\u6cd5\u5728\u63a8\u8350\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "WebRec\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7f51\u7edc\u68c0\u7d22\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6311\u6218\uff0c\u901a\u8fc7LLM\u63a8\u7406\u548c\u6d88\u606f\u4f20\u9012\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2511.14221", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14221", "abs": "https://arxiv.org/abs/2511.14221", "authors": ["Hao Jiang", "Guoquan Wang", "Donglin Zhou", "Sheng Yu", "Yang Zeng", "Wencong Zeng", "Kun Gai", "Guorui Zhou"], "title": "LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have enhanced text-based recommendation by enriching traditional ID-based methods with semantic generalization capabilities. Text-based methods typically encode item textual information via prompt design and generate discrete semantic IDs through item tokenization. However, in domain-specific tasks such as local-life services, simply injecting location information into prompts fails to capture fine-grained spatial characteristics and real-world distance awareness among items. To address this, we propose LGSID, an LLM-Aligned Geographic Item Tokenization Framework for Local-life Recommendation. This framework consists of two key components: (1) RL-based Geographic LLM Alignment, and (2) Hierarchical Geographic Item Tokenization. In the RL-based alignment module, we initially train a list-wise reward model to capture real-world spatial relationships among items. We then introduce a novel G-DPO algorithm that uses pre-trained reward model to inject generalized spatial knowledge and collaborative signals into LLMs while preserving their semantic understanding. Furthermore, we propose a hierarchical geographic item tokenization strategy, where primary tokens are derived from discrete spatial and content attributes, and residual tokens are refined using the aligned LLM's geographic representation vectors. Extensive experiments on real-world Kuaishou industry datasets show that LGSID consistently outperforms state-of-the-art discriminative and generative recommendation models. Ablation studies, visualizations, and case studies further validate its effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e86LGSID\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50LLM\u7684\u5730\u7406\u611f\u77e5\u80fd\u529b\u548c\u5206\u5c42\u5730\u7406\u9879\u76ee\u6807\u8bb0\u5316\uff0c\u89e3\u51b3\u4e86\u672c\u5730\u751f\u6d3b\u670d\u52a1\u4e2d\u4f4d\u7f6e\u4fe1\u606f\u5efa\u6a21\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u672c\u5730\u751f\u6d3b\u670d\u52a1\u7b49\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\uff0c\u7b80\u5355\u5c06\u4f4d\u7f6e\u4fe1\u606f\u6ce8\u5165\u63d0\u793a\u65e0\u6cd5\u6355\u6349\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7279\u5f81\u548c\u9879\u76ee\u95f4\u7684\u771f\u5b9e\u8ddd\u79bb\u611f\u77e5\u3002", "method": "\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5730\u7406LLM\u5bf9\u9f50\u548c\u5206\u5c42\u5730\u7406\u9879\u76ee\u6807\u8bb0\u5316\u3002\u4f7f\u7528G-DPO\u7b97\u6cd5\u6ce8\u5165\u7a7a\u95f4\u77e5\u8bc6\u548c\u534f\u4f5c\u4fe1\u53f7\uff0c\u540c\u65f6\u4fdd\u7559LLM\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "result": "\u5728\u5feb\u624b\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLGSID\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5224\u522b\u5f0f\u548c\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u3002\u6d88\u878d\u7814\u7a76\u3001\u53ef\u89c6\u5316\u548c\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "LGSID\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u672c\u5730\u751f\u6d3b\u63a8\u8350\u4e2d\u7684\u5730\u7406\u5efa\u6a21\u95ee\u9898\uff0c\u901a\u8fc7LLM\u5bf9\u9f50\u548c\u5206\u5c42\u6807\u8bb0\u5316\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2511.14403", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14403", "abs": "https://arxiv.org/abs/2511.14403", "authors": ["Moyu Zhang", "Yujun Jin", "Yun Chen", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng"], "title": "Infer As You Train: A Symmetric Paradigm of Masked Generative for Click-Through Rate Prediction", "comment": "4 pages, 4 tables, 1 figure", "summary": "Generative models are increasingly being explored in click-through rate (CTR) prediction field to overcome the limitations of the conventional discriminative paradigm, which rely on a simple binary classification objective. However, existing generative models typically confine the generative paradigm to the training phase, primarily for representation learning. During online inference, they revert to a standard discriminative paradigm, failing to leverage their powerful generative capabilities to further improve prediction accuracy. This fundamental asymmetry between the training and inference phases prevents the generative paradigm from realizing its full potential. To address this limitation, we propose the Symmetric Masked Generative Paradigm for CTR prediction (SGCTR), a novel framework that establishes symmetry between the training and inference phases. Specifically, after acquiring generative capabilities by learning feature dependencies during training, SGCTR applies the generative capabilities during online inference to iteratively redefine the features of input samples, which mitigates the impact of noisy features and enhances prediction accuracy. Extensive experiments validate the superiority of SGCTR, demonstrating that applying the generative paradigm symmetrically across both training and inference significantly unlocks its power in CTR prediction.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u79f0\u63a9\u7801\u751f\u6210\u8303\u5f0fSGCTR\uff0c\u5728CTR\u9884\u6d4b\u4e2d\u5b9e\u73b0\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u5bf9\u79f0\u6027\uff0c\u901a\u8fc7\u751f\u6210\u80fd\u529b\u5728\u63a8\u7406\u65f6\u91cd\u65b0\u5b9a\u4e49\u8f93\u5165\u7279\u5f81\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u751f\u6210\u8303\u5f0f\uff0c\u4f46\u5728\u63a8\u7406\u9636\u6bb5\u4ecd\u56de\u5f52\u5224\u522b\u8303\u5f0f\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u751f\u6210\u80fd\u529b\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5b58\u5728\u8bad\u7ec3\u4e0e\u63a8\u7406\u4e0d\u5bf9\u79f0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSGCTR\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u5b66\u4e60\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u83b7\u5f97\u751f\u6210\u80fd\u529b\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u5e94\u7528\u751f\u6210\u80fd\u529b\u8fed\u4ee3\u91cd\u5b9a\u4e49\u8f93\u5165\u6837\u672c\u7279\u5f81\uff0c\u51cf\u8f7b\u566a\u58f0\u7279\u5f81\u5f71\u54cd\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1SGCTR\u7684\u4f18\u8d8a\u6027\uff0c\u8bc1\u660e\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u5bf9\u79f0\u5e94\u7528\u751f\u6210\u8303\u5f0f\u80fd\u663e\u8457\u91ca\u653e\u5176\u5728CTR\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u5bf9\u79f0\u5e94\u7528\u751f\u6210\u8303\u5f0f\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u80fd\u6709\u6548\u63d0\u5347CTR\u9884\u6d4b\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u5bf9\u79f0\u95ee\u9898\u3002"}}
{"id": "2511.14405", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14405", "abs": "https://arxiv.org/abs/2511.14405", "authors": ["Dun Zhang", "Ziyang Zeng", "Yudong Zhou", "Shuyang Lu"], "title": "Jasper-Token-Compression-600M Technical Report", "comment": "10 pages, 1 figure", "summary": "This technical report presents the training methodology and evaluation results of the open-source Jasper-Token-Compression-600M model, released in November 2025. Building on previous distillation-based recipes from the English Stella and Jasper models, we successfully extend this approach to a bilingual (English and Chinese) domain, further enhancing model performance through the incorporation of contrastive learning. A key innovation of our model is the introduction of a one-dimensional convolution-based token compression module. We dynamically adjust the compression rate during training, enabling the model to learn more robust and efficient compressed text representations. By combining knowledge distillation with token compression techniques, we achieve significant improvements in both embedding quality and inference efficiency. Our model performs with higher efficiency than a traditional 0.6B model while achieving performance comparable to that of an 8B model. For more information on the model release, visit: https://huggingface.co/infgrad/Jasper-Token-Compression-600M.", "AI": {"tldr": "Jasper-Token-Compression-600M\u662f\u4e00\u4e2a\u5f00\u6e90\u7684600M\u53c2\u6570\u53cc\u8bed\u6a21\u578b\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u521b\u65b0\u7684token\u538b\u7f29\u6280\u672f\uff0c\u5728\u4fdd\u63018B\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5c06\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u4ece\u82f1\u8bed\u6269\u5c55\u5230\u53cc\u8bed\uff08\u82f1\u4e2d\uff09\u9886\u57df\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u52a8\u6001token\u538b\u7f29\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u7ed3\u5408\u77e5\u8bc6\u84b8\u998f\u4e0e\u4e00\u7ef4\u5377\u79eftoken\u538b\u7f29\u6a21\u5757\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7387\uff0c\u5b66\u4e60\u66f4\u9c81\u68d2\u9ad8\u6548\u7684\u538b\u7f29\u6587\u672c\u8868\u793a\uff0c\u5e76\u878d\u5165\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u6a21\u578b\u5728\u4fdd\u63018B\u6a21\u578b\u6027\u80fd\u6c34\u5e73\u7684\u540c\u65f6\uff0c\u63a8\u7406\u6548\u7387\u663e\u8457\u9ad8\u4e8e\u4f20\u7edf600M\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5d4c\u5165\u8d28\u91cf\u548c\u63a8\u7406\u6548\u7387\u7684\u53cc\u91cd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u8bc1\u660e\u4e86\u77e5\u8bc6\u84b8\u998f\u4e0etoken\u538b\u7f29\u6280\u672f\u7ed3\u5408\u5728\u53cc\u8bed\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u9ad8\u6548\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.14461", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14461", "abs": "https://arxiv.org/abs/2511.14461", "authors": ["Dani\u00ebl Wilten", "Gideon Maillette de Buy Wenniger", "Arjen Hommersom", "Paul Lucassen", "Emiel Poortman"], "title": "Effective Diversification of Multi-Carousel Book Recommendation", "comment": "Accepted as a conference paper at BNAIC/BeNeLearn 2025; The 37th Benelux Conference on Artificial Intelligence and the 34th Belgian Dutch Conference on Machine Learning", "summary": "Using multiple carousels, lists that wrap around and can be scrolled, is the basis for offering content in most contemporary movie streaming platforms. Carousels allow for highlighting different aspects of users' taste, that fall in categories such as genres and authors. However, while carousels offer structure and greater ease of navigation, they alone do not increase diversity in recommendations, while this is essential to keep users engaged. In this work we propose several approaches to effectively increase item diversity within the domain of book recommendations, on top of a collaborative filtering algorithm. These approaches are intended to improve book recommendations in the web catalogs of public libraries. Furthermore, we introduce metrics to evaluate the resulting strategies, and show that the proposed system finds a suitable balance between accuracy and beyond-accuracy aspects.", "AI": {"tldr": "\u63d0\u51fa\u5728\u56fe\u4e66\u63a8\u8350\u7cfb\u7edf\u4e2d\u4f7f\u7528\u8f6e\u64ad\u754c\u9762\u589e\u52a0\u591a\u6837\u6027\u7684\u65b9\u6cd5\uff0c\u5728\u534f\u540c\u8fc7\u6ee4\u7b97\u6cd5\u57fa\u7840\u4e0a\u63d0\u9ad8\u63a8\u8350\u9879\u76ee\u7684\u591a\u6837\u6027", "motivation": "\u867d\u7136\u8f6e\u64ad\u754c\u9762\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u548c\u6613\u4e8e\u5bfc\u822a\u7684\u4f53\u9a8c\uff0c\u4f46\u672c\u8eab\u5e76\u4e0d\u80fd\u589e\u52a0\u63a8\u8350\u7684\u591a\u6837\u6027\uff0c\u800c\u591a\u6837\u6027\u5bf9\u4e8e\u4fdd\u6301\u7528\u6237\u53c2\u4e0e\u5ea6\u81f3\u5173\u91cd\u8981", "method": "\u5728\u534f\u540c\u8fc7\u6ee4\u7b97\u6cd5\u57fa\u7840\u4e0a\u63d0\u51fa\u591a\u79cd\u65b9\u6cd5\u6765\u6709\u6548\u589e\u52a0\u56fe\u4e66\u63a8\u8350\u9879\u76ee\u7684\u591a\u6837\u6027", "result": "\u63d0\u51fa\u7684\u7cfb\u7edf\u5728\u51c6\u786e\u6027\u548c\u8d85\u8d8a\u51c6\u786e\u6027\u65b9\u9762\u627e\u5230\u4e86\u5408\u9002\u7684\u5e73\u8861", "conclusion": "\u8be5\u7cfb\u7edf\u9002\u7528\u4e8e\u516c\u5171\u56fe\u4e66\u9986\u7f51\u7edc\u76ee\u5f55\u7684\u56fe\u4e66\u63a8\u8350\uff0c\u80fd\u591f\u63d0\u9ad8\u63a8\u8350\u7684\u591a\u6837\u6027"}}
{"id": "2511.14758", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14758", "abs": "https://arxiv.org/abs/2511.14758", "authors": ["Dawn Lawrie", "James Mayfield", "Eugene Yang", "Andrew Yates", "Sean MacAvaney", "Ronak Pradeep", "Scott Miller", "Paul McNamee", "Luca Soldani"], "title": "NeuCLIRBench: A Modern Evaluation Collection for Monolingual, Cross-Language, and Multilingual Information Retrieval", "comment": "14 pages, 1 figure", "summary": "To measure advances in retrieval, test collections with relevance judgments that can faithfully distinguish systems are required. This paper presents NeuCLIRBench, an evaluation collection for cross-language and multilingual retrieval. The collection consists of documents written natively in Chinese, Persian, and Russian, as well as those same documents machine translated into English. The collection supports several retrieval scenarios including: monolingual retrieval in English, Chinese, Persian, or Russian; cross-language retrieval with English as the query language and one of the other three languages as the document language; and multilingual retrieval, again with English as the query language and relevant documents in all three languages. NeuCLIRBench combines the TREC NeuCLIR track topics of 2022, 2023, and 2024. The 250,128 judgments across approximately 150 queries for the monolingual and cross-language tasks and 100 queries for multilingual retrieval provide strong statistical discriminatory power to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included with the collection so that developers of reranking algorithms are no longer reliant on BM25 as their first-stage retriever. NeuCLIRBench is publicly available.", "AI": {"tldr": "NeuCLIRBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8de8\u8bed\u8a00\u548c\u591a\u8bed\u8a00\u68c0\u7d22\u8bc4\u4f30\u7684\u6d4b\u8bd5\u96c6\u5408\uff0c\u5305\u542b\u4e2d\u6587\u3001\u6ce2\u65af\u8bed\u3001\u4fc4\u8bed\u7684\u539f\u751f\u6587\u6863\u53ca\u5176\u82f1\u6587\u673a\u5668\u7ffb\u8bd1\u7248\u672c\uff0c\u652f\u6301\u5355\u8bed\u3001\u8de8\u8bed\u8a00\u548c\u591a\u8bed\u8a00\u68c0\u7d22\u573a\u666f\u3002", "motivation": "\u4e3a\u4e86\u51c6\u786e\u8861\u91cf\u68c0\u7d22\u7cfb\u7edf\u7684\u8fdb\u5c55\uff0c\u9700\u8981\u80fd\u591f\u53ef\u9760\u533a\u5206\u7cfb\u7edf\u6027\u80fd\u7684\u6d4b\u8bd5\u96c6\u5408\u548c\u76f8\u5173\u6027\u5224\u65ad\u3002", "method": "\u7ed3\u5408TREC NeuCLIR 2022-2024\u8d5b\u9053\u7684\u4e3b\u9898\uff0c\u5305\u542b25\u4e07\u591a\u4e2a\u76f8\u5173\u6027\u5224\u65ad\uff0c\u6db5\u76d6\u7ea6150\u4e2a\u5355\u8bed\u548c\u8de8\u8bed\u8a00\u67e5\u8be2\u4ee5\u53ca100\u4e2a\u591a\u8bed\u8a00\u67e5\u8be2\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u795e\u7ecf\u68c0\u7d22\u7cfb\u7edf\u7684\u878d\u5408\u57fa\u7ebf\u3002", "result": "\u8be5\u96c6\u5408\u5177\u6709\u5f3a\u5927\u7684\u7edf\u8ba1\u533a\u5206\u80fd\u529b\u6765\u533a\u5206\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u4e3a\u91cd\u6392\u5e8f\u7b97\u6cd5\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6bd4BM25\u66f4\u597d\u7684\u7b2c\u4e00\u7ea7\u68c0\u7d22\u5668\u57fa\u7ebf\u3002", "conclusion": "NeuCLIRBench\u662f\u4e00\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u8bc4\u4f30\u8d44\u6e90\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u8de8\u8bed\u8a00\u548c\u591a\u8bed\u8a00\u68c0\u7d22\u7cfb\u7edf\u7684\u8bc4\u4f30\u4e0e\u6bd4\u8f83\u3002"}}
