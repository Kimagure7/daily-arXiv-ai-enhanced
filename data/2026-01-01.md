<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System](https://arxiv.org/abs/2512.23961)
*Junjie H. Xu*

Main category: cs.IR

TL;DR: 该研究提出了一种基于智能体AI的KYC推荐系统，并在五个内容垂直领域进行评估，比较了四个实验组在不同截断水平下的nDCG性能。


<details>
  <summary>Details</summary>
Motivation: 金融领域的KYC（了解你的客户）需要更智能的推荐系统来提升用户体验和合规效率。现有推荐系统在个性化程度和跨垂直领域适应性方面存在不足，需要结合智能体AI技术来改进。

Method: 使用智能体AI构建推荐系统，在广告、新闻、八卦、用户生成内容和技术五个垂直领域进行测试。将用户分为四个实验组（基于KYC使用强度），采用nDCG@k（k=1,3,5）作为评估指标，并参考百度和小红书等行业基准。

Result: 通过实验数据与理论框架、行业基准的综合分析，展示了智能体推荐系统在不同垂直领域的性能表现，为大规模智能体推荐系统的工程实现提供了实证结果。

Conclusion: 智能体AI在KYC推荐系统中展现出良好潜力，能够适应多个内容垂直领域的需求。该研究为金融领域大规模智能体推荐系统的设计和实施提供了重要参考。

Abstract: This research presents a cutting-edge recommendation system utilizing agentic AI for KYC (Know Your Customer in the financial domain), and its evaluation across five distinct content verticals: Advertising (Ad), News, Gossip, Sharing (User-Generated Content), and Technology (Tech). The study compares the performance of four experimental groups, grouping by the intense usage of KYC, benchmarking them against the Normalized Discounted Cumulative Gain (nDCG) metric at truncation levels of $k=1$, $k=3$, and $k=5$. By synthesizing experimental data with theoretical frameworks and industry benchmarks from platforms such as Baidu and Xiaohongshu, this research provides insight by showing experimental results for engineering a large-scale agentic recommendation system.

</details>


### [2] [Time-Aware Adaptive Side Information Fusion for Sequential Recommendation](https://arxiv.org/abs/2512.24246)
*Jie Luo,Wenyu Zhang,Xinming Zhang,Yuan Fang*

Main category: cs.IR

TL;DR: TASIF框架通过时间感知、自适应去噪和高效融合机制，解决了序列推荐中忽略时间动态、噪声敏感和计算成本高的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前序列推荐模型存在三个主要局限：1）忽略时间戳中的细粒度时间动态；2）对用户交互序列中的噪声敏感；3）依赖计算昂贵的融合架构。需要系统性地解决这些问题。

Method: 提出TASIF框架，包含三个协同组件：1）简单即插即用的时间跨度划分机制捕捉全局时间模式；2）自适应频率滤波器使用可学习门控自适应去噪特征序列；3）高效自适应侧信息融合层采用"引导不混合"架构，属性引导注意力机制但不混入内容表示的项目嵌入。

Result: 在四个公共数据集上的大量实验表明，TASIF显著优于最先进的基线方法，同时在训练中保持了优秀的效率。

Conclusion: TASIF框架通过时间感知、自适应去噪和高效融合机制，系统性地解决了序列推荐中的关键挑战，实现了性能提升和计算效率的平衡。

Abstract: Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a "guide-not-mix" architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at https://github.com/jluo00/TASIF.

</details>


### [3] [RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation](https://arxiv.org/abs/2512.24268)
*Pankayaraj Pathmanathan,Michael-Andrei Panaitescu-Liess,Cho-Yu Jason Chiang,Furong Huang*

Main category: cs.IR

TL;DR: 本文提出RAGPart和RAGMask两种检索阶段防御方法，对抗RAG管道中的语料库中毒攻击，通过文档分区和令牌掩码技术保护检索增强生成系统。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)虽然能增强大语言模型的外部知识并减少幻觉，但面临语料库中毒攻击的严重漏洞，攻击者可通过注入恶意文档操纵模型输出，需要轻量级防御方案。

Method: 提出两种检索阶段防御：1) RAGPart利用密集检索器的训练动态，通过文档分区减轻中毒点影响；2) RAGMask基于目标令牌掩码下的显著相似性偏移识别可疑令牌。两种方法直接在检索器上操作，无需修改生成模型。

Result: 在两个基准测试、四种中毒策略和四种最先进检索器上，防御方法能持续降低攻击成功率，同时在良性条件下保持效用。还引入了可解释攻击来压力测试防御机制。

Conclusion: 研究展示了检索阶段防御的潜力和局限性，为鲁棒的RAG部署提供了实用见解，强调直接在检索器层面防御的轻量级优势。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.

</details>


### [4] [MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems](https://arxiv.org/abs/2512.24325)
*Wan Jiang,Xinyi Zang,Yudong Zhao,Yusi Zou,Yunfei Lu,Junbo Tong,Yang Liu,Ming Li,Jiani Shi,Xin Yang*

Main category: cs.IR

TL;DR: MaRCA：基于多智能体强化学习的推荐系统端到端计算资源分配框架，在电商广告系统中实现16.67%收入提升


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统面临模型复杂性和流量规模带来的计算挑战，现有方法简化多阶段计算资源分配，忽略阶段间依赖关系，限制了全局最优性

Method: 提出MaRCA多智能体强化学习框架，将推荐系统各阶段建模为协作智能体，采用集中训练分散执行（CTDE）策略，引入AutoBucket TestBench进行精确计算成本估计，以及基于模型预测控制（MPC）的收入-成本平衡器

Result: 自2024年11月在领先全球电商平台广告管道端到端部署以来，MaRCA每日处理数千亿广告请求，在使用现有计算资源的情况下实现16.67%的收入提升

Conclusion: MaRCA通过端到端计算资源分配有效解决了大规模推荐系统的计算挑战，显著提升业务收入，证明了多智能体强化学习在复杂工业系统中的实用性

Abstract: Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources.

</details>


### [5] [On the Factual Consistency of Text-based Explainable Recommendation Models](https://arxiv.org/abs/2512.24366)
*Ben Kabongo,Vincent Guigue*

Main category: cs.IR

TL;DR: 该研究提出了一个评估基于文本的可解释推荐系统事实一致性的框架，发现现有模型虽然语义相似度高，但事实一致性极低，揭示了当前可解释推荐系统在事实准确性方面的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管基于文本的可解释推荐系统利用LLM生成流畅的解释，但这些解释是否与可用证据事实一致仍是一个未充分探索的关键问题。现有研究缺乏对解释事实一致性的系统评估。

Method: 设计基于提示的流水线，使用LLM从评论中提取原子解释语句构建事实基准；创建增强基准数据集；提出结合LLM和NLI的语句级对齐指标来评估事实一致性和相关性。

Result: 对6个最先进的可解释推荐模型进行实验发现：虽然模型在语义相似度得分很高（BERTScore F1: 0.81-0.90），但所有事实性指标都显示极低性能（LLM-based语句级精度: 4.38%-32.88%）。

Conclusion: 研究揭示了可解释推荐系统中事实一致性的严重差距，强调了事实感知评估的必要性，为开发更可信的解释系统提供了基础。

Abstract: Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems.

</details>


### [6] [MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints](https://arxiv.org/abs/2512.24711)
*Kangyang Luo,Shuzheng Si,Yuzhuo Bai,Cheng Gao,Zhitong Wang,Cheng Huang,Yingli Shen,Yufeng Han,Wenhao Li,Cunliang Kong,Maosong Sun*

Main category: cs.IR

TL;DR: MEIC-DT是一种基于轻量级Transformer的双阈值内存高效增量聚类方法，用于指代消解，通过双阈值约束机制和智能缓存管理在内存限制下实现高性能。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型时代，监督神经方法在指代消解方面仍是SOTA，但其在增量聚类中的潜力未充分探索，特别是在长文本处理中平衡效率与性能的挑战。

Method: 提出MEIC-DT方法，包含：1) 双阈值约束机制，精确控制Transformer输入规模在预定义内存预算内；2) 统计感知驱逐策略(SAES)，利用训练和推理阶段的统计特征进行智能缓存管理；3) 内部正则化策略(IRP)，通过选择最具代表性的提及来战略性地压缩聚类。

Result: 在常见基准测试上的广泛实验表明，MEIC-DT在严格的内存约束下实现了高度竞争力的指代消解性能。

Conclusion: MEIC-DT通过创新的双阈值机制和智能缓存管理，成功解决了增量聚类中内存效率与性能平衡的挑战，为长文本指代消解提供了有效的解决方案。

Abstract: In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \textbf{MEIC-DT}, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer's input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\textbf{SAES}), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\textbf{IRP}) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints.

</details>


### [7] [MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation](https://arxiv.org/abs/2512.24715)
*Kang Fu,Honglei Zhang,Xuechao Zou,Yidong Li*

Main category: cs.IR

TL;DR: 提出MDiffFR方法，使用模态引导的扩散模型为联邦推荐中的冷启动物品生成嵌入表示，解决现有映射方法导致的嵌入对齐问题


<details>
  <summary>Details</summary>
Motivation: 联邦推荐中严格的隐私限制使得跨客户端访问用户-物品交互数据和用户画像受限，导致难以学习新物品的全局有效表示，使物品冷启动问题更加严峻。现有基于属性到嵌入映射的方法存在一对一映射固定、难以适应不同数据分布、导致嵌入错位等问题。

Method: 提出MDiffFR框架：1）在服务器端使用定制的扩散模型为冷启动物品生成嵌入表示；2）部署预训练的模态编码器提取模态特征作为条件信号，指导反向去噪过程以对齐物品语义；3）将生成的嵌入分发给客户端进行冷启动推理。

Result: 在四个真实数据集上的广泛实验表明，该方法在联邦推荐中持续优于所有基线方法。理论分析验证了该方法相比现有基于映射的方法具有更强的隐私保证。

Conclusion: MDiffFR通过模态引导的扩散生成方法有效解决了联邦推荐中的物品冷启动问题，克服了传统映射方法的局限性，同时提供了更强的隐私保护。

Abstract: Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs.

</details>


### [8] [OpenOneRec Technical Report](https://arxiv.org/abs/2512.24762)
*Guorui Zhou,Honghui Bao,Jiaming Huang,Jiaxin Deng,Jinghao Zhang,Junda She,Kuo Cai,Lejian Ren,Lu Ren,Qiang Luo,Qianqian Wang,Qigen Hu,Rongzhou Zhang,Ruiming Tang,Shiyao Wang,Wuchao Li,Xiangyu Wu,Xinchen Luo,Xingmei Wang,Yifei Hu,Yunfan Wu,Zhanyu Liu,Zhiyang Zhang,Zixing Zhang,Bo Chen,Bin Wen,Chaoyi Ma,Chengru Song,Chenglong Chu,Defu Lian,Fan Yang,Feng Jiang,Hongtao Cheng,Huanjie Wang,Kun Gai,Pengfei Zheng,Qiang Wang,Rui Huang,Siyang Mao,Tingting Gao,Wei Yuan,Yan Wang,Yang Zhou,Yi Su,Zexuan Cheng,Zhixin Ling,Ziming Li*

Main category: cs.IR

TL;DR: OneRec系列提出RecIF-Bench基准和OneRec-Foundation模型，通过统一训练框架和规模化方法，在推荐任务上实现SOTA性能，推动推荐系统向通用智能发展。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统虽然通过OneRec系列实现了端到端生成框架，但仍存在与通用智能的差距：受限于孤立数据，缺乏世界知识、推理能力和指令跟随能力，且缺乏评估这些综合能力的整体基准。

Method: 1) 提出RecIF-Bench基准，包含8个多样化任务，全面评估从基础预测到复杂推理的能力；2) 发布包含9600万交互的大规模训练数据集；3) 开源完整训练框架（数据处理、协同预训练、后训练）；4) 开发OneRec-Foundation模型系列（1.7B和8B参数）。

Result: OneRec-Foundation模型在RecIF-Bench所有任务上达到新的SOTA；在Amazon基准上，相比最强基线平均Recall@10提升26.8%（10个数据集）；推荐能力可预测地扩展，同时减轻通用知识的灾难性遗忘。

Conclusion: 这项工作标志着向构建真正智能推荐系统迈出了一步，但实现这一愿景仍面临重大技术和理论挑战，需要更广泛的研究参与。

Abstract: While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.

</details>


### [9] [HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment](https://arxiv.org/abs/2512.24787)
*Yunsheng Pang,Zijian Liu,Yudong Li,Shaojie Zhu,Zijian Luo,Chenyun Yu,Sikai Wu,Shichen Shen,Cong Xu,Bin Wang,Kai Jiang,Hongyong Yu,Chengxiang Zhuo,Zang Li*

Main category: cs.IR

TL;DR: HiGR是一个高效的生成式slate推荐框架，通过分层规划和列表级偏好对齐解决现有自回归方法的语义纠缠和低效解码问题，在商业媒体平台上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有自回归方法在slate推荐中存在语义纠缠的item tokenization和缺乏整体规划的低效顺序解码问题，需要更高效的生成式推荐框架。

Method: 1) 使用残差量化和对比约束的自动编码器将item token化为语义结构化ID；2) 将生成解耦为列表级规划阶段（全局slate意图）和item级解码阶段；3) 引入列表级偏好对齐目标直接优化slate质量。

Result: 在商业媒体平台上，HiGR在离线评估中比SOTA方法提升超过10%的推荐质量，推理速度提升5倍；在线A/B测试中，平均观看时间增加1.22%，平均视频观看量增加1.73%。

Conclusion: HiGR通过分层规划和列表级偏好对齐有效解决了生成式slate推荐中的关键挑战，实现了显著的性能提升和推理加速，在实际部署中验证了其有效性。

Abstract: Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests.

</details>


### [10] [RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment](https://arxiv.org/abs/2512.24943)
*Chenji Lu,Zhuo Chen,Hui Zhao,Zhenyi Wang,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: RAIR是一个中文电商搜索相关性评估基准，包含通用、长尾困难和视觉显著性三个子集，为行业提供标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有相关性评估基准缺乏足够的复杂性，无法全面评估模型性能，且行业内缺乏标准化的相关性评估指标。

Method: 提出RAIR基准，包含三个子集：1)行业平衡采样的通用子集评估基础能力；2)关注挑战性案例的长尾困难子集评估性能极限；3)视觉显著性子集评估多模态理解能力。

Result: 在14个开源和闭源模型上进行实验，结果显示RAIR对GPT-5也构成足够挑战，GPT-5表现最佳。RAIR数据已公开可用。

Conclusion: RAIR为相关性评估提供了行业基准，同时为通用LLM和VLM评估提供了新见解，建立了标准化评估框架。

Abstract: Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.

</details>
