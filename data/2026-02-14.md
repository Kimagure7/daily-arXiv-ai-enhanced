<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 1]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [MTFM: A Scalable and Alignment-free Foundation Model for Industrial Recommendation in Meituan](https://arxiv.org/abs/2602.11235)
*Xin Song,Zhilin Guan,Ruidong Han,Binghao Tang,Tianwen Chen,Bing Li,Zihao Li,Han Zhang,Fei Jiang,Chaolin Xie,Chi Ma,Chunyang Jiang,Chunzhen Jing,Dengxuan Li,Fengyi Li,Lei Yu,Mengyao Sun,Pu Wang,Qing Wang,Rui Fan,Shangyu Chen,Shifeng Du,Siyuan Bai,Wei Lin,Wentao Zhu,Zhou Han,Zhuo Chen,Zikang Xu*

Main category: cs.IR

TL;DR: MTFM是美团提出的推荐系统基础模型，通过异构token化跨域数据、多场景用户级样本聚合、分组查询注意力等技术创新，解决了传统跨域多场景推荐方法资源消耗大、输入对齐严格的问题，实现了高效可扩展的多场景推荐。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统通常涉及多个场景，但现有的跨域推荐(CDR)和多场景推荐(MSR)方法需要大量资源和严格的输入对齐，限制了系统的可扩展性。需要一种更高效、更灵活的多场景推荐框架。

Method: 1. 将跨域数据转换为异构token，以对齐自由的方式捕获多场景知识；2. 引入多场景用户级样本聚合，减少实例数量提升训练吞吐量；3. 采用分组查询注意力(GQA)和定制化混合目标注意力(Hybrid Target Attention)降低内存使用和计算复杂度；4. 实施系统级优化，如内核融合和消除CPU-GPU阻塞。

Result: 离线和在线实验验证了MTFM的有效性，通过扩展模型容量和多场景训练数据实现了显著的性能提升。系统优化显著提高了训练和推理吞吐量。

Conclusion: MTFM提供了一个高效、可扩展的推荐系统基础模型框架，通过技术创新解决了多场景推荐中的资源消耗和输入对齐问题，为工业级多场景推荐系统提供了有效的解决方案。

Abstract: Industrial recommendation systems typically involve multiple scenarios, yet existing cross-domain (CDR) and multi-scenario (MSR) methods often require prohibitive resources and strict input alignment, limiting their extensibility. We propose MTFM (Meituan Foundation Model for Recommendation), a transformer-based framework that addresses these challenges. Instead of pre-aligning inputs, MTFM transforms cross-domain data into heterogeneous tokens, capturing multi-scenario knowledge in an alignment-free manner. To enhance efficiency, we first introduce a multi-scenario user-level sample aggregation that significantly enhances training throughput by reducing the total number of instances. We further integrate Grouped-Query Attention and a customized Hybrid Target Attention to minimize memory usage and computational complexity. Furthermore, we implement various system-level optimizations, such as kernel fusion and the elimination of CPU-GPU blocking, to further enhance both training and inference throughput. Offline and online experiments validate the effectiveness of MTFM, demonstrating that significant performance gains are achieved by scaling both model capacity and multi-scenario training data.

</details>
