{"id": "2602.00002", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00002", "abs": "https://arxiv.org/abs/2602.00002", "authors": ["Yu Zheng", "Chen Gao", "Jianxin Chang", "Yanan Niu", "Yang Song", "Depeng Jin", "Meng Wang", "Yong Li"], "title": "Disentangled Interest Network for Out-of-Distribution CTR Prediction", "comment": "Accepted by ACM TOIS", "summary": "Click-through rate (CTR) prediction, which estimates the probability of a user clicking on a given item, is a critical task for online information services. Existing approaches often make strong assumptions that training and test data come from the same distribution. However, the data distribution varies since user interests are constantly evolving, resulting in the out-of-distribution (OOD) issue. In addition, users tend to have multiple interests, some of which evolve faster than others. Towards this end, we propose Disentangled Click-Through Rate prediction (DiseCTR), which introduces a causal perspective of recommendation and disentangles multiple aspects of user interests to alleviate the OOD issue in recommendation. We conduct a causal factorization of CTR prediction involving user interest, exposure model, and click model, based on which we develop a deep learning implementation for these three causal mechanisms. Specifically, we first design an interest encoder with sparse attention which maps raw features to user interests, and then introduce a weakly supervised interest disentangler to learn independent interest embeddings, which are further integrated by an attentive interest aggregator for prediction. Experimental results on three real-world datasets show that DiseCTR achieves the best accuracy and robustness in OOD recommendation against state-of-the-art approaches, significantly improving AUC and GAUC by over 0.02 and reducing logloss by over 13.7%. Further analyses demonstrate that DiseCTR successfully disentangles user interests, which is the key to OOD generalization for CTR prediction. We have released the code and data at https://github.com/DavyMorgan/DiseCTR/.", "AI": {"tldr": "DiseCTR\u901a\u8fc7\u56e0\u679c\u89c6\u89d2\u89e3\u8026\u7528\u6237\u591a\u5174\u8da3\uff0c\u7f13\u89e3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5206\u5e03\u5916\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347CTR\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709CTR\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u6765\u81ea\u76f8\u540c\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u4e2d\u7528\u6237\u5174\u8da3\u4e0d\u65ad\u6f14\u53d8\u5bfc\u81f4\u5206\u5e03\u53d8\u5316\uff08OOD\u95ee\u9898\uff09\uff0c\u4e14\u7528\u6237\u6709\u591a\u91cd\u5174\u8da3\uff0c\u5176\u4e2d\u90e8\u5206\u5174\u8da3\u6f14\u5316\u66f4\u5feb\u3002", "method": "\u63d0\u51faDiseCTR\u6846\u67b6\uff1a1) \u4ece\u56e0\u679c\u89d2\u5ea6\u5bf9CTR\u9884\u6d4b\u8fdb\u884c\u56e0\u5b50\u5206\u89e3\uff08\u7528\u6237\u5174\u8da3\u3001\u66dd\u5149\u6a21\u578b\u3001\u70b9\u51fb\u6a21\u578b\uff09\uff1b2) \u4f7f\u7528\u7a00\u758f\u6ce8\u610f\u529b\u7684\u5174\u8da3\u7f16\u7801\u5668\uff1b3) \u5f31\u76d1\u7763\u5174\u8da3\u89e3\u8026\u5668\u5b66\u4e60\u72ec\u7acb\u5174\u8da3\u5d4c\u5165\uff1b4) \u6ce8\u610f\u529b\u5174\u8da3\u805a\u5408\u5668\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cDiseCTR\u5728OOD\u63a8\u8350\u4e2d\u8fbe\u5230\u6700\u4f73\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0cAUC\u548cGAUC\u63d0\u5347\u8d85\u8fc70.02\uff0clogloss\u964d\u4f4e\u8d85\u8fc713.7%\u3002\u5206\u6790\u663e\u793a\u6210\u529f\u89e3\u8026\u4e86\u7528\u6237\u5174\u8da3\u3002", "conclusion": "DiseCTR\u901a\u8fc7\u56e0\u679c\u89c6\u89d2\u89e3\u8026\u7528\u6237\u591a\u5174\u8da3\uff0c\u6709\u6548\u7f13\u89e3\u4e86CTR\u9884\u6d4b\u4e2d\u7684OOD\u95ee\u9898\uff0c\u7528\u6237\u5174\u8da3\u89e3\u8026\u662fOOD\u6cdb\u5316\u7684\u5173\u952e\u3002\u5df2\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u3002"}}
{"id": "2602.00003", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00003", "abs": "https://arxiv.org/abs/2602.00003", "authors": ["Ye Liu", "Xu Chen", "Wuji Chen", "Mang Li"], "title": "Efficient Multilingual Search Relevance Modeling in E-Commerce via LLM Mixture-of-Experts", "comment": "4 pages, 2 figures", "summary": "In e-commerce platforms, search relevance directly influences both user experience and merchant revenue. In multi-country deployments, diverse linguistic, cultural, and product catalog contexts introduce significant distribution shifts, posing substantial challenges to relevance modeling. Existing approaches typically enhance the reasoning or multilingual abilities of a single monolithic model, yet they remain limited by data diversity, coverage gaps, and high inference costs in heterogeneous environments. Our empirical analysis reveals that different LLM base models exhibit complementary strengths across languages and regions, motivating an expert-based architecture. We propose a scalable LLM-based Mixture-of-Experts (MoE) framework that dynamically routes queries to specialized experts and fuses their embeddings through concatenation. Among rule-based, pseudo-label-based, and fully end-to-end strategies, end-to-end hard routing with concatenation offers the best balance of effectiveness and efficiency. To mitigate inference overhead, we further develop an engineering-optimized offline batch pipeline with resource-efficient scheduling, which hides memory latency, improves GPU utilization, and reduces GPU-hour consumption by up to 35% compared with synchronous execution. On datasets spanning six Southeast Asian markets, our MoE improves AUC by 0.72 percentage points over a dense baseline with the same active parameters. Meanwhile, the optimized pipeline achieves 27.6 queries per second (QPS), a 9% throughput improvement. These results demonstrate superior multilingual relevance and efficiency, delivering strong cost-effectiveness for real-world e-commerce search systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u67e5\u8be2\u5230\u4e13\u95e8\u4e13\u5bb6\u5e76\u878d\u5408\u5d4c\u5165\uff0c\u4f18\u5316\u591a\u56fd\u7535\u5546\u641c\u7d22\u76f8\u5173\u6027\uff0c\u5728\u63d0\u5347\u6548\u679c\u7684\u540c\u65f6\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u591a\u56fd\u7535\u5546\u5e73\u53f0\u4e2d\uff0c\u8bed\u8a00\u3001\u6587\u5316\u548c\u4ea7\u54c1\u76ee\u5f55\u7684\u5dee\u5f02\u5bfc\u81f4\u6570\u636e\u5206\u5e03\u504f\u79fb\uff0c\u4f20\u7edf\u5355\u4e00\u6a21\u578b\u5728\u6570\u636e\u591a\u6837\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u63a8\u7406\u6210\u672c\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u7814\u7a76\u53d1\u73b0\u4e0d\u540cLLM\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u5730\u533a\u5177\u6709\u4e92\u8865\u4f18\u52bf\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u5bb6\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684LLM\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u52a8\u6001\u8def\u7531\u67e5\u8be2\u5230\u4e13\u95e8\u4e13\u5bb6\uff1b2\uff09\u901a\u8fc7\u62fc\u63a5\u878d\u5408\u4e13\u5bb6\u5d4c\u5165\uff1b3\uff09\u6bd4\u8f83\u57fa\u4e8e\u89c4\u5219\u3001\u4f2a\u6807\u7b7e\u548c\u7aef\u5230\u7aef\u7b56\u7565\uff0c\u53d1\u73b0\u7aef\u5230\u7aef\u786c\u8def\u7531\u62fc\u63a5\u6548\u679c\u6700\u4f73\uff1b4\uff09\u5f00\u53d1\u5de5\u7a0b\u4f18\u5316\u7684\u79bb\u7ebf\u6279\u5904\u7406\u7ba1\u9053\uff0c\u901a\u8fc7\u8d44\u6e90\u9ad8\u6548\u8c03\u5ea6\u9690\u85cf\u5185\u5b58\u5ef6\u8fdf\uff0c\u63d0\u9ad8GPU\u5229\u7528\u7387\u3002", "result": "\u5728\u4e1c\u5357\u4e9a\u516d\u4e2a\u5e02\u573a\u6570\u636e\u96c6\u4e0a\uff0cMoE\u76f8\u6bd4\u76f8\u540c\u6d3b\u8dc3\u53c2\u6570\u7684\u5bc6\u96c6\u57fa\u7ebf\u63d0\u5347AUC 0.72\u4e2a\u767e\u5206\u70b9\u3002\u4f18\u5316\u7ba1\u9053\u8fbe\u523027.6 QPS\uff0c\u541e\u5410\u91cf\u63d0\u53479%\uff0cGPU\u5c0f\u65f6\u6d88\u8017\u51cf\u5c11\u9ad8\u8fbe35%\u3002", "conclusion": "\u8be5\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\u5728\u63d0\u5347\u591a\u8bed\u8a00\u641c\u7d22\u76f8\u5173\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u63a8\u7406\uff0c\u4e3a\u5b9e\u9645\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u6210\u672c\u6548\u76ca\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00004", "categories": ["cs.IR", "cs.CL", "cs.DL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00004", "abs": "https://arxiv.org/abs/2602.00004", "authors": ["Yue Yu", "Ting Bai", "HengZhi Lan", "Li Qian", "Li Peng", "Jie Wu", "Wei Liu", "Jian Luan", "Chuan Shi"], "title": "C$^2$-Cite: Contextual-Aware Citation Generation for Attributed Large Language Models", "comment": "WSDM26", "summary": "The attribution technique enhances the credibility of LLMs by adding citations to the generated sentences, enabling users to trace back to the original sources and verify the reliability of the output. However, existing instruction-tuned attributed LLMs often fail to properly interpret the contextual semantics of citation symbols (e.g., [i]) during text generation. This shortcoming arises from their insufficient awareness of the context information surrounding citation markers, which in turn leads to disjointed references and poor integration of retrieved knowledge into the generated content. To address this issue, we propose a novel \\textbf{C}ontextual-aware \\textbf{C}itation generation framework (\\textbf{C$^2$}-\\textbf{Cite}) that explicitly integrates the semantic relationships between citation markers and their referenced content. Specifically, a contextual citation alignment mechanism is adopted: it first encodes the retrieved document contexts into the symbol representation of citations, then aligns the marker numbers by decoding information from a citation router function. This mechanism enables the transformation of citation markers from generic placeholders into active knowledge pointers that link to the referenced source information. Experimental results on the ALCE benchmark across three datasets validate our framework C$^2$-Cite++: it outperforms the SOTA baseline by an average of 5.8\\% in citation quality and 17.4\\% in response correctness. The implementation is publicly available at https://github.com/BAI-LAB/c2cite", "AI": {"tldr": "\u63d0\u51faC\u00b2-Cite\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f15\u7528\u751f\u6210\u673a\u5236\uff0c\u63d0\u5347LLM\u751f\u6210\u6587\u672c\u4e2d\u5f15\u7528\u7684\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u7684\u5f52\u56e0LLM\u5728\u751f\u6210\u6587\u672c\u65f6\uff0c\u672a\u80fd\u5145\u5206\u7406\u89e3\u5f15\u7528\u7b26\u53f7\uff08\u5982[i]\uff09\u7684\u4e0a\u4e0b\u6587\u8bed\u4e49\uff0c\u5bfc\u81f4\u5f15\u7528\u4e0d\u8fde\u8d2f\u4e14\u68c0\u7d22\u77e5\u8bc6\u6574\u5408\u4e0d\u4f73", "method": "\u63d0\u51faC\u00b2-Cite\u6846\u67b6\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u5f15\u7528\u5bf9\u9f50\u673a\u5236\uff1a\u5148\u5c06\u68c0\u7d22\u6587\u6863\u4e0a\u4e0b\u6587\u7f16\u7801\u5230\u5f15\u7528\u7b26\u53f7\u8868\u793a\u4e2d\uff0c\u7136\u540e\u901a\u8fc7\u5f15\u7528\u8def\u7531\u51fd\u6570\u89e3\u7801\u5bf9\u9f50\u6807\u8bb0\u7f16\u53f7", "result": "\u5728ALCE\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cC\u00b2-Cite++\u5e73\u5747\u5728\u5f15\u7528\u8d28\u91cf\u4e0a\u4f18\u4e8eSOTA\u57fa\u7ebf5.8%\uff0c\u5728\u54cd\u5e94\u6b63\u786e\u6027\u4e0a\u4f18\u4e8e17.4%", "conclusion": "C\u00b2-Cite\u6846\u67b6\u6210\u529f\u5c06\u5f15\u7528\u6807\u8bb0\u4ece\u901a\u7528\u5360\u4f4d\u7b26\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u77e5\u8bc6\u6307\u9488\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u6587\u672c\u7684\u5f15\u7528\u8d28\u91cf\u548c\u8bed\u4e49\u8fde\u8d2f\u6027"}}
{"id": "2602.00005", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00005", "abs": "https://arxiv.org/abs/2602.00005", "authors": ["Shuai Wang", "Harrisen Scells", "Bevan Koopman", "Guido Zuccon"], "title": "AutoBool: An Reinforcement-Learning trained LLM for Effective Automated Boolean Query Generation for Systematic Reviews", "comment": null, "summary": "We present AutoBool, a reinforcement learning (RL) framework that trains large language models (LLMs) to generate effective Boolean queries for medical systematic reviews. Boolean queries are the primary mechanism for literature retrieval in this domain and must achieve high recall while maintaining reasonable precision - a challenging balance that existing prompt-based LLM approaches often struggle to achieve. A major limitation in this space is the lack of high-quality ground-truth Boolean queries for each topic, which makes supervised fine-tuning impractical. AutoBool addresses this challenge by using RL to directly optimize query generation with retrieval measures, without requiring target queries. To support this effort, we create and release the largest dataset of its kind: 65588 topics in total for training and evaluating the task of automatic Boolean query formulation. Experiments on our new dataset and two established datasets (CLEF TAR and Seed Collection) show that AutoBool significantly outperforms zero shot/few shot prompting and matches or exceeds the effectiveness of much larger GPT-based models (e.g., GPT-4o, O3) using smaller backbones. It also approaches effectiveness of expert-authored queries while retrieving 10 to 16 times fewer documents. Ablation studies reveal the critical roles of model backbone, size, decoding temperature, and prompt design. Code and data are available at https://github.com/ielab/AutoBool.", "AI": {"tldr": "AutoBool\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u533b\u5b66\u7cfb\u7edf\u7efc\u8ff0\u7684\u6709\u6548\u5e03\u5c14\u67e5\u8be2\uff0c\u65e0\u9700\u771f\u5b9e\u67e5\u8be2\u6807\u7b7e\uff0c\u901a\u8fc7\u68c0\u7d22\u6307\u6807\u76f4\u63a5\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u63d0\u793a\u65b9\u6cd5\u5e76\u63a5\u8fd1\u4e13\u5bb6\u6c34\u5e73\u3002", "motivation": "\u533b\u5b66\u7cfb\u7edf\u7efc\u8ff0\u4e2d\u5e03\u5c14\u67e5\u8be2\u662f\u6587\u732e\u68c0\u7d22\u7684\u4e3b\u8981\u65b9\u6cd5\uff0c\u9700\u8981\u5728\u4fdd\u6301\u5408\u7406\u7cbe\u5ea6\u7684\u540c\u65f6\u8fbe\u5230\u9ad8\u53ec\u56de\u7387\uff0c\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u7684LLM\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u8fd9\u4e00\u6311\u6218\u3002\u4e3b\u8981\u9650\u5236\u662f\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u771f\u5b9e\u5e03\u5c14\u67e5\u8be2\u6807\u7b7e\uff0c\u4f7f\u5f97\u76d1\u7763\u5fae\u8c03\u4e0d\u53ef\u884c\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u76f4\u63a5\u4f18\u5316\u67e5\u8be2\u751f\u6210\u4e0e\u68c0\u7d22\u6307\u6807\uff0c\u65e0\u9700\u76ee\u6807\u67e5\u8be2\u6807\u7b7e\u3002\u521b\u5efa\u5e76\u53d1\u5e03\u4e86\u5305\u542b65588\u4e2a\u4e3b\u9898\u7684\u6700\u5927\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u81ea\u52a8\u5e03\u5c14\u67e5\u8be2\u751f\u6210\u4efb\u52a1\u3002", "result": "\u5728\u65b0\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u73b0\u6709\u6570\u636e\u96c6\uff08CLEF TAR\u548cSeed Collection\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAutoBool\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\u65b9\u6cd5\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u66f4\u5927\u7684GPT\u6a21\u578b\uff08\u5982GPT-4o\u3001O3\uff09\u7684\u6548\u679c\uff0c\u540c\u65f6\u63a5\u8fd1\u4e13\u5bb6\u7f16\u5199\u7684\u67e5\u8be2\u6548\u679c\uff0c\u4f46\u68c0\u7d22\u7684\u6587\u6863\u6570\u91cf\u51cf\u5c1110-16\u500d\u3002", "conclusion": "AutoBool\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u533b\u5b66\u7cfb\u7edf\u7efc\u8ff0\u4e2d\u5e03\u5c14\u67e5\u8be2\u751f\u6210\u7684\u6311\u6218\uff0c\u65e0\u9700\u771f\u5b9e\u67e5\u8be2\u6807\u7b7e\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u63a5\u8fd1\u4e13\u5bb6\u6c34\u5e73\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u68c0\u7d22\u8d1f\u62c5\u3002\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u9aa8\u5e72\u3001\u5927\u5c0f\u3001\u89e3\u7801\u6e29\u5ea6\u548c\u63d0\u793a\u8bbe\u8ba1\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2602.00006", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00006", "abs": "https://arxiv.org/abs/2602.00006", "authors": ["Arun Kavishwar", "William Lotter"], "title": "FDA AI Search: Making FDA-Authorized AI Devices Searchable", "comment": "Findings paper presented at the 5th Machine Learning for Health (ML4H) Symposium (2025)", "summary": "Over 1,200 AI-enabled medical devices have received marketing authorization from the U.S. FDA, yet identifying devices suited to specific clinical needs remains challenging because the FDA's databases contain only limited metadata and non-searchable summary PDFs. To address this gap, we developed FDA AI Search, a website that enables semantic querying of FDA-authorized AI-enabled devices. The backend includes an embedding-based retrieval system, where LLM-extracted features from authorization summaries are compared to user queries to find relevant matches. We present quantitative and qualitative evaluation that support the effectiveness of the retrieval algorithm compared to keyword-based methods. As FDA-authorized AI devices become increasingly prevalent and their use cases expand, we envision that the tool will assist healthcare providers in identifying devices aligned with their clinical needs and support developers in formulating novel AI applications.", "AI": {"tldr": "FDA AI Search\u662f\u4e00\u4e2a\u8bed\u4e49\u641c\u7d22\u7f51\u7ad9\uff0c\u5e2e\u52a9\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u4eceFDA\u6388\u6743\u76841200\u591a\u6b3eAI\u533b\u7597\u8bbe\u5907\u4e2d\u5feb\u901f\u627e\u5230\u7b26\u5408\u4e34\u5e8a\u9700\u6c42\u7684\u4ea7\u54c1\uff0c\u89e3\u51b3\u4e86FDA\u6570\u636e\u5e93\u4ec5\u63d0\u4f9b\u6709\u9650\u5143\u6570\u636e\u548c\u975e\u53ef\u641c\u7d22PDF\u7684\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1FDA\u5df2\u6388\u6743\u8d85\u8fc71200\u6b3eAI\u533b\u7597\u8bbe\u5907\uff0c\u4f46\u7531\u4e8eFDA\u6570\u636e\u5e93\u4ec5\u5305\u542b\u6709\u9650\u7684\u5143\u6570\u636e\u548c\u975e\u53ef\u641c\u7d22\u7684PDF\u6458\u8981\uff0c\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u5f88\u96be\u627e\u5230\u9002\u5408\u7279\u5b9a\u4e34\u5e8a\u9700\u6c42\u7684\u8bbe\u5907\u3002", "method": "\u5f00\u53d1\u4e86FDA AI Search\u7f51\u7ad9\uff0c\u91c7\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7LLM\u4ece\u6388\u6743\u6458\u8981\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u4e0e\u7528\u6237\u67e5\u8be2\u8fdb\u884c\u8bed\u4e49\u5339\u914d\u6765\u5bfb\u627e\u76f8\u5173\u8bbe\u5907\u3002", "result": "\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u68c0\u7d22\u7b97\u6cd5\u76f8\u6bd4\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u65b9\u6cd5\u66f4\u6709\u6548\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5339\u914d\u7528\u6237\u67e5\u8be2\u548c\u533b\u7597\u8bbe\u5907\u3002", "conclusion": "\u968f\u7740FDA\u6388\u6743\u7684AI\u8bbe\u5907\u65e5\u76ca\u666e\u53ca\u548c\u5e94\u7528\u573a\u666f\u6269\u5c55\uff0c\u8be5\u5de5\u5177\u5c06\u5e2e\u52a9\u533b\u7597\u63d0\u4f9b\u8005\u627e\u5230\u7b26\u5408\u4e34\u5e8a\u9700\u6c42\u7684\u8bbe\u5907\uff0c\u5e76\u652f\u6301\u5f00\u53d1\u8005\u6784\u601d\u65b0\u7684AI\u5e94\u7528\u3002"}}
{"id": "2602.00008", "categories": ["cs.IR", "cs.CY", "cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.00008", "abs": "https://arxiv.org/abs/2602.00008", "authors": ["He Wang", "Ziyu Zhou", "Hanxiang Liu"], "title": "Front-Loaded or Balanced? The Mechanism through Which Review Order Affects Overall Ratings in Premium Service Settings", "comment": null, "summary": "In the increasingly prevalent landscape of high-quality service contexts, whether consumer evaluation interfaces adopt a rating-first or review-first sequence has become a critical factor shaping rating authenticity and feedback quality. While prior research has primarily examined review content and sentiment, systematic investigation into how evaluation order influences rating outcomes remains limited. Through exploratory analyses, we find that Letterboxd -- which employs a review-first, rating-after mechanism -- exhibits a more centralized rating distribution with fewer extreme scores, whereas Yelp -- which adopts a rating-first, review-after mechanism -- shows a pronounced bimodal distribution with more polarized ratings. Three controlled experiments further demonstrate that in high-quality service contexts, a rating-first (vs. review-first) interface significantly elevates consumers' overall ratings. Mechanism analyses indicate that cognitive effort and affective heuristics serve as dual pathways: a rating-first (vs. review-first) sequence reduces cognitive effort and heightens affective heuristics, thereby increasing rating scores. Moreover, service quality moderates this process. When service quality is low, the rating-first (vs. review-first) sequence instead leads to lower ratings. This research reveals the psychological mechanisms through which evaluation order affects consumer ratings via cognitive and affective pathways. It extends theoretical understanding of online rating formation and offers practical implications for optimizing platform interface design to enhance rating authenticity and credibility.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bc4\u4ef7\u987a\u5e8f\u5f71\u54cd\u8bc4\u5206\uff1a\u5148\u8bc4\u5206\u540e\u8bc4\u4ef7\uff08\u5982Yelp\uff09\u5bfc\u81f4\u8bc4\u5206\u66f4\u9ad8\u4e14\u66f4\u4e24\u6781\u5206\u5316\uff0c\u5148\u8bc4\u4ef7\u540e\u8bc4\u5206\uff08\u5982Letterboxd\uff09\u5219\u8bc4\u5206\u66f4\u96c6\u4e2d\u3002\u8ba4\u77e5\u52aa\u529b\u548c\u60c5\u611f\u542f\u53d1\u662f\u53cc\u91cd\u4f5c\u7528\u673a\u5236\u3002", "motivation": "\u5728\u9ad8\u8d28\u91cf\u670d\u52a1\u573a\u666f\u4e2d\uff0c\u6d88\u8d39\u8005\u8bc4\u4ef7\u754c\u9762\u7684\u987a\u5e8f\uff08\u5148\u8bc4\u5206\u540e\u8bc4\u4ef7 vs \u5148\u8bc4\u4ef7\u540e\u8bc4\u5206\uff09\u5bf9\u8bc4\u5206\u771f\u5b9e\u6027\u548c\u53cd\u9988\u8d28\u91cf\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5bf9\u6b64\u7f3a\u4e4f\u7cfb\u7edf\u63a2\u8ba8\u3002", "method": "\u901a\u8fc7\u63a2\u7d22\u6027\u5206\u6790\u6bd4\u8f83Letterboxd\uff08\u5148\u8bc4\u4ef7\u540e\u8bc4\u5206\uff09\u548cYelp\uff08\u5148\u8bc4\u5206\u540e\u8bc4\u4ef7\uff09\u7684\u8bc4\u5206\u5206\u5e03\uff0c\u5e76\u8fdb\u884c\u4e09\u4e2a\u63a7\u5236\u5b9e\u9a8c\u68c0\u9a8c\u8bc4\u4ef7\u987a\u5e8f\u5bf9\u8bc4\u5206\u7684\u5f71\u54cd\u673a\u5236\u3002", "result": "\u5148\u8bc4\u5206\u540e\u8bc4\u4ef7\u7684\u754c\u9762\u5728\u9ad8\u8d28\u91cf\u670d\u52a1\u573a\u666f\u4e2d\u663e\u8457\u63d0\u9ad8\u6d88\u8d39\u8005\u603b\u4f53\u8bc4\u5206\uff1b\u8ba4\u77e5\u52aa\u529b\u51cf\u5c11\u548c\u60c5\u611f\u542f\u53d1\u589e\u5f3a\u662f\u53cc\u91cd\u4f5c\u7528\u673a\u5236\uff1b\u670d\u52a1\u8d28\u91cf\u8d77\u8c03\u8282\u4f5c\u7528\uff0c\u4f4e\u8d28\u91cf\u670d\u52a1\u65f6\u5148\u8bc4\u5206\u540e\u8bc4\u4ef7\u53cd\u800c\u964d\u4f4e\u8bc4\u5206\u3002", "conclusion": "\u8bc4\u4ef7\u987a\u5e8f\u901a\u8fc7\u8ba4\u77e5\u548c\u60c5\u611f\u53cc\u91cd\u8def\u5f84\u5f71\u54cd\u6d88\u8d39\u8005\u8bc4\u5206\uff0c\u4e3a\u5728\u7ebf\u8bc4\u5206\u5f62\u6210\u7406\u8bba\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u5bf9\u4f18\u5316\u5e73\u53f0\u754c\u9762\u8bbe\u8ba1\u4ee5\u63d0\u5347\u8bc4\u5206\u771f\u5b9e\u6027\u548c\u53ef\u4fe1\u5ea6\u5177\u6709\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2602.00010", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00010", "abs": "https://arxiv.org/abs/2602.00010", "authors": ["Mathieu Ciancone", "Clovis Varangot-Reille", "Marion Schaeffer"], "title": "ChunkNorris: A High-Performance and Low-Energy Approach to PDF Parsing and Chunking", "comment": null, "summary": "In Retrieval-Augmented Generation applications, the Information Retrieval part is central as it provides the contextual information that enables a Large Language Model to generate an appropriate and truthful response. High quality parsing and chunking are critical as efficient data segmentation directly impacts downstream tasks, i.e. Information Retrieval and answer generation. In this paper, we introduce ChunkNorris, a novel heuristic-based technique designed to optimise the parsing and chunking of PDF documents. Our approach does not rely on machine learning and employs a suite of simple yet effective heuristics to achieve high performance with minimal computational overhead. We demonstrate the efficiency of ChunkNorris through a comprehensive benchmark against existing parsing and chunking methods, evaluating criteria such as execution time, energy consumption, and retrieval accuracy. We propose an open-access dataset to produce our results. ChunkNorris outperforms baseline and more advanced techniques, offering a practical and efficient alternative for Information Retrieval tasks. Therefore, this research highlights the potential of heuristic-based methods for real-world, resource-constrained RAG use cases.", "AI": {"tldr": "ChunkNorris\uff1a\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u65b0\u578bPDF\u6587\u6863\u89e3\u6790\u4e0e\u5206\u5757\u6280\u672f\uff0c\u4e0d\u4f9d\u8d56\u673a\u5668\u5b66\u4e60\uff0c\u5728\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684RAG\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u9ad8\u6548\u65b9\u6848\u3002", "motivation": "\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5e94\u7528\u4e2d\uff0c\u4fe1\u606f\u68c0\u7d22\u90e8\u5206\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e0a\u4e0b\u6587\u4fe1\u606f\u4ee5\u751f\u6210\u9002\u5f53\u4e14\u771f\u5b9e\u7684\u56de\u7b54\u3002\u9ad8\u8d28\u91cf\u7684\u89e3\u6790\u548c\u5206\u5757\u76f4\u63a5\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\uff08\u4fe1\u606f\u68c0\u7d22\u548c\u7b54\u6848\u751f\u6210\uff09\u7684\u6548\u679c\u3002", "method": "\u63d0\u51faChunkNorris\u6280\u672f\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u673a\u5668\u5b66\u4e60\uff0c\u91c7\u7528\u4e00\u5957\u7b80\u5355\u800c\u6709\u6548\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u6765\u4f18\u5316PDF\u6587\u6863\u7684\u89e3\u6790\u548c\u5206\u5757\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u6267\u884c\u65f6\u95f4\u3001\u80fd\u8017\u548c\u68c0\u7d22\u51c6\u786e\u6027\uff0cChunkNorris\u5728\u5404\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u548c\u66f4\u5148\u8fdb\u7684\u6280\u672f\uff0c\u4e3a\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5f3a\u8c03\u4e86\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u65b9\u6cd5\u5728\u5b9e\u9645\u8d44\u6e90\u53d7\u9650\u7684RAG\u7528\u4f8b\u4e2d\u7684\u6f5c\u529b\uff0cChunkNorris\u4e3aPDF\u6587\u6863\u89e3\u6790\u548c\u5206\u5757\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00011", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00011", "abs": "https://arxiv.org/abs/2602.00011", "authors": ["Fatima Nasser", "Fouad Trad", "Ammar Mohanna", "Ghada El-Hajj Fuleihan", "Ali Chehab"], "title": "Chained Prompting for Better Systematic Review Search Strategies", "comment": "Accepted in the 3rd International Conference on Foundation and Large Language Models (FLLM2025)", "summary": "Systematic reviews require the use of rigorously designed search strategies to ensure both comprehensive retrieval and minimization of bias. Conventional manual approaches, although methodologically systematic, are resource-intensive and susceptible to subjectivity, whereas heuristic and automated techniques frequently under-perform in recall unless supplemented by extensive expert input. We introduce a Large Language Model (LLM)-based chained prompt engineering framework for the automated development of search strategies in systematic reviews. The framework replicates the procedural structure of manual search design while leveraging LLMs to decompose review objectives, extract and formalize PICO elements, generate conceptual representations, expand terminologies, and synthesize Boolean queries. In addition to query construction, the framework exhibits superior performance in generating well-structured PICO elements relative to existing methods, thereby strengthening the foundation for high-recall search strategies. Evaluation on a subset of the LEADSInstruct dataset demonstrates that the framework attains a 0.9 average recall. These results significantly exceed the performance of existing approaches. Error analysis further highlights the critical role of precise objective specification and terminological alignment in optimizing retrieval effectiveness. These findings confirm the capacity of LLM-based pipelines to yield transparent, reproducible, and high-performing search strategies, and highlight their potential as scalable instruments for supporting evidence synthesis and evidence-based practice.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u94fe\u5f0f\u63d0\u793a\u5de5\u7a0b\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u7efc\u8ff0\u4e2d\u81ea\u52a8\u5316\u6784\u5efa\u641c\u7d22\u7b56\u7565\uff0c\u5b9e\u73b0\u9ad8\u53ec\u56de\u7387", "motivation": "\u4f20\u7edf\u624b\u52a8\u6784\u5efa\u641c\u7d22\u7b56\u7565\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u6613\u53d7\u4e3b\u89c2\u6027\u5f71\u54cd\uff0c\u800c\u542f\u53d1\u5f0f\u548c\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u65b9\u6cd5\u4e25\u8c28\u6027\u53c8\u80fd\u63d0\u9ad8\u6548\u7387\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u94fe\u5f0f\u63d0\u793a\u5de5\u7a0b\u6846\u67b6\uff0c\u6a21\u62df\u624b\u52a8\u641c\u7d22\u8bbe\u8ba1\u6d41\u7a0b\uff1a\u5206\u89e3\u7efc\u8ff0\u76ee\u6807\u3001\u63d0\u53d6\u548c\u5f62\u5f0f\u5316PICO\u5143\u7d20\u3001\u751f\u6210\u6982\u5ff5\u8868\u793a\u3001\u6269\u5c55\u672f\u8bed\u3001\u5408\u6210\u5e03\u5c14\u67e5\u8be2\u3002", "result": "\u5728LEADSInstruct\u6570\u636e\u96c6\u5b50\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6846\u67b6\u8fbe\u52300.9\u7684\u5e73\u5747\u53ec\u56de\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u5728\u751f\u6210\u7ed3\u6784\u5316PICO\u5143\u7d20\u65b9\u9762\u4e5f\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u7ba1\u9053\u80fd\u591f\u4ea7\u751f\u900f\u660e\u3001\u53ef\u91cd\u590d\u4e14\u9ad8\u6027\u80fd\u7684\u641c\u7d22\u7b56\u7565\uff0c\u5177\u6709\u652f\u6301\u8bc1\u636e\u5408\u6210\u548c\u5faa\u8bc1\u5b9e\u8df5\u7684\u89c4\u6a21\u5316\u6f5c\u529b\u3002\u7cbe\u786e\u7684\u76ee\u6807\u89c4\u8303\u548c\u672f\u8bed\u5bf9\u9f50\u5bf9\u68c0\u7d22\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.00013", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00013", "abs": "https://arxiv.org/abs/2602.00013", "authors": ["Vipul Dinesh Pawar"], "title": "Linear-PAL: A Lightweight Ranker for Mitigating Shortcut Learning in Personalized, High-Bias Tabular Ranking", "comment": null, "summary": "In e-commerce ranking, implicit user feedback is systematically confounded by Position Bias -- the strong propensity of users to interact with top-ranked items regardless of relevance. While Deep Learning architectures (e.g., Two-Tower Networks) are the standard solution for de-biasing, we demonstrate that in High-Bias Regimes, state-of-the-art Deep Ensembles suffer from Shortcut Learning: they minimize training loss by overfitting to the rank signal, leading to degraded ranking quality despite high prediction accuracy. We propose Linear Position-bias Aware Learning (Linear-PAL), a lightweight framework that enforces de-biasing through structural constraints: explicit feature conjunctions and aggressive regularization. We further introduce a Vectorized Integer Hashing technique for feature generation, replacing string-based operations with $O(N)$ vectorized arithmetic. Evaluating on a large-scale dataset (4.2M samples), Linear-PAL achieves Pareto Dominance: it outperforms Deep Ensembles in de-biased ranking quality (Relevance AUC: 0.7626 vs. 0.6736) while reducing training latency by 43x (40s vs 1762s). This computational efficiency enables high-frequency retraining, allowing the system to capture user-specific emerging market trends and deliver robust, personalized ranking in near real-time.", "AI": {"tldr": "\u63d0\u51faLinear-PAL\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u7ea6\u675f\u89e3\u51b3\u9ad8\u504f\u5dee\u573a\u666f\u4e0b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6377\u5f84\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u53bb\u504f\u6392\u5e8f\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5b9e\u73b0\u5e15\u7d2f\u6258\u4f18\u52bf", "motivation": "\u7535\u5546\u6392\u5e8f\u4e2d\uff0c\u9690\u5f0f\u7528\u6237\u53cd\u9988\u5b58\u5728\u4e25\u91cd\u7684\u4f4d\u7f6e\u504f\u5dee\u95ee\u9898\u3002\u5728\u9ad8\u504f\u5dee\u573a\u666f\u4e0b\uff0c\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u96c6\u6210\u6a21\u578b\u4f1a\u51fa\u73b0\u6377\u5f84\u5b66\u4e60\uff0c\u8fc7\u5ea6\u62df\u5408\u6392\u540d\u4fe1\u53f7\uff0c\u5bfc\u81f4\u6392\u5e8f\u8d28\u91cf\u4e0b\u964d", "method": "\u63d0\u51faLinear-PAL\u6846\u67b6\uff1a1) \u901a\u8fc7\u663e\u5f0f\u7279\u5f81\u8fde\u63a5\u548c\u6fc0\u8fdb\u6b63\u5219\u5316\u7684\u7ed3\u6784\u7ea6\u675f\u5f3a\u5236\u53bb\u504f\uff1b2) \u5f15\u5165\u5411\u91cf\u5316\u6574\u6570\u54c8\u5e0c\u6280\u672f\u66ff\u4ee3\u5b57\u7b26\u4e32\u64cd\u4f5c\uff0c\u5b9e\u73b0O(N)\u5411\u91cf\u5316\u7b97\u672f", "result": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6(420\u4e07\u6837\u672c)\u4e0a\uff0cLinear-PAL\u5b9e\u73b0\u5e15\u7d2f\u6258\u4f18\u52bf\uff1a\u53bb\u504f\u6392\u5e8f\u8d28\u91cf(\u76f8\u5173\u6027AUC: 0.7626 vs 0.6736)\u4f18\u4e8e\u6df1\u5ea6\u96c6\u6210\uff0c\u8bad\u7ec3\u5ef6\u8fdf\u964d\u4f4e43\u500d(40\u79d2 vs 1762\u79d2)", "conclusion": "Linear-PAL\u7684\u8ba1\u7b97\u6548\u7387\u652f\u6301\u9ad8\u9891\u91cd\u8bad\u7ec3\uff0c\u80fd\u591f\u6355\u6349\u7528\u6237\u7279\u5b9a\u7684\u65b0\u5174\u5e02\u573a\u8d8b\u52bf\uff0c\u5b9e\u73b0\u8fd1\u4e4e\u5b9e\u65f6\u7684\u9c81\u68d2\u4e2a\u6027\u5316\u6392\u5e8f"}}
{"id": "2602.00052", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00052", "abs": "https://arxiv.org/abs/2602.00052", "authors": ["Ramtin Babaeipour", "Fran\u00e7ois Charest", "Madison Wright"], "title": "AI-assisted Protocol Information Extraction For Improved Accuracy and Efficiency in Clinical Trial Workflows", "comment": null, "summary": "Increasing clinical trial protocol complexity, amendments, and challenges around knowledge management create significant burden for trial teams. Structuring protocol content into standard formats has the potential to improve efficiency, support documentation quality, and strengthen compliance. We evaluate an Artificial Intelligence (AI) system using generative LLMs with Retrieval-Augmented Generation (RAG) for automated clinical trial protocol information extraction. We compare the extraction accuracy of our clinical-trial-specific RAG process against that of publicly available (standalone) LLMs. We also assess the operational impact of AI-assistance on simulated extraction CRC workflows. Our RAG process was measured as more accurate (87.8%) than standalone LLMs with fine-tuned prompts (62.6%) against expert-supported reference annotations. In the simulated extraction workflows, AI-assisted tasks were completed 40% faster, rated as less cognitively demanding and strongly preferred by users. While expert oversight remains essential, this suggests that AI-assisted extraction can enable protocol intelligence at scale, motivating the integration of similar methodologies into real world clinical workflows to further validate its impact on feasibility, study start-up, and post-activation monitoring.", "AI": {"tldr": "\u4f7f\u7528RAG\u589e\u5f3a\u7684\u751f\u6210\u5f0fLLM\u8fdb\u884c\u4e34\u5e8a\u8bd5\u9a8c\u65b9\u6848\u4fe1\u606f\u81ea\u52a8\u63d0\u53d6\uff0c\u76f8\u6bd4\u72ec\u7acbLLM\u51c6\u786e\u7387\u66f4\u9ad8\uff0887.8% vs 62.6%\uff09\uff0cAI\u8f85\u52a9\u5de5\u4f5c\u6d41\u6548\u7387\u63d0\u534740%\u4e14\u7528\u6237\u504f\u597d\u5ea6\u66f4\u9ad8\u3002", "motivation": "\u4e34\u5e8a\u8bd5\u9a8c\u65b9\u6848\u65e5\u76ca\u590d\u6742\u3001\u4fee\u8ba2\u9891\u7e41\u4ee5\u53ca\u77e5\u8bc6\u7ba1\u7406\u56f0\u96be\u7ed9\u8bd5\u9a8c\u56e2\u961f\u5e26\u6765\u6c89\u91cd\u8d1f\u62c5\u3002\u5c06\u65b9\u6848\u5185\u5bb9\u7ed3\u6784\u5316\u5230\u6807\u51c6\u683c\u5f0f\u4e2d\uff0c\u6709\u671b\u63d0\u9ad8\u6548\u7387\u3001\u63d0\u5347\u6587\u6863\u8d28\u91cf\u5e76\u52a0\u5f3a\u5408\u89c4\u6027\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684AI\u7cfb\u7edf\uff0c\u4f7f\u7528\u751f\u6210\u5f0fLLM\u81ea\u52a8\u63d0\u53d6\u4e34\u5e8a\u8bd5\u9a8c\u65b9\u6848\u4fe1\u606f\u3002\u6bd4\u8f83\u4e34\u5e8a\u8bd5\u9a8c\u4e13\u7528RAG\u6d41\u7a0b\u4e0e\u516c\u5f00\u53ef\u7528\u72ec\u7acbLLM\u7684\u63d0\u53d6\u51c6\u786e\u6027\uff0c\u5e76\u8bc4\u4f30AI\u8f85\u52a9\u5bf9\u6a21\u62df\u63d0\u53d6\u5de5\u4f5c\u6d41\u7684\u64cd\u4f5c\u5f71\u54cd\u3002", "result": "RAG\u6d41\u7a0b\u51c6\u786e\u7387\uff0887.8%\uff09\u663e\u8457\u9ad8\u4e8e\u7ecf\u8fc7\u7cbe\u7ec6\u8c03\u4f18\u63d0\u793a\u7684\u72ec\u7acbLLM\uff0862.6%\uff09\u3002\u5728\u6a21\u62df\u63d0\u53d6\u5de5\u4f5c\u6d41\u4e2d\uff0cAI\u8f85\u52a9\u4efb\u52a1\u5b8c\u6210\u901f\u5ea6\u5feb40%\uff0c\u8ba4\u77e5\u8d1f\u8377\u66f4\u4f4e\uff0c\u7528\u6237\u5f3a\u70c8\u504f\u597dAI\u8f85\u52a9\u65b9\u5f0f\u3002", "conclusion": "\u867d\u7136\u4e13\u5bb6\u76d1\u7763\u4ecd\u7136\u5fc5\u8981\uff0c\u4f46AI\u8f85\u52a9\u63d0\u53d6\u80fd\u591f\u5b9e\u73b0\u5927\u89c4\u6a21\u65b9\u6848\u667a\u80fd\u5316\uff0c\u63a8\u52a8\u7c7b\u4f3c\u65b9\u6cd5\u6574\u5408\u5230\u771f\u5b9e\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5176\u5bf9\u53ef\u884c\u6027\u3001\u7814\u7a76\u542f\u52a8\u548c\u6fc0\u6d3b\u540e\u76d1\u6d4b\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.00083", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00083", "abs": "https://arxiv.org/abs/2602.00083", "authors": ["Yuxin Yang", "Gangda Deng", "\u00d6mer Faruk Akg\u00fcl", "Nima Chitsazan", "Yash Govilkar", "Akasha Tigalappanavara", "Shi-Xiong Zhang", "Sambit Sahu", "Viktor Prasanna"], "title": "SPARC-RAG: Adaptive Sequential-Parallel Scaling with Context Management for Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) grounds large language model outputs in external evidence, but remains challenged on multi-hop question answering that requires long reasoning. Recent works scale RAG at inference time along two complementary dimensions: sequential depth for iterative refinement and parallel width for coverage expansion. However, naive scaling causes context contamination and scaling inefficiency, leading to diminishing or negative returns despite increased computation. To address these limitations, we propose SPARC-RAG, a multi-agent framework that coordinates sequential and parallel inference-time scaling under a unified context management mechanism. SPARC-RAG employs specialized agents that maintain a shared global context and provide explicit control over the scaling process. It generates targeted, complementary sub-queries for each branch to enable diverse parallel exploration, and explicitly regulates exiting decisions based on answer correctness and evidence grounding. To optimize scaling behavior, we further introduce a lightweight fine-tuning method with process-level verifiable preferences, which improves the efficiency of sequential scaling and effectiveness of parallel scaling. Across single- and multi-hop QA benchmarks, SPARC-RAG consistently outperforms previous RAG baselines, yielding an average +6.2 F1 improvement under lower inference cost.", "AI": {"tldr": "SPARC-RAG\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u987a\u5e8f\u548c\u5e76\u884c\u63a8\u7406\u6269\u5c55\u6765\u89e3\u51b3\u4f20\u7edfRAG\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u91c7\u7528\u5168\u5c40\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u8f7b\u91cf\u7ea7\u5fae\u8c03\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u540c\u65f6\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u957f\u63a8\u7406\u94fe\u3002\u73b0\u6709\u7684\u63a8\u7406\u65f6\u6269\u5c55\u65b9\u6cd5\uff08\u987a\u5e8f\u6df1\u5ea6\u548c\u5e76\u884c\u5bbd\u5ea6\uff09\u5b58\u5728\u4e0a\u4e0b\u6587\u6c61\u67d3\u548c\u6269\u5c55\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8ba1\u7b97\u589e\u52a0\u4f46\u6536\u76ca\u9012\u51cf\u751a\u81f3\u4e3a\u8d1f\u3002", "method": "\u63d0\u51faSPARC-RAG\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1\uff09\u534f\u8c03\u987a\u5e8f\u548c\u5e76\u884c\u63a8\u7406\u6269\u5c55\u7684\u7edf\u4e00\u4e0a\u4e0b\u6587\u7ba1\u7406\u673a\u5236\uff1b2\uff09\u4e13\u7528\u667a\u80fd\u4f53\u7ef4\u62a4\u5171\u4eab\u5168\u5c40\u4e0a\u4e0b\u6587\uff1b3\uff09\u4e3a\u6bcf\u4e2a\u5206\u652f\u751f\u6210\u6709\u9488\u5bf9\u6027\u7684\u4e92\u8865\u5b50\u67e5\u8be2\u4ee5\u5b9e\u73b0\u591a\u6837\u5316\u5e76\u884c\u63a2\u7d22\uff1b4\uff09\u57fa\u4e8e\u7b54\u6848\u6b63\u786e\u6027\u548c\u8bc1\u636e\u57fa\u7840\u660e\u786e\u8c03\u8282\u9000\u51fa\u51b3\u7b56\uff1b5\uff09\u5f15\u5165\u8f7b\u91cf\u7ea7\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528\u8fc7\u7a0b\u7ea7\u53ef\u9a8c\u8bc1\u504f\u597d\u4f18\u5316\u6269\u5c55\u884c\u4e3a\u3002", "result": "\u5728\u5355\u8df3\u548c\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPARC-RAG\u59cb\u7ec8\u4f18\u4e8e\u4e4b\u524d\u7684RAG\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747F1\u5206\u6570\u63d0\u5347+6.2\uff0c\u540c\u65f6\u63a8\u7406\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "SPARC-RAG\u901a\u8fc7\u534f\u8c03\u987a\u5e8f\u548c\u5e76\u884c\u63a8\u7406\u6269\u5c55\uff0c\u7ed3\u5408\u7edf\u4e00\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u8f7b\u91cf\u7ea7\u5fae\u8c03\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u6269\u5c55\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u548c\u6210\u672c\u964d\u4f4e\u7684\u53cc\u91cd\u4f18\u52bf\u3002"}}
{"id": "2602.00296", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00296", "abs": "https://arxiv.org/abs/2602.00296", "authors": ["Ziqi Wang", "Xi Zhu", "Shuhang Lin", "Haochen Xue", "Minghao Guo", "Yongfeng Zhang"], "title": "RAGRouter-Bench: A Dataset and Benchmark for Adaptive RAG Routing", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a core paradigm for grounding large language models with external knowledge. Despite extensive efforts exploring diverse retrieval strategies, existing studies predominantly focus on query-side complexity or isolated method improvements, lacking a systematic understanding of how RAG paradigms behave across different query-corpus contexts and effectiveness-efficiency trade-offs. In this work, we introduce RAGRouter-Bench, the first dataset and benchmark designed for adaptive RAG routing. RAGRouter-Bench revisits retrieval from a query-corpus compatibility perspective and standardizes five representative RAG paradigms for systematic evaluation across 7,727 queries and 21,460 documents spanning diverse domains. The benchmark incorporates three canonical query types together with fine-grained semantic and structural corpus metrics, as well as a unified evaluation for both generation quality and resource consumption. Experiments with DeepSeek-V3 and LLaMA-3.1-8B demonstrate that no single RAG paradigm is universally optimal, that paradigm applicability is strongly shaped by query-corpus interactions, and that increased advanced mechanism does not necessarily yield better effectiveness-efficiency trade-offs. These findings underscore the necessity of routing-aware evaluation and establish a foundation for adaptive, interpretable, and generalizable next-generation RAG systems.", "AI": {"tldr": "RAGRouter-Bench\uff1a\u9996\u4e2a\u7528\u4e8e\u81ea\u9002\u5e94RAG\u8def\u7531\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540cRAG\u8303\u5f0f\u5728\u591a\u6837\u5316\u67e5\u8be2-\u8bed\u6599\u5e93\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u6700\u4f18\u8303\u5f0f\uff0c\u9002\u7528\u6027\u53d6\u51b3\u4e8e\u67e5\u8be2-\u8bed\u6599\u5e93\u4ea4\u4e92\u3002", "motivation": "\u73b0\u6709RAG\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u67e5\u8be2\u4fa7\u590d\u6742\u6027\u6216\u5b64\u7acb\u65b9\u6cd5\u6539\u8fdb\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u540cRAG\u8303\u5f0f\u5728\u4e0d\u540c\u67e5\u8be2-\u8bed\u6599\u5e93\u4e0a\u4e0b\u6587\u548c\u6548\u679c-\u6548\u7387\u6743\u8861\u4e2d\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u5f15\u5165RAGRouter-Bench\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u4ece\u67e5\u8be2-\u8bed\u6599\u5e93\u517c\u5bb9\u6027\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u68c0\u7d22\uff0c\u6807\u51c6\u53165\u79cd\u4ee3\u8868\u6027RAG\u8303\u5f0f\uff0c\u57287,727\u4e2a\u67e5\u8be2\u548c21,460\u4e2a\u6587\u6863\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5305\u542b3\u79cd\u89c4\u8303\u67e5\u8be2\u7c7b\u578b\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49/\u7ed3\u6784\u8bed\u6599\u5e93\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u6ca1\u6709\u5355\u4e00RAG\u8303\u5f0f\u666e\u904d\u6700\u4f18\uff1b2\uff09\u8303\u5f0f\u9002\u7528\u6027\u53d7\u67e5\u8be2-\u8bed\u6599\u5e93\u4ea4\u4e92\u5f3a\u70c8\u5f71\u54cd\uff1b3\uff09\u589e\u52a0\u9ad8\u7ea7\u673a\u5236\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u7684\u6548\u679c-\u6548\u7387\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8def\u7531\u611f\u77e5\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u6cdb\u5316\u7684\u4e0b\u4e00\u4ee3RAG\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.00495", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00495", "abs": "https://arxiv.org/abs/2602.00495", "authors": ["Yiteng Tu", "Weihang Su", "Shuguang Han", "Yiqun Liu", "Qingyao Ai"], "title": "Equity vs. Equality: Optimizing Ranking Fairness for Tailored Provider Needs", "comment": null, "summary": "Ranking plays a central role in connecting users and providers in Information Retrieval (IR) systems, making provider-side fairness an important challenge. While recent research has begun to address fairness in ranking, most existing approaches adopt an equality-based perspective, aiming to ensure that providers with similar content receive similar exposure. However, it overlooks the diverse needs of real-world providers, whose utility from ranking may depend not only on exposure but also on outcomes like sales or engagement. Consequently, exposure-based fairness may not accurately capture the true utility perceived by different providers with varying priorities. To this end, we introduce an equity-oriented fairness framework that explicitly models each provider's preferences over key outcomes such as exposure and sales, thus evaluating whether a ranking algorithm can fulfill these individualized goals while maintaining overall fairness across providers. Based on this framework, we develop EquityRank, a gradient-based algorithm that jointly optimizes user-side effectiveness and provider-side equity. Extensive offline and online simulations demonstrate that EquityRank offers improved trade-offs between effectiveness and fairness and adapts to heterogeneous provider needs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEquityRank\u7b97\u6cd5\uff0c\u901a\u8fc7\u5efa\u6a21\u4e0d\u540c\u63d0\u4f9b\u5546\u7684\u4e2a\u6027\u5316\u504f\u597d\uff08\u5982\u66dd\u5149\u548c\u9500\u552e\uff09\uff0c\u5728\u4fdd\u6301\u68c0\u7d22\u6548\u679c\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u63d0\u4f9b\u5546\u7aef\u6392\u540d\u3002", "motivation": "\u73b0\u6709\u6392\u540d\u516c\u5e73\u6027\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u66dd\u5149\u5e73\u7b49\uff0c\u4f46\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e0d\u540c\u63d0\u4f9b\u5546\u5bf9\u66dd\u5149\u3001\u9500\u552e\u7b49\u7ed3\u679c\u7684\u5dee\u5f02\u5316\u9700\u6c42\u3002\u66dd\u5149\u516c\u5e73\u6027\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5177\u6709\u4e0d\u540c\u4f18\u5148\u7ea7\u7684\u63d0\u4f9b\u5546\u7684\u5b9e\u9645\u6548\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u516c\u5e73\u7684\u6846\u67b6\uff0c\u663e\u5f0f\u5efa\u6a21\u6bcf\u4e2a\u63d0\u4f9b\u5546\u5bf9\u5173\u952e\u7ed3\u679c\uff08\u5982\u66dd\u5149\u548c\u9500\u552e\uff09\u7684\u504f\u597d\uff0c\u5f00\u53d1EquityRank\u68af\u5ea6\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u7528\u6237\u7aef\u6548\u679c\u548c\u63d0\u4f9b\u5546\u7aef\u516c\u5e73\u6027\u3002", "result": "\u5927\u91cf\u79bb\u7ebf\u548c\u5728\u7ebf\u6a21\u62df\u8868\u660e\uff0cEquityRank\u5728\u6548\u679c\u548c\u516c\u5e73\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6743\u8861\uff0c\u5e76\u80fd\u9002\u5e94\u5f02\u6784\u7684\u63d0\u4f9b\u5546\u9700\u6c42\u3002", "conclusion": "\u901a\u8fc7\u8003\u8651\u63d0\u4f9b\u5546\u7684\u4e2a\u6027\u5316\u504f\u597d\uff0cEquityRank\u6846\u67b6\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6ee1\u8db3\u4e0d\u540c\u63d0\u4f9b\u5546\u7684\u516c\u5e73\u6027\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u7cfb\u7edf\u7684\u6574\u4f53\u6548\u679c\u3002"}}
{"id": "2602.00632", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00632", "abs": "https://arxiv.org/abs/2602.00632", "authors": ["Hongxun Ding", "Keqin Bao", "Jizhi Zhang", "Yi Fang", "Wenxin Xu", "Fuli Feng", "Xiangnan He"], "title": "Towards Sample-Efficient and Stable Reinforcement Learning for LLM-based Recommendation", "comment": null, "summary": "While Long Chain-of-Thought (Long CoT) reasoning has shown promise in Large Language Models (LLMs), its adoption for enhancing recommendation quality is growing rapidly. In this work, we critically examine this trend and argue that Long CoT is inherently ill-suited for the sequential recommendation domain. We attribute this misalignment to two primary factors: excessive inference latency and the lack of explicit cognitive reasoning patterns in user behavioral data. Driven by these observations, we propose pivoting away from the CoT structure to directly leverage its underlying mechanism: Reinforcement Learning (RL), to explore the item space. However, applying RL directly faces significant obstacles, notably low sample efficiency-where most actions fail to provide learning signals-and training instability. To overcome these limitations, we propose RISER, a novel Reinforced Item Space Exploration framework for Recommendation. RISER is designed to transform non-learnable trajectories into effective pairwise preference data for optimization. Furthermore, it incorporates specific strategies to ensure stability, including the prevention of redundant rollouts and the constraint of token-level update magnitudes. Extensive experiments on three real-world datasets show that RISER significantly outperforms competitive baselines, establishing a robust paradigm for RL-enhanced LLM recommendation. Our code will be available at https://anonymous.4open.science/r/RISER/.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6279\u5224\u6027\u5730\u5206\u6790\u4e86\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684RISER\u6846\u67b6\u6765\u66ff\u4ee3CoT\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u975e\u5b66\u4e60\u8f68\u8ff9\u8f6c\u5316\u4e3a\u6210\u5bf9\u504f\u597d\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6d41\u884c\u8d8b\u52bf\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff1a\u63a8\u7406\u5ef6\u8fdf\u8fc7\u9ad8\uff0c\u4e14\u7528\u6237\u884c\u4e3a\u6570\u636e\u7f3a\u4e4f\u660e\u786e\u7684\u8ba4\u77e5\u63a8\u7406\u6a21\u5f0f\u3002\u9700\u8981\u5bfb\u627e\u66f4\u5408\u9002\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u3002", "method": "\u63d0\u51faRISER\u6846\u67b6\uff0c\u653e\u5f03CoT\u7ed3\u6784\uff0c\u76f4\u63a5\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u7269\u54c1\u7a7a\u95f4\u3002\u901a\u8fc7\u5c06\u975e\u5b66\u4e60\u8f68\u8ff9\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u6210\u5bf9\u504f\u597d\u6570\u636e\u8fdb\u884c\u4f18\u5316\uff0c\u5e76\u91c7\u7528\u9632\u6b62\u5197\u4f59\u8f68\u8ff9\u548c\u7ea6\u675ftoken\u7ea7\u66f4\u65b0\u5e45\u5ea6\u7b49\u7b56\u7565\u786e\u4fdd\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRISER\u663e\u8457\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3aRL\u589e\u5f3a\u7684LLM\u63a8\u8350\u5efa\u7acb\u4e86\u7a33\u5065\u7684\u8303\u5f0f\u3002", "conclusion": "\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e0d\u9002\u5408\u5e8f\u5217\u63a8\u8350\u9886\u57df\uff0c\u800c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684RISER\u6846\u67b6\u901a\u8fc7\u6709\u6548\u7684\u7269\u54c1\u7a7a\u95f4\u63a2\u7d22\u548c\u7a33\u5b9a\u8bad\u7ec3\u7b56\u7565\uff0c\u4e3aLLM\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00682", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00682", "abs": "https://arxiv.org/abs/2602.00682", "authors": ["Yuecheng Li", "Hengwei Ju", "Zeyu Song", "Wei Yang", "Chi Lu", "Peng Jiang", "Kun Gai"], "title": "RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment", "comment": "Under Review", "summary": "Multimodal recommendation systems typically integrates user behavior with multimodal data from items, thereby capturing more accurate user preferences. Concurrently, with the rise of large models (LMs), multimodal recommendation is increasingly leveraging their strengths in semantic understanding and contextual reasoning. However, LM representations are inherently optimized for general semantic tasks, while recommendation models rely heavily on sparse user/item unique identity (ID) features. Existing works overlook the fundamental representational divergence between large models and recommendation systems, resulting in incompatible multimodal representations and suboptimal recommendation performance. To bridge this gap, we propose RecGOAT, a novel yet simple dual semantic alignment framework for LLM-enhanced multimodal recommendation, which offers theoretically guaranteed alignment capability. RecGOAT first employs graph attention networks to enrich collaborative semantics by modeling item-item, user-item, and user-user relationships, leveraging user/item LM representations and interaction history. Furthermore, we design a dual-granularity progressive multimodality-ID alignment framework, which achieves instance-level and distribution-level semantic alignment via cross-modal contrastive learning (CMCL) and optimal adaptive transport (OAT), respectively. Theoretically, we demonstrate that the unified representations derived from our alignment framework exhibit superior semantic consistency and comprehensiveness. Extensive experiments on three public benchmarks show that our RecGOAT achieves state-of-the-art performance, empirically validating our theoretical insights. Additionally, the deployment on a large-scale online advertising platform confirms the model's effectiveness and scalability in industrial recommendation scenarios. Code available at https://github.com/6lyc/RecGOAT-LLM4Rec.", "AI": {"tldr": "RecGOAT\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u8bed\u4e49\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u53cc\u91cd\u7c92\u5ea6\u5bf9\u9f50\uff08\u5b9e\u4f8b\u7ea7\u548c\u5206\u5e03\u7ea7\uff09\u6765\u5f25\u5408\u5927\u6a21\u578b\u4e0e\u63a8\u8350\u7cfb\u7edf\u4e4b\u95f4\u7684\u8868\u5f81\u5dee\u5f02\uff0c\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u4f18\u5316\u4e8e\u901a\u7528\u8bed\u4e49\u4efb\u52a1\uff09\u4e0e\u63a8\u8350\u7cfb\u7edf\uff08\u4f9d\u8d56\u7a00\u758f\u7528\u6237/\u7269\u54c1ID\u7279\u5f81\uff09\u4e4b\u95f4\u7684\u8868\u5f81\u5dee\u5f02\uff0c\u5bfc\u81f4\u4e0d\u517c\u5bb9\u7684\u591a\u6a21\u6001\u8868\u793a\u548c\u6b21\u4f18\u7684\u63a8\u8350\u6027\u80fd\u3002", "method": "1. \u4f7f\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u5efa\u6a21\u7269\u54c1-\u7269\u54c1\u3001\u7528\u6237-\u7269\u54c1\u3001\u7528\u6237-\u7528\u6237\u5173\u7cfb\uff0c\u5229\u7528\u7528\u6237/\u7269\u54c1\u7684\u5927\u6a21\u578b\u8868\u793a\u548c\u4ea4\u4e92\u5386\u53f2\u4e30\u5bcc\u534f\u540c\u8bed\u4e49\uff1b2. \u8bbe\u8ba1\u53cc\u91cd\u7c92\u5ea6\u6e10\u8fdb\u5f0f\u591a\u6a21\u6001-ID\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\uff0c\u901a\u8fc7\u6700\u4f18\u81ea\u9002\u5e94\u4f20\u8f93\u5b9e\u73b0\u5206\u5e03\u7ea7\u5bf9\u9f50\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7406\u8bba\u8bc1\u660e\u4e86\u7edf\u4e00\u8868\u793a\u5177\u6709\u66f4\u597d\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u5168\u9762\u6027\u3002\u5728\u5927\u578b\u5728\u7ebf\u5e7f\u544a\u5e73\u53f0\u4e0a\u7684\u90e8\u7f72\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u5de5\u4e1a\u63a8\u8350\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "RecGOAT\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u7684\u53cc\u8bed\u4e49\u5bf9\u9f50\u6846\u67b6\u6210\u529f\u5f25\u5408\u4e86\u5927\u6a21\u578b\u4e0e\u63a8\u8350\u7cfb\u7edf\u4e4b\u95f4\u7684\u8868\u5f81\u5dee\u5f02\uff0c\u4e3aLLM\u589e\u5f3a\u7684\u591a\u6a21\u6001\u63a8\u8350\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.00727", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00727", "abs": "https://arxiv.org/abs/2602.00727", "authors": ["Fangda Chen", "Yueyang Wang", "Chaoli Lou", "Min Gao", "Qingyu Xiong"], "title": "SWGCN: Synergy Weighted Graph Convolutional Network for Multi-Behavior Recommendation", "comment": "Accepted by Information Sciences", "summary": "Multi-behavior recommendation paradigms have emerged to capture diverse user activities, forecasting primary conversions (e.g., purchases) by leveraging secondary signals like browsing history. However, current graph-based methods often overlook cross-behavioral synergistic signals and fine-grained intensity of individual actions. Motivated by the need to overcome these shortcomings, we introduce Synergy Weighted Graph Convolutional Network (SWGCN). SWGCN introduces two novel components: a Target Preference Weigher, which adaptively assigns weights to user-item interactions within each behavior, and a Synergy Alignment Task, which guides its training by leveraging an Auxiliary Preference Valuator. This task prioritizes interactions from synergistic signals that more accurately reflect user preferences. The performance of our model is rigorously evaluated through comprehensive tests on three open-source datasets, specifically Taobao, IJCAI, and Beibei. On the Taobao dataset, SWGCN yields relative gains of 112.49% and 156.36% in terms of Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG), respectively. It also yields consistent gains on IJCAI and Beibei, confirming its robustness and generalizability across various datasets. Our implementation is open-sourced and can be accessed via https://github.com/FangdChen/SWGCN.", "AI": {"tldr": "SWGCN\u901a\u8fc7\u76ee\u6807\u504f\u597d\u52a0\u6743\u5668\u548c\u534f\u540c\u5bf9\u9f50\u4efb\u52a1\uff0c\u5728\u591a\u884c\u4e3a\u63a8\u8350\u4e2d\u6709\u6548\u6355\u6349\u8de8\u884c\u4e3a\u534f\u540c\u4fe1\u53f7\u548c\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5f3a\u5ea6\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fe\u7684\u591a\u884c\u4e3a\u63a8\u8350\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u8de8\u884c\u4e3a\u534f\u540c\u4fe1\u53f7\u548c\u4e2a\u4f53\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u5f3a\u5ea6\uff0c\u9700\u8981\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u6027\u6765\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "method": "\u63d0\u51faSynergy Weighted Graph Convolutional Network (SWGCN)\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u76ee\u6807\u504f\u597d\u52a0\u6743\u5668\uff08\u4e3a\u6bcf\u4e2a\u884c\u4e3a\u5185\u7684\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u81ea\u9002\u5e94\u5206\u914d\u6743\u91cd\uff09\u548c\u534f\u540c\u5bf9\u9f50\u4efb\u52a1\uff08\u901a\u8fc7\u8f85\u52a9\u504f\u597d\u8bc4\u4f30\u5668\u6307\u5bfc\u8bad\u7ec3\uff0c\u4f18\u5148\u8003\u8651\u80fd\u66f4\u51c6\u786e\u53cd\u6620\u7528\u6237\u504f\u597d\u7684\u534f\u540c\u4fe1\u53f7\u4ea4\u4e92\uff09\u3002", "result": "\u5728Taobao\u3001IJCAI\u548cBeibei\u4e09\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5728Taobao\u6570\u636e\u96c6\u4e0aHR\u76f8\u5bf9\u63d0\u5347112.49%\uff0cNDCG\u76f8\u5bf9\u63d0\u5347156.36%\uff0c\u5728\u5176\u4ed6\u6570\u636e\u96c6\u4e0a\u4e5f\u83b7\u5f97\u4e00\u81f4\u63d0\u5347\uff0c\u8bc1\u660e\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SWGCN\u901a\u8fc7\u6709\u6548\u6355\u6349\u8de8\u884c\u4e3a\u534f\u540c\u4fe1\u53f7\u548c\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5f3a\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u884c\u4e3a\u63a8\u8350\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.00730", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00730", "abs": "https://arxiv.org/abs/2602.00730", "authors": ["Zixuan Li"], "title": "Towards Trustworthy Multimodal Recommendation", "comment": "Preprint, 10 pages, 5 figures", "summary": "Recent advances in multimodal recommendation have demonstrated the effectiveness of incorporating visual and textual content into collaborative filtering. However, real-world deployments raise an increasingly important yet underexplored issue: trustworthiness. On modern e-commerce platforms, multimodal content can be misleading or unreliable (e.g., visually inconsistent product images or click-bait titles), injecting untrustworthy signals into multimodal representations and making existing recommenders brittle under modality corruption. In this work, we take a step towards trustworthy multimodal recommendation from both a method and an analysis perspective. First, we propose a plug-and-play modality-level rectification component that mitigates untrustworthy modality features by learning soft correspondences between items and multimodal features. Using lightweight projections and Sinkhorn-based soft matching, the rectification suppresses mismatched modality signals while preserving semantic consistency, and can be integrated into existing multimodal recommenders without architectural modifications. Second, we present two practical insights on interaction-level trustworthiness under noisy collaborative signals: (i) training-set pseudo interactions can help or hurt performance under noise depending on prior-signal alignment; and (ii) propagation-graph pseudo edges can also help or hurt robustness, as message passing may amplify misalignment. Extensive experiments on multiple datasets and backbones under varying corruption levels demonstrate improved robustness from modality rectification and validate the above interaction-level observations.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u63d2\u62d4\u7684\u6a21\u6001\u7ea7\u6821\u6b63\u7ec4\u4ef6\uff0c\u901a\u8fc7\u8f6f\u5bf9\u5e94\u5b66\u4e60\u7f13\u89e3\u4e0d\u53ef\u4fe1\u7684\u591a\u6a21\u6001\u7279\u5f81\uff0c\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u9c81\u68d2\u6027", "motivation": "\u73b0\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u63a8\u8350\u9762\u4e34\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u591a\u6a21\u6001\u5185\u5bb9\u53ef\u80fd\u5b58\u5728\u8bef\u5bfc\u6216\u4e0d\u4e00\u81f4\uff08\u5982\u89c6\u89c9\u4e0d\u4e00\u81f4\u7684\u4ea7\u54c1\u56fe\u7247\u6216\u70b9\u51fb\u8bf1\u9975\u6807\u9898\uff09\uff0c\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u5728\u6a21\u6001\u635f\u574f\u4e0b\u53d8\u5f97\u8106\u5f31", "method": "\u63d0\u51fa\u53ef\u63d2\u62d4\u7684\u6a21\u6001\u7ea7\u6821\u6b63\u7ec4\u4ef6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6295\u5f71\u548cSinkhorn\u8f6f\u5339\u914d\u5b66\u4e60\u7269\u54c1\u4e0e\u591a\u6a21\u6001\u7279\u5f81\u95f4\u7684\u8f6f\u5bf9\u5e94\u5173\u7cfb\uff0c\u6291\u5236\u4e0d\u5339\u914d\u7684\u6a21\u6001\u4fe1\u53f7\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u9aa8\u5e72\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u6001\u6821\u6b63\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u4ea4\u4e92\u7ea7\u53ef\u4fe1\u5ea6\u7684\u4e24\u4e2a\u89c2\u5bdf\uff1a\u8bad\u7ec3\u96c6\u4f2a\u4ea4\u4e92\u548c\u4f20\u64ad\u56fe\u4f2a\u8fb9\u5728\u566a\u58f0\u4e0b\u7684\u53cc\u91cd\u5f71\u54cd", "conclusion": "\u6a21\u6001\u7ea7\u6821\u6b63\u7ec4\u4ef6\u80fd\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5904\u7406\u4e0d\u53ef\u4fe1\u591a\u6a21\u6001\u5185\u5bb9\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00805", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00805", "abs": "https://arxiv.org/abs/2602.00805", "authors": ["Yunhan Li", "Mingjie Xie", "Zihan Gong", "Zeyang Shi", "Gengshen Wu", "Min Yang"], "title": "Optimizing Retrieval Components for a Shared Backbone via Component-Wise Multi-Stage Training", "comment": "4 pages, 3 figures, 3 tables", "summary": "Recent advances in embedding-based retrieval have enabled dense retrievers to serve as core infrastructure in many industrial systems, where a single retrieval backbone is often shared across multiple downstream applications. In such settings, retrieval quality directly constrains system performance and extensibility, while coupling model selection, deployment, and rollback decisions across applications.\n  In this paper, we present empirical findings and a system-level solution for optimizing retrieval components deployed as a shared backbone in production legal retrieval systems. We adopt a multi-stage optimization framework for dense retrievers and rerankers, and show that different retrieval components exhibit stage-dependent trade-offs. These observations motivate a component-wise, mixed-stage configuration rather than relying on a single uniformly optimal checkpoint. The resulting backbone is validated through end-to-end evaluation and deployed as a shared retrieval service supporting multiple industrial applications.", "AI": {"tldr": "\u9488\u5bf9\u5de5\u4e1a\u6cd5\u5f8b\u68c0\u7d22\u7cfb\u7edf\u4e2d\u5171\u4eab\u68c0\u7d22\u9aa8\u5e72\u7f51\u7edc\u7684\u4f18\u5316\uff0c\u63d0\u51fa\u57fa\u4e8e\u591a\u9636\u6bb5\u4f18\u5316\u7684\u7ec4\u4ef6\u7ea7\u6df7\u5408\u914d\u7f6e\u65b9\u6cd5\uff0c\u66ff\u4ee3\u5355\u4e00\u6700\u4f18\u68c0\u67e5\u70b9\u7b56\u7565", "motivation": "\u5728\u5de5\u4e1a\u7cfb\u7edf\u4e2d\uff0c\u5355\u4e00\u68c0\u7d22\u9aa8\u5e72\u7f51\u7edc\u901a\u5e38\u88ab\u591a\u4e2a\u4e0b\u6e38\u5e94\u7528\u5171\u4eab\uff0c\u68c0\u7d22\u8d28\u91cf\u76f4\u63a5\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u8026\u5408\u4e86\u8de8\u5e94\u7528\u7684\u6a21\u578b\u9009\u62e9\u3001\u90e8\u7f72\u548c\u56de\u6eda\u51b3\u7b56", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u4f18\u5316\u6846\u67b6\u5bf9\u7a20\u5bc6\u68c0\u7d22\u5668\u548c\u91cd\u6392\u5e8f\u5668\u8fdb\u884c\u4f18\u5316\uff0c\u53d1\u73b0\u4e0d\u540c\u68c0\u7d22\u7ec4\u4ef6\u5448\u73b0\u9636\u6bb5\u4f9d\u8d56\u7684\u6743\u8861\uff0c\u63d0\u51fa\u7ec4\u4ef6\u7ea7\u6df7\u5408\u9636\u6bb5\u914d\u7f6e\u65b9\u6cd5", "result": "\u901a\u8fc7\u7aef\u5230\u7aef\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u4f18\u5316\u540e\u7684\u68c0\u7d22\u9aa8\u5e72\u7f51\u7edc\uff0c\u5e76\u4f5c\u4e3a\u5171\u4eab\u68c0\u7d22\u670d\u52a1\u90e8\u7f72\u5230\u652f\u6301\u591a\u4e2a\u5de5\u4e1a\u5e94\u7528\u4e2d", "conclusion": "\u5728\u5de5\u4e1a\u6cd5\u5f8b\u68c0\u7d22\u7cfb\u7edf\u4e2d\uff0c\u7ec4\u4ef6\u7ea7\u6df7\u5408\u9636\u6bb5\u914d\u7f6e\u6bd4\u5355\u4e00\u6700\u4f18\u68c0\u67e5\u70b9\u7b56\u7565\u66f4\u6709\u6548\uff0c\u80fd\u591f\u4f18\u5316\u5171\u4eab\u68c0\u7d22\u9aa8\u5e72\u7f51\u7edc\u7684\u6027\u80fd"}}
{"id": "2602.01023", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01023", "abs": "https://arxiv.org/abs/2602.01023", "authors": ["Kai Yuan", "Anthony Zheng", "Jia Hu", "Divyanshu Sheth", "Hemanth Velaga", "Kylee Kim", "Matteo Guarrera", "Besim Avci", "Xuetao Yin", "Rajyashree Mukherjee", "Sean Suchter"], "title": "Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment", "comment": "11 pages, 4 figures", "summary": "Query Auto-Completion (QAC) suggests query completions as users type, helping them articulate intent and reach results more efficiently. Existing approaches face fundamental challenges: traditional retrieve-and-rank pipelines have limited long-tail coverage and require extensive feature engineering, while recent generative methods suffer from hallucination and safety risks. We present a unified framework that reformulates QAC as end-to-end list generation through Retrieval-Augmented Generation (RAG) and multi-objective Direct Preference Optimization (DPO). Our approach combines three key innovations: (1) reformulating QAC as end-to-end list generation with multi-objective optimization; (2) defining and deploying a suite of rule-based, model-based, and LLM-as-judge verifiers for QAC, and using them in a comprehensive methodology that combines RAG, multi-objective DPO, and iterative critique-revision for high-quality synthetic data; (3) a hybrid serving architecture enabling efficient production deployment under strict latency constraints. Evaluation on a large-scale commercial search platform demonstrates substantial improvements: offline metrics show gains across all dimensions, human evaluation yields +0.40 to +0.69 preference scores, and a controlled online experiment achieves 5.44\\% reduction in keystrokes and 3.46\\% increase in suggestion adoption, validating that unified generation with RAG and multi-objective alignment provides an effective solution for production QAC. This work represents a paradigm shift to end-to-end generation powered by large language models, RAG, and multi-objective alignment, establishing a production-validated framework that can benefit the broader search and recommendation industry.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u67e5\u8be2\u81ea\u52a8\u8865\u5168\u6846\u67b6\uff0c\u5c06QAC\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7aef\u5230\u7aef\u5217\u8868\u751f\u6210\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u591a\u76ee\u6807\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff0c\u5728\u5546\u4e1a\u641c\u7d22\u5e73\u53f0\u4e0a\u53d6\u5f97\u663e\u8457\u6548\u679c\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u67e5\u8be2\u81ea\u52a8\u8865\u5168\u65b9\u6cd5\u9762\u4e34\u6839\u672c\u6311\u6218\uff1a\u4f20\u7edf\u7684\u68c0\u7d22-\u6392\u5e8f\u6d41\u6c34\u7ebf\u957f\u5c3e\u8986\u76d6\u6709\u9650\u4e14\u9700\u8981\u5927\u91cf\u7279\u5f81\u5de5\u7a0b\uff0c\u800c\u751f\u6210\u5f0f\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u5b89\u5168\u98ce\u9669\u3002\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "1) \u5c06QAC\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7aef\u5230\u7aef\u5217\u8868\u751f\u6210\u5e76\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\uff1b2) \u90e8\u7f72\u57fa\u4e8e\u89c4\u5219\u3001\u57fa\u4e8e\u6a21\u578b\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u9a8c\u8bc1\u5668\u5957\u4ef6\uff0c\u7ed3\u5408RAG\u3001\u591a\u76ee\u6807DPO\u548c\u8fed\u4ee3\u6279\u5224-\u4fee\u8ba2\u65b9\u6cd5\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\uff1b3) \u6df7\u5408\u670d\u52a1\u67b6\u6784\u5728\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u751f\u4ea7\u90e8\u7f72\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5546\u4e1a\u641c\u7d22\u5e73\u53f0\u4e0a\u8bc4\u4f30\u663e\u793a\uff1a\u79bb\u7ebf\u6307\u6807\u5728\u6240\u6709\u7ef4\u5ea6\u5747\u6709\u63d0\u5347\uff0c\u4eba\u5de5\u8bc4\u4f30\u83b7\u5f97+0.40\u5230+0.69\u504f\u597d\u5206\u6570\uff0c\u53d7\u63a7\u5728\u7ebf\u5b9e\u9a8c\u5b9e\u73b05.44%\u51fb\u952e\u51cf\u5c11\u548c3.46%\u5efa\u8bae\u91c7\u7eb3\u7387\u589e\u52a0\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u5411\u7531\u5927\u8bed\u8a00\u6a21\u578b\u3001RAG\u548c\u591a\u76ee\u6807\u5bf9\u9f50\u9a71\u52a8\u7684\u7aef\u5230\u7aef\u751f\u6210\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u751f\u4ea7\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u53ef\u4e3a\u66f4\u5e7f\u6cdb\u7684\u641c\u7d22\u548c\u63a8\u8350\u884c\u4e1a\u5e26\u6765\u76ca\u5904\u3002"}}
{"id": "2602.01865", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01865", "abs": "https://arxiv.org/abs/2602.01865", "authors": ["Shaopeng Chen", "Chuyue Xie", "Huimin Ren", "Shaozong Zhang", "Han Zhang", "Ruobing Cheng", "Zhiqiang Cao", "Zehao Ju", "Gao Yu", "Jie Ding", "Xiaodong Chen", "Xuewu Jiao", "Shuanglong Li", "Liu Lin"], "title": "GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm", "comment": null, "summary": "Traditional Deep Learning Recommendation Models (DLRMs) face increasing bottlenecks in performance and efficiency, often struggling with generalization and long-sequence modeling. Inspired by the scaling success of Large Language Models (LLMs), we propose Generative Ranking for Ads at Baidu (GRAB), an end-to-end generative framework for Click-Through Rate (CTR) prediction. GRAB integrates a novel Causal Action-aware Multi-channel Attention (CamA) mechanism to effectively capture temporal dynamics and specific action signals within user behavior sequences. Full-scale online deployment demonstrates that GRAB significantly outperforms established DLRMs, delivering a 3.05% increase in revenue and a 3.49% rise in CTR. Furthermore, the model demonstrates desirable scaling behavior: its expressive power shows a monotonic and approximately linear improvement as longer interaction sequences are utilized.", "AI": {"tldr": "GRAB\u662f\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0f\u6846\u67b6\u7684CTR\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u56e0\u679c\u611f\u77e5\u591a\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u767e\u5ea6\u5e7f\u544a\u7cfb\u7edf\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6536\u5165\u548c\u70b9\u51fb\u7387\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u63a8\u8350\u6a21\u578b\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u9762\u4e34\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u6cdb\u5316\u80fd\u529b\u548c\u957f\u5e8f\u5217\u5efa\u6a21\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u53d7\u5230\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u6210\u529f\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6709\u6548\u5904\u7406\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u7684\u7aef\u5230\u7aef\u751f\u6210\u5f0f\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86GRAB\uff08Generative Ranking for Ads at Baidu\uff09\u6846\u67b6\uff0c\u91c7\u7528\u521b\u65b0\u7684\u56e0\u679c\u611f\u77e5\u591a\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\uff08CamA\uff09\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u52a8\u6001\u548c\u7279\u5b9a\u52a8\u4f5c\u4fe1\u53f7\u3002", "result": "\u5168\u89c4\u6a21\u5728\u7ebf\u90e8\u7f72\u663e\u793a\uff0cGRAB\u663e\u8457\u4f18\u4e8e\u73b0\u6709DLRMs\uff0c\u5e26\u67653.05%\u7684\u6536\u5165\u589e\u957f\u548c3.49%\u7684CTR\u63d0\u5347\u3002\u6a21\u578b\u8868\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\uff1a\u968f\u7740\u4f7f\u7528\u66f4\u957f\u7684\u4ea4\u4e92\u5e8f\u5217\uff0c\u5176\u8868\u8fbe\u80fd\u529b\u5448\u73b0\u5355\u8c03\u4e14\u8fd1\u4f3c\u7ebf\u6027\u7684\u63d0\u5347\u3002", "conclusion": "GRAB\u6210\u529f\u5c06\u751f\u6210\u5f0f\u6846\u67b6\u5e94\u7528\u4e8eCTR\u9884\u6d4b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u4e86\u4f20\u7edf\u63a8\u8350\u6a21\u578b\u7684\u74f6\u9888\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u4e1a\u52a1\u6548\u679c\u63d0\u5347\uff0c\u5e76\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u7279\u6027\u3002"}}
{"id": "2602.02024", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02024", "abs": "https://arxiv.org/abs/2602.02024", "authors": ["Cl\u00e9mence R\u00e9da", "Tomas Rigaux", "Hiba Bederina", "Koh Takeuchi", "Hisashi Kashima", "Jill-J\u00eann Vie"], "title": "Adaptive Quality-Diversity Trade-offs for Large-Scale Batch Recommendation", "comment": null, "summary": "A core research question in recommender systems is to propose batches of highly relevant and diverse items, that is, items personalized to the user's preferences, but which also might get the user out of their comfort zone. This diversity might induce properties of serendipidity and novelty which might increase user engagement or revenue. However, many real-life problems arise in that case: e.g., avoiding to recommend distinct but too similar items to reduce the churn risk, and computational cost for large item libraries, up to millions of items. First, we consider the case when the user feedback model is perfectly observed and known in advance, and introduce an efficient algorithm called B-DivRec combining determinantal point processes and a fuzzy denuding procedure to adjust the degree of item diversity. This helps enforcing a quality-diversity trade-off throughout the user history. Second, we propose an approach to adaptively tailor the quality-diversity trade-off to the user, so that diversity in recommendations can be enhanced if it leads to positive feedback, and vice-versa. Finally, we illustrate the performance and versatility of B-DivRec in the two settings on synthetic and real-life data sets on movie recommendation and drug repurposing.", "AI": {"tldr": "\u63d0\u51faB-DivRec\u7b97\u6cd5\uff0c\u7ed3\u5408\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u548c\u6a21\u7cca\u53bb\u91cd\u6280\u672f\uff0c\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5e73\u8861\u76f8\u5173\u6027\u4e0e\u591a\u6837\u6027\uff0c\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u8d28\u91cf-\u591a\u6837\u6027\u6743\u8861\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u9700\u8981\u540c\u65f6\u63a8\u8350\u9ad8\u5ea6\u76f8\u5173\u4e14\u591a\u6837\u5316\u7684\u7269\u54c1\uff0c\u65e2\u8981\u4e2a\u6027\u5316\u53c8\u8981\u7a81\u7834\u7528\u6237\u8212\u9002\u533a\uff0c\u4f46\u73b0\u5b9e\u4e2d\u5b58\u5728\u907f\u514d\u63a8\u8350\u8fc7\u4e8e\u76f8\u4f3c\u7269\u54c1\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u6311\u6218\u3002", "method": "1. \u5728\u7528\u6237\u53cd\u9988\u6a21\u578b\u5df2\u77e5\u60c5\u51b5\u4e0b\uff0c\u63d0\u51faB-DivRec\u7b97\u6cd5\uff0c\u7ed3\u5408\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u548c\u6a21\u7cca\u53bb\u91cd\u6280\u672f\u8c03\u6574\u7269\u54c1\u591a\u6837\u6027\u7a0b\u5ea6\uff1b2. \u63d0\u51fa\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u6839\u636e\u7528\u6237\u53cd\u9988\u52a8\u6001\u8c03\u6574\u8d28\u91cf-\u591a\u6837\u6027\u6743\u8861\u3002", "result": "\u5728\u7535\u5f71\u63a8\u8350\u548c\u836f\u7269\u518d\u5229\u7528\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86B-DivRec\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u5e73\u8861\u76f8\u5173\u6027\u4e0e\u591a\u6837\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "B-DivRec\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8d28\u91cf-\u591a\u6837\u6027\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u673a\u5236\u53ef\u4ee5\u4f18\u5316\u7528\u6237\u4f53\u9a8c\u548c\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2602.02338", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02338", "abs": "https://arxiv.org/abs/2602.02338", "authors": ["Yu Liang", "Zhongjin Zhang", "Yuxuan Zhu", "Kerui Zhang", "Zhiluohan Guo", "Wenhang Zhou", "Zonqi Yang", "Kangle Wu", "Yabo Ni", "Anxiang Zeng", "Cong Fu", "Jianxin Wang", "Jiazhi Xia"], "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs", "comment": null, "summary": "Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.", "AI": {"tldr": "ReSID\u662f\u4e00\u4e2a\u63a8\u8350\u539f\u751f\u7684\u8bed\u4e49ID\u6846\u67b6\uff0c\u901a\u8fc7\u573a\u611f\u77e5\u63a9\u7801\u81ea\u7f16\u7801\u548c\u5168\u5c40\u5bf9\u9f50\u6b63\u4ea4\u91cf\u5316\uff0c\u5728\u4e0d\u4f9d\u8d56LLM\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u5e8f\u5217\u63a8\u8350\uff0c\u6027\u80fd\u63d0\u534710%\u4ee5\u4e0a\uff0ctoken\u5316\u6210\u672c\u964d\u4f4e122\u500d\u3002", "motivation": "\u73b0\u6709\u8bed\u4e49ID\u63a8\u8350\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u5d4c\u5165\u4e0e\u534f\u540c\u9884\u6d4b\u5f31\u8026\u5408\u3001\u901a\u7528\u91cf\u5316\u5bf9\u81ea\u56de\u5f52\u5efa\u6a21\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u4ece\u4fe1\u606f\u4fdd\u7559\u548c\u5e8f\u5217\u53ef\u9884\u6d4b\u6027\u89d2\u5ea6\u91cd\u65b0\u8bbe\u8ba1\u3002", "method": "\u63d0\u51faReSID\u6846\u67b6\uff1a1) \u573a\u611f\u77e5\u63a9\u7801\u81ea\u7f16\u7801(FAMAE)\u4ece\u7ed3\u6784\u5316\u7279\u5f81\u5b66\u4e60\u9884\u6d4b\u5145\u5206\u7684\u7269\u54c1\u8868\u793a\uff1b2) \u5168\u5c40\u5bf9\u9f50\u6b63\u4ea4\u91cf\u5316(GAOQ)\u901a\u8fc7\u8054\u5408\u51cf\u5c11\u8bed\u4e49\u6a21\u7cca\u6027\u548c\u524d\u7f00\u6761\u4ef6\u4e0d\u786e\u5b9a\u6027\u6765\u751f\u6210\u7d27\u51d1\u53ef\u9884\u6d4b\u7684SID\u5e8f\u5217\u3002", "result": "\u572810\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cReSID\u6301\u7eed\u4f18\u4e8e\u5f3a\u5e8f\u5217\u548cSID\u751f\u6210\u57fa\u7ebf\uff0c\u5e73\u5747\u63d0\u5347\u8d85\u8fc710%\uff0c\u540c\u65f6token\u5316\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe122\u500d\u3002", "conclusion": "ReSID\u63d0\u4f9b\u4e86\u4e00\u4e2a\u63a8\u8350\u539f\u751f\u7684\u8bed\u4e49ID\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u65b0\u601d\u8003\u8868\u793a\u5b66\u4e60\u548c\u91cf\u5316\u8bbe\u8ba1\uff0c\u5728\u4e0d\u4f9d\u8d56LLM\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u8350\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2602.02444", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.02444", "abs": "https://arxiv.org/abs/2602.02444", "authors": ["Tyler Skow", "Alexander Martin", "Benjamin Van Durme", "Rama Chellappa", "Reno Kriz"], "title": "RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval", "comment": null, "summary": "Reranking is a critical component of modern retrieval systems, which typically pair an efficient first-stage retriever with a more expressive model to refine results. While large reasoning models have driven rapid progress in text-centric reranking, reasoning-based reranking for video retrieval remains underexplored. To address this gap, we introduce RANKVIDEO, a reasoning-based reranker for video retrieval that explicitly reasons over query-video pairs using video content to assess relevance. RANKVIDEO is trained using a two-stage curriculum consisting of perception-grounded supervised fine-tuning followed by reranking training that combines pointwise, pairwise, and teacher confidence distillation objectives, and is supported by a data synthesis pipeline for constructing reasoning-intensive query-video pairs. Experiments on the large-scale MultiVENT 2.0 benchmark demonstrate that RANKVIDEO consistently improves retrieval performance within a two-stage framework, yielding an average improvement of 31% on nDCG@10 and outperforming text-only and vision-language reranking alternatives, while more efficient.", "AI": {"tldr": "RANKVIDEO\uff1a\u7528\u4e8e\u89c6\u9891\u68c0\u7d22\u7684\u57fa\u4e8e\u63a8\u7406\u7684\u91cd\u65b0\u6392\u5e8f\u5668\uff0c\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u67e5\u8be2-\u89c6\u9891\u5bf9\u6765\u63d0\u5347\u68c0\u7d22\u6027\u80fd", "motivation": "\u867d\u7136\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u6587\u672c\u91cd\u65b0\u6392\u5e8f\u65b9\u9762\u53d6\u5f97\u4e86\u5feb\u901f\u8fdb\u5c55\uff0c\u4f46\u57fa\u4e8e\u63a8\u7406\u7684\u89c6\u9891\u68c0\u7d22\u91cd\u65b0\u6392\u5e8f\u4ecd\u7136\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u5bf9\u67e5\u8be2-\u89c6\u9891\u5bf9\u7684\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faRANKVIDEO\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bfe\u7a0b\u8bad\u7ec3\uff1a1\uff09\u611f\u77e5\u57fa\u7840\u7684\u76d1\u7763\u5fae\u8c03\uff1b2\uff09\u7ed3\u5408\u70b9\u5bf9\u3001\u5bf9\u5076\u548c\u6559\u5e08\u7f6e\u4fe1\u5ea6\u84b8\u998f\u76ee\u6807\u7684\u91cd\u65b0\u6392\u5e8f\u8bad\u7ec3\u3002\u652f\u6301\u6570\u636e\u5408\u6210\u6d41\u7a0b\u6784\u5efa\u63a8\u7406\u5bc6\u96c6\u7684\u67e5\u8be2-\u89c6\u9891\u5bf9\u3002", "result": "\u5728MultiVENT 2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRANKVIDEO\u5728\u4e24\u7ea7\u68c0\u7d22\u6846\u67b6\u4e0b\u5e73\u5747\u63d0\u534731%\u7684nDCG@10\u6027\u80fd\uff0c\u4f18\u4e8e\u7eaf\u6587\u672c\u548c\u89c6\u89c9\u8bed\u8a00\u91cd\u65b0\u6392\u5e8f\u66ff\u4ee3\u65b9\u6848\uff0c\u540c\u65f6\u66f4\u9ad8\u6548\u3002", "conclusion": "RANKVIDEO\u8bc1\u660e\u4e86\u57fa\u4e8e\u63a8\u7406\u7684\u91cd\u65b0\u6392\u5e8f\u5728\u89c6\u9891\u68c0\u7d22\u4e2d\u7684\u6709\u6548\u6027\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u89c6\u9891\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u91cd\u65b0\u6392\u5e8f\u80fd\u529b\u3002"}}
