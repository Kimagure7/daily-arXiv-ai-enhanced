{"id": "2510.09857", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09857", "abs": "https://arxiv.org/abs/2510.09857", "authors": ["Xiao Yang", "Peifeng Yin", "Abe Engle", "Jinfeng Zhuang", "Ling Leng"], "title": "MTMD: A Multi-Task Multi-Domain Framework for Unified Ad Lightweight Ranking at Pinterest", "comment": "AdKDD 2025", "summary": "The lightweight ad ranking layer, living after the retrieval stage and before\nthe fine ranker, plays a critical role in the success of a cascaded ad\nrecommendation system. Due to the fact that there are multiple optimization\ntasks depending on the ad domain, e.g., Click Through Rate (CTR) for click ads\nand Conversion Rate (CVR) for conversion ads, as well as multiple surfaces\nwhere an ad is served (home feed, search, or related item recommendation) with\ndiverse ad products (shopping or standard ad); it is an essentially challenging\nproblem in industry on how to do joint holistic optimization in the lightweight\nranker, such that the overall platform's value, advertiser's value, and user's\nvalue are maximized.\n  Deep Neural Network (DNN)-based multitask learning (MTL) can handle multiple\ngoals naturally, with each prediction head mapping to a particular optimization\ngoal. However, in practice, it is unclear how to unify data from different\nsurfaces and ad products into a single model. It is critical to learn\ndomain-specialized knowledge and explicitly transfer knowledge between domains\nto make MTL effective. We present a Multi-Task Multi-Domain (MTMD) architecture\nunder the classic Two-Tower paradigm, with the following key contributions: 1)\nhandle different prediction tasks, ad products, and ad serving surfaces in a\nunified framework; 2) propose a novel mixture-of-expert architecture to learn\nboth specialized knowledge each domain and common knowledge shared between\ndomains; 3) propose a domain adaption module to encourage knowledge transfer\nbetween experts; 4) constrain the modeling of different prediction tasks. MTMD\nimproves the offline loss value by 12% to 36%, mapping to 2% online reduction\nin cost per click. We have deployed this single MTMD framework into production\nfor Pinterest ad recommendation replacing 9 production models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4efb\u52a1\u591a\u9886\u57df\uff08MTMD\uff09\u67b6\u6784\uff0c\u7528\u4e8e\u8f7b\u91cf\u7ea7\u5e7f\u544a\u6392\u5e8f\u5c42\u7684\u8054\u5408\u4f18\u5316\uff0c\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u548c\u9886\u57df\u9002\u5e94\u6a21\u5757\u5b9e\u73b0\u8de8\u9886\u57df\u77e5\u8bc6\u5171\u4eab\u4e0e\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u4e2d\u591a\u4f18\u5316\u4efb\u52a1\uff08\u5982CTR\u3001CVR\uff09\u3001\u591a\u5e7f\u544a\u4ea7\u54c1\uff08\u8d2d\u7269\u5e7f\u544a\u3001\u6807\u51c6\u5e7f\u544a\uff09\u548c\u591a\u6295\u653e\u573a\u666f\uff08\u9996\u9875\u3001\u641c\u7d22\u3001\u76f8\u5173\u63a8\u8350\uff09\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5927\u5316\u5e73\u53f0\u3001\u5e7f\u544a\u4e3b\u548c\u7528\u6237\u4ef7\u503c\u3002", "method": "\u57fa\u4e8e\u53cc\u5854\u8303\u5f0f\u6784\u5efaMTMD\u67b6\u6784\uff0c\u91c7\u7528\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u5b66\u4e60\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u548c\u5171\u4eab\u77e5\u8bc6\uff0c\u5f15\u5165\u9886\u57df\u9002\u5e94\u6a21\u5757\u4fc3\u8fdb\u4e13\u5bb6\u95f4\u77e5\u8bc6\u8fc1\u79fb\uff0c\u5e76\u5bf9\u4e0d\u540c\u9884\u6d4b\u4efb\u52a1\u8fdb\u884c\u7ea6\u675f\u5efa\u6a21\u3002", "result": "\u79bb\u7ebf\u635f\u5931\u503c\u964d\u4f4e12%-36%\uff0c\u5bf9\u5e94\u5728\u7ebf\u6bcf\u6b21\u70b9\u51fb\u6210\u672c\u51cf\u5c112%\uff0c\u5df2\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u66ff\u4ee39\u4e2a\u751f\u4ea7\u6a21\u578b\u3002", "conclusion": "MTMD\u6846\u67b6\u6210\u529f\u7edf\u4e00\u4e86\u591a\u4efb\u52a1\u591a\u9886\u57df\u7684\u5e7f\u544a\u63a8\u8350\u4f18\u5316\uff0c\u901a\u8fc7\u77e5\u8bc6\u5171\u4eab\u548c\u8fc1\u79fb\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.09897", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.09897", "abs": "https://arxiv.org/abs/2510.09897", "authors": ["Wonbin Kweon", "Runchu Tian", "SeongKu Kang", "Pengcheng Jiang", "Zhiyong Lu", "Jiawei Han", "Hwanjo Yu"], "title": "PairSem: LLM-Guided Pairwise Semantic Matching for Scientific Document Retrieval", "comment": null, "summary": "Scientific document retrieval is a critical task for enabling knowledge\ndiscovery and supporting research across diverse domains. However, existing\ndense retrieval methods often struggle to capture fine-grained scientific\nconcepts in texts due to their reliance on holistic embeddings and limited\ndomain understanding. Recent approaches leverage large language models (LLMs)\nto extract fine-grained semantic entities and enhance semantic matching, but\nthey typically treat entities as independent fragments, overlooking the\nmulti-faceted nature of scientific concepts. To address this limitation, we\npropose Pairwise Semantic Matching (PairSem), a framework that represents\nrelevant semantics as entity-aspect pairs, capturing complex, multi-faceted\nscientific concepts. PairSem is unsupervised, base retriever-agnostic, and\nplug-and-play, enabling precise and context-aware matching without requiring\nquery-document labels or entity annotations. Extensive experiments on multiple\ndatasets and retrievers demonstrate that PairSem significantly improves\nretrieval performance, highlighting the importance of modeling multi-aspect\nsemantics in scientific information retrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e86Pairwise Semantic Matching (PairSem)\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u4f53-\u65b9\u9762\u5bf9\u8868\u793a\u76f8\u5173\u8bed\u4e49\uff0c\u6355\u6349\u590d\u6742\u591a\u65b9\u9762\u7684\u79d1\u5b66\u6982\u5ff5\uff0c\u663e\u8457\u63d0\u5347\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u6027\u80fd", "motivation": "\u73b0\u6709\u5bc6\u96c6\u68c0\u7d22\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u6587\u672c\u4e2d\u7684\u7ec6\u7c92\u5ea6\u79d1\u5b66\u6982\u5ff5\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u6574\u4f53\u5d4c\u5165\u4e14\u9886\u57df\u7406\u89e3\u6709\u9650\u3002\u867d\u7136\u6700\u8fd1\u65b9\u6cd5\u5229\u7528LLM\u63d0\u53d6\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5b9e\u4f53\uff0c\u4f46\u901a\u5e38\u5c06\u5b9e\u4f53\u89c6\u4e3a\u72ec\u7acb\u7247\u6bb5\uff0c\u5ffd\u7565\u4e86\u79d1\u5b66\u6982\u5ff5\u7684\u591a\u65b9\u9762\u6027\u8d28", "method": "\u63d0\u51faPairSem\u6846\u67b6\uff0c\u5c06\u76f8\u5173\u8bed\u4e49\u8868\u793a\u4e3a\u5b9e\u4f53-\u65b9\u9762\u5bf9\uff0c\u6355\u6349\u590d\u6742\u591a\u65b9\u9762\u7684\u79d1\u5b66\u6982\u5ff5\u3002\u8be5\u6846\u67b6\u662f\u65e0\u76d1\u7763\u7684\u3001\u57fa\u7840\u68c0\u7d22\u5668\u65e0\u5173\u7684\u3001\u5373\u63d2\u5373\u7528\u7684\uff0c\u65e0\u9700\u67e5\u8be2-\u6587\u6863\u6807\u7b7e\u6216\u5b9e\u4f53\u6807\u6ce8", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u68c0\u7d22\u5668\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPairSem\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u6027\u80fd", "conclusion": "\u8bc1\u660e\u4e86\u5728\u79d1\u5b66\u4fe1\u606f\u68c0\u7d22\u4e2d\u5efa\u6a21\u591a\u65b9\u9762\u8bed\u4e49\u7684\u91cd\u8981\u6027"}}
{"id": "2510.10095", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10095", "abs": "https://arxiv.org/abs/2510.10095", "authors": ["Peiyuan Gong", "Feiran Zhu", "Yaqi Yin", "Chenglei Dai", "Chao Zhang", "Kai Zheng", "Wentian Bao", "Jiaxin Mao", "Yi Zhang"], "title": "CardRewriter: Leveraging Knowledge Cards for Long-Tail Query Rewriting on Short-Video Platforms", "comment": null, "summary": "Short-video platforms have rapidly become a new generation of information\nretrieval systems, where users formulate queries to access desired videos.\nHowever, user queries, especially long-tail ones, often suffer from spelling\nerrors, incomplete phrasing, and ambiguous intent, resulting in mismatches\nbetween user expectations and retrieved results. While large language models\n(LLMs) have shown success in long-tail query rewriting within e-commerce, they\nstruggle on short-video platforms, where proprietary content such as short\nvideos, live streams, micro dramas, and user social networks falls outside\ntheir training distribution. To address this challenge, we introduce\n\\textbf{CardRewriter}, an LLM-based framework that incorporates domain-specific\nknowledge to enhance long-tail query rewriting. For each query, our method\naggregates multi-source knowledge relevant to the query and summarizes it into\nan informative and query-relevant knowledge card. This card then guides the LLM\nto better capture user intent and produce more effective query rewrites. We\noptimize CardRewriter using a two-stage training pipeline: supervised\nfine-tuning followed by group relative policy optimization, with a tailored\nreward system balancing query relevance and retrieval effectiveness. Offline\nexperiments show that CardRewriter substantially improves rewriting quality for\nqueries targeting proprietary content. Online A/B testing further confirms\nsignificant gains in long-view rate (LVR) and click-through rate (CTR), along\nwith a notable reduction in initiative query reformulation rate (IQRR). Since\nSeptember 2025, CardRewriter has been deployed on Kuaishou, one of China's\nlargest short-video platforms, serving hundreds of millions of users daily.", "AI": {"tldr": "CardRewriter\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u77ed\u89c6\u9891\u5e73\u53f0\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u6765\u6539\u8fdb\u957f\u5c3e\u67e5\u8be2\u91cd\u5199\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u76f8\u5173\u6027\u548c\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u77ed\u89c6\u9891\u5e73\u53f0\u7528\u6237\u67e5\u8be2\u5b58\u5728\u62fc\u5199\u9519\u8bef\u3001\u8868\u8ff0\u4e0d\u5b8c\u6574\u548c\u610f\u56fe\u6a21\u7cca\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u68c0\u7d22\u7ed3\u679c\u4e0e\u7528\u6237\u671f\u671b\u4e0d\u5339\u914d\u3002\u4f20\u7edfLLM\u5728\u77ed\u89c6\u9891\u5e73\u53f0\u4e13\u6709\u5185\u5bb9\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u5185\u5bb9\u4e0d\u5728\u5176\u8bad\u7ec3\u5206\u5e03\u4e2d\u3002", "method": "\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u805a\u5408\u591a\u6e90\u76f8\u5173\u77e5\u8bc6\u5e76\u603b\u7ed3\u6210\u4fe1\u606f\u4e30\u5bcc\u7684\u77e5\u8bc6\u5361\u7247\uff0c\u7528\u8be5\u5361\u7247\u6307\u5bfcLLM\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u610f\u56fe\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\u76d1\u7763\u5fae\u8c03\u540e\u63a5\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u5e76\u8bbe\u8ba1\u5e73\u8861\u67e5\u8be2\u76f8\u5173\u6027\u548c\u68c0\u7d22\u6548\u679c\u7684\u5956\u52b1\u7cfb\u7edf\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793aCardRewriter\u663e\u8457\u63d0\u5347\u4e13\u6709\u5185\u5bb9\u67e5\u8be2\u7684\u91cd\u5199\u8d28\u91cf\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u8bc1\u5b9e\u957f\u89c2\u770b\u7387\u548c\u70b9\u51fb\u7387\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u4e3b\u52a8\u67e5\u8be2\u91cd\u6784\u7387\u660e\u663e\u964d\u4f4e\u3002", "conclusion": "CardRewriter\u81ea2025\u5e749\u6708\u8d77\u5df2\u5728\u5feb\u624b\u5e73\u53f0\u90e8\u7f72\uff0c\u6bcf\u65e5\u4e3a\u6570\u4ebf\u7528\u6237\u63d0\u4f9b\u670d\u52a1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u77ed\u89c6\u9891\u5e73\u53f0\u957f\u5c3e\u67e5\u8be2\u91cd\u5199\u95ee\u9898\u3002"}}
{"id": "2510.10109", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10109", "abs": "https://arxiv.org/abs/2510.10109", "authors": ["Shuangquan Lyu", "Ming Wang", "Huajun Zhang", "Jiasen Zheng", "Junjiang Lin", "Xiaoxuan Sun"], "title": "Integrating Structure-Aware Attention and Knowledge Graphs in Explainable Recommendation Systems", "comment": null, "summary": "This paper designs and implements an explainable recommendation model that\nintegrates knowledge graphs with structure-aware attention mechanisms. The\nmodel is built on graph neural networks and incorporates a multi-hop neighbor\naggregation strategy. By integrating the structural information of knowledge\ngraphs and dynamically assigning importance to different neighbors through an\nattention mechanism, the model enhances its ability to capture implicit\npreference relationships. In the proposed method, users and items are embedded\ninto a unified graph structure. Multi-level semantic paths are constructed\nbased on entities and relations in the knowledge graph to extract richer\ncontextual information. During the rating prediction phase, recommendations are\ngenerated through the interaction between user and target item representations.\nThe model is optimized using a binary cross-entropy loss function. Experiments\nconducted on the Amazon Books dataset validate the superior performance of the\nproposed model across various evaluation metrics. The model also shows good\nconvergence and stability. These results further demonstrate the effectiveness\nand practicality of structure-aware attention mechanisms in knowledge\ngraph-enhanced recommendation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u7ed3\u6784\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u7684\u53ef\u89e3\u91ca\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u591a\u8df3\u90bb\u5c45\u805a\u5408\u7b56\u7565\uff0c\u52a8\u6001\u5206\u914d\u90bb\u5c45\u91cd\u8981\u6027\u4ee5\u6355\u6349\u9690\u5f0f\u504f\u597d\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6355\u6349\u7528\u6237\u548c\u7269\u54c1\u95f4\u7684\u590d\u6742\u9690\u5f0f\u5173\u7cfb\uff0c\u9700\u8981\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u4fe1\u606f\u6765\u63d0\u5347\u63a8\u8350\u6548\u679c\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5c06\u7528\u6237\u548c\u7269\u54c1\u5d4c\u5165\u7edf\u4e00\u56fe\u7ed3\u6784\uff0c\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u5b9e\u4f53\u548c\u5173\u7cfb\u6784\u5efa\u591a\u7ea7\u8bed\u4e49\u8def\u5f84\uff0c\u4f7f\u7528\u7ed3\u6784\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u5206\u914d\u90bb\u5c45\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u7528\u6237-\u76ee\u6807\u7269\u54c1\u8868\u793a\u4ea4\u4e92\u751f\u6210\u63a8\u8350\u3002", "result": "\u5728Amazon Books\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u5404\u9879\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u826f\u597d\u7684\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7ed3\u6784\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u5728\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u63a8\u8350\u4e2d\u5177\u6709\u663e\u8457\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u63d0\u5347\u63a8\u8350\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.10127", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10127", "abs": "https://arxiv.org/abs/2510.10127", "authors": ["Qiya Yang", "Xiaoxi Liang", "Zeping Xiao", "Yingjie Deng", "Yalong Wang", "Yongqi Liu", "Han Li"], "title": "Breaking the Likelihood Trap: Consistent Generative Recommendation with Graph-structured Model", "comment": null, "summary": "Reranking, as the final stage of recommender systems, demands real-time\ninference, accuracy, and diversity. It plays a crucial role in determining the\nfinal exposure, directly influencing user experience. Recently, generative\nreranking has gained increasing attention for its strong ability to model\ncomplex dependencies among items. However, most existing methods suffer from\nthe \"likelihood trap\", where high-likelihood sequences are often perceived as\nlow-quality by humans. These models tend to repeatedly recommend a set of\nhigh-frequency items, resulting in list homogeneity, thereby limiting user\nengagement. In this work, we propose Consistent Graph-structured Generative\nRecommendation (Congrats), a novel generative reranking framework. To break the\nlikelihood trap, we introduce a novel graph-structured decoder that can capture\ndiverse sequences along multiple paths. This design not only expands the\ndecoding space to promote diversity, but also improves prediction accuracy by\nimplicit item dependencies derived from vertex transitions. Furthermore, we\ndesign a differentiable cascade system that incorporates an evaluator, enabling\nthe model to learn directly from user preferences as the training objective.\nExtensive offline experiments validate the superior performance of Congrats\nover state-of-the-art reranking methods. Moreover, Congrats has been evaluated\non a large-scale video-sharing app, Kuaishou, with over 300 million daily\nactive users, demonstrating that our approach significantly improves both\nrecommendation quality and diversity, validating our effectiveness in practical\nindustrial environments.", "AI": {"tldr": "\u63d0\u51faCongrats\u6846\u67b6\u89e3\u51b3\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u7684\"\u4f3c\u7136\u9677\u9631\"\u95ee\u9898\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u89e3\u7801\u5668\u6355\u83b7\u591a\u6837\u5316\u5e8f\u5217\uff0c\u63d0\u5347\u63a8\u8350\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u65b9\u6cd5\u5b58\u5728\"\u4f3c\u7136\u9677\u9631\"\uff0c\u9ad8\u4f3c\u7136\u5e8f\u5217\u5f80\u5f80\u8d28\u91cf\u4f4e\uff0c\u5bfc\u81f4\u91cd\u590d\u63a8\u8350\u9ad8\u9891\u9879\u76ee\uff0c\u9020\u6210\u5217\u8868\u540c\u8d28\u5316\uff0c\u9650\u5236\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "method": "\u8bbe\u8ba1\u56fe\u7ed3\u6784\u89e3\u7801\u5668\u6355\u83b7\u591a\u8def\u5f84\u591a\u6837\u5316\u5e8f\u5217\uff0c\u6269\u5c55\u89e3\u7801\u7a7a\u95f4\uff1b\u6784\u5efa\u53ef\u5fae\u5206\u7ea7\u8054\u7cfb\u7edf\u5305\u542b\u8bc4\u4f30\u5668\uff0c\u76f4\u63a5\u4ece\u7528\u6237\u504f\u597d\u5b66\u4e60\u8bad\u7ec3\u76ee\u6807\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u6700\u5148\u8fdb\u91cd\u6392\u5e8f\u65b9\u6cd5\uff1b\u5728\u5feb\u624b3\u4ebf\u65e5\u6d3b\u7528\u6237\u7684\u5927\u89c4\u6a21\u8bc4\u4f30\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002", "conclusion": "Congrats\u6846\u67b6\u6709\u6548\u89e3\u51b3\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u7684\u591a\u6837\u6027\u95ee\u9898\uff0c\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.10419", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10419", "abs": "https://arxiv.org/abs/2510.10419", "authors": ["Weiwei Sun", "Keyi Kong", "Xinyu Ma", "Shuaiqiang Wang", "Dawei Yin", "Maarten de Rijke", "Zhaochun Ren", "Yiming Yang"], "title": "ZeroGR: A Generalizable and Scalable Framework for Zero-Shot Generative Retrieval", "comment": null, "summary": "Generative retrieval (GR) reformulates information retrieval (IR) by framing\nit as the generation of document identifiers (docids), thereby enabling an\nend-to-end optimization and seamless integration with generative language\nmodels (LMs). Despite notable progress under supervised training, GR still\nstruggles to generalize to zero-shot IR scenarios, which are prevalent in\nreal-world applications. To tackle this challenge, we propose \\textsc{ZeroGR},\na zero-shot generative retrieval framework that leverages natural language\ninstructions to extend GR across a wide range of IR tasks. Specifically,\n\\textsc{ZeroGR} is composed of three key components: (i) an LM-based docid\ngenerator that unifies heterogeneous documents (e.g., text, tables, code) into\nsemantically meaningful docids; (ii) an instruction-tuned query generator that\ngenerates diverse types of queries from natural language task descriptions to\nenhance corpus indexing; and (iii) a reverse annealing decoding strategy to\nbalance precision and recall during docid generation. We investigate the impact\nof instruction fine-tuning scale and find that performance consistently\nimproves as the number of IR tasks encountered during training increases.\nEmpirical results on the BEIR and MAIR benchmarks demonstrate that\n\\textsc{ZeroGR} outperforms strong dense retrieval and generative baselines in\nzero-shot settings, establishing a new state-of-the-art for instruction-driven\nGR.", "AI": {"tldr": "ZeroGR\u662f\u4e00\u4e2a\u96f6\u6837\u672c\u751f\u6210\u5f0f\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5c06\u751f\u6210\u5f0f\u68c0\u7d22\u6269\u5c55\u5230\u5404\u79cd\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u5bc6\u96c6\u68c0\u7d22\u548c\u751f\u6210\u5f0f\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0f\u68c0\u7d22\u5728\u76d1\u7763\u8bad\u7ec3\u4e0b\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5e38\u89c1\u7684\u96f6\u6837\u672c\u68c0\u7d22\u573a\u666f\u4e2d\u4ecd\u96be\u4ee5\u6cdb\u5316\u3002", "method": "\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6587\u6863ID\u751f\u6210\u5668\u3001\u6307\u4ee4\u8c03\u4f18\u7684\u67e5\u8be2\u751f\u6210\u5668\uff0c\u4ee5\u53ca\u5e73\u8861\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7684\u53cd\u5411\u9000\u706b\u89e3\u7801\u7b56\u7565\u3002", "result": "\u5728BEIR\u548cMAIR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cZeroGR\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u6307\u4ee4\u9a71\u52a8\u751f\u6210\u5f0f\u68c0\u7d22\u7684\u65b0SOTA\u3002", "conclusion": "\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u89c4\u6a21\u7684\u6269\u5c55\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u6307\u4ee4\u9a71\u52a8\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.10440", "categories": ["cs.IR", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10440", "abs": "https://arxiv.org/abs/2510.10440", "authors": ["Alex Ayoub", "Samuel Robertson", "Dawen Liang", "Harald Steck", "Nathan Kallus"], "title": "Does Weighting Improve Matrix Factorization for Recommender Systems?", "comment": "In the proceedings of the Web Conference (WWW) 2025 (11 pages)", "summary": "Matrix factorization is a widely used approach for top-N recommendation and\ncollaborative filtering. When implemented on implicit feedback data (such as\nclicks), a common heuristic is to upweight the observed interactions. This\nstrategy has been shown to improve performance for certain algorithms. In this\npaper, we conduct a systematic study of various weighting schemes and matrix\nfactorization algorithms. Somewhat surprisingly, we find that training with\nunweighted data can perform comparably to, and sometimes outperform, training\nwith weighted data, especially for large models. This observation challenges\nthe conventional wisdom. Nevertheless, we identify cases where weighting can be\nbeneficial, particularly for models with lower capacity and specific\nregularization schemes. We also derive efficient algorithms for exactly\nminimizing several weighted objectives that were previously considered\ncomputationally intractable. Our work provides a comprehensive analysis of the\ninterplay between weighting, regularization, and model capacity in matrix\nfactorization for recommender systems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u9690\u5f0f\u53cd\u9988\u6570\u636e\u7684\u77e9\u9635\u5206\u89e3\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u672a\u52a0\u6743\u8bad\u7ec3\u7684\u8868\u73b0\u4e0e\u52a0\u6743\u8bad\u7ec3\u76f8\u5f53\u751a\u81f3\u66f4\u597d\uff0c\u7279\u522b\u662f\u5728\u5927\u6a21\u578b\u4e2d\uff0c\u8fd9\u6311\u6218\u4e86\u4f20\u7edf\u8ba4\u77e5\u3002", "motivation": "\u7814\u7a76\u77e9\u9635\u5206\u89e3\u5728\u9690\u5f0f\u53cd\u9988\u6570\u636e\u4e2d\u5e38\u7528\u7684\u52a0\u6743\u7b56\u7565\u662f\u5426\u603b\u662f\u6709\u6548\uff0c\u4ee5\u53ca\u4e0d\u540c\u52a0\u6743\u65b9\u6848\u4e0e\u7b97\u6cd5\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u5404\u79cd\u52a0\u6743\u65b9\u6848\u548c\u77e9\u9635\u5206\u89e3\u7b97\u6cd5\uff0c\u5305\u62ec\u63a8\u5bfc\u51e0\u79cd\u52a0\u6743\u76ee\u6807\u51fd\u6570\u7684\u9ad8\u6548\u7cbe\u786e\u6700\u5c0f\u5316\u7b97\u6cd5\u3002", "result": "\u672a\u52a0\u6743\u6570\u636e\u8bad\u7ec3\u7684\u8868\u73b0\u4e0e\u52a0\u6743\u8bad\u7ec3\u76f8\u5f53\u751a\u81f3\u66f4\u597d\uff0c\u7279\u522b\u662f\u5728\u5927\u6a21\u578b\u4e2d\uff1b\u4f46\u5728\u4f4e\u5bb9\u91cf\u6a21\u578b\u548c\u7279\u5b9a\u6b63\u5219\u5316\u65b9\u6848\u4e2d\uff0c\u52a0\u6743\u4ecd\u6709\u4f18\u52bf\u3002", "conclusion": "\u6743\u91cd\u7b56\u7565\u3001\u6b63\u5219\u5316\u548c\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u5b58\u5728\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u77e9\u9635\u5206\u89e3\u63d0\u4f9b\u4e86\u5168\u9762\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2510.10511", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10511", "abs": "https://arxiv.org/abs/2510.10511", "authors": ["Xu Zhao", "Xiaopeng Ye", "Chen Xu", "Weiran Shen", "Jun Xu"], "title": "Towards Long-Term User Welfare in Recommender Systems via Creator-Oriented Information Revelation", "comment": null, "summary": "Improving the long-term user welfare (e.g., sustained user engagement) has\nbecome a central objective of recommender systems (RS). In real-world\nplatforms, the creation behaviors of content creators plays a crucial role in\nshaping long-term welfare beyond short-term recommendation accuracy, making the\neffective steering of creator behavior essential to foster a healthier RS\necosystem. Existing works typically rely on re-ranking algorithms that\nheuristically adjust item exposure to steer creators' behavior. However, when\nembedded within recommendation pipelines, such a strategy often conflicts with\nthe short-term objective of improving recommendation accuracy, leading to\nperformance degradation and suboptimal long-term welfare. The well-established\neconomics studies offer us valuable insights for an alternative approach\nwithout relying on recommendation algorithmic design: revealing information\nfrom an information-rich party (sender) to a less-informed party (receiver) can\neffectively change the receiver's beliefs and steer their behavior. Inspired by\nthis idea, we propose an information-revealing framework, named Long-term\nWelfare Optimization via Information Revelation (LoRe). In this framework, we\nutilize a classical information revelation method (i.e., Bayesian persuasion)\nto map the stakeholders in RS, treating the platform as the sender and creators\nas the receivers. To address the challenge posed by the unrealistic assumption\nof traditional economic methods, we formulate the process of information\nrevelation as a Markov Decision Process (MDP) and propose a learning algorithm\ntrained and inferred in environments with boundedly rational creators.\nExtensive experiments on two real-world RS datasets demonstrate that our method\ncan effectively outperform existing fair re-ranking methods and information\nrevealing strategies in improving long-term user welfare.", "AI": {"tldr": "\u63d0\u51faLoRe\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u63ed\u793a\u800c\u975e\u91cd\u65b0\u6392\u5e8f\u7b97\u6cd5\u6765\u4f18\u5316\u63a8\u8350\u7cfb\u7edf\u7684\u957f\u671f\u7528\u6237\u798f\u5229\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u529d\u8bf4\u65b9\u6cd5\u5c06\u5e73\u53f0\u4f5c\u4e3a\u53d1\u9001\u8005\u3001\u521b\u4f5c\u8005\u4f5c\u4e3a\u63a5\u6536\u8005\uff0c\u901a\u8fc7MDP\u5efa\u6a21\u89e3\u51b3\u4f20\u7edf\u7ecf\u6d4e\u65b9\u6cd5\u5047\u8bbe\u4e0d\u73b0\u5b9e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u91cd\u65b0\u6392\u5e8f\u7684\u65b9\u6cd5\u5728\u63d0\u5347\u957f\u671f\u7528\u6237\u798f\u5229\u65f6\u4e0e\u77ed\u671f\u63a8\u8350\u51c6\u786e\u6027\u76ee\u6807\u51b2\u7a81\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u53d7\u7ecf\u6d4e\u5b66\u7814\u7a76\u542f\u53d1\uff0c\u901a\u8fc7\u4fe1\u606f\u63ed\u793a\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u5f15\u5bfc\u521b\u4f5c\u8005\u884c\u4e3a\uff0c\u4ece\u800c\u4f18\u5316\u63a8\u8350\u7cfb\u7edf\u751f\u6001\u7cfb\u7edf\u3002", "method": "\u63d0\u51faLoRe\u6846\u67b6\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u529d\u8bf4\u4f5c\u4e3a\u4fe1\u606f\u63ed\u793a\u65b9\u6cd5\uff0c\u5c06\u4fe1\u606f\u63ed\u793a\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u8bbe\u8ba1\u5b66\u4e60\u7b97\u6cd5\u5728\u6709\u754c\u7406\u6027\u521b\u4f5c\u8005\u73af\u5883\u4e2d\u8fdb\u884c\u8bad\u7ec3\u548c\u63a8\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u63a8\u8350\u7cfb\u7edf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u957f\u671f\u7528\u6237\u798f\u5229\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u516c\u5e73\u91cd\u65b0\u6392\u5e8f\u65b9\u6cd5\u548c\u4fe1\u606f\u63ed\u793a\u7b56\u7565\u3002", "conclusion": "LoRe\u6846\u67b6\u901a\u8fc7\u4fe1\u606f\u63ed\u793a\u6709\u6548\u89e3\u51b3\u4e86\u957f\u671f\u798f\u5229\u4f18\u5316\u95ee\u9898\uff0c\u907f\u514d\u4e86\u4e0e\u77ed\u671f\u76ee\u6807\u7684\u51b2\u7a81\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u751f\u6001\u7cfb\u7edf\u5065\u5eb7\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.10556", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10556", "abs": "https://arxiv.org/abs/2510.10556", "authors": ["Donglin Zhou", "Weike Pan", "Zhong Ming"], "title": "Self-Supervised Representation Learning with ID-Content Modality Alignment for Sequential Recommendation", "comment": null, "summary": "Sequential recommendation (SR) models often capture user preferences based on\nthe historically interacted item IDs, which usually obtain sub-optimal\nperformance when the interaction history is limited. Content-based sequential\nrecommendation has recently emerged as a promising direction that exploits\nitems' textual and visual features to enhance preference learning. However,\nthere are still three key challenges: (i) how to reduce the semantic gap\nbetween different content modality representations; (ii) how to jointly model\nuser behavior preferences and content preferences; and (iii) how to design an\neffective training strategy to align ID representations and content\nrepresentations. To address these challenges, we propose a novel model,\nself-supervised representation learning with ID-Content modality alignment,\nnamed SICSRec. Firstly, we propose a LLM-driven sample construction method and\ndevelop a supervised fine-tuning approach to align item-level modality\nrepresentations. Secondly, we design a novel Transformer-based sequential\nmodel, where an ID-modality sequence encoder captures user behavior\npreferences, a content-modality sequence encoder learns user content\npreferences, and a mix-modality sequence decoder grasps the intrinsic\nrelationship between these two types of preferences. Thirdly, we propose a\ntwo-step training strategy with a content-aware contrastive learning task to\nalign modality representations and ID representations, which decouples the\ntraining process of content modality dependency and item collaborative\ndependency. Extensive experiments conducted on four public video streaming\ndatasets demonstrate our SICSRec outperforms the state-of-the-art ID-modality\nsequential recommenders and content-modality sequential recommenders by 8.04%\non NDCG@5 and 6.62% on NDCD@10 on average, respectively.", "AI": {"tldr": "\u63d0\u51faSICSRec\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u548cID-\u5185\u5bb9\u6a21\u6001\u5bf9\u9f50\u6765\u89e3\u51b3\u5185\u5bb9\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u4e09\u5927\u6311\u6218\uff1a\u6a21\u6001\u8bed\u4e49\u5dee\u8ddd\u3001\u884c\u4e3a\u4e0e\u5185\u5bb9\u504f\u597d\u8054\u5408\u5efa\u6a21\u3001ID\u4e0e\u5185\u5bb9\u8868\u793a\u5bf9\u9f50\u8bad\u7ec3\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eID\u7684\u5e8f\u5217\u63a8\u8350\u5728\u4ea4\u4e92\u5386\u53f2\u6709\u9650\u65f6\u6027\u80fd\u4e0d\u4f73\uff0c\u800c\u73b0\u6709\u5185\u5bb9\u63a8\u8350\u65b9\u6cd5\u9762\u4e34\u6a21\u6001\u8bed\u4e49\u5dee\u8ddd\u3001\u504f\u597d\u8054\u5408\u5efa\u6a21\u548c\u8868\u793a\u5bf9\u9f50\u4e09\u5927\u6311\u6218\u3002", "method": "1. LLM\u9a71\u52a8\u7684\u6837\u672c\u6784\u5efa\u548c\u76d1\u7763\u5fae\u8c03\u5bf9\u9f50\u9879\u76ee\u7ea7\u6a21\u6001\u8868\u793a\uff1b2. \u57fa\u4e8eTransformer\u7684\u4e09\u6a21\u5757\u67b6\u6784\uff1aID\u6a21\u6001\u5e8f\u5217\u7f16\u7801\u5668\u3001\u5185\u5bb9\u6a21\u6001\u5e8f\u5217\u7f16\u7801\u5668\u548c\u6df7\u5408\u6a21\u6001\u5e8f\u5217\u89e3\u7801\u5668\uff1b3. \u4e24\u6b65\u8bad\u7ec3\u7b56\u7565\u548c\u5185\u5bb9\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u4efb\u52a1\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u89c6\u9891\u6d41\u6570\u636e\u96c6\u4e0a\uff0cSICSRec\u76f8\u6bd4\u6700\u5148\u8fdb\u7684ID\u6a21\u6001\u548c\u5185\u5bb9\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u5668\uff0cNDCG@5\u5e73\u5747\u63d0\u53478.04%\uff0cNDCG@10\u5e73\u5747\u63d0\u53476.62%\u3002", "conclusion": "SICSRec\u901a\u8fc7\u6709\u6548\u7684\u6a21\u6001\u5bf9\u9f50\u548c\u8054\u5408\u5efa\u6a21\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e8f\u5217\u63a8\u8350\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4ea4\u4e92\u5386\u53f2\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2510.10564", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10564", "abs": "https://arxiv.org/abs/2510.10564", "authors": ["Liang Li", "Zhou Yang", "Xiaofei Zhu"], "title": "Multi-Granularity Sequence Denoising with Weakly Supervised Signal for Sequential Recommendation", "comment": null, "summary": "Sequential recommendation aims to predict the next item based on user\ninterests in historical interaction sequences. Historical interaction sequences\noften contain irrelevant noisy items, which significantly hinders the\nperformance of recommendation systems. Existing research employs unsupervised\nmethods that indirectly identify item-granularity irrelevant noise by\npredicting the ground truth item. Since these methods lack explicit noise\nlabels, they are prone to misidentify users' interested items as noise.\nAdditionally, while these methods focus on removing item-granularity noise\ndriven by the ground truth item, they overlook interest-granularity noise,\nlimiting their ability to perform broader denoising based on user interests. To\naddress these issues, we propose Multi-Granularity Sequence Denoising with\nWeakly Supervised Signal for Sequential Recommendation(MGSD-WSS). MGSD-WSS\nfirst introduces the Multiple Gaussian Kernel Perceptron module to map the\noriginal and enhance sequence into a common representation space and utilizes\nweakly supervised signals to accurately identify noisy items in the historical\ninteraction sequence. Subsequently, it employs the item-granularity denoising\nmodule with noise-weighted contrastive learning to obtain denoised item\nrepresentations. Then, it extracts target interest representations from the\nground truth item and applies noise-weighted contrastive learning to obtain\ndenoised interest representations. Finally, based on the denoised item and\ninterest representations, MGSD-WSS predicts the next item. Extensive\nexperiments on five datasets demonstrate that the proposed method significantly\noutperforms state-of-the-art sequence recommendation and denoising models. Our\ncode is available at https://github.com/lalunex/MGSD-WSS.", "AI": {"tldr": "\u63d0\u51faMGSD-WSS\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u5e8f\u5217\u53bb\u566a\u548c\u5f31\u76d1\u7763\u4fe1\u53f7\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u566a\u58f0\u95ee\u9898\uff0c\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5386\u53f2\u4ea4\u4e92\u5e8f\u5217\u5e38\u5305\u542b\u65e0\u5173\u566a\u58f0\u9879\uff0c\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\u7f3a\u4e4f\u663e\u5f0f\u566a\u58f0\u6807\u7b7e\uff0c\u5bb9\u6613\u8bef\u5224\u7528\u6237\u5174\u8da3\u9879\u4e3a\u566a\u58f0\uff0c\u4e14\u53ea\u5173\u6ce8\u9879\u7c92\u5ea6\u566a\u58f0\u800c\u5ffd\u7565\u5174\u8da3\u7c92\u5ea6\u566a\u58f0\u3002", "method": "\u4f7f\u7528\u591a\u9ad8\u65af\u6838\u611f\u77e5\u5668\u6a21\u5757\u6620\u5c04\u5e8f\u5217\u5230\u5171\u540c\u8868\u793a\u7a7a\u95f4\uff0c\u5229\u7528\u5f31\u76d1\u7763\u4fe1\u53f7\u8bc6\u522b\u566a\u58f0\u9879\uff1b\u901a\u8fc7\u566a\u58f0\u52a0\u6743\u5bf9\u6bd4\u5b66\u4e60\u83b7\u5f97\u53bb\u566a\u9879\u8868\u793a\uff1b\u4ece\u771f\u5b9e\u9879\u63d0\u53d6\u76ee\u6807\u5174\u8da3\u8868\u793a\u5e76\u53bb\u566a\uff1b\u57fa\u4e8e\u53bb\u566a\u8868\u793a\u9884\u6d4b\u4e0b\u4e00\u9879\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5e8f\u5217\u63a8\u8350\u548c\u53bb\u566a\u6a21\u578b\u3002", "conclusion": "MGSD-WSS\u901a\u8fc7\u591a\u7c92\u5ea6\u53bb\u566a\u548c\u5f31\u76d1\u7763\u4fe1\u53f7\u6709\u6548\u89e3\u51b3\u4e86\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2510.10828", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10828", "abs": "https://arxiv.org/abs/2510.10828", "authors": ["Zhenghan Tai", "Hanwei Wu", "Qingchen Hu", "Jijun Chi", "Hailin He", "Lei Ding", "Tung Sum Thomas Kwok", "Bohuai Xiao", "Yuchen Hua", "Suyuchen Wang", "Peng Lu", "Muzhi Li", "Yihong Wu", "Liheng Ma", "Jerry Huang", "Jiayi Zhang", "Gonghao Zhang", "Chaolong Jiang", "Jingrui Tian", "Sicheng Lyu", "Zeyu Li", "Boyu Han", "Fengran Mo", "Xinyue Yu", "Yufei Cui", "Ling Zhou", "Xinyu Wang"], "title": "VeritasFi: An Adaptable, Multi-tiered RAG Framework for Multi-modal Financial Question Answering", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is becoming increasingly essential for\nQuestion Answering (QA) in the financial sector, where accurate and\ncontextually grounded insights from complex public disclosures are crucial.\nHowever, existing financial RAG systems face two significant challenges: (1)\nthey struggle to process heterogeneous data formats, such as text, tables, and\nfigures; and (2) they encounter difficulties in balancing general-domain\napplicability with company-specific adaptation. To overcome these challenges,\nwe present VeritasFi, an innovative hybrid RAG framework that incorporates a\nmulti-modal preprocessing pipeline alongside a cutting-edge two-stage training\nstrategy for its re-ranking component. VeritasFi enhances financial QA through\nthree key innovations: (1) A multi-modal preprocessing pipeline that seamlessly\ntransforms heterogeneous data into a coherent, machine-readable format. (2) A\ntripartite hybrid retrieval engine that operates in parallel, combining deep\nmulti-path retrieval over a semantically indexed document corpus, real-time\ndata acquisition through tool utilization, and an expert-curated memory bank\nfor high-frequency questions, ensuring comprehensive scope, accuracy, and\nefficiency. (3) A two-stage training strategy for the document re-ranker, which\ninitially constructs a general, domain-specific model using anonymized data,\nfollowed by rapid fine-tuning on company-specific data for targeted\napplications. By integrating our proposed designs, VeritasFi presents a\ngroundbreaking framework that greatly enhances the adaptability and robustness\nof financial RAG systems, providing a scalable solution for both general-domain\nand company-specific QA tasks. Code accompanying this work is available at\nhttps://github.com/simplew4y/VeritasFi.git.", "AI": {"tldr": "VeritasFi\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u6df7\u5408RAG\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u9884\u5904\u7406\u3001\u4e09\u91cd\u6df7\u5408\u68c0\u7d22\u5f15\u64ce\u548c\u4e24\u9636\u6bb5\u91cd\u6392\u5e8f\u8bad\u7ec3\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u91d1\u878dQA\u4e2d\u5904\u7406\u5f02\u6784\u6570\u636e\u548c\u5e73\u8861\u901a\u7528\u6027\u4e0e\u516c\u53f8\u7279\u5b9a\u9002\u5e94\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u91d1\u878dRAG\u7cfb\u7edf\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u96be\u4ee5\u5904\u7406\u6587\u672c\u3001\u8868\u683c\u3001\u56fe\u5f62\u7b49\u5f02\u6784\u6570\u636e\u683c\u5f0f\uff0c\u4ee5\u53ca\u5728\u901a\u7528\u9886\u57df\u9002\u7528\u6027\u548c\u516c\u53f8\u7279\u5b9a\u9002\u5e94\u6027\u4e4b\u95f4\u96be\u4ee5\u5e73\u8861\u3002", "method": "\u63d0\u51faVeritasFi\u6df7\u5408RAG\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u591a\u6a21\u6001\u9884\u5904\u7406\u7ba1\u9053\u5c06\u5f02\u6784\u6570\u636e\u8f6c\u6362\u4e3a\u7edf\u4e00\u683c\u5f0f\uff1b2\uff09\u4e09\u91cd\u6df7\u5408\u68c0\u7d22\u5f15\u64ce\u5e76\u884c\u8fd0\u884c\uff0c\u7ed3\u5408\u8bed\u4e49\u7d22\u5f15\u6587\u6863\u68c0\u7d22\u3001\u5b9e\u65f6\u6570\u636e\u83b7\u53d6\u548c\u4e13\u5bb6\u8bb0\u5fc6\u5e93\uff1b3\uff09\u4e24\u9636\u6bb5\u91cd\u6392\u5e8f\u8bad\u7ec3\u7b56\u7565\uff0c\u5148\u6784\u5efa\u901a\u7528\u6a21\u578b\u518d\u9488\u5bf9\u516c\u53f8\u5fae\u8c03\u3002", "result": "VeritasFi\u663e\u8457\u589e\u5f3a\u4e86\u91d1\u878dRAG\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u901a\u7528\u9886\u57df\u548c\u516c\u53f8\u7279\u5b9a\u7684QA\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "VeritasFi\u901a\u8fc7\u96c6\u6210\u591a\u6a21\u6001\u5904\u7406\u3001\u6df7\u5408\u68c0\u7d22\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u4e3a\u91d1\u878dQA\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a81\u7834\u6027\u7684\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.10920", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10920", "abs": "https://arxiv.org/abs/2510.10920", "authors": ["Yi Yu", "Zhenxing Hu"], "title": "Comparative Explanations via Counterfactual Reasoning in Recommendations", "comment": null, "summary": "Explainable recommendation through counterfactual reasoning seeks to identify\nthe influential aspects of items in recommendations, which can then be used as\nexplanations. However, state-of-the-art approaches, which aim to minimize\nchanges in product aspects while reversing their recommended decisions\naccording to an aggregated decision boundary score, often lead to factual\ninaccuracies in explanations. To solve this problem, in this work we propose a\nnovel method of Comparative Counterfactual Explanations for Recommendation\n(CoCountER). CoCountER creates counterfactual data based on soft swap\noperations, enabling explanations for recommendations of arbitrary pairs of\ncomparative items. Empirical experiments validate the effectiveness of our\napproach.", "AI": {"tldr": "\u63d0\u51faCoCountER\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f6f\u4ea4\u6362\u64cd\u4f5c\u751f\u6210\u53cd\u4e8b\u5b9e\u6570\u636e\uff0c\u4e3a\u4efb\u610f\u5bf9\u6bd4\u7269\u54c1\u5bf9\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u63a8\u8350\u89e3\u91ca\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5bfc\u81f4\u89e3\u91ca\u4e8b\u5b9e\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u63a8\u8350\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u4ea7\u54c1\u65b9\u9762\u53d8\u5316\u6765\u53cd\u8f6c\u63a8\u8350\u51b3\u7b56\uff0c\u4f46\u5f80\u5f80\u5bfc\u81f4\u89e3\u91ca\u5b58\u5728\u4e8b\u5b9e\u4e0d\u51c6\u786e\u6027\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "CoCountER\u65b9\u6cd5\u4f7f\u7528\u8f6f\u4ea4\u6362\u64cd\u4f5c\u521b\u5efa\u53cd\u4e8b\u5b9e\u6570\u636e\uff0c\u80fd\u591f\u4e3a\u4efb\u610f\u5bf9\u6bd4\u7269\u54c1\u5bf9\u751f\u6210\u63a8\u8350\u89e3\u91ca\u3002", "result": "\u5b9e\u8bc1\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "CoCountER\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u53ef\u89e3\u91ca\u63a8\u8350\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u63a8\u7406\u8bc6\u522b\u7269\u54c1\u65b9\u9762\u7684\u5f71\u54cd\u529b\u3002"}}
{"id": "2510.10955", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10955", "abs": "https://arxiv.org/abs/2510.10955", "authors": ["Yu Cui", "Feng Liu", "Jiawei Chen", "Canghong Jin", "Xingyu Lou", "Changwang Zhang", "Jun Wang", "Yuegang Sun", "Can Wang"], "title": "HatLLM: Hierarchical Attention Masking for Enhanced Collaborative Modeling in LLM-based Recommendation", "comment": null, "summary": "Recent years have witnessed a surge of research on leveraging large language\nmodels (LLMs) for sequential recommendation. LLMs have demonstrated remarkable\npotential in inferring users' nuanced preferences through fine-grained semantic\nreasoning. However, they also exhibit a notable limitation in effectively\nmodeling collaborative signals, i.e., behavioral correlations inherent in\nusers' historical interactions. Our empirical analysis further reveals that the\nattention mechanisms in LLMs tend to disproportionately focus on tokens within\nthe same item, thereby impeding the capture of cross-item correlations.\n  To address this limitation, we propose a novel hierarchical attention masking\nstrategy for LLM-based recommendation, termed HatLLM. Specifically, in shallow\nlayers, HatLLM masks attention between tokens from different items,\nfacilitating intra-item semantic understanding; in contrast, in deep layers,\nHatLLM masks attention within items, thereby compelling the model to capture\ncross-item correlations. This progressive, layer-wise approach enables LLMs to\njointly model both token-level and item-level dependencies. Extensive\nexperiments on three real-world datasets demonstrate that HatLLM achieves\nsignificant performance gains (9.13% on average) over existing LLM-based\nmethods.", "AI": {"tldr": "\u63d0\u51faHatLLM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u6ce8\u610f\u529b\u63a9\u7801\u7b56\u7565\u89e3\u51b3LLMs\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u534f\u4f5c\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u5728\u6d45\u5c42\u5173\u6ce8\u9879\u76ee\u5185\u8bed\u4e49\uff0c\u6df1\u5c42\u5173\u6ce8\u9879\u76ee\u95f4\u76f8\u5173\u6027\u3002", "motivation": "LLMs\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u7528\u6237\u5386\u53f2\u4ea4\u4e92\u4e2d\u7684\u884c\u4e3a\u76f8\u5173\u6027\uff08\u534f\u4f5c\u4fe1\u53f7\uff09\uff0c\u4e14\u6ce8\u610f\u529b\u673a\u5236\u503e\u5411\u4e8e\u8fc7\u5ea6\u5173\u6ce8\u540c\u4e00\u9879\u76ee\u5185\u7684token\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u6ce8\u610f\u529b\u63a9\u7801\u7b56\u7565HatLLM\uff1a\u6d45\u5c42\u63a9\u7801\u4e0d\u540c\u9879\u76ee\u95f4token\u7684\u6ce8\u610f\u529b\uff0c\u4fc3\u8fdb\u9879\u76ee\u5185\u8bed\u4e49\u7406\u89e3\uff1b\u6df1\u5c42\u63a9\u7801\u9879\u76ee\u5185token\u7684\u6ce8\u610f\u529b\uff0c\u5f3a\u5236\u6a21\u578b\u6355\u6349\u9879\u76ee\u95f4\u76f8\u5173\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHatLLM\u76f8\u6bd4\u73b0\u6709LLM\u65b9\u6cd5\u5e73\u5747\u63d0\u53479.13%\u7684\u6027\u80fd\u3002", "conclusion": "\u5206\u5c42\u6ce8\u610f\u529b\u63a9\u7801\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347LLMs\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u5176\u80fd\u591f\u8054\u5408\u5efa\u6a21token\u7ea7\u548c\u9879\u76ee\u7ea7\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2510.10978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10978", "abs": "https://arxiv.org/abs/2510.10978", "authors": ["Bohao Wang", "Jiawei Chen", "Feng Liu", "Changwang Zhang", "Jun Wang", "Canghong Jin", "Chun Chen", "Can Wang"], "title": "Does LLM Focus on the Right Words? Diagnosing Language Bias in LLM-based Recommenders", "comment": null, "summary": "Large language models (LLMs), owing to their extensive open-domain knowledge\nand semantic reasoning capabilities, have been increasingly integrated into\nrecommender systems (RS). However, a substantial gap remains between the\npre-training objectives of LLMs and the specific requirements of recommendation\ntasks. To address this gap, supervised fine-tuning (SFT) is commonly performed\non specially curated recommendation datasets to further enhance their\npredictive ability. Despite its success, SFT exhibits a critical limitation: it\ninduces Language Bias, whereby the model over-relies on auxiliary tokens-such\nas task descriptions and prefix-generated tokens-while underutilizing core user\ninteraction tokens that encode user-specific preferences. This bias not only\nundermines recommendation accuracy but also raises unfairness concerns.\n  To address this issue, we propose Group Distributionally Robust\nOptimization-based Tuning (GDRT), a novel fine-tuning paradigm that enforces\nconsistent model performance across token groups with varying degrees of\nrelevance to auxiliary tokens. By adaptively upweighting underperforming\ngroups, typically those weakly correlated with auxiliary tokens, GDRT shifts\nthe model's attention from superficial auxiliary cues to informative user\ninteraction tokens, thereby mitigating language bias. Extensive experiments\nconducted on three public datasets demonstrate that GDRT effectively mitigates\nlanguage bias, yielding substantial improvements in recommendation accuracy\n(with an average NDCG@10 gain of 24.29%) and significantly enhancing\nrecommendation fairness.", "AI": {"tldr": "\u63d0\u51faGDRT\u65b9\u6cd5\u89e3\u51b3LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u8bed\u8a00\u504f\u89c1\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u7ec4\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027", "motivation": "\u73b0\u6709\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5bfc\u81f4\u8bed\u8a00\u504f\u89c1\uff0c\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u8f85\u52a9\u6807\u8bb0\u800c\u5ffd\u89c6\u6838\u5fc3\u7528\u6237\u4ea4\u4e92\u6807\u8bb0\uff0c\u5f71\u54cd\u63a8\u8350\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027", "method": "\u63d0\u51fa\u57fa\u4e8e\u5206\u7ec4\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u7684\u8c03\u4f18\u65b9\u6cd5(GDRT)\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u52a0\u6743\u8868\u73b0\u4e0d\u4f73\u7684\u6807\u8bb0\u7ec4\uff0c\u5c06\u6a21\u578b\u6ce8\u610f\u529b\u4ece\u8f85\u52a9\u7ebf\u7d22\u8f6c\u5411\u4fe1\u606f\u4e30\u5bcc\u7684\u7528\u6237\u4ea4\u4e92\u6807\u8bb0", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGDRT\u6709\u6548\u7f13\u89e3\u8bed\u8a00\u504f\u89c1\uff0cNDCG@10\u5e73\u5747\u63d0\u534724.29%\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u516c\u5e73\u6027", "conclusion": "GDRT\u662f\u4e00\u79cd\u6709\u6548\u7684\u5fae\u8c03\u8303\u5f0f\uff0c\u80fd\u591f\u7f13\u89e3LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8bed\u8a00\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u548c\u516c\u5e73\u6027"}}
{"id": "2510.11056", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11056", "abs": "https://arxiv.org/abs/2510.11056", "authors": ["Runze Xia", "Yupeng Ji", "Yuxi Zhou", "Haodong Liu", "Teng Zhang", "Piji Li"], "title": "From Reasoning LLMs to BERT: A Two-Stage Distillation Framework for Search Relevance", "comment": null, "summary": "Query-service relevance prediction in e-commerce search systems faces strict\nlatency requirements that prevent the direct application of Large Language\nModels (LLMs). To bridge this gap, we propose a two-stage reasoning\ndistillation framework to transfer reasoning capabilities from a powerful\nteacher LLM to a lightweight, deployment-friendly student model. In the first\nstage, we address the limitations of general-purpose LLMs by constructing a\ndomain-adapted teacher model. This is achieved through a three-step process:\ndomain-adaptive pre-training to inject platform knowledge, supervised\nfine-tuning to elicit reasoning skills, and preference optimization with a\nmulti-dimensional reward model to ensure the generation of reliable and\npreference-aligned reasoning paths. This teacher can then automatically\nannotate massive query-service pairs from search logs with both relevance\nlabels and reasoning chains. In the second stage, to address the challenges of\narchitectural heterogeneity in standard distillation, we introduce Contrastive\nReasoning Self-Distillation (CRSD). By modeling the behavior of the same\nstudent model under \"standard\" and \"reasoning-augmented\" inputs as a\nteacher-student relationship, CRSD enables the lightweight model to internalize\nthe teacher's complex decision-making mechanisms without needing the explicit\nreasoning path at inference. Offline evaluations and online A/B testing in the\nMeituan search advertising system demonstrate that our framework achieves\nsignificant improvements across multiple metrics, validating its effectiveness\nand practical value.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u63a8\u7406\u84b8\u998f\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8fc1\u79fb\u5230\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\u4e2d\uff0c\u89e3\u51b3\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u4e2d\u67e5\u8be2-\u670d\u52a1\u76f8\u5173\u6027\u9884\u6d4b\u7684\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u5bf9\u5ef6\u8fdf\u6709\u4e25\u683c\u8981\u6c42\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\uff0c\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u4f46\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u6784\u5efa\u9886\u57df\u9002\u5e94\u6559\u5e08\u6a21\u578b\uff1a\u901a\u8fc7\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u5bf9\u6bd4\u63a8\u7406\u81ea\u84b8\u998f(CRSD)\uff0c\u901a\u8fc7\u6807\u51c6\u8f93\u5165\u548c\u63a8\u7406\u589e\u5f3a\u8f93\u5165\u7684\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u5728\u7f8e\u56e2\u641c\u7d22\u5e7f\u544a\u7cfb\u7edf\u7684\u79bb\u7ebf\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u7535\u5546\u641c\u7d22\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u7684\u6210\u529f\u8fc1\u79fb\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.11066", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11066", "abs": "https://arxiv.org/abs/2510.11066", "authors": ["Alin Fan", "Hanqing Li", "Sihan Lu", "Jingsong Yuan", "Jiandong Zhang"], "title": "Decoupled Multimodal Fusion for User Interest Modeling in Click-Through Rate Prediction", "comment": null, "summary": "Modern industrial recommendation systems improve recommendation performance\nby integrating multimodal representations from pre-trained models into ID-based\nClick-Through Rate (CTR) prediction frameworks. However, existing approaches\ntypically adopt modality-centric modeling strategies that process ID-based and\nmultimodal embeddings independently, failing to capture fine-grained\ninteractions between content semantics and behavioral signals. In this paper,\nwe propose Decoupled Multimodal Fusion (DMF), which introduces a\nmodality-enriched modeling strategy to enable fine-grained interactions between\nID-based collaborative representations and multimodal representations for user\ninterest modeling. Specifically, we construct target-aware features to bridge\nthe semantic gap across different embedding spaces and leverage them as side\ninformation to enhance the effectiveness of user interest modeling.\nFurthermore, we design an inference-optimized attention mechanism that\ndecouples the computation of target-aware features and ID-based embeddings\nbefore the attention layer, thereby alleviating the computational bottleneck\nintroduced by incorporating target-aware features. To achieve comprehensive\nmultimodal integration, DMF combines user interest representations learned\nunder the modality-centric and modality-enriched modeling strategies. Offline\nexperiments on public and industrial datasets demonstrate the effectiveness of\nDMF. Moreover, DMF has been deployed on the product recommendation system of\nthe international e-commerce platform Lazada, achieving relative improvements\nof 5.30% in CTCVR and 7.43% in GMV with negligible computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u89e3\u8026\u591a\u6a21\u6001\u878d\u5408(DMF)\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u6001\u589e\u5f3a\u5efa\u6a21\u7b56\u7565\u5b9e\u73b0ID\u8868\u793a\u4e0e\u591a\u6a21\u6001\u8868\u793a\u7684\u7ec6\u7c92\u5ea6\u4ea4\u4e92\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u6a21\u6001\u4e2d\u5fc3\u5efa\u6a21\u7b56\u7565\uff0c\u72ec\u7acb\u5904\u7406ID\u548c\u591a\u6a21\u6001\u5d4c\u5165\uff0c\u65e0\u6cd5\u6355\u6349\u5185\u5bb9\u8bed\u4e49\u4e0e\u884c\u4e3a\u4fe1\u53f7\u4e4b\u95f4\u7684\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u3002", "method": "\u6784\u5efa\u76ee\u6807\u611f\u77e5\u7279\u5f81\u6765\u6865\u63a5\u4e0d\u540c\u5d4c\u5165\u7a7a\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u8bbe\u8ba1\u63a8\u7406\u4f18\u5316\u7684\u6ce8\u610f\u529b\u673a\u5236\u89e3\u8026\u76ee\u6807\u611f\u77e5\u7279\u5f81\u548cID\u5d4c\u5165\u7684\u8ba1\u7b97\uff0c\u7ed3\u5408\u6a21\u6001\u4e2d\u5fc3\u548c\u6a21\u6001\u589e\u5f3a\u4e24\u79cd\u5efa\u6a21\u7b56\u7565\u3002", "result": "\u5728\u516c\u5f00\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5728Lazada\u7535\u5546\u5e73\u53f0\u90e8\u7f72\u540e\uff0cCTCVR\u76f8\u5bf9\u63d0\u53475.30%\uff0cGMV\u76f8\u5bf9\u63d0\u53477.43%\uff0c\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "DMF\u901a\u8fc7\u6a21\u6001\u589e\u5f3a\u5efa\u6a21\u7b56\u7565\u6210\u529f\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u7684\u591a\u6a21\u6001\u4ea4\u4e92\uff0c\u5728\u63d0\u5347\u63a8\u8350\u6027\u80fd\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2510.11100", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11100", "abs": "https://arxiv.org/abs/2510.11100", "authors": ["Shuwei Chen", "Jiajun Cui", "Zhengqi Xu", "Fan Zhang", "Jiangke Fan", "Teng Zhang", "Xingxing Wang"], "title": "HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction", "comment": "10 pages, 6 figures", "summary": "Click-through rate (CTR) prediction, which models behavior sequence and\nnon-sequential features (e.g., user/item profiles or cross features) to infer\nuser interest, underpins industrial recommender systems. However, most methods\nface three forms of heterogeneity that degrade predictive performance: (i)\nFeature Heterogeneity persists when limited sequence side features provide less\ngranular interest representation compared to extensive non-sequential features,\nthereby impairing sequence modeling performance; (ii) Context Heterogeneity\narises because a user's interest in an item will be influenced by other items,\nyet point-wise prediction neglects cross-item interaction context from the\nentire item set; (iii) Architecture Heterogeneity stems from the fragmented\nintegration of specialized network modules, which compounds the model's\neffectiveness, efficiency and scalability in industrial deployments. To tackle\nthe above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for\nmodeling sequential and set-wise contexts. First, we align sequence side\nfeatures with non-sequential features for accurate sequence modeling and\nfine-grained interest representation. Second, we shift the prediction paradigm\nfrom point-wise to set-wise, facilitating cross-item interaction in a highly\nparallel manner. Third, HoMer's unified encoder-decoder architecture achieves\ndual optimization through structural simplification and shared computation,\nensuring computational efficiency while maintaining scalability with model\nsize. Without arduous modification to the prediction pipeline, HoMer\nsuccessfully scales up and outperforms our industrial baseline by 0.0099 in the\nAUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%.\nAdditionally, HoMer saves 27% of GPU resources via preliminary engineering\noptimization, further validating its superiority and practicality.", "AI": {"tldr": "HoMer\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u540c\u8d28\u6027\u7684Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u7279\u5f81\u5bf9\u9f50\u3001\u96c6\u5408\u5f0f\u9884\u6d4b\u548c\u7edf\u4e00\u67b6\u6784\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86CTR\u9884\u6d4b\u4e2d\u7684\u7279\u5f81\u5f02\u8d28\u6027\u3001\u4e0a\u4e0b\u6587\u5f02\u8d28\u6027\u548c\u67b6\u6784\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u548c\u8d44\u6e90\u8282\u7701\u3002", "motivation": "\u73b0\u6709CTR\u9884\u6d4b\u65b9\u6cd5\u9762\u4e34\u4e09\u79cd\u5f02\u8d28\u6027\u95ee\u9898\uff1a\u7279\u5f81\u5f02\u8d28\u6027\uff08\u5e8f\u5217\u7279\u5f81\u4e0e\u975e\u5e8f\u5217\u7279\u5f81\u4e0d\u5e73\u8861\uff09\u3001\u4e0a\u4e0b\u6587\u5f02\u8d28\u6027\uff08\u70b9\u5f0f\u9884\u6d4b\u5ffd\u7565\u8de8\u9879\u76ee\u4ea4\u4e92\uff09\u3001\u67b6\u6784\u5f02\u8d28\u6027\uff08\u6a21\u5757\u5316\u96c6\u6210\u5f71\u54cd\u6548\u7387\uff09\u3002\u8fd9\u4e9b\u9650\u5236\u4e86\u6a21\u578b\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "1. \u5e8f\u5217\u7279\u5f81\u4e0e\u975e\u5e8f\u5217\u7279\u5f81\u5bf9\u9f50\uff0c\u5b9e\u73b0\u7cbe\u786e\u5e8f\u5217\u5efa\u6a21\u548c\u7ec6\u7c92\u5ea6\u5174\u8da3\u8868\u793a\uff1b2. \u4ece\u70b9\u5f0f\u9884\u6d4b\u8f6c\u5411\u96c6\u5408\u5f0f\u9884\u6d4b\uff0c\u652f\u6301\u9ad8\u5ea6\u5e76\u884c\u7684\u8de8\u9879\u76ee\u4ea4\u4e92\uff1b3. \u91c7\u7528\u7edf\u4e00\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u7b80\u5316\u548c\u5171\u4eab\u8ba1\u7b97\u5b9e\u73b0\u53cc\u91cd\u4f18\u5316\u3002", "result": "\u5728\u5de5\u4e1a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAUC\u6307\u6807\u63d0\u53470.0099\uff0c\u5728\u7ebf\u4e1a\u52a1\u6307\u6807CTR/RPM\u5206\u522b\u63d0\u53471.99%/2.46%\u3002\u901a\u8fc7\u521d\u6b65\u5de5\u7a0b\u4f18\u5316\u8282\u770127%\u7684GPU\u8d44\u6e90\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u4f18\u8d8a\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "HoMer\u901a\u8fc7\u540c\u8d28\u6027\u5bfc\u5411\u7684\u8bbe\u8ba1\uff0c\u5728\u4e0d\u6539\u53d8\u9884\u6d4b\u6d41\u7a0b\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u6269\u5c55\u5e76\u8d85\u8d8a\u4e86\u5de5\u4e1a\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u89e3\u51b3CTR\u9884\u6d4b\u5f02\u8d28\u6027\u95ee\u9898\u548c\u63d0\u5347\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.11122", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11122", "abs": "https://arxiv.org/abs/2510.11122", "authors": ["Tingqiao Xu", "Shaowei Yao", "Chenhe Dong", "Yiming Jin", "Zerui Huang", "Dan Ou", "Haihong Tang"], "title": "DyKnow-RAG: Dynamic Knowledge Utilization Reinforcement Framework for Noisy Retrieval-Augmented Generation in E-commerce Search Relevance", "comment": null, "summary": "Accurately modeling query-item relevance drives e-commerce ranking, yet\nlong-tail, knowledge-heavy, and fast-evolving queries exceed parametric LLM\ncoverage. External context (reviews, attribute encyclopedias, UGC) can help but\nis noisy, and single-pass latency and cost forbid any clean-then-summarize\nstep. The model must, per query, judge relevance and decide whether to use,\npartially use, or ignore the context. DyKnow-RAG is a dynamic noisy-RAG\nframework built on Group Relative Policy Optimization. It trains two rollout\ngroups (no external context vs a single retrieved chunk) and applies\nposterior-driven inter-group advantage scaling that adaptively reweights their\ncontributions by the per-query correctness gap. This teaches when to trust\nretrieval versus fall back to parametric knowledge, without process labels,\nvalue networks, or extra inference passes, preserving single-pass, single-chunk\ndeployment under production latency. Training combines: (1) supervised\ninitialization with a structured rationale that explicitly records the\ncontext-usage decision; (2) an RL pool prioritized by SFT uncertainty to focus\nwhere context choice is most consequential; and (3) an optional lightweight DPO\nwarm start to stabilize with-context calibration. Under a unified\nretrieval/index and fixed latency budget, DyKnow-RAG outperforms SFT, DPO, and\nvanilla GRPO in offline tests, and delivers consistent lifts on GSB, Query\nGoodrate, and Item Goodrate in Taobao A/B testing. It is deployed in Taobao's\nproduction relevance system, serving live traffic. To our knowledge, it is\namong the first single-pass RAG solutions for e-commerce relevance, turning\nnoisy external signals into reliable gains without added online complexity.", "AI": {"tldr": "DyKnow-RAG\u662f\u4e00\u4e2a\u52a8\u6001\u566a\u58f0RAG\u6846\u67b6\uff0c\u901a\u8fc7Group Relative Policy Optimization\u8bad\u7ec3\u6a21\u578b\u5728\u7535\u5546\u6392\u5e8f\u4e2d\u81ea\u9002\u5e94\u51b3\u5b9a\u662f\u5426\u4f7f\u7528\u5916\u90e8\u4e0a\u4e0b\u6587\uff0c\u65e0\u9700\u989d\u5916\u63a8\u7406\u6b65\u9aa4\u5373\u53ef\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u5904\u7406\u566a\u58f0\u5916\u90e8\u4fe1\u606f\u3002", "motivation": "\u7535\u5546\u6392\u5e8f\u4e2d\uff0c\u957f\u5c3e\u67e5\u8be2\u3001\u77e5\u8bc6\u5bc6\u96c6\u548c\u5feb\u901f\u53d8\u5316\u7684\u67e5\u8be2\u8d85\u51fa\u4e86\u53c2\u6570\u5316LLM\u7684\u8986\u76d6\u8303\u56f4\uff0c\u800c\u5916\u90e8\u4e0a\u4e0b\u6587\uff08\u8bc4\u8bba\u3001\u5c5e\u6027\u767e\u79d1\u3001UGC\uff09\u5b58\u5728\u566a\u58f0\u4e14\u65e0\u6cd5\u8fdb\u884c\u6e05\u7406-\u603b\u7ed3\u6b65\u9aa4\uff0c\u9700\u8981\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u5224\u65ad\u662f\u5426\u4f7f\u7528\u4e0a\u4e0b\u6587\u3002", "method": "\u57fa\u4e8eGroup Relative Policy Optimization\uff0c\u8bad\u7ec3\u4e24\u4e2arollout\u7ec4\uff08\u65e0\u5916\u90e8\u4e0a\u4e0b\u6587 vs \u5355\u4e2a\u68c0\u7d22\u5757\uff09\uff0c\u5e94\u7528\u540e\u9a8c\u9a71\u52a8\u7684\u7ec4\u95f4\u4f18\u52bf\u7f29\u653e\uff0c\u6839\u636e\u6bcf\u67e5\u8be2\u6b63\u786e\u6027\u5dee\u8ddd\u81ea\u9002\u5e94\u91cd\u65b0\u52a0\u6743\u5b83\u4eec\u7684\u8d21\u732e\u3002\u8bad\u7ec3\u5305\u62ec\u76d1\u7763\u521d\u59cb\u5316\u3001\u57fa\u4e8eSFT\u4e0d\u786e\u5b9a\u6027\u7684RL\u6c60\u4f18\u5148\u6392\u5e8f\u548c\u53ef\u9009DPO\u9884\u70ed\u3002", "result": "\u5728\u7edf\u4e00\u68c0\u7d22/\u7d22\u5f15\u548c\u56fa\u5b9a\u5ef6\u8fdf\u9884\u7b97\u4e0b\uff0cDyKnow-RAG\u5728\u79bb\u7ebf\u6d4b\u8bd5\u4e2d\u4f18\u4e8eSFT\u3001DPO\u548c\u666e\u901aGRPO\uff0c\u5728\u6dd8\u5b9dA/B\u6d4b\u8bd5\u4e2d\u5728GSB\u3001Query Goodrate\u548cItem Goodrate\u6307\u6807\u4e0a\u6301\u7eed\u63d0\u5347\uff0c\u5df2\u5728\u6dd8\u5b9d\u751f\u4ea7\u76f8\u5173\u6027\u7cfb\u7edf\u4e2d\u90e8\u7f72\u3002", "conclusion": "DyKnow-RAG\u662f\u9996\u6279\u7528\u4e8e\u7535\u5546\u76f8\u5173\u6027\u7684\u5355\u6b21RAG\u89e3\u51b3\u65b9\u6848\u4e4b\u4e00\uff0c\u5c06\u566a\u58f0\u5916\u90e8\u4fe1\u53f7\u8f6c\u5316\u4e3a\u53ef\u9760\u6536\u76ca\uff0c\u800c\u65e0\u9700\u589e\u52a0\u5728\u7ebf\u590d\u6742\u6027\u3002"}}
{"id": "2510.11317", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11317", "abs": "https://arxiv.org/abs/2510.11317", "authors": ["Chen Gao", "Zixin Zhao", "Lv Shao", "Tong Liu"], "title": "Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines", "comment": null, "summary": "Click-Through Rate (CTR) prediction, a cornerstone of modern recommender\nsystems, has been dominated by discriminative models that react to past user\nbehavior rather than proactively modeling user intent. Existing generative\nparadigms attempt to address this but suffer from critical limitations: Large\nLanguage Model (LLM) based methods create a semantic mismatch by forcing\ne-commerce signals into a linguistic space, while ID-based generation is\nconstrained by item memorization and cold-start issues. To overcome these\nlimitations, we propose a novel generative pre-training paradigm. Our model\nlearns to predict the Next Interest Flow, a dense vector sequence representing\na user's future intent, while simultaneously modeling its internal Interest\nDiversity and Interest Evolution Velocity to ensure the representation is both\nrich and coherent. However, this two-stage approach introduces a critical\nobjective mismatch between the generative and discriminative stages. We resolve\nthis via a bidirectional alignment strategy, which harmonizes the two stages\nthrough cross-stage weight initialization and a dynamic Semantic Alignment\nModule for fine-tuning. Additionally, we enhance the underlying discriminative\nmodel with a Temporal Sequential Pairwise (TSP) mechanism to better capture\ntemporal causality. We present the All-domain Moveline Evolution Network\n(AMEN), a unified framework implementing our entire pipeline. Extensive offline\nexperiments validate AMEN's superiority over strong baselines, and a\nlarge-scale online A/B test demonstrates its significant real-world impact,\ndelivering substantial improvements in key business metrics.", "AI": {"tldr": "\u63d0\u51faAMEN\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u9884\u6d4b\u7528\u6237\u672a\u6765\u5174\u8da3\u6d41\uff0c\u89e3\u51b3\u4f20\u7edfCTR\u9884\u6d4b\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u53cc\u5411\u5bf9\u9f50\u7b56\u7565\u534f\u8c03\u751f\u6210\u548c\u5224\u522b\u9636\u6bb5\u3002", "motivation": "\u4f20\u7edfCTR\u9884\u6d4b\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u5224\u522b\u5f0f\u65b9\u6cd5\uff0c\u88ab\u52a8\u54cd\u5e94\u7528\u6237\u5386\u53f2\u884c\u4e3a\u800c\u975e\u4e3b\u52a8\u5efa\u6a21\u7528\u6237\u610f\u56fe\u3002\u73b0\u6709\u751f\u6210\u5f0f\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u51b7\u542f\u52a8\u95ee\u9898\u3002", "method": "\u63d0\u51faNext Interest Flow\u9884\u6d4b\uff0c\u5efa\u6a21\u5174\u8da3\u591a\u6837\u6027\u548c\u6f14\u5316\u901f\u5ea6\uff1b\u91c7\u7528\u53cc\u5411\u5bf9\u9f50\u7b56\u7565\uff0c\u5305\u62ec\u8de8\u9636\u6bb5\u6743\u91cd\u521d\u59cb\u5316\u548c\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\uff1b\u5f15\u5165TSP\u673a\u5236\u589e\u5f3a\u65f6\u5e8f\u56e0\u679c\u5efa\u6a21\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793aAMEN\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5927\u89c4\u6a21\u5728\u7ebfA/B\u6d4b\u8bd5\u8bc1\u660e\u5176\u5728\u5173\u952e\u4e1a\u52a1\u6307\u6807\u4e0a\u5e26\u6765\u663e\u8457\u63d0\u5347\u3002", "conclusion": "AMEN\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u4e0e\u5224\u522b\u5f0f\u6a21\u578b\u95f4\u7684\u76ee\u6807\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3aCTR\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11323", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11323", "abs": "https://arxiv.org/abs/2510.11323", "authors": ["Zhe Wang", "Yaming Yang", "Ziyu Guan", "Bin Tong", "Rui Wang", "Wei Zhao", "Hongbo Deng"], "title": "Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate Marketing", "comment": null, "summary": "In recent years, affiliate marketing has emerged as a revenue-sharing\nstrategy where merchants collaborate with promoters to promote their products.\nIt not only increases product exposure but also allows promoters to earn a\ncommission. This paper addresses the pivotal yet under-explored challenge in\naffiliate marketing: accurately assessing and predicting the contributions of\npromoters in product promotion. We design a novel metric for evaluating the\nindirect contributions of the promoter, called propagation scale.\nUnfortunately, existing time series forecasting techniques fail to deliver\naccurate predictions due to the propagation scale being influenced by multiple\nfactors and the inherent complexities arising from dynamic scenarios. To\naddress this issue, we decouple the network structure from the node signals and\npropose a two-stage solution: initially, the basic self-sales and network\nstructure prediction are conducted separately, followed by the synthesis of the\npropagation scale. Specifically, we design a graph convolution encoding scheme\nbased on descendant neighbors and incorporate hypergraph convolution to\nefficiently capture complex promotional dynamics. Additionally, three auxiliary\ntasks are employed: self-sales prediction for base estimations, descendant\nprediction to synthesize propagation scale, and promoter activation prediction\nto mitigate high volatility issues. Extensive offline experiments on\nlarge-scale industrial datasets validate the superiority of our method. We\nfurther deploy our model on Alimama platform with over $100,000$ promoters,\nachieving a $9.29\\%$ improvement in GMV and a $5.89\\%$ increase in sales\nvolume.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u8054\u76df\u8425\u9500\u4e2d\u63a8\u5e7f\u8005\u95f4\u63a5\u8d21\u732e\u7684\u65b0\u6307\u6807\u2014\u2014\u4f20\u64ad\u89c4\u6a21\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u9884\u6d4b\u6a21\u578b\u6765\u89e3\u51b3\u8be5\u6307\u6807\u7684\u591a\u56e0\u7d20\u5f71\u54cd\u548c\u52a8\u6001\u590d\u6742\u6027\u3002", "motivation": "\u8054\u76df\u8425\u9500\u4e2d\u51c6\u786e\u8bc4\u4f30\u548c\u9884\u6d4b\u63a8\u5e7f\u8005\u5728\u4ea7\u54c1\u63a8\u5e7f\u4e2d\u7684\u8d21\u732e\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6311\u6218\uff0c\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6280\u672f\u7531\u4e8e\u4f20\u64ad\u89c4\u6a21\u53d7\u591a\u56e0\u7d20\u5f71\u54cd\u548c\u52a8\u6001\u573a\u666f\u590d\u6742\u6027\u800c\u65e0\u6cd5\u63d0\u4f9b\u51c6\u786e\u9884\u6d4b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u89e3\u51b3\u65b9\u6848\uff1a\u9996\u5148\u5206\u522b\u8fdb\u884c\u57fa\u672c\u81ea\u9500\u552e\u548c\u7f51\u7edc\u7ed3\u6784\u9884\u6d4b\uff0c\u7136\u540e\u5408\u6210\u4f20\u64ad\u89c4\u6a21\u3002\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u540e\u4ee3\u90bb\u5c45\u7684\u56fe\u5377\u79ef\u7f16\u7801\u65b9\u6848\uff0c\u5e76\u5f15\u5165\u8d85\u56fe\u5377\u79ef\u6765\u6709\u6548\u6355\u6349\u590d\u6742\u7684\u63a8\u5e7f\u52a8\u6001\uff0c\u540c\u65f6\u4f7f\u7528\u4e09\u4e2a\u8f85\u52a9\u4efb\u52a1\u6765\u7f13\u89e3\u9ad8\u6ce2\u52a8\u6027\u95ee\u9898\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002\u5728\u62e5\u6709\u8d85\u8fc710\u4e07\u63a8\u5e7f\u8005\u7684Alimama\u5e73\u53f0\u4e0a\u90e8\u7f72\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86GMV\u63d0\u53479.29%\u548c\u9500\u552e\u91cf\u589e\u52a05.89%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u8054\u76df\u8425\u9500\u4e2d\u63a8\u5e7f\u8005\u7684\u4f20\u64ad\u89c4\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e1a\u52a1\u6307\u6807\uff0c\u4e3a\u8054\u76df\u8425\u9500\u8d21\u732e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11394", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11394", "abs": "https://arxiv.org/abs/2510.11394", "authors": ["Haosheng Qian", "Yixing Fan", "Jiafeng Guo", "Ruqing Zhang", "Qi Chen", "Dawei Yin", "Xueqi Cheng"], "title": "VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for\nenhancing the responses of large language models (LLMs) with external knowledge\nsources. Despite the impressive performance in complex question-answering\ntasks, RAG still struggles with hallucinations. Attributing RAG-generated\ncontent through in-line citations has demonstrated potential in reducing\nhallucinations and facilitating human verification. Existing citation\ngeneration methods primarily rely on either fine-tuning the generator or\nemploying post-processing approaches for citation matching. However, the former\napproach demands substantial annotated data and computational resources, while\nthe latter often encounters difficulties in managing multiple citations and\nfrequently produces suboptimal results. In this paper, we introduce a novel\nframework, called VeriCite, designed to rigorously validate supporting evidence\nand enhance answer attribution. Specifically, VeriCite breaks down into a\nthree-stage generation: 1) The initial answer generation first generates a\nresponse based on all available contexts and has its claims verified through\nthe NLI model; 2) the supporting evidence selection assesses the utility of\neach document and extracts useful supporting evidences; 3) the final answer\nrefinement integrates the initial response and collected evidences to produce\nthe final, refined answer.We conduct experiments across five open-source LLMs\nand four datasets, demonstrating that VeriCite can significantly improve\ncitation quality while maintaining the correctness of the answers.", "AI": {"tldr": "VeriCite\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7NLI\u6a21\u578b\u9a8c\u8bc1\u3001\u652f\u6301\u8bc1\u636e\u9009\u62e9\u548c\u7b54\u6848\u7cbe\u70bc\u6765\u589e\u5f3aRAG\u7cfb\u7edf\u7684\u5f15\u7528\u751f\u6210\u8d28\u91cf\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u5728\u5f15\u7528\u751f\u6210\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5fae\u8c03\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u540e\u5904\u7406\u65b9\u6cd5\u5728\u5904\u7406\u591a\u5f15\u7528\u65f6\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u4e09\u9636\u6bb5\u751f\u6210\uff1a1)\u57fa\u4e8e\u4e0a\u4e0b\u6587\u751f\u6210\u521d\u59cb\u7b54\u6848\u5e76\u7528NLI\u6a21\u578b\u9a8c\u8bc1\uff1b2)\u8bc4\u4f30\u6587\u6863\u6548\u7528\u5e76\u63d0\u53d6\u652f\u6301\u8bc1\u636e\uff1b3)\u6574\u5408\u521d\u59cb\u7b54\u6848\u548c\u8bc1\u636e\u751f\u6210\u6700\u7ec8\u7cbe\u70bc\u7b54\u6848\u3002", "result": "\u5728\u4e94\u4e2a\u5f00\u6e90LLM\u548c\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVeriCite\u80fd\u663e\u8457\u63d0\u9ad8\u5f15\u7528\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u7b54\u6848\u6b63\u786e\u6027\u3002", "conclusion": "VeriCite\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86RAG\u7cfb\u7edf\u4e2d\u7684\u5f15\u7528\u751f\u6210\u95ee\u9898\uff0c\u901a\u8fc7\u4e25\u8c28\u7684\u8bc1\u636e\u9a8c\u8bc1\u548c\u7b54\u6848\u7cbe\u70bc\u8fc7\u7a0b\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2510.11402", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11402", "abs": "https://arxiv.org/abs/2510.11402", "authors": ["Gregor Meehan", "Johan Pauwels"], "title": "On Inherited Popularity Bias in Cold-Start Item Recommendation", "comment": "Published at ACM RecSys 2025", "summary": "Collaborative filtering (CF) recommender systems struggle with making\npredictions on unseen, or 'cold', items. Systems designed to address this\nchallenge are often trained with supervision from warm CF models in order to\nleverage collaborative and content information from the available interaction\ndata. However, since they learn to replicate the behavior of CF methods,\ncold-start models may therefore also learn to imitate their predictive biases.\nIn this paper, we show that cold-start systems can inherit popularity bias, a\ncommon cause of recommender system unfairness arising when CF models overfit to\nmore popular items, thereby maximizing user-oriented accuracy but neglecting\nrarer items. We demonstrate that cold-start recommenders not only mirror the\npopularity biases of warm models, but are in fact affected more severely:\nbecause they cannot infer popularity from interaction data, they instead\nattempt to estimate it based solely on content features. This leads to\nsignificant over-prediction of certain cold items with similar content to\npopular warm items, even if their ground truth popularity is very low. Through\nexperiments on three multimedia datasets, we analyze the impact of this\nbehavior on three generative cold-start methods. We then describe a simple\npost-processing bias mitigation method that, by using embedding magnitude as a\nproxy for predicted popularity, can produce more balanced recommendations with\nlimited harm to user-oriented cold-start accuracy.", "AI": {"tldr": "\u51b7\u542f\u52a8\u63a8\u8350\u7cfb\u7edf\u4f1a\u7ee7\u627f\u70ed\u542f\u52a8\u6a21\u578b\u7684\u6d41\u884c\u5ea6\u504f\u89c1\uff0c\u751a\u81f3\u66f4\u4e25\u91cd\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ea\u80fd\u57fa\u4e8e\u5185\u5bb9\u7279\u5f81\u6765\u4f30\u8ba1\u6d41\u884c\u5ea6\uff0c\u5bfc\u81f4\u5bf9\u4e0e\u70ed\u95e8\u7269\u54c1\u5185\u5bb9\u76f8\u4f3c\u7684\u51b7\u7269\u54c1\u8fdb\u884c\u8fc7\u5ea6\u9884\u6d4b\u3002", "motivation": "\u51b7\u542f\u52a8\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u4ece\u70ed\u542f\u52a8CF\u6a21\u578b\u4e2d\u5b66\u4e60\uff0c\u4f46\u8fd9\u6837\u53ef\u80fd\u4f1a\u7ee7\u627f\u70ed\u542f\u52a8\u6a21\u578b\u7684\u9884\u6d4b\u504f\u89c1\uff0c\u7279\u522b\u662f\u6d41\u884c\u5ea6\u504f\u89c1\uff0c\u4ece\u800c\u5f71\u54cd\u63a8\u8350\u516c\u5e73\u6027\u3002", "method": "\u5728\u4e09\u4e2a\u591a\u5a92\u4f53\u6570\u636e\u96c6\u4e0a\u5206\u6790\u4e09\u79cd\u751f\u6210\u5f0f\u51b7\u542f\u52a8\u65b9\u6cd5\u7684\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u7684\u540e\u5904\u7406\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\uff0c\u4f7f\u7528\u5d4c\u5165\u5411\u91cf\u5927\u5c0f\u4f5c\u4e3a\u9884\u6d4b\u6d41\u884c\u5ea6\u7684\u4ee3\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u51b7\u542f\u52a8\u63a8\u8350\u5668\u4e0d\u4ec5\u955c\u50cf\u70ed\u6a21\u578b\u7684\u6d41\u884c\u5ea6\u504f\u89c1\uff0c\u800c\u4e14\u53d7\u5f71\u54cd\u66f4\u4e25\u91cd\uff0c\u56e0\u4e3a\u5b83\u4eec\u65e0\u6cd5\u4ece\u4ea4\u4e92\u6570\u636e\u63a8\u65ad\u6d41\u884c\u5ea6\uff0c\u53ea\u80fd\u57fa\u4e8e\u5185\u5bb9\u7279\u5f81\u8fdb\u884c\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u540e\u5904\u7406\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u66f4\u5e73\u8861\u7684\u63a8\u8350\uff0c\u540c\u65f6\u5bf9\u7528\u6237\u5bfc\u5411\u7684\u51b7\u542f\u52a8\u51c6\u786e\u6027\u5f71\u54cd\u6709\u9650\u3002"}}
{"id": "2510.11438", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11438", "abs": "https://arxiv.org/abs/2510.11438", "authors": ["Yujiang Wu", "Shanshan Zhong", "Yubin Kim", "Chenyan Xiong"], "title": "What Generative Search Engines Like and How to Optimize Web Content Cooperatively", "comment": null, "summary": "By employing large language models (LLMs) to retrieve documents and generate\nnatural language responses, Generative Engines, such as Google AI overview and\nChatGPT, provide significantly enhanced user experiences and have rapidly\nbecome the new form of search. Their rapid adoption also drives the needs of\nGenerative Engine Optimization (GEO), as content providers are eager to gain\nmore traction from them. In this paper, we introduce AutoGEO, a framework to\nautomatically learn generative engine preferences when using retrieved contents\nfor response generation, and rewrite web contents for more such traction.\nAutoGEO first prompts frontier LLMs to explain generative engine preferences\nand extract meaningful preference rules from these explanations. Then it uses\npreference rules as context engineering for AutoGEO$_\\text{API}$, a\nprompt-based GEO system, and as rule-based rewards to train\nAutoGEO$_\\text{Mini}$, a cost-effective GEO model. Experiments on the standard\nGEO-Bench and two newly constructed benchmarks using real user queries\ndemonstrate the effectiveness of AutoGEO in enhancing content traction while\npreserving search utility. Analyses confirm the learned rules' robustness and\nabilities to capture unique preferences in variant domains, and AutoGEO\nsystems' ability to embed them in content optimization. The code is released at\nhttps://github.com/cxcscmu/AutoGEO.", "AI": {"tldr": "AutoGEO\u662f\u4e00\u4e2a\u81ea\u52a8\u5b66\u4e60\u751f\u6210\u5f15\u64ce\u504f\u597d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u504f\u597d\u89c4\u5219\u6765\u4f18\u5316\u7f51\u9875\u5185\u5bb9\uff0c\u4ee5\u63d0\u5347\u5728\u751f\u6210\u5f15\u64ce\u4e2d\u7684\u66dd\u5149\u5ea6\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u7684\u666e\u53ca\uff0c\u5185\u5bb9\u63d0\u4f9b\u8005\u9700\u8981\u4f18\u5316\u5185\u5bb9\u4ee5\u83b7\u5f97\u66f4\u591a\u66dd\u5149\uff0c\u4f46\u624b\u52a8\u4f18\u5316\u6210\u672c\u9ad8\u6602\u4e14\u6548\u679c\u6709\u9650\u3002", "method": "\u9996\u5148\u4f7f\u7528\u524d\u6cbfLLM\u89e3\u91ca\u751f\u6210\u5f15\u64ce\u504f\u597d\u5e76\u63d0\u53d6\u89c4\u5219\uff0c\u7136\u540e\u5229\u7528\u8fd9\u4e9b\u89c4\u5219\u8fdb\u884c\u63d0\u793a\u5de5\u7a0b\u548c\u8bad\u7ec3\u6210\u672c\u6548\u76ca\u6a21\u578b\u3002", "result": "\u5728\u6807\u51c6GEO-Bench\u548c\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoGEO\u6709\u6548\u63d0\u5347\u4e86\u5185\u5bb9\u66dd\u5149\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u641c\u7d22\u5b9e\u7528\u6027\u3002", "conclusion": "AutoGEO\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u5e76\u5d4c\u5165\u751f\u6210\u5f15\u64ce\u7684\u504f\u597d\u89c4\u5219\uff0c\u4e3a\u5185\u5bb9\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11483", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11483", "abs": "https://arxiv.org/abs/2510.11483", "authors": ["Heydar Soudani", "Hamed Zamani", "Faegheh Hasibi"], "title": "Uncertainty Quantification for Retrieval-Augmented Reasoning", "comment": null, "summary": "Retrieval-augmented reasoning (RAR) is a recent evolution of\nretrieval-augmented generation (RAG) that employs multiple reasoning steps for\nretrieval and generation. While effective for some complex queries, RAR remains\nvulnerable to errors and misleading outputs. Uncertainty quantification (UQ)\noffers methods to estimate the confidence of systems' outputs. These methods,\nhowever, often handle simple queries with no retrieval or single-step\nretrieval, without properly handling RAR setup. Accurate estimation of UQ for\nRAR requires accounting for all sources of uncertainty, including those arising\nfrom retrieval and generation. In this paper, we account for all these sources\nand introduce Retrieval-Augmented Reasoning Consistency (R2C)--a novel UQ\nmethod for RAR. The core idea of R2C is to perturb the multi-step reasoning\nprocess by applying various actions to reasoning steps. These perturbations\nalter the retriever's input, which shifts its output and consequently modifies\nthe generator's input at the next step. Through this iterative feedback loop,\nthe retriever and generator continuously reshape one another's inputs, enabling\nus to capture uncertainty arising from both components. Experiments on five\npopular RAR systems across diverse QA datasets show that R2C improves AUROC by\nover 5% on average compared to the state-of-the-art UQ baselines. Extrinsic\nevaluations using R2C as an external signal further confirm its effectiveness\nfor two downstream tasks: in Abstention, it achieves ~5% gains in both\nF1Abstain and AccAbstain; in Model Selection, it improves the exact match by\n~7% over single models and ~3% over selection methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86R2C\u65b9\u6cd5\uff0c\u901a\u8fc7\u6270\u52a8\u591a\u6b65\u63a8\u7406\u8fc7\u7a0b\u6765\u91cf\u5316\u68c0\u7d22\u589e\u5f3a\u63a8\u7406(RAR)\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6027\u80fd", "motivation": "\u73b0\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u68c0\u7d22\u589e\u5f3a\u63a8\u7406(RAR)\u4e2d\u7684\u591a\u6b65\u63a8\u7406\u8fc7\u7a0b\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u68c0\u7d22\u548c\u751f\u6210\u73af\u8282\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6e90", "method": "R2C\u901a\u8fc7\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u5e94\u7528\u5404\u79cd\u6270\u52a8\u64cd\u4f5c\uff0c\u6539\u53d8\u68c0\u7d22\u5668\u7684\u8f93\u5165\uff0c\u4ece\u800c\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u6355\u83b7\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\u7684\u4e0d\u786e\u5b9a\u6027", "result": "\u5728\u4e94\u4e2aRAR\u7cfb\u7edf\u548c\u591a\u4e2aQA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cR2C\u76f8\u6bd4\u73b0\u6709\u6700\u4f18UQ\u57fa\u7ebf\u5e73\u5747\u63d0\u5347AUROC\u8d85\u8fc75%\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4e5f\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "R2C\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9RAR\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u6355\u83b7\u591a\u6b65\u63a8\u7406\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd"}}
{"id": "2510.11560", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11560", "abs": "https://arxiv.org/abs/2510.11560", "authors": ["Elisabeth Kirsten", "Jost Grosse Perdekamp", "Mihir Upadhyay", "Krishna P. Gummadi", "Muhammad Bilal Zafar"], "title": "Characterizing Web Search in The Age of Generative AI", "comment": null, "summary": "The advent of LLMs has given rise to a new type of web search: Generative\nsearch, where LLMs retrieve web pages related to a query and generate a single,\ncoherent text as a response. This output modality stands in stark contrast to\ntraditional web search, where results are returned as a ranked list of\nindependent web pages. In this paper, we ask: Along what dimensions do\ngenerative search outputs differ from traditional web search? We compare\nGoogle, a traditional web search engine, with four generative search engines\nfrom two providers (Google and OpenAI) across queries from four domains. Our\nanalysis reveals intriguing differences. Most generative search engines cover a\nwider range of sources compared to web search. Generative search engines vary\nin the degree to which they rely on internal knowledge contained within the\nmodel parameters v.s. external knowledge retrieved from the web. Generative\nsearch engines surface varying sets of concepts, creating new opportunities for\nenhancing search diversity and serendipity. Our results also highlight the need\nfor revisiting evaluation criteria for web search in the age of Generative AI.", "AI": {"tldr": "\u6bd4\u8f83\u4f20\u7edf\u641c\u7d22\u5f15\u64ce\u4e0e\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u5728\u641c\u7d22\u7ed3\u679c\u8986\u76d6\u8303\u56f4\u3001\u77e5\u8bc6\u6765\u6e90\u3001\u6982\u5ff5\u591a\u6837\u6027\u7b49\u65b9\u9762\u7684\u5dee\u5f02", "motivation": "\u968f\u7740LLM\u7684\u53d1\u5c55\uff0c\u751f\u6210\u5f0f\u641c\u7d22\uff08\u76f4\u63a5\u751f\u6210\u8fde\u8d2f\u6587\u672c\u56de\u7b54\uff09\u4e0e\u4f20\u7edf\u641c\u7d22\uff08\u8fd4\u56de\u7f51\u9875\u6392\u540d\u5217\u8868\uff09\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83\u4e24\u8005\u7684\u5dee\u5f02\u7ef4\u5ea6", "method": "\u6bd4\u8f83Google\u4f20\u7edf\u641c\u7d22\u5f15\u64ce\u4e0e\u6765\u81eaGoogle\u548cOpenAI\u7684\u56db\u4e2a\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\uff0c\u4f7f\u7528\u6765\u81ea\u56db\u4e2a\u9886\u57df\u7684\u67e5\u8be2\u8fdb\u884c\u5206\u6790", "result": "\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u8986\u76d6\u66f4\u5e7f\u7684\u6765\u6e90\uff1b\u4e0d\u540c\u751f\u6210\u5f0f\u5f15\u64ce\u5728\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u77e5\u8bc6vs\u5916\u90e8\u68c0\u7d22\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff1b\u751f\u6210\u5f0f\u641c\u7d22\u5448\u73b0\u66f4\u591a\u6837\u5316\u7684\u6982\u5ff5\uff0c\u4e3a\u641c\u7d22\u591a\u6837\u6027\u548c\u5076\u7136\u53d1\u73b0\u521b\u9020\u65b0\u673a\u4f1a", "conclusion": "\u751f\u6210\u5f0f\u641c\u7d22\u4e0e\u4f20\u7edf\u641c\u7d22\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u751f\u6210AI\u65f6\u4ee3\u4e0b\u7684\u7f51\u7edc\u641c\u7d22\u8bc4\u4f30\u6807\u51c6"}}
{"id": "2510.11589", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11589", "abs": "https://arxiv.org/abs/2510.11589", "authors": ["Shubham Chatterjee", "Jeff Dalton"], "title": "QDER: Query-Specific Document and Entity Representations for Multi-Vector Document Re-Ranking", "comment": "Published in: Proceedings of the 48th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval (SIGIR 2025)", "summary": "Neural IR has advanced through two distinct paths: entity-oriented approaches\nleveraging knowledge graphs and multi-vector models capturing fine-grained\nsemantics. We introduce QDER, a neural re-ranking model that unifies these\napproaches by integrating knowledge graph semantics into a multi-vector model.\nQDER's key innovation lies in its modeling of query-document relationships:\nrather than computing similarity scores on aggregated embeddings, we maintain\nindividual token and entity representations throughout the ranking process,\nperforming aggregation only at the final scoring stage - an approach we call\n\"late aggregation.\" We first transform these fine-grained representations\nthrough learned attention patterns, then apply carefully chosen mathematical\noperations for precise matches. Experiments across five standard benchmarks\nshow that QDER achieves significant performance gains, with improvements of 36%\nin nDCG@20 over the strongest baseline on TREC Robust 2004 and similar\nimprovements on other datasets. QDER particularly excels on difficult queries,\nachieving an nDCG@20 of 0.70 where traditional approaches fail completely\n(nDCG@20 = 0.0), setting a foundation for future work in entity-aware\nretrieval.", "AI": {"tldr": "QDER\u662f\u4e00\u4e2a\u795e\u7ecf\u91cd\u6392\u5e8f\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u56fe\u8c31\u8bed\u4e49\u6574\u5408\u5230\u591a\u5411\u91cf\u6a21\u578b\u4e2d\uff0c\u7edf\u4e00\u4e86\u5b9e\u4f53\u5bfc\u5411\u548c\u591a\u5411\u91cf\u65b9\u6cd5\u3002\u5b83\u91c7\u7528\"\u5ef6\u8fdf\u805a\u5408\"\u7b56\u7565\uff0c\u5728\u6700\u7ec8\u8bc4\u5206\u9636\u6bb5\u624d\u8fdb\u884c\u805a\u5408\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u7edf\u4e00\u795e\u7ecf\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u4f53\u5bfc\u5411\u65b9\u6cd5\u548c\u6355\u6349\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7684\u591a\u5411\u91cf\u6a21\u578b\uff0c\u4ee5\u514b\u670d\u5404\u81ea\u5c40\u9650\u6027\u3002", "method": "\u4fdd\u6301\u5355\u72ec\u7684token\u548c\u5b9e\u4f53\u8868\u793a\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u8f6c\u6362\u8fd9\u4e9b\u7ec6\u7c92\u5ea6\u8868\u793a\uff0c\u7136\u540e\u5728\u6700\u7ec8\u8bc4\u5206\u9636\u6bb5\u5e94\u7528\u7cbe\u5fc3\u9009\u62e9\u7684\u6570\u5b66\u8fd0\u7b97\u8fdb\u884c\u7cbe\u786e\u5339\u914d\u3002", "result": "\u5728\u4e94\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQDER\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5728TREC Robust 2004\u4e0anDCG@20\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u9ad836%\uff0c\u5728\u56f0\u96be\u67e5\u8be2\u4e0a\u8fbe\u52300.70\u7684nDCG@20\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u5b8c\u5168\u5931\u8d25\u3002", "conclusion": "QDER\u4e3a\u5b9e\u4f53\u611f\u77e5\u68c0\u7d22\u7684\u672a\u6765\u5de5\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7279\u522b\u5728\u56f0\u96be\u67e5\u8be2\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5ef6\u8fdf\u805a\u5408\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.11592", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11592", "abs": "https://arxiv.org/abs/2510.11592", "authors": ["Shubham Chatterjee"], "title": "REGENT: Relevance-Guided Attention for Entity-Aware Multi-Vector Neural Re-Ranking", "comment": "To be published in: Proceedings of the 2025 Annual International ACM\n  SIGIR Conference on Research and Development in Information Retrieval in the\n  Asia Pacific Region (SIGIR-AP 2025)", "summary": "Current neural re-rankers often struggle with complex information needs and\nlong, content-rich documents. The fundamental issue is not computational--it is\nintelligent content selection: identifying what matters in lengthy,\nmulti-faceted texts. While humans naturally anchor their understanding around\nkey entities and concepts, neural models process text within rigid token\nwindows, treating all interactions as equally important and missing critical\nsemantic signals. We introduce REGENT, a neural re-ranking model that mimics\nhuman-like understanding by using entities as a \"semantic skeleton\" to guide\nattention. REGENT integrates relevance guidance directly into the attention\nmechanism, combining fine-grained lexical matching with high-level semantic\nreasoning. This relevance-guided attention enables the model to focus on\nconceptually important content while maintaining sensitivity to precise term\nmatches. REGENT achieves new state-of-the-art performance in three challenging\ndatasets, providing up to 108% improvement over BM25 and consistently\noutperforming strong baselines including ColBERT and RankVicuna. To our\nknowledge, this is the first work to successfully integrate entity semantics\ndirectly into neural attention, establishing a new paradigm for entity-aware\ninformation retrieval.", "AI": {"tldr": "REGENT\u6a21\u578b\u901a\u8fc7\u5c06\u5b9e\u4f53\u8bed\u4e49\u76f4\u63a5\u96c6\u6210\u5230\u795e\u7ecf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u89e3\u51b3\u4e86\u795e\u7ecf\u91cd\u6392\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4fe1\u606f\u9700\u6c42\u548c\u957f\u6587\u6863\u65f6\u7684\u5185\u5bb9\u9009\u62e9\u95ee\u9898\uff0c\u5728\u4e09\u4e2a\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u91cd\u6392\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4fe1\u606f\u9700\u6c42\u548c\u5185\u5bb9\u4e30\u5bcc\u7684\u957f\u6587\u6863\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u6839\u672c\u95ee\u9898\u5728\u4e8e\u667a\u80fd\u5185\u5bb9\u9009\u62e9\u3002\u4eba\u7c7b\u7406\u89e3\u56f4\u7ed5\u5173\u952e\u5b9e\u4f53\u548c\u6982\u5ff5\u5c55\u5f00\uff0c\u800c\u795e\u7ecf\u6a21\u578b\u5728\u56fa\u5b9atoken\u7a97\u53e3\u5185\u5904\u7406\u6587\u672c\uff0c\u5c06\u6240\u6709\u4ea4\u4e92\u89c6\u4e3a\u540c\u7b49\u91cd\u8981\uff0c\u9519\u8fc7\u4e86\u5173\u952e\u7684\u8bed\u4e49\u4fe1\u53f7\u3002", "method": "REGENT\u6a21\u578b\u4f7f\u7528\u5b9e\u4f53\u4f5c\u4e3a\"\u8bed\u4e49\u9aa8\u67b6\"\u6765\u5f15\u5bfc\u6ce8\u610f\u529b\uff0c\u6a21\u4eff\u4eba\u7c7b\u7406\u89e3\u65b9\u5f0f\u3002\u5b83\u5c06\u76f8\u5173\u6027\u6307\u5bfc\u76f4\u63a5\u96c6\u6210\u5230\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u7ed3\u5408\u7ec6\u7c92\u5ea6\u8bcd\u6c47\u5339\u914d\u548c\u9ad8\u5c42\u6b21\u8bed\u4e49\u63a8\u7406\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u4e13\u6ce8\u4e8e\u6982\u5ff5\u4e0a\u91cd\u8981\u7684\u5185\u5bb9\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u7cbe\u786e\u672f\u8bed\u5339\u914d\u7684\u654f\u611f\u6027\u3002", "result": "REGENT\u5728\u4e09\u4e2a\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u76f8\u6bd4BM25\u63d0\u4f9b\u4e86\u9ad8\u8fbe108%\u7684\u6539\u8fdb\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u5305\u62ecColBERT\u548cRankVicuna\u5728\u5185\u7684\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u6210\u529f\u5c06\u5b9e\u4f53\u8bed\u4e49\u76f4\u63a5\u96c6\u6210\u5230\u795e\u7ecf\u6ce8\u610f\u529b\u4e2d\u7684\u5de5\u4f5c\uff0c\u4e3a\u5b9e\u4f53\u611f\u77e5\u4fe1\u606f\u68c0\u7d22\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.11639", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11639", "abs": "https://arxiv.org/abs/2510.11639", "authors": ["Zhanyu Liu", "Shiyao Wang", "Xingmei Wang", "Rongzhou Zhang", "Jiaxin Deng", "Honghui Bao", "Jinghao Zhang", "Wuchao Li", "Pengfei Zheng", "Xiangyu Wu", "Yifei Hu", "Qigen Hu", "Xinchen Luo", "Lejian Ren", "Zixing Zhang", "Qianqian Wang", "Kuo Cai", "Yunfan Wu", "Hongtao Cheng", "Zexuan Cheng", "Lu Ren", "Huanjie Wang", "Yi Su", "Ruiming Tang", "Kun Gai", "Guorui Zhou"], "title": "OneRec-Think: In-Text Reasoning for Generative Recommendation", "comment": null, "summary": "The powerful generative capacity of Large Language Models (LLMs) has\ninstigated a paradigm shift in recommendation. However, existing generative\nmodels (e.g., OneRec) operate as implicit predictors, critically lacking the\ncapacity for explicit and controllable reasoning-a key advantage of LLMs. To\nbridge this gap, we propose OneRec-Think, a unified framework that seamlessly\nintegrates dialogue, reasoning, and personalized recommendation. OneRec-Think\nincorporates: (1) Itemic Alignment: cross-modal Item-Textual Alignment for\nsemantic grounding; (2) Reasoning Activation: Reasoning Scaffolding to activate\nLLM reasoning within the recommendation context; and (3) Reasoning Enhancement,\nwhere we design a recommendation-specific reward function that accounts for the\nmulti-validity nature of user preferences. Experiments across public benchmarks\nshow state-of-the-art performance. Moreover, our proposed \"Think-Ahead\"\narchitecture enables effective industrial deployment on Kuaishou, achieving a\n0.159\\% gain in APP Stay Time and validating the practical efficacy of the\nmodel's explicit reasoning capability.", "AI": {"tldr": "OneRec-Think\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u5c06\u5bf9\u8bdd\u3001\u63a8\u7406\u548c\u4e2a\u6027\u5316\u63a8\u8350\u76f8\u7ed3\u5408\uff0c\u5728\u5feb\u624b\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5b9e\u9645\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u7f3a\u4e4f\u663e\u5f0f\u548c\u53ef\u63a7\u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u8fd9\u6b63\u662f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a\u9879\u76ee\u5bf9\u9f50\uff08\u8de8\u6a21\u6001\u9879\u76ee-\u6587\u672c\u5bf9\u9f50\uff09\u3001\u63a8\u7406\u6fc0\u6d3b\uff08\u5728\u63a8\u8350\u4e0a\u4e0b\u6587\u4e2d\u6fc0\u6d3bLLM\u63a8\u7406\uff09\u3001\u63a8\u7406\u589e\u5f3a\uff08\u8bbe\u8ba1\u8003\u8651\u7528\u6237\u504f\u597d\u591a\u6709\u6548\u6027\u7684\u7279\u5b9a\u5956\u52b1\u51fd\u6570\uff09\u3002", "result": "\u5728\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u5feb\u624b\u5e73\u53f0\u4e0a\u90e8\u7f72\u83b7\u5f970.159%\u7684APP\u505c\u7559\u65f6\u95f4\u63d0\u5347\u3002", "conclusion": "OneRec-Think\u6846\u67b6\u6210\u529f\u5c06\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u5f15\u5165\u63a8\u8350\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2510.11654", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11654", "abs": "https://arxiv.org/abs/2510.11654", "authors": ["Daniel Berhane Araya", "Duoduo Liao"], "title": "FinVet: A Collaborative Framework of RAG and External Fact-Checking Agents for Financial Misinformation Detection", "comment": null, "summary": "Financial markets face growing threats from misinformation that can trigger\nbillions in losses in minutes. Most existing approaches lack transparency in\ntheir decision-making and provide limited attribution to credible sources. We\nintroduce FinVet, a novel multi-agent framework that integrates two\nRetrieval-Augmented Generation (RAG) pipelines with external fact-checking\nthrough a confidence-weighted voting mechanism. FinVet employs adaptive\nthree-tier processing that dynamically adjusts verification strategies based on\nretrieval confidence, from direct metadata extraction to hybrid reasoning to\nfull model-based analysis. Unlike existing methods, FinVet provides\nevidence-backed verdicts, source attribution, confidence scores, and explicit\nuncertainty flags when evidence is insufficient. Experimental evaluation on the\nFinFact dataset shows that FinVet achieves an F1 score of 0.85, which is a\n10.4% improvement over the best individual pipeline (fact-check pipeline) and\n37% improvement over standalone RAG approaches.", "AI": {"tldr": "FinVet\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u4e24\u4e2a\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\u548c\u5916\u90e8\u4e8b\u5b9e\u6838\u67e5\uff0c\u91c7\u7528\u7f6e\u4fe1\u5ea6\u52a0\u6743\u6295\u7968\u673a\u5236\u6765\u5bf9\u6297\u91d1\u878d\u5e02\u573a\u4e2d\u7684\u9519\u8bef\u4fe1\u606f\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u9762\u4e34\u9519\u8bef\u4fe1\u606f\u7684\u5a01\u80c1\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u51b3\u7b56\u900f\u660e\u5ea6\u4e14\u96be\u4ee5\u6eaf\u6e90\u53ef\u4fe1\u6765\u6e90\u3002", "method": "FinVet\u91c7\u7528\u81ea\u9002\u5e94\u4e09\u5c42\u5904\u7406\u673a\u5236\uff0c\u6839\u636e\u68c0\u7d22\u7f6e\u4fe1\u5ea6\u52a8\u6001\u8c03\u6574\u9a8c\u8bc1\u7b56\u7565\uff1a\u4ece\u76f4\u63a5\u5143\u6570\u636e\u63d0\u53d6\u5230\u6df7\u5408\u63a8\u7406\u518d\u5230\u5b8c\u6574\u6a21\u578b\u5206\u6790\uff0c\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u52a0\u6743\u6295\u7968\u3002", "result": "\u5728FinFact\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFinVet\u8fbe\u52300.85\u7684F1\u5206\u6570\uff0c\u6bd4\u6700\u4f73\u5355\u7ba1\u9053(\u4e8b\u5b9e\u6838\u67e5\u7ba1\u9053)\u63d0\u534710.4%\uff0c\u6bd4\u72ec\u7acbRAG\u65b9\u6cd5\u63d0\u534737%\u3002", "conclusion": "FinVet\u901a\u8fc7\u63d0\u4f9b\u8bc1\u636e\u652f\u6301\u7684\u88c1\u51b3\u3001\u6765\u6e90\u5f52\u5c5e\u3001\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u548c\u660e\u786e\u7684\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91d1\u878d\u5e02\u573a\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
