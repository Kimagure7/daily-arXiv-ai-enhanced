<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [JAG: Joint Attribute Graphs for Filtered Nearest Neighbor Search](https://arxiv.org/abs/2602.10258)
*Haike Xu,Guy Blelloch,Laxman Dhulipala,Lars Gottesbüren,Rajesh Jayaram,Jakub Łącki*

Main category: cs.IR

TL;DR: JAG (Joint Attribute Graphs) 是一种图基过滤最近邻搜索算法，通过引入属性和过滤距离，将二元过滤约束转化为连续导航指导，在多种过滤类型和选择性范围内实现稳健性能。


<details>
  <summary>Details</summary>
Motivation: 现有过滤最近邻搜索算法对查询选择性和过滤类型高度敏感，通常只在特定过滤类别或狭窄选择性范围内表现良好，无法满足实际部署中对新过滤类型和未知查询选择性的泛化需求。

Method: 提出JAG算法，引入属性和过滤距离概念，将二元过滤约束转化为连续导航指导。构建同时优化向量相似性和属性邻近性的邻近图，防止导航死胡同。

Result: 在五个数据集和四种过滤类型（标签、范围、子集、布尔）上的实验表明，JAG在吞吐量和召回鲁棒性方面显著优于现有最先进的基线方法。

Conclusion: JAG通过联合优化向量相似性和属性邻近性，实现了在整个选择性谱系和多种过滤类型上的稳健性能，解决了现有算法泛化能力不足的问题。

Abstract: Despite filtered nearest neighbor search being a fundamental task in modern vector search systems, the performance of existing algorithms is highly sensitive to query selectivity and filter type. In particular, existing solutions excel either at specific filter categories (e.g., label equality) or within narrow selectivity bands (e.g., pre-filtering for low selectivity) and are therefore a poor fit for practical deployments that demand generalization to new filter types and unknown query selectivities. In this paper, we propose JAG (Joint Attribute Graphs), a graph-based algorithm designed to deliver robust performance across the entire selectivity spectrum and support diverse filter types. Our key innovation is the introduction of attribute and filter distances, which transform binary filter constraints into continuous navigational guidance. By constructing a proximity graph that jointly optimizes for both vector similarity and attribute proximity, JAG prevents navigational dead-ends and allows JAG to consistently outperform prior graph-based filtered nearest neighbor search methods. Our experimental results across five datasets and four filter types (Label, Range, Subset, Boolean) demonstrate that JAG significantly outperforms existing state-of-the-art baselines in both throughput and recall robustness.

</details>


### [2] [MLDocRAG: Multimodal Long-Context Document Retrieval Augmented Generation](https://arxiv.org/abs/2602.10271)
*Yongyue Zhang,Yaxiong Wu*

Main category: cs.IR

TL;DR: 该论文提出MLDocRAG框架，通过多模态块-查询图(MCQG)来解决长文档多模态理解中的跨模态异质性和跨页面推理挑战，提升检索质量和答案准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态长文档理解的两个主要挑战：(1) 跨模态异质性——在不同模态（段落、图表、表格）中定位相关信息；(2) 跨页面推理——聚合分散在不同页面的证据。采用以查询为中心的表述，将跨模态和跨页面信息投影到统一的查询表示空间。

Method: 提出MLDocRAG框架，构建多模态块-查询图(MCQG)。通过多模态文档扩展过程，从异构文档块生成细粒度查询，并将这些查询链接到跨模态和跨页面的对应内容。这种基于图的结构支持选择性、以查询为中心的检索和结构化证据聚合。

Result: 在MMLongBench-Doc和LongDocURL数据集上的实验表明，MLDocRAG持续提升了检索质量和答案准确性，证明了其在长上下文多模态理解中的有效性。

Conclusion: MLDocRAG框架通过多模态块-查询图成功解决了长文档多模态理解中的跨模态异质性和跨页面推理挑战，为长上下文多模态问答提供了有效的检索增强生成解决方案。

Abstract: Understanding multimodal long-context documents that comprise multimodal chunks such as paragraphs, figures, and tables is challenging due to (1) cross-modal heterogeneity to localize relevant information across modalities, (2) cross-page reasoning to aggregate dispersed evidence across pages. To address these challenges, we are motivated to adopt a query-centric formulation that projects cross-modal and cross-page information into a unified query representation space, with queries acting as abstract semantic surrogates for heterogeneous multimodal content. In this paper, we propose a Multimodal Long-Context Document Retrieval Augmented Generation (MLDocRAG) framework that leverages a Multimodal Chunk-Query Graph (MCQG) to organize multimodal document content around semantically rich, answerable queries. MCQG is constructed via a multimodal document expansion process that generates fine-grained queries from heterogeneous document chunks and links them to their corresponding content across modalities and pages. This graph-based structure enables selective, query-centric retrieval and structured evidence aggregation, thereby enhancing grounding and coherence in long-context multimodal question answering. Experiments on datasets MMLongBench-Doc and LongDocURL demonstrate that MLDocRAG consistently improves retrieval quality and answer accuracy, demonstrating its effectiveness for long-context multimodal understanding.

</details>


### [3] [Single-Turn LLM Reformulation Powered Multi-Stage Hybrid Re-Ranking for Tip-of-the-Tongue Known-Item Retrieval](https://arxiv.org/abs/2602.10321)
*Debayan Mukhopadhyay,Utshab Kumar Ghosh,Shubham Chatterjee*

Main category: cs.IR

TL;DR: 使用8B参数通用LLM进行单次查询重写，解决"舌尖现象"检索问题，通过多阶段检索流程显著提升检索效果


<details>
  <summary>Details</summary>
Motivation: "舌尖现象"检索（Tip-of-the-Tongue retrieval）面临模糊描述检索具体项目的挑战，传统伪相关反馈方法在初始召回率低时效果不佳

Method: 使用通用8B参数LLM单次调用进行查询重写，不进行领域特定微调；采用多阶段检索流程：稀疏检索（BM25）、稠密/延迟交互重排（Contriever、E5-large-v2、ColBERTv2）、monoT5交叉编码、列表重排（Qwen 2.5 72B）

Result: 在2025 TREC-ToT数据集上，查询重写使召回率提升20.61%；后续重排使nDCG@10提升33.88%、MRR提升29.92%、MAP@10提升29.98%

Conclusion: 轻量级预检索转换能有效解决"舌尖现象"检索问题，解锁下游排序器潜力，且增益主要来自提示策略而非模型专业化

Abstract: Retrieving known items from vague descriptions, Tip-of-the-Tongue (ToT) retrieval, remains a significant challenge. We propose using a single call to a generic 8B-parameter LLM for query reformulation, bridging the gap between ill-formed ToT queries and specific information needs. This method is particularly effective where standard Pseudo-Relevance Feedback fails due to poor initial recall. Crucially, our LLM is not fine-tuned for ToT or specific domains, demonstrating that gains stem from our prompting strategy rather than model specialization. Rewritten queries feed a multi-stage pipeline: sparse retrieval (BM25), dense/late-interaction reranking (Contriever, E5-large-v2, ColBERTv2), monoT5 cross-encoding, and list-wise reranking (Qwen 2.5 72B). Experiments on 2025 TREC-ToT datasets show that while raw queries yield poor performance, our lightweight pre-retrieval transformation improves Recall by 20.61%. Subsequent reranking improves nDCG@10 by 33.88%, MRR by 29.92%, and MAP@10 by 29.98%, offering a cost-effective intervention that unlocks the potential of downstream rankers. Code and data: https://github.com/debayan1405/TREC-TOT-2025

</details>


### [4] [GeoGR: A Generative Retrieval Framework for Spatio-Temporal Aware POI Recommendation](https://arxiv.org/abs/2602.10411)
*Fangye Wang,Haowen Lin,Yifang Yuan,Siyuan Wang,Xiaojiang Zhou,Song Yang,Pengjie Wang*

Main category: cs.IR

TL;DR: GeoGR是一个面向导航LBS的地理生成推荐框架，通过两阶段设计解决POI预测中语义ID建模不足和LLM对齐问题，在AMAP平台上验证了实际效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于SID的POI推荐方法在复杂稀疏的真实环境中存在两个关键限制：1) 高质量跨类别时空协作关系的语义ID建模不足；2) 大语言模型与POI推荐任务的对齐不佳。

Method: 两阶段设计：1) 地理感知的SID标记化管道，通过地理约束的共访问POI对、对比学习和迭代优化学习时空协作语义表示；2) 多阶段LLM训练策略，通过模板化持续预训练对齐非原生SID标记，并通过监督微调实现自回归POI生成。

Result: 在多个真实世界数据集上超越最先进基线，在AMAP平台部署后服务数百万用户，多个在线指标显著提升，验证了实际有效性和生产可扩展性。

Conclusion: GeoGR框架成功解决了POI推荐中的语义ID建模和LLM对齐问题，为导航LBS提供了有效的意图感知POI推荐解决方案，在实际生产环境中表现出色。

Abstract: Next Point-of-Interest (POI) prediction is a fundamental task in location-based services, especially critical for large-scale navigation platforms like AMAP that serve billions of users across diverse lifestyle scenarios. While recent POI recommendation approaches based on SIDs have achieved promising, they struggle in complex, sparse real-world environments due to two key limitations: (1) inadequate modeling of high-quality SIDs that capture cross-category spatio-temporal collaborative relationships, and (2) poor alignment between large language models (LLMs) and the POI recommendation task. To this end, we propose GeoGR, a geographic generative recommendation framework tailored for navigation-based LBS like AMAP, which perceives users' contextual state changes and enables intent-aware POI recommendation. GeoGR features a two-stage design: (i) a geo-aware SID tokenization pipeline that explicitly learns spatio-temporal collaborative semantic representations via geographically constrained co-visited POI pairs, contrastive learning, and iterative refinement; and (ii) a multi-stage LLM training strategy that aligns non-native SID tokens through multiple template-based continued pre-training(CPT) and enables autoregressive POI generation via supervised fine-tuning(SFT). Extensive experiments on multiple real-world datasets demonstrate GeoGR's superiority over state-of-the-art baselines. Moreover, deployment on the AMAP platform, serving millions of users with multiple online metrics boosting, confirms its practical effectiveness and scalability in production.

</details>


### [5] [End-to-End Semantic ID Generation for Generative Advertisement Recommendation](https://arxiv.org/abs/2602.10445)
*Jie Jiang,Xinxun Zhang,Enming Zhang,Yuling Xiong,Jun Zhang,Jingwen Wang,Huan Yu,Yuxiang Wang,Hao Wang,Xiao Yan,Jiawei Jiang*

Main category: cs.IR

TL;DR: UniSID是一个统一的语义ID生成框架，用于生成式广告推荐，通过端到端联合优化嵌入和语义ID，解决了现有两阶段压缩方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐主要使用残差量化生成语义ID，但存在两个主要问题：1）两阶段压缩导致目标不对齐和语义退化；2）残差量化的结构导致误差累积。需要解决这些限制来提升语义ID的质量。

Method: 提出UniSID框架：1）端到端联合优化嵌入和语义ID，让语义信息直接流入语义ID空间；2）引入多粒度对比学习策略，对齐不同语义ID层级的项目；3）提出基于摘要的广告重建机制，鼓励语义ID捕捉广告上下文中未明确存在的高层语义信息。

Result: 实验表明UniSID在多个下游广告场景中持续优于最先进的语义ID生成方法，在命中率指标上相比最强基线提升了高达4.62%。

Conclusion: UniSID通过统一的端到端框架解决了现有语义ID生成方法的局限性，能够更好地捕捉细粒度和高层语义信息，显著提升了生成式广告推荐的性能。

Abstract: Generative Recommendation (GR) has excelled by framing recommendation as next-token prediction. This paradigm relies on Semantic IDs (SIDs) to tokenize large-scale items into discrete sequences. Existing GR approaches predominantly generate SIDs via Residual Quantization (RQ), where items are encoded into embeddings and then quantized to discrete SIDs. However, this paradigm suffers from inherent limitations: 1) Objective misalignment and semantic degradation stemming from the two-stage compression; 2) Error accumulation inherent in the structure of RQ. To address these limitations, we propose UniSID, a Unified SID generation framework for generative advertisement recommendation. Specifically, we jointly optimize embeddings and SIDs in an end-to-end manner from raw advertising data, enabling semantic information to flow directly into the SID space and thus addressing the inherent limitations of the two-stage cascading compression paradigm. To capture fine-grained semantics, a multi-granularity contrastive learning strategy is introduced to align distinct items across SID levels. Finally, a summary-based ad reconstruction mechanism is proposed to encourage SIDs to capture high-level semantic information that is not explicitly present in advertising contexts. Experiments demonstrate that UniSID consistently outperforms state-of-the-art SID generation methods, yielding up to a 4.62% improvement in Hit Rate metrics across downstream advertising scenarios compared to the strongest baseline.

</details>


### [6] [Compute Only Once: UG-Separation for Efficient Large Recommendation Models](https://arxiv.org/abs/2602.10455)
*Hui Lu,Zheng Chai,Shipeng Bai,Hao Zhang,Zhifang Fan,Kunmin Bai,Yingwen Wu,Bingzheng Wei,Xiang Sun,Ziyan Gong,Tianyi Liu,Hua Chen,Deping Xie,Zhongkai Chen,Zhiliang Guo,Qiwei Chen,Yuchao Zheng*

Main category: cs.IR

TL;DR: UG-Sep通过用户-组分离机制，首次在密集交互模型中实现可复用的用户侧计算，结合信息补偿和量化技术，显著降低推理延迟20%而不影响效果。


<details>
  <summary>Details</summary>
Motivation: 随着推荐系统模型规模扩大，训练和推理成本急剧增加。虽然长序列模型可以通过KV缓存复用用户侧计算，但在密集特征交互架构中，用户和候选项目特征在层间深度纠缠，难以实现这种复用。

Method: 提出用户-组分离框架，通过掩码机制在token混合层中显式解耦用户侧和项目侧信息流，保持部分token的纯用户侧表示；设计信息补偿策略自适应重建被抑制的用户-项目交互；结合W8A16权重量化缓解内存带宽瓶颈。

Result: 在字节跳动的离线评估和大规模在线A/B实验中，UG-Sep在多个业务场景（包括信息流推荐和广告系统）中将推理延迟降低高达20%，同时不损害在线用户体验或商业指标。

Conclusion: UG-Sep首次在密集交互模型中实现了可复用的用户侧计算，通过解耦设计、信息补偿和量化优化，在保持推荐效果的同时显著降低了推理成本，为大规模推荐系统的效率优化提供了有效解决方案。

Abstract: Driven by scaling laws, recommender systems increasingly rely on large-scale models to capture complex feature interactions and user behaviors, but this trend also leads to prohibitive training and inference costs. While long-sequence models(e.g., LONGER) can reuse user-side computation through KV caching, such reuse is difficult in dense feature interaction architectures(e.g., RankMixer), where user and group (candidate item) features are deeply entangled across layers. In this work, we propose User-Group Separation (UG-Sep), a novel framework that enables reusable user-side computation in dense interaction models for the first time. UG-Sep introduces a masking mechanism that explicitly disentangles user-side and item-side information flows within token-mixing layers, ensuring that a subset of tokens to preserve purely user-side representations across layers. This design enables corresponding token computations to be reused across multiple samples, significantly reducing redundant inference cost. To compensate for potential expressiveness loss induced by masking, we further propose an Information Compensation strategy that adaptively reconstructs suppressed user-item interactions. Moreover, as UG-Sep substantially reduces user-side FLOPs and exposes memory-bound components, we incorporate W8A16 (8-bit weight, 16-bit activation) weight-only quantization to alleviate memory bandwidth bottlenecks and achieve additional acceleration. We conduct extensive offline evaluations and large-scale online A/B experiments at ByteDance, demonstrating that UG-Sep reduces inference latency by up to 20 percent without degrading online user experience or commercial metrics across multiple business scenarios, including feed recommendation and advertising systems.

</details>


### [7] [ChainRec: An Agentic Recommender Learning to Route Tool Chains for Diverse and Evolving Interests](https://arxiv.org/abs/2602.10490)
*Fuchun Li,Qian Li,Xingyu Gao,Bocheng Pan,Yang Wu,Jun Zhang,Huan Yu,Jie Jiang,Jinsheng Xiao,Hailong Shi*

Main category: cs.IR

TL;DR: ChainRec：一种使用规划器动态选择推理工具的智能推荐系统，通过工具标准化和偏好优化规划，在冷启动和兴趣演变场景中显著提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐系统大多采用固定工作流程，无法适应多样化的用户场景（如冷启动、兴趣转移）。需要一种能够根据具体情境动态决定证据收集策略的智能推荐代理。

Method: 1. 从专家轨迹构建标准化的工具代理库；2. 使用监督微调和偏好优化训练规划器，动态选择工具、决定执行顺序和停止时机；3. 在AgentRecBench基准上进行实验验证。

Result: 在Amazon、Yelp和Goodreads数据集上的实验表明，ChainRec在Avg HR@{1,3,5}指标上持续优于强基线方法，在冷启动和兴趣演变场景中提升尤为显著。消融研究验证了工具标准化和偏好优化规划的重要性。

Conclusion: ChainRec通过动态工具选择和规划，实现了更灵活、自适应的智能推荐，特别适合处理用户场景的多样性。工具标准化和偏好优化规划是提升推荐系统性能的关键因素。

Abstract: Large language models (LLMs) are increasingly integrated into recommender systems, motivating recent interest in agentic and reasoning-based recommendation. However, most existing approaches still rely on fixed workflows, applying the same reasoning procedure across diverse recommendation scenarios. In practice, user contexts vary substantially-for example, in cold-start settings or during interest shifts, so an agent should adaptively decide what evidence to gather next rather than following a scripted process. To address this, we propose ChainRec, an agentic recommender that uses a planner to dynamically select reasoning tools. ChainRec builds a standardized Tool Agent Library from expert trajectories. It then trains a planner using supervised fine-tuning and preference optimization to dynamically select tools, decide their order, and determine when to stop. Experiments on AgentRecBench across Amazon, Yelp, and Goodreads show that ChainRec consistently improves Avg HR@{1,3,5} over strong baselines, with especially notable gains in cold-start and evolving-interest scenarios. Ablation studies further validate the importance of tool standardization and preference-optimized planning.

</details>


### [8] [Boundary-Aware Multi-Behavior Dynamic Graph Transformer for Sequential Recommendation](https://arxiv.org/abs/2602.10493)
*Jingsong Su,Xuetao Ma,Mingming Li,Qiannan Zhu,Yu Guo*

Main category: cs.IR

TL;DR: MB-DGT模型通过动态图变换器和多行为边界感知损失，同时建模动态图拓扑和序列交互模式，提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统方法无法同时处理动态图拓扑和序列交互模式，且未能充分捕捉多行为边界，限制了用户偏好建模的准确性

Method: 提出边界感知多行为动态图变换器(MB-DGT)，包含基于变换器的动态图聚合器来建模用户偏好，以及用户特定的多行为损失函数来区分不同行为边界

Result: 在三个数据集上的实验表明，该模型始终提供显著的推荐性能提升

Conclusion: MB-DGT通过动态图结构细化和多行为边界感知，实现了更全面动态的用户偏好表示，显著提升了推荐效果

Abstract: In the landscape of contemporary recommender systems, user-item interactions are inherently dynamic and sequential, often characterized by various behaviors. Prior research has explored the modeling of user preferences through sequential interactions and the user-item interaction graph, utilizing advanced techniques such as graph neural networks and transformer-based architectures. However, these methods typically fall short in simultaneously accounting for the dynamic nature of graph topologies and the sequential pattern of interactions in user preference models. Moreover, they often fail to adequately capture the multiple user behavior boundaries during model optimization. To tackle these challenges, we introduce a boundary-aware Multi-Behavioral Dynamic Graph Transformer (MB-DGT) model that dynamically refines the graph structure to reflect the evolving patterns of user behaviors and interactions. Our model involves a transformer-based dynamic graph aggregator for user preference modeling, which assimilates the changing graph structure and the sequence of user behaviors. This integration yields a more comprehensive and dynamic representation of user preferences. For model optimization, we implement a user-specific multi-behavior loss function that delineates the interest boundaries among different behaviors, thereby enriching the personalized learning of user preferences. Comprehensive experiments across three datasets indicate that our model consistently delivers remarkable recommendation performance.

</details>


### [9] [Campaign-2-PT-RAG: LLM-Guided Semantic Product Type Attribution for Scalable Campaign Ranking](https://arxiv.org/abs/2602.10577)
*Yiming Che,Mansi Mane,Keerthi Gopalakrishnan,Parisa Kaghazgaran,Murali Mohana Krishna Dandu,Archana Venkatachalapathy,Sinduja Subramaniam,Yokila Arora,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.IR

TL;DR: 论文提出Campaign-2-PT-RAG框架，使用LLM解析电商营销活动内容，通过语义检索和分类器识别活动推广的产品类型，从而生成用户-活动购买标签，解决营销活动效果归因难题。


<details>
  <summary>Details</summary>
Motivation: 电商营销活动排名模型需要大规模训练标签来识别哪些用户购买是由活动影响导致的。然而，由于营销活动使用创意性、主题性的语言，不直接映射到具体产品购买，生成这些标签具有挑战性。缺乏清晰的产品级归因限制了监督学习在活动优化中的应用。

Method: 提出Campaign-2-PT-RAG框架：1) 使用大语言模型(LLM)解析营销活动内容，捕捉隐含意图；2) 通过语义检索在平台分类体系中检索候选产品类型(PT)；3) 使用结构化LLM分类器评估每个产品类型的相关性，生成活动特定的产品覆盖集；4) 用户购买匹配这些产品类型时生成正训练标签，用于下游排名模型。

Result: 在内部和合成数据集上的实验表明，该LLM辅助方法能生成高质量标签，在保持超过99%召回率的同时，达到78-90%的精确度，验证了专家标注的活动-产品类型映射。

Conclusion: 该方法将模糊的归因问题转化为可处理的语义对齐任务，为电商环境中的营销活动排名优化等下游任务提供了可扩展且一致的监督信号。

Abstract: E-commerce campaign ranking models require large-scale training labels indicating which users purchased due to campaign influence. However, generating these labels is challenging because campaigns use creative, thematic language that does not directly map to product purchases. Without clear product-level attribution, supervised learning for campaign optimization remains limited. We present \textbf{Campaign-2-PT-RAG}, a scalable label generation framework that constructs user--campaign purchase labels by inferring which product types (PTs) each campaign promotes. The framework first interprets campaign content using large language models (LLMs) to capture implicit intent, then retrieves candidate PTs through semantic search over the platform taxonomy. A structured LLM-based classifier evaluates each PT's relevance, producing a campaign-specific product coverage set. User purchases matching these PTs generate positive training labels for downstream ranking models. This approach reframes the ambiguous attribution problem into a tractable semantic alignment task, enabling scalable and consistent supervision for downstream tasks such as campaign ranking optimization in production e-commerce environments. Experiments on internal and synthetic datasets, validated against expert-annotated campaign--PT mappings, show that our LLM-assisted approach generates high-quality labels with 78--90% precision while maintaining over 99% recall.

</details>


### [10] [S-GRec: Personalized Semantic-Aware Generative Recommendation with Asymmetric Advantage](https://arxiv.org/abs/2602.10606)
*Jie Jiang,Hongbo Tang,Wenjie Wu,Yangru Huang,Zhenmao Li,Qian Li,Changping Wang,Jun Zhang,Huan Yu*

Main category: cs.IR

TL;DR: S-GRec框架通过解耦在线轻量生成器与离线LLM语义评判器，在训练时引入语义监督，同时通过非对称优势策略优化确保语义目标与商业目标一致，实现无需实时LLM推理的高效推荐系统。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型从行为日志训练时对用户意图的监督较弱，而LLM虽能提供丰富语义先验，但直接应用于工业推荐面临两大障碍：语义信号可能与平台商业目标冲突，且LLM推理成本过高。

Method: 1. 提出S-GRec框架，解耦在线轻量生成器与离线LLM语义评判器；2. 设计两阶段个性化语义评判器(PSJ)，生成可解释方面证据并学习用户条件聚合；3. 提出非对称优势策略优化(A2PO)，以商业奖励为锚点，仅在语义优势一致时注入语义优势。

Result: 在公开基准和大规模生产系统中验证了有效性和可扩展性：在线A/B测试中CTR获得统计显著提升，GMV提升1.19%，且无需实时LLM推理。

Conclusion: S-GRec成功解决了LLM在工业推荐中的两大障碍，通过解耦架构和策略优化实现了语义监督与商业目标的一致性，为生成式推荐提供了高效可扩展的解决方案。

Abstract: Generative recommendation models sequence generation to produce items end-to-end, but training from behavioral logs often provides weak supervision on underlying user intent. Although Large Language Models (LLMs) offer rich semantic priors that could supply such supervision, direct adoption in industrial recommendation is hindered by two obstacles: semantic signals can conflict with platform business objectives, and LLM inference is prohibitively expensive at scale. This paper presents S-GRec, a semantic-aware framework that decouples an online lightweight generator from an offline LLM-based semantic judge for train-time supervision. S-GRec introduces a two-stage Personalized Semantic Judge (PSJ) that produces interpretable aspect evidence and learns user-conditional aggregation from pairwise feedback, yielding stable semantic rewards. To prevent semantic supervision from deviating from business goals, Asymmetric Advantage Policy Optimization (A2PO) anchors optimization on business rewards (e.g., eCPM) and injects semantic advantages only when they are consistent. Extensive experiments on public benchmarks and a large-scale production system validate both effectiveness and scalability, including statistically significant gains in CTR and a 1.19\% lift in GMV in online A/B tests, without requiring real-time LLM inference.

</details>


### [11] [A Cognitive Distribution and Behavior-Consistent Framework for Black-Box Attacks on Recommender Systems](https://arxiv.org/abs/2602.10633)
*Hongyue Zhan,Mingming Li,Dongqin Liu,Hui Wang,Yaning Zhang,Xi Zhou,Honglei Lv,Jiao Dai,Jizhong Han*

Main category: cs.IR

TL;DR: 提出双增强攻击框架：认知分布驱动提取机制+行为感知噪声项目生成策略，显著提升攻击成功率和规避率


<details>
  <summary>Details</summary>
Motivation: 现有黑盒提取攻击主要依赖硬标签或成对学习，忽略排名位置重要性，导致知识转移不完整；纯梯度方法生成的对抗序列缺乏语义一致性，容易被检测

Method: 1. 认知分布驱动提取机制：基于首因效应和位置偏差，将离散排名映射为具有位置感知衰减的连续值分布；2. 行为感知噪声项目生成策略：联合优化协同信号和梯度信号，确保语义一致性和统计隐蔽性

Result: 在多个数据集上的实验表明，该方法在攻击成功率和规避率方面显著优于现有方法

Conclusion: 验证了认知建模和行为一致性整合对于安全推荐系统的价值，为防御对抗攻击提供了新视角

Abstract: With the growing deployment of sequential recommender systems in e-commerce and other fields, their black-box interfaces raise security concerns: models are vulnerable to extraction and subsequent adversarial manipulation. Existing black-box extraction attacks primarily rely on hard labels or pairwise learning, often ignoring the importance of ranking positions, which results in incomplete knowledge transfer. Moreover, adversarial sequences generated via pure gradient methods lack semantic consistency with real user behavior, making them easily detectable. To overcome these limitations, this paper proposes a dual-enhanced attack framework. First, drawing on primacy effects and position bias, we introduce a cognitive distribution-driven extraction mechanism that maps discrete rankings into continuous value distributions with position-aware decay, thereby advancing from order alignment to cognitive distribution alignment. Second, we design a behavior-aware noisy item generation strategy that jointly optimizes collaborative signals and gradient signals. This ensures both semantic coherence and statistical stealth while effectively promoting target item rankings. Extensive experiments on multiple datasets demonstrate that our approach significantly outperforms existing methods in both attack success rate and evasion rate, validating the value of integrating cognitive modeling and behavioral consistency for secure recommender systems.

</details>


### [12] [EST: Towards Efficient Scaling Laws in Click-Through Rate Prediction via Unified Modeling](https://arxiv.org/abs/2602.10811)
*Mingyang Liu,Yong Bai,Zhangming Chan,Sishuo Chen,Xiang-Rong Sheng,Han Zhu,Jian Xu,Xinyang Chen*

Main category: cs.IR

TL;DR: EST模型通过全统一建模处理原始输入，使用轻量交叉注意力和内容稀疏注意力，在淘宝广告平台实现3.27% RPM提升和1.22% CTR提升


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测方法通常采用早期行为聚合以保持效率，但这种非统一或部分统一建模会丢弃细粒度的token级信号，形成信息瓶颈，限制了扩展收益

Method: 提出高效可扩展Transformer（EST），通过单一序列处理所有原始输入实现全统一建模。包含两个模块：轻量交叉注意力（LCA）修剪冗余自交互以关注高影响跨特征依赖；内容稀疏注意力（CSA）利用内容相似性动态选择高信号行为

Result: EST展现出稳定高效的能量定律扩展关系，可实现可预测的性能增益。在淘宝展示广告平台部署中，显著优于生产基线，实现3.27% RPM提升和1.22% CTR提升

Conclusion: EST通过全统一建模解决了工业CTR预测中的信息瓶颈问题，建立了可扩展工业CTR预测模型的实用路径，在效率和性能之间取得了良好平衡

Abstract: Efficiently scaling industrial Click-Through Rate (CTR) prediction has recently attracted significant research attention. Existing approaches typically employ early aggregation of user behaviors to maintain efficiency. However, such non-unified or partially unified modeling creates an information bottleneck by discarding fine-grained, token-level signals essential for unlocking scaling gains. In this work, we revisit the fundamental distinctions between CTR prediction and Large Language Models (LLMs), identifying two critical properties: the asymmetry in information density between behavioral and non-behavioral features, and the modality-specific priors of content-rich signals. Accordingly, we propose the Efficiently Scalable Transformer (EST), which achieves fully unified modeling by processing all raw inputs in a single sequence without lossy aggregation. EST integrates two modules: Lightweight Cross-Attention (LCA), which prunes redundant self-interactions to focus on high-impact cross-feature dependencies, and Content Sparse Attention (CSA), which utilizes content similarity to dynamically select high-signal behaviors. Extensive experiments show that EST exhibits a stable and efficient power-law scaling relationship, enabling predictable performance gains with model scale. Deployed on Taobao's display advertising platform, EST significantly outperforms production baselines, delivering a 3.27\% RPM (Revenue Per Mile) increase and a 1.22\% CTR lift, establishing a practical pathway for scalable industrial CTR prediction models.

</details>


### [13] [Training-Induced Bias Toward LLM-Generated Content in Dense Retrieval](https://arxiv.org/abs/2602.10833)
*William Xion,Wolfgang Nejdl*

Main category: cs.IR

TL;DR: 研究发现密集检索器的"来源偏见"（偏好LLM生成文本）主要是训练诱导的现象，而非其固有属性，且困惑度解释力有限。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明密集检索器存在"来源偏见"，即偏好大型语言模型生成的文本而非人类文本。研究者想探究这种偏见的起源，特别是困惑度是否为主要原因，以及训练过程如何影响这种偏见。

Method: 使用SciFact和Natural Questions数据集的并行人类生成和LLM生成版本，比较无监督检查点与不同训练设置的模型：领域内人类文本微调、领域内LLM生成文本微调、以及MS MARCO微调。通过重新附加语言建模头到微调后的密集检索器编码器进行困惑度探测。

Result: 1) 无监督检索器没有统一的pro-LLM偏好，方向和程度取决于数据集；2) MS MARCO微调始终将排名偏向LLM生成文本；3) 领域内微调产生数据集特定且不一致的偏好变化；4) LLM生成语料微调诱导明显的pro-LLM偏见；5) 困惑度探测显示相关性接近随机水平，削弱了困惑度的解释力。

Conclusion: 来源偏见是训练诱导的现象，而非密集检索器的固有属性。训练数据的选择显著影响检索器的偏见模式，困惑度不能很好地解释这种偏见现象。

Abstract: Dense retrieval is a promising approach for acquiring relevant context or world knowledge in open-domain natural language processing tasks and is now widely used in information retrieval applications. However, recent reports claim a broad preference for text generated by large language models (LLMs). This bias is called "source bias", and it has been hypothesized that lower perplexity contributes to this effect. In this study, we revisit this claim by conducting a controlled evaluation to trace the emergence of such preferences across training stages and data sources. Using parallel human- and LLM-generated counterparts of the SciFact and Natural Questions (NQ320K) datasets, we compare unsupervised checkpoints with models fine-tuned using in-domain human text, in-domain LLM-generated text, and MS MARCO. Our results show the following: 1) Unsupervised retrievers do not exhibit a uniform pro-LLM preference. The direction and magnitude depend on the dataset. 2) Across the settings tested, supervised fine-tuning on MS MARCO consistently shifts the rankings toward LLM-generated text. 3) In-domain fine-tuning produces dataset-specific and inconsistent shifts in preference. 4) Fine-tuning on LLM-generated corpora induces a pronounced pro-LLM bias. Finally, a retriever-centric perplexity probe involving the reattachment of a language modeling head to the fine-tuned dense retriever encoder indicates agreement with relevance near chance, thereby weakening the explanatory power of perplexity. Our study demonstrates that source bias is a training-induced phenomenon rather than an inherent property of dense retrievers.

</details>
