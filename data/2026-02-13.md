<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 17]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [From Noise to Order: Learning to Rank via Denoising Diffusion](https://arxiv.org/abs/2602.11453)
*Sajad Ebrahimi,Bhaskar Mitra,Negar Arabzadeh,Ye Yuan,Haolun Wu,Fattane Zarrinkalam,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: 提出DiffusionRank，一种基于去噪扩散的深度生成式学习排序方法，替代传统的判别式方法，通过建模特征向量和相关性标签的联合分布来提升排序模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统学习排序方法主要采用判别式机器学习方法，仅建模文档相关性概率。判别式方法中过参数化模型可能以不同方式拟合训练数据，而生成式方法能建模完整数据分布，有望产生更鲁棒的排序模型。

Method: 提出DiffusionRank，基于TabDiff（面向表格数据的去噪扩散生成模型）进行扩展，创建生成式等价于经典判别式点对点和成对学习排序目标。

Result: 实验结果表明，DiffusionRank模型相比其判别式对应模型有显著改进，证明了生成式方法在学习排序任务中的优势。

Conclusion: 这项工作为未来研究开辟了丰富空间，展示了如何利用扩散等深度生成建模的最新进展来改进信息检索中的学习排序技术。

Abstract: In information retrieval (IR), learning-to-rank (LTR) methods have traditionally limited themselves to discriminative machine learning approaches that model the probability of the document being relevant to the query given some feature representation of the query-document pair. In this work, we propose an alternative denoising diffusion-based deep generative approach to LTR that instead models the full joint distribution over feature vectors and relevance labels. While in the discriminative setting, an over-parameterized ranking model may find different ways to fit the training data, we hypothesize that candidate solutions that can explain the full data distribution under the generative setting produce more robust ranking models. With this motivation, we propose DiffusionRank that extends TabDiff, an existing denoising diffusion-based generative model for tabular datasets, to create generative equivalents of classical discriminative pointwise and pairwise LTR objectives. Our empirical results demonstrate significant improvements from DiffusionRank models over their discriminative counterparts. Our work points to a rich space for future research exploration on how we can leverage ongoing advancements in deep generative modeling approaches, such as diffusion, for learning-to-rank in IR.

</details>


### [2] [KuaiSearch: A Large-Scale E-Commerce Search Dataset for Recall, Ranking, and Relevance](https://arxiv.org/abs/2602.11518)
*Yupeng Li,Ben Chen,Mingyue Cheng,Zhiding Liu,Xuxin Zhang,Chenyi Lei,Wenwu Ou*

Main category: cs.IR

TL;DR: KuaiSearch是一个基于快手平台真实用户搜索交互构建的电商搜索数据集，是目前最大的电商搜索数据集，覆盖冷启动用户和长尾商品，涵盖召回、排序和相关性判断三个搜索阶段。


<details>
  <summary>Details</summary>
Motivation: 现有电商搜索数据集存在多个局限性：查询通常是启发式构建的、过滤了冷启动用户和长尾商品、查询和商品文本被匿名化、大多只覆盖搜索管道的单一阶段，这些限制了基于LLM的电商搜索研究。

Method: 基于快手平台的真实用户搜索交互构建KuaiSearch数据集，保留真实用户查询和自然语言商品文本，覆盖冷启动用户和长尾商品，系统性地涵盖搜索管道的三个关键阶段：召回、排序和相关性判断。

Result: KuaiSearch是目前可用的最大电商搜索数据集，从商品、用户和查询等多个角度进行了全面分析，并在多个代表性搜索任务上建立了基准实验。

Conclusion: 实验结果表明，KuaiSearch为真实世界电商搜索研究提供了有价值的基础，能够解决现有数据集的局限性，促进基于LLM的电商搜索研究发展。

Abstract: E-commerce search serves as a central interface, connecting user demands with massive product inventories and plays a vital role in our daily lives. However, in real-world applications, it faces challenges, including highly ambiguous queries, noisy product texts with weak semantic order, and diverse user preferences, all of which make it difficult to accurately capture user intent and fine-grained product semantics. In recent years, significant advances in large language models (LLMs) for semantic representation and contextual reasoning have created new opportunities to address these challenges. Nevertheless, existing e-commerce search datasets still suffer from notable limitations: queries are often heuristically constructed, cold-start users and long-tail products are filtered out, query and product texts are anonymized, and most datasets cover only a single stage of the search pipeline. Collectively, these issues constrain research on LLM-based e-commerce search. To address these challenges, we construct and release KuaiSearch. To the best of our knowledge, it is the largest e-commerce search dataset currently available. KuaiSearch is built upon real user search interactions from the Kuaishou platform, preserving authentic user queries and natural-language product texts, covering cold-start users and long-tail products, and systematically spanning three key stages of the search pipeline: recall, ranking, and relevance judgment. We conduct a comprehensive analysis of KuaiSearch from multiple perspectives, including products, users, and queries, and establish benchmark experiments across several representative search tasks. Experimental results demonstrate that KuaiSearch provides a valuable foundation for research on real-world e-commerce search.

</details>


### [3] [LASER: An Efficient Target-Aware Segmented Attention Framework for End-to-End Long Sequence Modeling](https://arxiv.org/abs/2602.11562)
*Tianhe Lin,Ziwei Xiong,Baoyuan Ou,Yingjie Qin,Lai Xu,Xiaocheng Zhong,Yao Hu,Zhiyong Wang,Tao Zhou,Yubin Xu,Di Wu*

Main category: cs.IR

TL;DR: LASER是一个全栈优化框架，通过系统效率（SeqVault）和算法效率（STA）解决超长用户行为序列建模中的延迟墙问题，在工业推荐系统中实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统中建模超长用户行为序列对于捕捉用户演变和终身兴趣至关重要，但在实时工业环境中部署面临严格的"延迟墙"限制，包括检索海量用户历史的高I/O延迟和标准注意力机制的二次计算复杂度。

Method: 1. 系统效率：引入SeqVault统一模式感知服务基础设施，采用混合DRAM-SSD索引策略。2. 算法效率：提出分段目标注意力（STA）机制，使用sigmoid门控策略过滤噪声项目，然后通过轻量级全局堆叠目标注意力（GSTA）模块捕获跨段依赖关系。

Result: SeqVault将检索延迟降低50%，CPU使用率降低75%，实现毫秒级访问完整实时和生命周期用户历史。在线A/B测试中，LASER在超过1亿日活跃用户上实现了ADVV提升2.36%和收入提升2.08%。

Conclusion: LASER通过系统级和算法级创新有效解决了超长用户行为序列建模的延迟瓶颈，在工业规模推荐系统中展示了显著的可扩展性和商业影响。

Abstract: Modeling ultra-long user behavior sequences is pivotal for capturing evolving and lifelong interests in modern recommendation systems. However, deploying such models in real-time industrial environments faces a strict "Latency Wall", constrained by two distinct bottlenecks: the high I/O latency of retrieving massive user histories and the quadratic computational complexity of standard attention mechanisms. To break these bottlenecks, we present LASER, a full-stack optimization framework developed and deployed at Xiaohongshu (RedNote). Our approach tackles the challenges through two complementary innovations: (1) System efficiency: We introduce SeqVault, a unified schema-aware serving infrastructure for long user histories. By implementing a hybrid DRAM-SSD indexing strategy, SeqVault reduces retrieval latency by 50% and CPU usage by 75%, ensuring millisecond-level access to full real-time and life-cycle user histories. (2) Algorithmic efficiency: We propose a Segmented Target Attention (STA) mechanism to address the computational overhead. Motivated by the inherent sparsity of user interests, STA employs a sigmoid-based gating strategy that acts as a silence mechanism to filter out noisy items. Subsequently, a lightweight Global Stacked Target Attention (GSTA) module refines these compressed segments to capture cross-segment dependencies without incurring high computational costs. This design performs effective sequence compression, reducing the complexity of long-sequence modeling while preserving critical signals. Extensive offline evaluations demonstrate that LASER consistently outperforms state-of-the-art baselines. In large-scale online A/B testing serving over 100 million daily active users, LASER achieved a 2.36% lift in ADVV and a 2.08% lift in revenue, demonstrating its scalability and significant commercial impact.

</details>


### [4] [Analytical Search](https://arxiv.org/abs/2602.11581)
*Yiteng Tu,Shuo Miao,Weihang Su,Yiqun Liu,Qingyao Ai*

Main category: cs.IR

TL;DR: 本文提出"分析性搜索"作为新兴搜索范式，旨在满足跨领域分析性信息需求，强调证据导向、过程驱动的分析工作流，而非传统相关性排序或简单问答。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索范式（相关性文档排序或RAG增强生成）难以满足跨领域（法律、金融、科学等）分析性信息需求的端到端要求。它们要么侧重信息查找而非问题解决，要么简单视为问答，对推理、证据使用和可验证性控制有限，无法支持具有多样化效用概念和高问责要求的分析性查询。

Method: 提出分析性搜索作为新兴搜索范式，将其重构为证据治理、过程导向的分析工作流，明确建模分析意图、检索证据进行融合，并通过结构化多步推理产生可验证结论。提出统一系统框架，集成查询理解、召回导向检索、推理感知融合和自适应验证。

Result: 建立了分析性搜索的概念框架和系统架构，将其与现有搜索范式进行对比定位，并讨论了构建分析性搜索引擎的潜在研究方向。

Conclusion: 分析性搜索具有重要的概念意义和实践价值，呼吁开发支持分析性信息需求的下一代搜索引擎。

Abstract: Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements.
  In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs.

</details>


### [5] [Recurrent Preference Memory for Efficient Long-Sequence Generative Recommendation](https://arxiv.org/abs/2602.11605)
*Yixiao Chen,Yuan Wang,Yue Liu,Qiyao Wang,Ke Cheng,Xin Xu,Juntong Yan,Shuojin Yang,Menghao Guo,Jun Zhang,Huan Yu,Jie Jiang*

Main category: cs.IR

TL;DR: Rec2PM框架通过将长用户交互历史压缩为紧凑的偏好记忆token，解决了生成式推荐模型中全注意力机制的计算成本高和噪声累积问题，实现了并行训练和高效推理。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型通常使用全注意力机制建模用户行为，但在处理终身序列时面临计算成本过高和随机交互噪声累积的挑战，需要更高效的长期序列处理方法。

Method: 提出Rec2PM框架，将长用户交互历史压缩为紧凑的偏好记忆token；采用自引用教师强制策略，利用历史全局视图生成参考记忆作为监督目标，实现并行化循环更新；将记忆表示为token嵌入而非KV缓存，提高存储效率。

Result: 在大规模基准测试中，Rec2PM显著降低了推理延迟和内存占用，同时相比全序列模型获得了更优的准确性；分析表明偏好记忆起到了去噪信息瓶颈的作用，有效过滤交互噪声并捕捉稳健的长期兴趣。

Conclusion: Rec2PM通过偏好记忆压缩和自引用教师强制策略，成功解决了生成式推荐模型在处理长序列时的计算效率和噪声问题，为大规模推荐系统提供了高效且准确的解决方案。

Abstract: Generative recommendation (GenRec) models typically model user behavior via full attention, but scaling to lifelong sequences is hindered by prohibitive computational costs and noise accumulation from stochastic interactions. To address these challenges, we introduce Rec2PM, a framework that compresses long user interaction histories into compact Preference Memory tokens. Unlike traditional recurrent methods that suffer from serial training, Rec2PM employs a novel self-referential teacher-forcing strategy: it leverages a global view of the history to generate reference memories, which serve as supervision targets for parallelized recurrent updates. This allows for fully parallel training while maintaining the capability for iterative updates during inference. Additionally, by representing memory as token embeddings rather than extensive KV caches, Rec2PM achieves extreme storage efficiency. Experiments on large-scale benchmarks show that Rec2PM significantly reduces inference latency and memory footprint while achieving superior accuracy compared to full-sequence models. Analysis reveals that the Preference Memory functions as a denoising Information Bottleneck, effectively filtering interaction noise to capture robust long-term interests.

</details>


### [6] [Evolutionary Router Feature Generation for Zero-Shot Graph Anomaly Detection with Mixture-of-Experts](https://arxiv.org/abs/2602.11622)
*Haiyang Jiang,Tong Chen,Xinyi Gao,Guansong Pang,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.IR

TL;DR: 提出EvoFG框架，通过进化特征生成和记忆增强路由器解决零样本图异常检测中的分布偏移问题，显著提升跨图泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有零样本图异常检测方法面临两大挑战：1）图结构、特征和异常模式的异质性使得单一GNN模型难以捕捉多样异常机制；2）MoE架构虽能整合多种GNN专家，但分布偏移导致路由决策困难，现有路由器无法捕获跨图泛化的路由模式。

Method: 提出EvoFG框架：1）进化特征生成方案，通过LLM生成器和Shapley值评估迭代构建选择信息丰富的结构特征；2）记忆增强路由器，结合不变学习目标捕获分布偏移下的可迁移路由模式。

Result: 在六个基准数据集上的实验表明，EvoFG持续优于现有最优基线方法，实现了强大且稳定的零样本图异常检测性能。

Conclusion: EvoFG通过进化特征生成和不变学习有效解决了零样本图异常检测中的分布偏移问题，为跨图泛化提供了新思路，在多个基准上展现了优越性能。

Abstract: Zero-shot graph anomaly detection (GAD) has attracted increasing attention recent years, yet the heterogeneity of graph structures, features, and anomaly patterns across graphs make existing single GNN methods insufficiently expressive to model diverse anomaly mechanisms. In this regard, Mixture-of-experts (MoE) architectures provide a promising paradigm by integrating diverse GNN experts with complementary inductive biases, yet their effectiveness in zero-shot GAD is severely constrained by distribution shifts, leading to two key routing challenges. First, nodes often carry vastly different semantics across graphs, and straightforwardly performing routing based on their features is prone to generating biased or suboptimal expert assignments. Second, as anomalous graphs often exhibit pronounced distributional discrepancies, existing router designs fall short in capturing domain-invariant routing principles that generalize beyond the training graphs. To address these challenges, we propose a novel MoE framework with evolutionary router feature generation (EvoFG) for zero-shot GAD. To enhance MoE routing, we propose an evolutionary feature generation scheme that iteratively constructs and selects informative structural features via an LLM-based generator and Shapley-guided evaluation. Moreover, a memory-enhanced router with an invariant learning objective is designed to capture transferable routing patterns under distribution shifts. Extensive experiments on six benchmarks show that EvoFG consistently outperforms state-of-the-art baselines, achieving strong and stable zero-shot GAD performance.

</details>


### [7] [IntTravel: A Real-World Dataset and Generative Framework for Integrated Multi-Task Travel Recommendation](https://arxiv.org/abs/2602.11664)
*Huimin Yan,Longfei Xu,Junjie Sun,Zheng Liu,Wei Luo,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: 提出了IntTravel——首个大规模集成旅行推荐数据集，包含41亿次交互，并基于此构建了一个端到端的解码器生成框架，实现了多任务推荐，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前POI推荐研究存在局限性：数据集碎片化，仅关注"去哪里"而忽略了出发时间、出行方式和途中需求等完整旅程要素；数据集规模有限阻碍了准确性能评估。

Method: 1) 构建IntTravel大规模公开数据集（41亿次交互，1.63亿用户，730万POI）；2) 提出端到端的解码器生成框架，通过信息保留、选择和因子分解来平衡任务协作与专业分化。

Result: 1) 在IntTravel数据集和非旅行基准测试中都达到了最先进的性能；2) 已在Amap平台部署，服务数亿用户，点击率提升1.09%；3) 数据集已公开可用。

Conclusion: IntTravel填补了集成旅行推荐领域的数据集空白，提出的多任务生成框架能够全面理解旅程的多个维度，显著提升了推荐性能，具有实际应用价值。

Abstract: Next Point of Interest (POI) recommendation is essential for modern mobility and location-based services. To provide a smooth user experience, models must understand several components of a journey holistically: "when to depart", "how to travel", "where to go", and "what needs arise via the route". However, current research is limited by fragmented datasets that focus merely on next POI recommendation ("where to go"), neglecting the departure time, travel mode, and situational requirements along the journey. Furthermore, the limited scale of these datasets impedes accurate evaluation of performance. To bridge this gap, we introduce IntTravel, the first large-scale public dataset for integrated travel recommendation, including 4.1 billion interactions from 163 million users with 7.3 million POIs. Built upon this dataset, we introduce an end-to-end, decoder-only generative framework for multi-task recommendation. It incorporates information preservation, selection, and factorization to balance task collaboration with specialized differentiation, yielding substantial performance gains. The framework's generalizability is highlighted by its state-of-the-art performance across both IntTravel dataset and an additional non-travel benchmark. IntTravel has been successfully deployed on Amap serving hundreds of millions of users, leading to a 1.09% increase in CTR. IntTravel is available at https://github.com/AMAP-ML/IntTravel.

</details>


### [8] [EpicCBR: Item-Relation-Enhanced Dual-Scenario Contrastive Learning for Cold-Start Bundle Recommendation](https://arxiv.org/abs/2602.11680)
*Yihang Li,Zhuo Liu,Wei Wei*

Main category: cs.IR

TL;DR: EpicCBR是一个用于冷启动捆绑推荐的多视图对比学习框架，通过挖掘项目关系构建用户画像，并利用历史捆绑信息和用户偏好来表征新捆绑特征，在冷启动和热启动场景下都表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有捆绑推荐模型主要依赖观察到的用户-捆绑交互，限制了新创建捆绑的探索。这些方法通常将每个捆绑视为独立实例，未能充分利用用户-项目和捆绑-项目关系，导致冷启动场景下的表示挑战。

Method: 提出多视图对比学习框架EpicCBR：1）精确挖掘和利用项目关系构建用户画像，识别可能参与捆绑的用户；2）基于流行度的方法，通过历史捆绑信息和用户偏好表征新捆绑特征；3）构建能够整合冷启动和热启动场景的多视图图对比学习框架。

Result: 在三个流行基准测试上的广泛实验表明，EpicCBR大幅超越现有最先进方法（最高达387%），充分证明了该方法在冷启动场景下的优越性。

Conclusion: EpicCBR通过多视图对比学习有效解决了捆绑推荐的冷启动问题，能够充分利用项目关系构建用户画像并表征新捆绑特征，在冷启动和热启动场景下都表现出强大的泛化能力。

Abstract: Bundle recommendation aims to recommend a set of items to users for overall consumption. Existing bundle recommendation models primarily depend on observed user-bundle interactions, limiting exploration of newly-emerged bundles that are constantly created. It pose a critical representation challenge for current bundle methods, as they usually treat each bundle as an independent instance, while neglecting to fully leverage the user-item (UI) and bundle-item (BI) relations over popular items. To alleviate it, in this paper we propose a multi-view contrastive learning framework for cold-start bundle recommendation, named EpicCBR. Specifically, it precisely mine and utilize the item relations to construct user profiles, identifying users likely to engage with bundles. Additionally, a popularity-based method that characterizes the features of new bundles through historical bundle information and user preferences is proposed. To build a framework that demonstrates robustness in both cold-start and warm-start scenarios, a multi-view graph contrastive learning framework capable of integrating these diverse scenarios is introduced to ensure the model's generalization capability. Extensive experiments conducted on three popular benchmarks showed that EpicCBR outperforms state-of-the-art by a large margin (up to 387%), sufficiently demonstrating the superiority of the proposed method in cold-start scenario. The code and dataset can be found in the GitHub repository: https://github.com/alexlovecoding/EpicCBR.

</details>


### [9] [Uncertainty-aware Generative Recommendation](https://arxiv.org/abs/2602.11719)
*Chenxiao Fan,Chongming Gao,Yaxin Gong,Haoyan Liu,Fuli Feng,Xiangnan He*

Main category: cs.IR

TL;DR: UGR框架通过不确定性感知优化解决生成式推荐中的不确定性盲视问题，提升推荐性能并稳定训练


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐偏好优化方法依赖二元结果正确性，存在不确定性盲视问题：忽略模型内在生成置信度、样本学习难度差异、缺乏显式置信度表达，导致训练不稳定和决策风险不可量化

Method: 提出不确定性感知生成式推荐（UGR）框架，包含三个机制：1）不确定性加权奖励惩罚置信错误；2）难度感知优化动态防止过早收敛；3）显式置信度对齐赋予模型置信表达能力

Result: 实验表明UGR不仅获得更优推荐性能，还从根本上稳定训练，避免标准方法常见的性能下降。学习到的置信度支持可靠的下游风险感知应用

Conclusion: UGR通过将不确定性作为关键信号进行自适应优化，解决了生成式推荐中的不确定性盲视问题，实现了性能提升和训练稳定，并为风险感知应用提供了基础

Abstract: Generative Recommendation has emerged as a transformative paradigm, reformulating recommendation as an end-to-end autoregressive sequence generation task. Despite its promise, existing preference optimization methods typically rely on binary outcome correctness, suffering from a systemic limitation we term uncertainty blindness. This issue manifests in the neglect of the model's intrinsic generation confidence, the variation in sample learning difficulty, and the lack of explicit confidence expression, directly leading to unstable training dynamics and unquantifiable decision risks. In this paper, we propose Uncertainty-aware Generative Recommendation (UGR), a unified framework that leverages uncertainty as a critical signal for adaptive optimization. UGR synergizes three mechanisms: (1) an uncertainty-weighted reward to penalize confident errors; (2) difficulty-aware optimization dynamics to prevent premature convergence; and (3) explicit confidence alignment to empower the model with confidence expression capabilities. Extensive experiments demonstrate that UGR not only yields superior recommendation performance but also fundamentally stabilizes training, preventing the performance degradation often observed in standard methods. Furthermore, the learned confidence enables reliable downstream risk-aware applications.

</details>


### [10] [ULTRA:Urdu Language Transformer-based Recommendation Architecture](https://arxiv.org/abs/2602.11836)
*Alishbah Bashir,Fatima Qaiser,Ijaz Hussain*

Main category: cs.IR

TL;DR: ULTRA：针对低资源乌尔都语新闻推荐的查询长度感知语义推荐框架，通过双嵌入架构和路由机制提升推荐相关性


<details>
  <summary>Details</summary>
Motivation: 乌尔都语作为低资源语言缺乏有效的语义内容推荐系统，现有方法依赖词汇匹配或语言无关技术，难以捕捉语义意图，在不同查询长度和信息需求下表现不佳，导致推荐相关性和适应性降低

Method: 提出ULTRA框架，采用双嵌入架构和查询长度感知路由机制，通过阈值驱动的决策过程将用户查询路由到专门优化的语义管道：短查询使用标题/标题级表示，长查询使用全文/文档级表示，利用基于Transformer的嵌入和优化池化策略实现上下文感知相似性搜索

Result: 在大规模乌尔都语新闻语料库上的实验表明，该架构在不同查询类型上持续提升推荐相关性，相比单管道基线，精度提升超过90%，证明了查询自适应语义对齐对低资源语言的有效性

Conclusion: ULTRA是一个稳健且可泛化的内容推荐架构，为低资源语言环境中的语义检索系统提供了实用的设计见解

Abstract: Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.

</details>


### [11] [Improving Neural Retrieval with Attribution-Guided Query Rewriting](https://arxiv.org/abs/2602.11841)
*Moncef Garouani,Josiane Mothe*

Main category: cs.IR

TL;DR: 提出一种基于归因引导的查询重写方法，利用检索器的梯度归因分数指导LLM重写查询，改善模糊或隐含查询的检索效果


<details>
  <summary>Details</summary>
Motivation: 神经检索器虽然有效但脆弱：未充分指定或模糊的查询即使存在相关文档也可能误导排序。现有方法仅部分解决此问题：LLM重写查询时没有检索器反馈，可解释性方法识别误导性标记但仅用于事后分析。

Method: 提出归因引导的查询重写方法：为每个查询计算检索器的梯度归因分数，将这些分数作为软指导纳入结构化提示中，让LLM澄清薄弱或误导性的查询组件同时保留意图。

Result: 在BEIR数据集上的评估显示，重写后的查询在检索效果上持续优于强基线，对于隐含或模糊的信息需求增益更大。

Conclusion: 通过将检索器的归因反馈整合到查询重写过程中，该方法有效解决了神经检索器的脆弱性问题，特别是对于模糊或隐含查询的检索效果有显著提升。

Abstract: Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.

</details>


### [12] [Efficient Crawling for Scalable Web Data Acquisition (Extended Version)](https://arxiv.org/abs/2602.11874)
*Antoine Gauquier,Ioana Manolescu,Pierre Senellart*

Main category: cs.IR

TL;DR: 本文提出了一种基于强化学习的聚焦网络爬虫SB-CLASSIFIER，用于高效获取统计数据集，仅需爬取网站的一小部分就能获取大部分目标资源。


<details>
  <summary>Details</summary>
Motivation: 新闻事实核查和社会经济研究需要高质量统计数据集，但这些数据集在线发布方式多样，大规模检索困难、低效甚至不可能。需要改进开放统计数据可访问性。

Method: 提出基于强化学习（休眠多臂老虎机）的聚焦网络爬虫算法SB-CLASSIFIER，通过学习哪些超链接能导向包含多个目标资源的页面，仅爬取网站部分内容而非整个网站。

Result: 在包含数百万网页的网站上实验表明，该爬虫高度高效，仅爬取网站一小部分就能获取大部分目标资源。

Conclusion: 通过强化学习方法，实现了高效、可扩展的统计数据集检索，解决了开放统计数据可访问性问题，为新闻事实核查和社会经济研究提供了有效工具。

Abstract: Journalistic fact-checking, as well as social or economic research, require analyzing high-quality statistics datasets (SDs, in short). However, retrieving SD corpora at scale may be hard, inefficient, or impossible, depending on how they are published online. To improve open statistics data accessibility, we present a focused Web crawling algorithm that retrieves as many targets, i.e., resources of certain types, as possible, from a given website, in an efficient and scalable way, by crawling (much) less than the full website. We show that optimally solving this problem is intractable, and propose an approach based on reinforcement learning, namely using sleeping bandits. We propose SB-CLASSIFIER, a crawler that efficiently learns which hyperlinks lead to pages that link to many targets, based on the paths leading to the links in their enclosing webpages. Our experiments on websites with millions of webpages show that our crawler is highly efficient, delivering high fractions of a site's targets while crawling only a small part.

</details>


### [13] [IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval](https://arxiv.org/abs/2602.11941)
*Benjamin Clavié,Atoof Shakir,Jonah Turner,Sean Lee,Aamir Shakir,Makoto P. Kato*

Main category: cs.IR

TL;DR: IncompeBench是一个高质量的音乐信息检索基准数据集，包含1,574个音乐片段、500个多样化查询和超过125,000个相关性标注，旨在解决当前音乐检索领域缺乏高质量评估基准的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态信息检索和音乐信息检索取得了显著进展，但当前缺乏高质量的音乐检索评估基准，这限制了该领域的进一步发展。

Method: 通过多阶段标注流程创建了一个精心标注的基准数据集，包含1,574个许可友好的高质量音乐片段、500个多样化查询和超过125,000个个体相关性判断，标注过程实现了人类标注者与生成数据之间的高度一致性。

Result: 创建了IncompeBench基准数据集，该数据集已公开可用，包含严格和宽松两个版本，并提供了相应的标注程序。

Conclusion: IncompeBench为音乐信息检索领域提供了一个高质量、可复现的评估基准，有助于推动该领域的研究和发展。

Abstract: Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.

</details>


### [14] [Compress, Cross and Scale: Multi-Level Compression Cross Networks for Efficient Scaling in Recommender Systems](https://arxiv.org/abs/2602.12041)
*Heng Yu,Xiangjun Zhou,Jie Xia,Heng Zhao,Anxin Wu,Yu Zhao,Dongying Kong*

Main category: cs.IR

TL;DR: MLCC是一种结构化特征交互架构，通过分层压缩和动态组合高效捕获高阶特征依赖，其多通道扩展MC-MLCC通过并行子空间分解实现高效水平扩展，在保持计算效率的同时显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统中的交互模块难以同时实现强大的交互能力、高计算效率和良好可扩展性，导致在严格生产约束下模型扩展的ROI有限。需要一种能高效捕获高阶特征依赖且计算复杂度可控的架构。

Method: 提出MLCC架构，通过分层压缩和动态组合组织特征交叉；进一步提出MC-MLCC多通道扩展，将特征交互分解到并行子空间，实现高效水平扩展并减少参数增长。

Result: 在三个公开基准和大规模工业数据集上，MLCC模型比强DLRM基线提升最多0.52 AUC，在可比性能下减少模型参数和FLOPs达26倍。在线A/B测试验证了实际有效性，已在Bilibili广告系统中广泛部署。

Conclusion: MLCC和MC-MLCC能够高效捕获高阶特征交互，在保持计算效率的同时显著提升预测性能，通过通道扩展实现稳定可预测的缩放行为，适合工业推荐系统在严格延迟和资源约束下的部署。

Abstract: Modeling high-order feature interactions efficiently is a central challenge in click-through rate and conversion rate prediction. Modern industrial recommender systems are predominantly built upon deep learning recommendation models, where the interaction backbone plays a critical role in determining both predictive performance and system efficiency. However, existing interaction modules often struggle to simultaneously achieve strong interaction capacity, high computational efficiency, and good scalability, resulting in limited ROI when models are scaled under strict production constraints. In this work, we propose MLCC, a structured feature interaction architecture that organizes feature crosses through hierarchical compression and dynamic composition, which can efficiently capture high-order feature dependencies while maintaining favorable computational complexity. We further introduce MC-MLCC, a Multi-Channel extension that decomposes feature interactions into parallel subspaces, enabling efficient horizontal scaling with improved representation capacity and significantly reduced parameter growth. Extensive experiments on three public benchmarks and a large-scale industrial dataset show that our proposed models consistently outperform strong DLRM-style baselines by up to 0.52 AUC, while reducing model parameters and FLOPs by up to 26$\times$ under comparable performance. Comprehensive scaling analyses demonstrate stable and predictable scaling behavior across embedding dimension, head number, and channel count, with channel-based scaling achieving substantially better efficiency than conventional embedding inflation. Finally, online A/B testing on a real-world advertising platform validates the practical effectiveness of our approach, which has been widely adopted in Bilibili advertising system under strict latency and resource constraints.

</details>


### [15] [Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset](https://arxiv.org/abs/2602.12129)
*Rahin Arefin Ahmed,Md. Anik Chowdhury,Sakil Ahmed Sheikh Reza,Devnil Bhattacharjee,Muhammad Abdullah Adnan,Nafis Sadeq*

Main category: cs.IR

TL;DR: 提出了RokomariBG数据集，这是首个大规模孟加拉语图书推荐知识图谱数据集，包含多种实体和关系，并提供了系统性的推荐模型基准测试。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语文学领域的个性化图书推荐研究一直受到缺乏结构化、大规模公开数据集的限制，特别是在低资源语言环境下。

Method: 构建了包含127,302本书、63,723用户、16,601作者等实体的多实体异构图数据集，并系统评估了协同过滤、矩阵分解、内容推荐、图神经网络、混合模型和神经检索架构等多种推荐模型。

Result: 神经检索模型在Top-N推荐任务中表现最佳（NDCG@10 = 0.204），研究表明利用多关系结构和文本侧信息对推荐性能有重要影响。

Conclusion: 该工作为孟加拉语图书推荐研究建立了基础基准和公开资源，支持可重复评估和未来在低资源文化领域的推荐系统研究。

Abstract: Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.
  To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset

</details>


### [16] [SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization](https://arxiv.org/abs/2602.12187)
*Sunghwan Kim,Wooseok Jeong,Serin Kim,Sangam Lee,Dongha Lee*

Main category: cs.IR

TL;DR: SAGEO Arena：首个支持端到端可见性评估的搜索增强生成引擎优化基准，整合了完整的生成搜索流程和网页结构信息，揭示了现有方法在实际条件下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有SAGEO（搜索增强生成引擎优化）评估环境存在重大缺陷：缺乏端到端可见性评估、基于预选文档而非真实检索流程、忽略网页结构信息（如schema标记），这些限制了SAGEO研究的实用性和真实性。

Method: 提出SAGEO Arena基准环境，整合大规模网页文档语料库和丰富的结构信息，构建完整的生成搜索流程（检索-重排序-生成），支持分阶段SAGEO分析，同时针对搜索优化（SEO）和生成优化（GEO）。

Result: 研究发现：1）现有SAGEO方法在实际条件下大多不实用，甚至损害检索和重排序性能；2）结构信息有助于缓解这些限制；3）有效的SAGEO需要针对每个流程阶段进行定制化优化。

Conclusion: SAGEO Arena为超越简化设置的现实SAGEO评估和优化铺平了道路，强调需要结合结构信息和分阶段优化策略，推动搜索增强生成引擎优化研究向更实用方向发展。

Abstract: Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.

</details>


### [17] [AttentionRetriever: Attention Layers are Secretly Long Document Retrievers](https://arxiv.org/abs/2602.12278)
*David Jiahao Fu,Lam Thanh Do,Jiayu Li,Kevin Chen-Chuan Chang*

Main category: cs.IR

TL;DR: AttentionRetriever：一种基于注意力机制和实体检索的新型长文档检索模型，解决了现有检索模型在长文档处理中的上下文感知、因果依赖和检索范围等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的检索模型并非为长文档检索设计，无法解决长文档检索中的关键挑战：上下文感知、因果依赖和检索范围。检索增强生成（RAG）虽然广泛用于帮助LLM处理长文档任务，但现有检索模型在这些方面存在不足。

Method: 提出AttentionRetriever模型，利用注意力机制和基于实体的检索来构建长文档的上下文感知嵌入，并确定检索范围。该方法结合了注意力机制的优势和实体检索的精确性。

Result: 通过大量实验，AttentionRetriever在长文档检索数据集上大幅优于现有检索模型，同时保持了与密集检索模型相当的效率。

Conclusion: AttentionRetriever成功解决了长文档检索的关键挑战，在性能和效率方面都表现出色，为长文档检索任务提供了有效的解决方案。

Abstract: Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.

</details>
