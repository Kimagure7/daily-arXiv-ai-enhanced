{"id": "2509.19509", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19509", "abs": "https://arxiv.org/abs/2509.19509", "authors": ["Cem Ashbaugh", "Leon Baumg\u00e4rtner", "Tim Gress", "Nikita Sidorov", "Daniel Werner"], "title": "AIRwaves at CheckThat! 2025: Retrieving Scientific Sources for Implicit Claims on Social Media with Dual Encoders and Neural Re-Ranking", "comment": "CLEF 2025 (Conference and Labs of the Evaluation Forum)", "summary": "Linking implicit scientific claims made on social media to their original\npublications is crucial for evidence-based fact-checking and scholarly\ndiscourse, yet it is hindered by lexical sparsity, very short queries, and\ndomain-specific language. Team AIRwaves ranked second in Subtask 4b of the\nCLEF-2025 CheckThat! Lab with an evidence-retrieval approach that markedly\noutperforms the competition baseline. The optimized sparse-retrieval\nbaseline(BM25) achieves MRR@5 = 0.5025 on the gold label blind test set. To\nsurpass this baseline, a two-stage retrieval pipeline is introduced: (i) a\nfirst stage that uses a dual encoder based on E5-large, fine-tuned using\nin-batch and mined hard negatives and enhanced through chunked tokenization and\nrich document metadata; and (ii) a neural re-ranking stage using a SciBERT\ncross-encoder. Replacing purely lexical matching with neural representations\nlifts performance to MRR@5 = 0.6174, and the complete pipeline further improves\nto MRR@5 = 0.6828. The findings demonstrate that coupling dense retrieval with\nneural re-rankers delivers a powerful and efficient solution for tweet-to-study\nmatching and provides a practical blueprint for future evidence-retrieval\npipelines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u68c0\u7d22\u7ba1\u9053\uff0c\u7528\u4e8e\u5c06\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u9690\u5f0f\u79d1\u5b66\u58f0\u660e\u94fe\u63a5\u5230\u539f\u59cb\u51fa\u7248\u7269\uff0c\u5728CLEF-2025 CheckThat! Lab\u7684Subtask 4b\u4e2d\u6392\u540d\u7b2c\u4e8c\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u79d1\u5b66\u58f0\u660e\u4e0e\u539f\u59cb\u51fa\u7248\u7269\u94fe\u63a5\u5bf9\u4e8e\u57fa\u4e8e\u8bc1\u636e\u7684\u4e8b\u5b9e\u6838\u67e5\u548c\u5b66\u672f\u8ba8\u8bba\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u53d7\u5230\u8bcd\u6c47\u7a00\u758f\u6027\u3001\u6781\u77ed\u67e5\u8be2\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u7684\u963b\u788d\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u7ba1\u9053\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8eE5-large\u7684\u53cc\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u6279\u5185\u548c\u6316\u6398\u7684\u56f0\u96be\u8d1f\u6837\u672c\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u589e\u5f3a\u5206\u5757\u6807\u8bb0\u5316\u548c\u4e30\u5bcc\u6587\u6863\u5143\u6570\u636e\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528SciBERT\u4ea4\u53c9\u7f16\u7801\u5668\u8fdb\u884c\u795e\u7ecf\u91cd\u6392\u5e8f\u3002", "result": "\u4f18\u5316\u540e\u7684\u7a00\u758f\u68c0\u7d22\u57fa\u7ebf(BM25)\u5728\u9ec4\u91d1\u6807\u7b7e\u76f2\u6d4b\u96c6\u4e0a\u8fbe\u5230MRR@5 = 0.5025\u3002\u795e\u7ecf\u8868\u793a\u5c06\u6027\u80fd\u63d0\u5347\u81f3MRR@5 = 0.6174\uff0c\u5b8c\u6574\u7ba1\u9053\u8fdb\u4e00\u6b65\u6539\u8fdb\u81f3MRR@5 = 0.6828\uff0c\u663e\u8457\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u3002", "conclusion": "\u5c06\u5bc6\u96c6\u68c0\u7d22\u4e0e\u795e\u7ecf\u91cd\u6392\u5e8f\u5668\u7ed3\u5408\u4e3a\u63a8\u6587\u5230\u7814\u7a76\u5339\u914d\u63d0\u4f9b\u4e86\u5f3a\u5927\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u8bc1\u636e\u68c0\u7d22\u7ba1\u9053\u63d0\u4f9b\u4e86\u5b9e\u7528\u84dd\u56fe\u3002"}}
{"id": "2509.19700", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.19700", "abs": "https://arxiv.org/abs/2509.19700", "authors": ["Seunghan Yang", "Juntae Lee", "Jihwan Bang", "Kyuhong Shim", "Minsoo Kim", "Simyung Chang"], "title": "Learning Contextual Retrieval for Robust Conversational Search", "comment": "EMNLP 2025 main conference", "summary": "Effective conversational search demands a deep understanding of user intent\nacross multiple dialogue turns. Users frequently use abbreviations and shift\ntopics in the middle of conversations, posing challenges for conventional\nretrievers. While query rewriting techniques improve clarity, they often incur\nsignificant computational cost due to additional autoregressive steps.\nMoreover, although LLM-based retrievers demonstrate strong performance, they\nare not explicitly optimized to track user intent in multi-turn settings, often\nfailing under topic drift or contextual ambiguity. To address these\nlimitations, we propose ContextualRetriever, a novel LLM-based retriever that\ndirectly incorporates conversational context into the retrieval process. Our\napproach introduces: (1) a context-aware embedding mechanism that highlights\nthe current query within the dialogue history; (2) intent-guided supervision\nbased on high-quality rewritten queries; and (3) a training strategy that\npreserves the generative capabilities of the base LLM. Extensive evaluations\nacross multiple conversational search benchmarks demonstrate that\nContextualRetriever significantly outperforms existing methods while incurring\nno additional inference overhead.", "AI": {"tldr": "\u63d0\u51faContextualRetriever\uff0c\u4e00\u79cd\u76f4\u63a5\u6574\u5408\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u7684LLM\u68c0\u7d22\u5668\uff0c\u89e3\u51b3\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7528\u6237\u610f\u56fe\u8ddf\u8e2a\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u4e0d\u589e\u52a0\u63a8\u7406\u5f00\u9500", "motivation": "\u4f20\u7edf\u68c0\u7d22\u5668\u96be\u4ee5\u5904\u7406\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u7f29\u5199\u548c\u8bdd\u9898\u8f6c\u6362\uff0c\u67e5\u8be2\u91cd\u5199\u6280\u672f\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709LLM\u68c0\u7d22\u5668\u672a\u9488\u5bf9\u591a\u8f6e\u610f\u56fe\u8ddf\u8e2a\u4f18\u5316\uff0c\u5bb9\u6613\u5728\u8bdd\u9898\u6f02\u79fb\u6216\u4e0a\u4e0b\u6587\u6a21\u7cca\u65f6\u5931\u8d25", "method": "\u5f15\u5165\u4e0a\u4e0b\u6587\u611f\u77e5\u5d4c\u5165\u673a\u5236\u7a81\u51fa\u5f53\u524d\u67e5\u8be2\uff0c\u57fa\u4e8e\u9ad8\u8d28\u91cf\u91cd\u5199\u67e5\u8be2\u7684\u610f\u56fe\u5f15\u5bfc\u76d1\u7763\uff0c\u4ee5\u53ca\u4fdd\u6301\u57fa\u7840LLM\u751f\u6210\u80fd\u529b\u7684\u8bad\u7ec3\u7b56\u7565", "result": "\u5728\u591a\u4e2a\u5bf9\u8bdd\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cContextualRetriever\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u4e0d\u4ea7\u751f\u989d\u5916\u63a8\u7406\u5f00\u9500", "conclusion": "ContextualRetriever\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u5bf9\u8bdd\u68c0\u7d22\u4e2d\u7684\u610f\u56fe\u8ddf\u8e2a\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272"}}
{"id": "2509.19767", "categories": ["cs.IR", "cs.AI", "cs.DB", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.19767", "abs": "https://arxiv.org/abs/2509.19767", "authors": ["Alireza Heidari", "Wei Zhang", "Ying Xiong"], "title": "FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion", "comment": "62 pages,12 figures", "summary": "Vector search powers transformers technology, but real-world use demands\nhybrid queries that combine vector similarity with attribute filters (e.g.,\n\"top document in category X, from 2023\"). Current solutions trade off recall,\nspeed, and flexibility, relying on fragile index hacks that don't scale. We\nintroduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric\nframework that elevates filtering to ANN optimization constraints and\nintroduces a convex fused space via a Lagrangian-like relaxation. Our method\njointly embeds attributes and vectors through transformer-based\nconvexification, turning hard filters into continuous, weighted penalties that\npreserve top-k semantics while enabling efficient approximate search. We prove\nthat FusedANN reduces to exact filtering under high selectivity, gracefully\nrelaxes to semantically nearest attributes when exact matches are insufficient,\nand preserves downstream ANN alpha-approximation guarantees. Empirically,\nFusedANN improves query throughput by eliminating brittle filtering stages,\nachieving superior recall-latency tradeoffs on standard hybrid benchmarks\nwithout specialized index hacks, delivering up to 3 times higher throughput and\nbetter recall than state-of-the-art hybrid and graph-based systems.\nTheoretically, we provide explicit error bounds and parameter selection rules\nthat make FusedANN practical for production. This establishes a principled,\nscalable, and verifiable bridge between symbolic constraints and vector\nsimilarity, unlocking a new generation of filtered retrieval systems for large,\nhybrid, and dynamic NLP/ML workloads.", "AI": {"tldr": "FusedANN\u662f\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5c5e\u6027\u8fc7\u6ee4\u63d0\u5347\u4e3aANN\u4f18\u5316\u7ea6\u675f\uff0c\u5f15\u5165\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u7684\u51f8\u878d\u5408\u7a7a\u95f4\uff0c\u5c06\u786c\u8fc7\u6ee4\u5668\u8f6c\u5316\u4e3a\u8fde\u7eed\u7684\u52a0\u6743\u60e9\u7f5a\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6df7\u5408\u67e5\u8be2\u641c\u7d22\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5411\u91cf\u641c\u7d22\u9700\u8981\u7ed3\u5408\u5411\u91cf\u76f8\u4f3c\u6027\u548c\u5c5e\u6027\u8fc7\u6ee4\u7684\u6df7\u5408\u67e5\u8be2\uff0c\u4f46\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5728\u53ec\u56de\u7387\u3001\u901f\u5ea6\u548c\u7075\u6d3b\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u4f9d\u8d56\u8106\u5f31\u7684\u7d22\u5f15\u6280\u5de7\u4e14\u65e0\u6cd5\u6269\u5c55\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u51f8\u5316\u65b9\u6cd5\u8054\u5408\u5d4c\u5165\u5c5e\u6027\u548c\u5411\u91cf\uff0c\u5c06\u786c\u8fc7\u6ee4\u5668\u8f6c\u5316\u4e3a\u8fde\u7eed\u52a0\u6743\u60e9\u7f5a\uff0c\u4fdd\u7559top-k\u8bed\u4e49\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u8fd1\u4f3c\u641c\u7d22\u3002", "result": "FusedANN\u5728\u6807\u51c6\u6df7\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6d88\u9664\u4e86\u8106\u5f31\u7684\u8fc7\u6ee4\u9636\u6bb5\uff0c\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u53ec\u56de\u7387-\u5ef6\u8fdf\u6743\u8861\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u6df7\u5408\u548c\u56fe\u57fa\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u9ad83\u500d\u4e14\u53ec\u56de\u7387\u66f4\u597d\u3002", "conclusion": "FusedANN\u5728\u7b26\u53f7\u7ea6\u675f\u548c\u5411\u91cf\u76f8\u4f3c\u6027\u4e4b\u95f4\u5efa\u7acb\u4e86\u539f\u5219\u6027\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u9a8c\u8bc1\u7684\u6865\u6881\uff0c\u4e3a\u5927\u89c4\u6a21\u3001\u6df7\u5408\u548c\u52a8\u6001\u7684NLP/ML\u5de5\u4f5c\u8d1f\u8f7d\u89e3\u9501\u4e86\u65b0\u4e00\u4ee3\u8fc7\u6ee4\u68c0\u7d22\u7cfb\u7edf\u3002"}}
{"id": "2509.19876", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.19876", "abs": "https://arxiv.org/abs/2509.19876", "authors": ["Qihang Zhao", "Xiaoyang Zheng", "Ben Chen", "Zhongbo Sun", "Chenyi Lei"], "title": "Adaptive User Interest Modeling via Conditioned Denoising Diffusion For Click-Through Rate Prediction", "comment": "5 pages, under review", "summary": "User behavior sequences in search systems resemble \"interest fossils\",\ncapturing genuine intent yet eroded by exposure bias, category drift, and\ncontextual noise. Current methods predominantly follow an \"identify-aggregate\"\nparadigm, assuming sequences immutably reflect user preferences while\noverlooking the organic entanglement of noise and genuine interest. Moreover,\nthey output static, context-agnostic representations, failing to adapt to\ndynamic intent shifts under varying Query-User-Item-Context conditions.\n  To resolve this dual challenge, we propose the Contextual Diffusion Purifier\n(CDP). By treating category-filtered behaviors as \"contaminated observations\",\nCDP employs a forward noising and conditional reverse denoising process guided\nby cross-interaction features (Query x User x Item x Context), controllably\ngenerating pure, context-aware interest representations that dynamically evolve\nwith scenarios. Extensive offline/online experiments demonstrate the\nsuperiority of CDP over state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faContextual Diffusion Purifier (CDP)\u65b9\u6cd5\uff0c\u901a\u8fc7\u524d\u5411\u52a0\u566a\u548c\u6761\u4ef6\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\uff0c\u4ece\u53d7\u6c61\u67d3\u7684\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u751f\u6210\u7eaf\u51c0\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5174\u8da3\u8868\u793a\uff0c\u89e3\u51b3\u641c\u7d22\u7cfb\u7edf\u4e2d\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u7684\u566a\u58f0\u6c61\u67d3\u548c\u9759\u6001\u8868\u793a\u95ee\u9898\u3002", "motivation": "\u641c\u7d22\u7cfb\u7edf\u4e2d\u7684\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u5b58\u5728\u66dd\u5149\u504f\u5dee\u3001\u7c7b\u522b\u6f02\u79fb\u548c\u4e0a\u4e0b\u6587\u566a\u58f0\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u5e8f\u5217\u4e0d\u53d8\u5730\u53cd\u6620\u7528\u6237\u504f\u597d\uff0c\u5ffd\u7565\u4e86\u566a\u58f0\u4e0e\u771f\u5b9e\u5174\u8da3\u7684\u6709\u673a\u7ea0\u7f20\uff0c\u4e14\u8f93\u51fa\u9759\u6001\u3001\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u8868\u793a\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u610f\u56fe\u53d8\u5316\u3002", "method": "CDP\u5c06\u7c7b\u522b\u8fc7\u6ee4\u540e\u7684\u884c\u4e3a\u89c6\u4e3a\u53d7\u6c61\u67d3\u89c2\u6d4b\uff0c\u91c7\u7528\u524d\u5411\u52a0\u566a\u548c\u6761\u4ef6\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8de8\u4ea4\u4e92\u7279\u5f81\uff08\u67e5\u8be2\u00d7\u7528\u6237\u00d7\u7269\u54c1\u00d7\u4e0a\u4e0b\u6587\uff09\u5f15\u5bfc\uff0c\u53ef\u63a7\u5730\u751f\u6210\u7eaf\u51c0\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5174\u8da3\u8868\u793a\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u8868\u660e\uff0cCDP\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "CDP\u6709\u6548\u89e3\u51b3\u4e86\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u566a\u58f0\u6c61\u67d3\u95ee\u9898\uff0c\u80fd\u591f\u751f\u6210\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u573a\u666f\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u5174\u8da3\u8868\u793a\uff0c\u5728\u641c\u7d22\u7cfb\u7edf\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.19931", "categories": ["cs.IR", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.19931", "abs": "https://arxiv.org/abs/2509.19931", "authors": ["Renxiang Wang", "Li Zhang"], "title": "Documentation Retrieval Improves Planning Language Generation", "comment": "12 pages, 14 figures, 1 table", "summary": "Certain strong LLMs have shown promise for zero-shot formal planning by\ngenerating planning languages like PDDL. Yet, performance of most open-source\nmodels under 50B parameters has been reported to be close to zero due to the\nlow-resource nature of these languages. We significantly improve their\nperformance via a series of lightweight pipelines that integrates documentation\nretrieval with modular code generation and error refinement. With models like\nLlama-4-Maverick, our best pipeline improves plan correctness from 0\\% to over\n80\\% on the common BlocksWorld domain. However, while syntactic errors are\nsubstantially reduced, semantic errors persist in more challenging domains,\nrevealing fundamental limitations in current models' reasoning\ncapabilities.\\footnote{Our code and data can be found at\nhttps://github.com/Nangxxxxx/PDDL-RAG", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7ba1\u9053\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u6863\u68c0\u7d22\u3001\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\u548c\u9519\u8bef\u7cbe\u70bc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e2d\u5c0f\u578b\u5f00\u6e90LLM\u5728\u96f6\u6837\u672c\u5f62\u5f0f\u5316\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5c06\u8ba1\u5212\u6b63\u786e\u7387\u4ece0%\u63d0\u5347\u81f380%\u4ee5\u4e0a\uff0c\u4f46\u8bed\u4e49\u9519\u8bef\u5728\u590d\u6742\u9886\u57df\u4ecd\u7136\u5b58\u5728\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u53c2\u6570\u5c0f\u4e8e50B\u7684\u5f00\u6e90LLM\u5728\u96f6\u6837\u672c\u5f62\u5f0f\u5316\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u96f6\uff0c\u4e3b\u8981\u539f\u56e0\u662fPDDL\u7b49\u89c4\u5212\u8bed\u8a00\u7684\u8d44\u6e90\u7a00\u7f3a\u6027\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u7ba1\u9053\u65b9\u6cd5\uff0c\u6574\u5408\u6587\u6863\u68c0\u7d22\u3001\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\u548c\u9519\u8bef\u7cbe\u70bc\u4e09\u4e2a\u6a21\u5757\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728BlocksWorld\u9886\u57df\uff0c\u6700\u4f73\u7ba1\u9053\u5c06\u8ba1\u5212\u6b63\u786e\u7387\u4ece0%\u63d0\u5347\u81f3\u8d85\u8fc780%\uff0c\u4f46\u8bed\u6cd5\u9519\u8bef\u5927\u5e45\u51cf\u5c11\u7684\u540c\u65f6\uff0c\u8bed\u4e49\u9519\u8bef\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u9886\u57df\u4ecd\u7136\u5b58\u5728\u3002", "conclusion": "\u867d\u7136\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u5f53\u524d\u6a21\u578b\u5728\u590d\u6742\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u4ecd\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u8bed\u4e49\u9519\u8bef\u95ee\u9898\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u3002"}}
{"id": "2509.19955", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2509.19955", "abs": "https://arxiv.org/abs/2509.19955", "authors": ["Chunxu Zhang", "Weipeng Zhang", "Guodong Long", "Zhiheng Xue", "Riting Xia", "Bo Yang"], "title": "Multimodal-enhanced Federated Recommendation: A Group-wise Fusion Approach", "comment": null, "summary": "Federated Recommendation (FR) is a new learning paradigm to tackle the\nlearn-to-rank problem in a privacy-preservation manner. How to integrate\nmulti-modality features into federated recommendation is still an open\nchallenge in terms of efficiency, distribution heterogeneity, and fine-grained\nalignment. To address these challenges, we propose a novel multimodal fusion\nmechanism in federated recommendation settings (GFMFR). Specifically, it\noffloads multimodal representation learning to the server, which stores item\ncontent and employs a high-capacity encoder to generate expressive\nrepresentations, alleviating client-side overhead. Moreover, a group-aware item\nrepresentation fusion approach enables fine-grained knowledge sharing among\nsimilar users while retaining individual preferences. The proposed fusion loss\ncould be simply plugged into any existing federated recommender systems\nempowering their capability by adding multi-modality features. Extensive\nexperiments on five public benchmark datasets demonstrate that GFMFR\nconsistently outperforms state-of-the-art multimodal FR baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u8054\u90a6\u63a8\u8350\u6846\u67b6GFMFR\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u7aef\u5904\u7406\u591a\u6a21\u6001\u7279\u5f81\u6765\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u540c\u65f6\u89e3\u51b3\u6548\u7387\u3001\u5206\u5e03\u5f02\u8d28\u6027\u548c\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u7b49\u6311\u6218\u3002", "motivation": "\u8054\u90a6\u63a8\u8350\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u9762\u4e34\u591a\u6a21\u6001\u7279\u5f81\u6574\u5408\u7684\u6311\u6218\uff0c\u5305\u62ec\u6548\u7387\u95ee\u9898\u3001\u5206\u5e03\u5f02\u8d28\u6027\u548c\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u56f0\u96be\u3002", "method": "GFMFR\u5c06\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\u5378\u8f7d\u5230\u670d\u52a1\u5668\u7aef\uff0c\u91c7\u7528\u5206\u7ec4\u611f\u77e5\u7684\u7269\u54c1\u8868\u793a\u878d\u5408\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u53ef\u63d2\u62d4\u7684\u878d\u5408\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGFMFR\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u6a21\u6001\u8054\u90a6\u63a8\u8350\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GFMFR\u4e3a\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2509.20099", "categories": ["cs.IR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.20099", "abs": "https://arxiv.org/abs/2509.20099", "authors": ["Wm. Matthew Kennedy", "Nishanshi Shukla", "Cigdem Patlak", "Blake Chambers", "Theodora Skeadas", "Tuesday", "Kingsley Owadara", "Aayush Dhanotiya"], "title": "Cascade! Human in the loop shortcomings can increase the risk of failures in recommender systems", "comment": null, "summary": "Recommender systems are among the most commonly deployed systems today.\nSystems design approaches to AI-powered recommender systems have done well to\nurge recommender system developers to follow more intentional data collection,\ncuration, and management procedures. So too has the \"human-in-the-loop\"\nparadigm been widely adopted, primarily to address the issue of accountability.\nHowever, in this paper, we take the position that human oversight in\nrecommender system design also entails novel risks that have yet to be fully\ndescribed. These risks are \"codetermined\" by the information context in which\nsuch systems are often deployed. Furthermore, new knowledge of the shortcomings\nof \"human-in-the-loop\" practices to deliver meaningful oversight of other AI\nsystems suggest that they may also be inadequate for achieving socially\nresponsible recommendations. We review how the limitations of human oversight\nmay increase the chances of a specific kind of failure: a \"cascade\" or\n\"compound\" failure. We then briefly explore how the unique dynamics of three\ncommon deployment contexts can make humans in the loop more likely to fail in\ntheir oversight duties. We then conclude with two recommendations.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u63a8\u8350\u7cfb\u7edf\u4e2d\"\u4eba\u5728\u56de\u8def\"\u76d1\u7763\u6a21\u5f0f\u7684\u65b0\u98ce\u9669\uff0c\u6307\u51fa\u8fd9\u79cd\u76d1\u7763\u65b9\u5f0f\u5728\u7279\u5b9a\u4fe1\u606f\u73af\u5883\u4e0b\u53ef\u80fd\u589e\u52a0\u7ea7\u8054\u5931\u8d25\u7684\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u5e7f\u6cdb\u91c7\u7528\"\u4eba\u5728\u56de\u8def\"\u6a21\u5f0f\u6765\u786e\u4fdd\u95ee\u8d23\u5236\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u4eba\u7c7b\u76d1\u7763\u65b9\u5f0f\u5b58\u5728\u5c1a\u672a\u5145\u5206\u63cf\u8ff0\u7684\u65b0\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u7684\u90e8\u7f72\u73af\u5883\u4e0b\u53ef\u80fd\u65e0\u6cd5\u5b9e\u73b0\u793e\u4f1a\u8d23\u4efb\u7684\u63a8\u8350\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4eba\u7c7b\u76d1\u7763\u7684\u5c40\u9650\u6027\u5982\u4f55\u589e\u52a0\u7279\u5b9a\u7c7b\u578b\u7684\u5931\u8d25\uff08\u7ea7\u8054\u6216\u590d\u5408\u5931\u8d25\uff09\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u63a2\u8ba8\u4e09\u79cd\u5e38\u89c1\u90e8\u7f72\u73af\u5883\u4e0b\u4eba\u7c7b\u76d1\u7763\u5931\u6548\u7684\u72ec\u7279\u52a8\u6001\u673a\u5236\u3002", "result": "\u7814\u7a76\u53d1\u73b0\"\u4eba\u5728\u56de\u8def\"\u5b9e\u8df5\u5728\u63d0\u4f9b\u6709\u610f\u4e49\u7684AI\u7cfb\u7edf\u76d1\u7763\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u63a8\u8350\u7cfb\u7edf\u9886\u57df\u53ef\u80fd\u65e0\u6cd5\u5b9e\u73b0\u793e\u4f1a\u8d23\u4efb\u76ee\u6807\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e24\u4e2a\u5efa\u8bae\u6765\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4eba\u7c7b\u76d1\u7763\u673a\u5236\uff0c\u4ee5\u964d\u4f4e\u7ea7\u8054\u5931\u8d25\u7684\u98ce\u9669\u5e76\u63d0\u9ad8\u7cfb\u7edf\u7684\u793e\u4f1a\u8d23\u4efb\u6027\u3002"}}
{"id": "2509.20134", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.20134", "abs": "https://arxiv.org/abs/2509.20134", "authors": ["Jarne Mathi Decker"], "title": "Intelligent Algorithm Selection for Recommender Systems: Meta-Learning via in-depth algorithm feature engineering", "comment": null, "summary": "The \"No Free Lunch\" theorem dictates that no single recommender algorithm is\noptimal for all users, creating a significant Algorithm Selection Problem.\nStandard meta-learning approaches aim to solve this by selecting an algorithm\nbased on user features, but treat the fundamentally diverse algorithms\nthemselves as equivalent, \"black-box\" choices. This thesis investigates the\nimpact of overcoming this limitation by engineering a comprehensive feature set\nto explicitly characterize the algorithms themselves. We combine static code\nmetrics, Abstract Syntax Tree properties, behavioral performance landmarks, and\nhigh-level conceptual features. We evaluate two meta-learners across five\ndatasets: a baseline using only user features and our proposed model using both\nuser and algorithm features. Our results show that the meta-learner augmented\nwith algorithm features achieves an average NDCG@10 of 0.143, a statistically\nsignificant improvement of 11.7% over the Single Best Algorithm baseline\n(0.128). However, we found that the inclusion of algorithm features did not\nlead to an improvement in overall NDCG@10 over the meta learner using only user\nfeatures (0.144). While adding algorithm features to the meta-learner did\nimprove its Top-1 selection accuracy (+16.1%), this was counterbalanced by\nleading to a lower Top-3 accuracy (-10.7%). We conclude that for the per-user\nalgorithm selection task in recommender systems, the predictive power of user\nfeatures is overwhelmingly dominant. While algorithm features improve selection\nprecision, unlocking their potential to boost overall performance remains a\nnon-trivial challenge.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u901a\u8fc7\u4e3a\u7b97\u6cd5\u672c\u8eab\u6784\u5efa\u7279\u5f81\u96c6\u6765\u6539\u8fdb\u7b97\u6cd5\u9009\u62e9\u95ee\u9898\uff0c\u53d1\u73b0\u867d\u7136\u7b97\u6cd5\u7279\u5f81\u63d0\u9ad8\u4e86Top-1\u9009\u62e9\u51c6\u786e\u7387\uff0c\u4f46\u7528\u6237\u7279\u5f81\u5728\u6574\u4f53\u6027\u80fd\u4e2d\u4ecd\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002", "motivation": "\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u7b97\u6cd5\u9009\u62e9\u95ee\u9898\uff0c\u4f20\u7edf\u5143\u5b66\u4e60\u65b9\u6cd5\u5c06\u7b97\u6cd5\u89c6\u4e3a\u9ed1\u76d2\u9009\u62e9\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e3a\u7b97\u6cd5\u672c\u8eab\u6784\u5efa\u7279\u5f81\u6765\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u9759\u6001\u4ee3\u7801\u6307\u6807\u3001\u62bd\u8c61\u8bed\u6cd5\u6811\u5c5e\u6027\u3001\u884c\u4e3a\u6027\u80fd\u57fa\u51c6\u548c\u9ad8\u5c42\u6982\u5ff5\u7279\u5f81\u7684\u7b97\u6cd5\u7279\u5f81\u96c6\uff0c\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u4ec5\u4f7f\u7528\u7528\u6237\u7279\u5f81\u7684\u57fa\u7ebf\u6a21\u578b\u548c\u540c\u65f6\u4f7f\u7528\u7528\u6237\u4e0e\u7b97\u6cd5\u7279\u5f81\u7684\u6a21\u578b\u3002", "result": "\u4f7f\u7528\u7b97\u6cd5\u7279\u5f81\u7684\u5143\u5b66\u4e60\u5668\u5e73\u5747NDCG@10\u4e3a0.143\uff0c\u6bd4\u5355\u4e00\u6700\u4f73\u7b97\u6cd5\u57fa\u7ebf\u63d0\u9ad811.7%\uff0c\u4f46\u4e0e\u4ec5\u4f7f\u7528\u7528\u6237\u7279\u5f81\u7684\u5143\u5b66\u4e60\u5668(0.144)\u76f8\u6bd4\u6ca1\u6709\u6539\u5584\u3002\u7b97\u6cd5\u7279\u5f81\u63d0\u9ad8\u4e86Top-1\u9009\u62e9\u51c6\u786e\u738716.1%\uff0c\u4f46\u964d\u4f4e\u4e86Top-3\u51c6\u786e\u738710.7%\u3002", "conclusion": "\u5728\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u7b97\u6cd5\u9009\u62e9\u4efb\u52a1\u4e2d\uff0c\u7528\u6237\u7279\u5f81\u7684\u9884\u6d4b\u80fd\u529b\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002\u867d\u7136\u7b97\u6cd5\u7279\u5f81\u80fd\u63d0\u9ad8\u9009\u62e9\u7cbe\u5ea6\uff0c\u4f46\u8981\u5229\u7528\u5176\u6f5c\u529b\u63d0\u5347\u6574\u4f53\u6027\u80fd\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002"}}
{"id": "2509.20225", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20225", "abs": "https://arxiv.org/abs/2509.20225", "authors": ["Hui Wang", "Jinghui Qin", "Wushao Wen", "Qingling Li", "Shanshan Zhong", "Zhongzhan Huang"], "title": "Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation", "comment": null, "summary": "Multimodal data has significantly advanced recommendation systems by\nintegrating diverse information sources to model user preferences and item\ncharacteristics. However, these systems often struggle with redundant and\nirrelevant information, which can degrade performance. Most existing methods\neither fuse multimodal information directly or use rigid architectural\nseparation for disentanglement, failing to adequately filter noise and model\nthe complex interplay between modalities. To address these challenges, we\npropose a novel framework, the Multimodal Representation-disentangled\nInformation Bottleneck (MRdIB). Concretely, we first employ a Multimodal\nInformation Bottleneck to compress the input representations, effectively\nfiltering out task-irrelevant noise while preserving rich semantic information.\nThen, we decompose the information based on its relationship with the\nrecommendation target into unique, redundant, and synergistic components. We\nachieve this decomposition with a series of constraints: a unique information\nlearning objective to preserve modality-unique signals, a redundant information\nlearning objective to minimize overlap, and a synergistic information learning\nobjective to capture emergent information. By optimizing these objectives,\nMRdIB guides a model to learn more powerful and disentangled representations.\nExtensive experiments on several competitive models and three benchmark\ndatasets demonstrate the effectiveness and versatility of our MRdIB in\nenhancing multimodal recommendation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u8868\u793a\u89e3\u7f20\u4fe1\u606f\u74f6\u9888\uff08MRdIB\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u538b\u7f29\u8f93\u5165\u8868\u793a\u6765\u8fc7\u6ee4\u4efb\u52a1\u65e0\u5173\u566a\u58f0\uff0c\u5e76\u5c06\u4fe1\u606f\u5206\u89e3\u4e3a\u72ec\u7279\u3001\u5197\u4f59\u548c\u534f\u540c\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u4ee5\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u5728\u5904\u7406\u5197\u4f59\u548c\u65e0\u5173\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u76f4\u63a5\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\u6216\u4f7f\u7528\u521a\u6027\u67b6\u6784\u5206\u79bb\u7684\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8fc7\u6ee4\u566a\u58f0\u548c\u5efa\u6a21\u6a21\u6001\u95f4\u590d\u6742\u4ea4\u4e92\u3002", "method": "\u9996\u5148\u4f7f\u7528\u591a\u6a21\u6001\u4fe1\u606f\u74f6\u9888\u538b\u7f29\u8f93\u5165\u8868\u793a\u4ee5\u8fc7\u6ee4\u566a\u58f0\uff0c\u7136\u540e\u5c06\u4fe1\u606f\u57fa\u4e8e\u4e0e\u63a8\u8350\u76ee\u6807\u7684\u5173\u7cfb\u5206\u89e3\u4e3a\u72ec\u7279\u3001\u5197\u4f59\u548c\u534f\u540c\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u5b66\u4e60\u76ee\u6807\uff08\u72ec\u7279\u4fe1\u606f\u5b66\u4e60\u3001\u5197\u4f59\u4fe1\u606f\u6700\u5c0f\u5316\u548c\u534f\u540c\u4fe1\u606f\u6355\u83b7\uff09\u6765\u5b9e\u73b0\u89e3\u7f20\u8868\u793a\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u7ade\u4e89\u6027\u6a21\u578b\u548c\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86MRdIB\u5728\u589e\u5f3a\u591a\u6a21\u6001\u63a8\u8350\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "MRdIB\u6846\u67b6\u80fd\u591f\u6307\u5bfc\u6a21\u578b\u5b66\u4e60\u66f4\u5f3a\u5927\u548c\u89e3\u7f20\u7684\u8868\u793a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u5197\u4f59\u548c\u566a\u58f0\u95ee\u9898\u3002"}}
{"id": "2509.20228", "categories": ["cs.IR", "cs.CL", "cs.HC", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2509.20228", "abs": "https://arxiv.org/abs/2509.20228", "authors": ["Jatin Agarwala", "George Paul", "Nemani Harsha Vardhan", "Vinoo Alluri"], "title": "Muse-it: A Tool for Analyzing Music Discourse on Reddit", "comment": null, "summary": "Music engagement spans diverse interactions with music, from selection and\nemotional response to its impact on behavior, identity, and social connections.\nSocial media platforms provide spaces where such engagement can be observed in\nnatural, unprompted conversations. Advances in natural language processing\n(NLP) and big data analytics make it possible to analyze these discussions at\nscale, extending music research to broader contexts. Reddit, in particular,\noffers anonymity that encourages diverse participation and yields rich\ndiscourse on music in ecological settings. Yet the scale of this data requires\ntools to extract, process, and analyze it effectively. We present Muse-it, a\nplatform that retrieves comprehensive Reddit data centered on user-defined\nqueries. It aggregates posts from across subreddits, supports topic modeling,\ntemporal trend analysis, and clustering, and enables efficient study of\nlarge-scale discourse. Muse-it also identifies music-related hyperlinks (e.g.,\nSpotify), retrieves track-level metadata such as artist, album, release date,\ngenre, popularity, and lyrics, and links these to the discussions. An\ninteractive interface provides dynamic visualizations of the collected data.\nMuse-it thus offers an accessible way for music researchers to gather and\nanalyze big data, opening new avenues for understanding music engagement as it\nnaturally unfolds online.", "AI": {"tldr": "Muse-it\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u6790Reddit\u4e0a\u97f3\u4e50\u76f8\u5173\u8ba8\u8bba\u7684\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u6570\u636e\u5206\u6790\u6280\u672f\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u5927\u89c4\u6a21\u7814\u7a76\u97f3\u4e50\u53c2\u4e0e\u884c\u4e3a\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u63d0\u4f9b\u4e86\u89c2\u5bdf\u81ea\u7136\u97f3\u4e50\u53c2\u4e0e\u884c\u4e3a\u7684\u7a7a\u95f4\uff0c\u4f46\u5927\u89c4\u6a21\u6570\u636e\u7684\u63d0\u53d6\u548c\u5206\u6790\u9700\u8981\u4e13\u95e8\u5de5\u5177\u3002Reddit\u7684\u533f\u540d\u6027\u9f13\u52b1\u591a\u6837\u5316\u53c2\u4e0e\uff0c\u4ea7\u751f\u4e86\u4e30\u5bcc\u7684\u97f3\u4e50\u8ba8\u8bba\u6570\u636e\u3002", "method": "\u5f00\u53d1Muse-it\u5e73\u53f0\uff0c\u4eceReddit\u68c0\u7d22\u7528\u6237\u5b9a\u4e49\u67e5\u8be2\u7684\u5168\u9762\u6570\u636e\uff0c\u652f\u6301\u4e3b\u9898\u5efa\u6a21\u3001\u65f6\u95f4\u8d8b\u52bf\u5206\u6790\u548c\u805a\u7c7b\uff0c\u8bc6\u522b\u97f3\u4e50\u76f8\u5173\u8d85\u94fe\u63a5\u5e76\u83b7\u53d6\u66f2\u76ee\u7ea7\u5143\u6570\u636e\u3002", "result": "\u5e73\u53f0\u80fd\u591f\u805a\u5408\u8de8\u5b50\u7248\u5757\u7684\u5e16\u5b50\uff0c\u63d0\u4f9b\u52a8\u6001\u53ef\u89c6\u5316\u754c\u9762\uff0c\u6709\u6548\u652f\u6301\u5927\u89c4\u6a21\u97f3\u4e50\u8ba8\u8bba\u7814\u7a76\u3002", "conclusion": "Muse-it\u4e3a\u97f3\u4e50\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u6536\u96c6\u548c\u5206\u6790\u5927\u6570\u636e\u7684\u4fbf\u6377\u9014\u5f84\uff0c\u4e3a\u7406\u89e3\u5728\u7ebf\u81ea\u7136\u53d1\u751f\u7684\u97f3\u4e50\u53c2\u4e0e\u884c\u4e3a\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
