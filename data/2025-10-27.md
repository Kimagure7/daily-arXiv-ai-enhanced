<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Gaussian Mixture Flow Matching with Domain Alignment for Multi-Domain Sequential Recommendation](https://arxiv.org/abs/2510.21021)
*Xiaoxin Ye,Chengkai Huang,Hongtao Huang,Lina Yao*

Main category: cs.IR

TL;DR: GMFlowRec是一个高效的多域序列推荐生成框架，通过高斯混合流匹配建模域感知转换轨迹，解决了现有方法在处理多域转换、域异构性和不平衡性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 用户在多域中的交互行为具有频繁复杂的转换特征，现有跨域序列推荐方法主要关注双域交互，无法有效处理多域转换中的域异构性、不平衡性以及扩展性问题。

Method: 提出GMFlowRec框架，包含：统一双掩码Transformer分离域不变和域特定意图；高斯混合流场捕捉多样化行为模式；域对齐先验支持频繁和稀疏转换。

Result: 在JD和Amazon数据集上的实验表明，GMFlowRec在NDCG@5指标上达到最先进性能，提升高达44%，同时通过单一统一骨干网络保持高效率。

Conclusion: GMFlowRec通过生成式框架有效解决了多域序列推荐中的挑战，实现了高性能和高效率，适用于现实世界的多域推荐场景。

Abstract: Users increasingly interact with content across multiple domains, resulting
in sequential behaviors marked by frequent and complex transitions. While
Cross-Domain Sequential Recommendation (CDSR) models two-domain interactions,
Multi-Domain Sequential Recommendation (MDSR) introduces significantly more
domain transitions, compounded by challenges such as domain heterogeneity and
imbalance. Existing approaches often overlook the intricacies of domain
transitions, tend to overfit to dense domains while underfitting sparse ones,
and struggle to scale effectively as the number of domains increases. We
propose \textit{GMFlowRec}, an efficient generative framework for MDSR that
models domain-aware transition trajectories via Gaussian Mixture Flow Matching.
GMFlowRec integrates: (1) a unified dual-masked Transformer to disentangle
domain-invariant and domain-specific intents, (2) a Gaussian Mixture flow field
to capture diverse behavioral patterns, and (3) a domain-aligned prior to
support frequent and sparse transitions. Extensive experiments on JD and Amazon
datasets demonstrate that GMFlowRec achieves state-of-the-art performance with
up to 44\% improvement in NDCG@5, while maintaining high efficiency via a
single unified backbone, making it scalable for real-world multi-domain
sequential recommendation.

</details>


### [2] [Communication Platform for Non-verbal Autistic children in Oman using Android mobile](https://arxiv.org/abs/2510.21028)
*Amna Al-Araimi,Yue Zheng,Haiming Liu*

Main category: cs.IR

TL;DR: 该论文提出一个结合网页面板和Android移动应用的平台，用于帮助阿曼的非语言自闭症儿童改善沟通能力，采用增强现实框架来促进创造性游戏和自我反思。


<details>
  <summary>Details</summary>
Motivation: 针对全球普遍存在的非语言自闭症谱系障碍问题，现有技术方法较为分散，不适合自闭症儿童的需求，特别是在阿曼地区需要专门的沟通辅助工具。

Method: 开发一个集成网页面板和Android移动应用的平台，融合多种干预措施，采用增强现实框架通过互动屏幕活动吸引自闭症儿童参与创造性游戏。

Result: 提出的平台能够帮助非语言自闭症儿童更好地进行沟通，改善他们的社交互动能力，特别是在阿曼地区的应用效果值得期待。

Conclusion: 整合的增强现实平台比分散的方法更适合自闭症儿童，能够有效提升他们的沟通能力和生活质量。

Abstract: This paper discusses the issue regarding Non-verbal Autism Spectrum Disorder.
It has been observed that this mental disorder is listed in major parts of the
world including the US, UK, and India. To mitigate this type of disorder, a
wide range of smartphones, computers, and artificial intelligence technologies
have been used. This technology has helped the population cope with
socialization and communication needs. Many applications have been developed to
enhance the communication capabilities of non-verbal autistic children. This
thesis project proposes the development of a platform that includes a web panel
and an Android mobile application to assist non-verbal autistic children in
communication, especially in Oman. Different interventions have been merged to
improve the quality of life for people on the autism spectrum. The main problem
identified in this case is that fragmented approaches are not suitable for
autistic children. The augmented reality framework provides the capability to
engage autistic children in creative play and self-reflection through
interactive screen-based activities.

</details>


### [3] [VOGUE: A Multimodal Dataset for Conversational Recommendation in Fashion](https://arxiv.org/abs/2510.21151)
*David Guo,Minqi Sun,Yilun Jiang,Jiazhou Liang,Scott Sanner*

Main category: cs.IR

TL;DR: VOGUE是一个新颖的多模态对话推荐数据集，包含60个真实时尚购物场景下的人类对话，配有视觉目录、用户档案和历史记录，支持对话推理的严格评估。


<details>
  <summary>Details</summary>
Motivation: 现有多模态对话推荐数据集存在模拟对话、忽略用户历史或反馈不足等限制，制约了相关研究和评估。

Method: 收集60个人类对话，每个对话配有共享视觉目录、商品元数据、用户时尚档案和历史，以及对话后评分。

Result: 分析发现视觉对话具有独特动态，推荐者常按特征分组推荐商品；MLLMs在总体对齐上接近人类水平，但在评分分布和偏好推理泛化方面存在系统误差。

Conclusion: VOGUE既是研究多模态对话系统的独特资源，也是超越当前顶级多模态基础模型推荐能力的挑战数据集。

Abstract: Multimodal conversational recommendation has emerged as a promising paradigm
for delivering personalized experiences through natural dialogue enriched by
visual and contextual grounding. Yet, current multimodal conversational
recommendation datasets remain limited: existing resources either simulate
conversations, omit user history, or fail to collect sufficiently detailed
feedback, all of which constrain the types of research and evaluation they
support.
  To address these gaps, we introduce VOGUE, a novel dataset of 60 humanhuman
dialogues in realistic fashion shopping scenarios. Each dialogue is paired with
a shared visual catalogue, item metadata, user fashion profiles and histories,
and post-conversation ratings from both Seekers and Assistants. This design
enables rigorous evaluation of conversational inference, including not only
alignment between predicted and ground-truth preferences, but also calibration
against full rating distributions and comparison with explicit and implicit
user satisfaction signals.
  Our initial analyses of VOGUE reveal distinctive dynamics of visually
grounded dialogue. For example, recommenders frequently suggest items
simultaneously in feature-based groups, which creates distinct conversational
phases bridged by Seeker critiques and refinements. Benchmarking multimodal
large language models against human recommenders shows that while MLLMs
approach human-level alignment in aggregate, they exhibit systematic
distribution errors in reproducing human ratings and struggle to generalize
preference inference beyond explicitly discussed items. These findings
establish VOGUE as both a unique resource for studying multimodal
conversational systems and as a challenge dataset beyond the current
recommendation capabilities of existing top-tier multimodal foundation models
such as GPT-4o-mini, GPT-5-mini, and Gemini-2.5-Flash.

</details>


### [4] [Bi-Level Optimization for Generative Recommendation: Bridging Tokenization and Generation](https://arxiv.org/abs/2510.21242)
*Yimeng Bai,Chang Liu,Yang Zhang,Dingxian Wang,Frank Yang,Andrew Rabinovich,Wenge Rong,Fuli Feng*

Main category: cs.IR

TL;DR: BLOGER是一个用于生成式推荐的双层优化框架，通过统一优化分词器和推荐器来解决现有方法中两者分离导致的标识符与推荐目标不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法通常将分词器和推荐器分开训练（顺序或交替），忽略了它们之间的相互依赖关系，导致分词器训练缺乏推荐目标的直接指导，产生次优标识符并降低推荐性能。

Method: 提出BLOGER框架，采用双层优化：下层训练推荐器使用分词序列，上层基于分词损失和推荐损失优化分词器。使用元学习方法高效求解，并引入梯度手术缓解上层更新中的梯度冲突。

Result: 在真实世界数据集上的广泛实验表明，BLOGER持续优于最先进的生成式推荐方法，同时保持实际效率，没有显著增加计算开销。

Conclusion: BLOGER有效弥合了项目分词和自回归生成之间的差距，确保项目标识符既信息丰富又与推荐目标对齐。

Abstract: Generative recommendation is emerging as a transformative paradigm by
directly generating recommended items, rather than relying on matching.
Building such a system typically involves two key components: (1) optimizing
the tokenizer to derive suitable item identifiers, and (2) training the
recommender based on those identifiers. Existing approaches often treat these
components separately--either sequentially or in alternation--overlooking their
interdependence. This separation can lead to misalignment: the tokenizer is
trained without direct guidance from the recommendation objective, potentially
yielding suboptimal identifiers that degrade recommendation performance.
  To address this, we propose BLOGER, a Bi-Level Optimization for GEnerative
Recommendation framework, which explicitly models the interdependence between
the tokenizer and the recommender in a unified optimization process. The lower
level trains the recommender using tokenized sequences, while the upper level
optimizes the tokenizer based on both the tokenization loss and recommendation
loss. We adopt a meta-learning approach to solve this bi-level optimization
efficiently, and introduce gradient surgery to mitigate gradient conflicts in
the upper-level updates, thereby ensuring that item identifiers are both
informative and recommendation-aligned. Extensive experiments on real-world
datasets demonstrate that BLOGER consistently outperforms state-of-the-art
generative recommendation methods while maintaining practical efficiency with
no significant additional computational overhead, effectively bridging the gap
between item tokenization and autoregressive generation.

</details>


### [5] [Pctx: Tokenizing Personalized Context for Generative Recommendation](https://arxiv.org/abs/2510.21276)
*Qiyong Zhong,Jiajie Su,Yunshan Ma,Julian McAuley,Yupeng Hou*

Main category: cs.IR

TL;DR: 提出个性化上下文感知分词器，将用户历史交互融入语义ID生成过程，解决现有生成推荐模型中分词方法静态非个性化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐模型的分词方法仅基于物品特征生成静态语义ID，假设统一的物品相似性标准，忽略了用户特定的视角和偏好。

Method: 设计个性化上下文感知分词器，在生成语义ID时融入用户历史交互信息，使同一物品在不同用户上下文中被分词为不同的语义ID。

Result: 在三个公共数据集上的实验表明，相比非个性化动作分词基线，NDCG@10指标提升最高达11.44%。

Conclusion: 个性化上下文感知分词器能够使生成推荐模型捕捉多种解释标准，产生更个性化的预测，显著提升推荐性能。

Abstract: Generative recommendation (GR) models tokenize each action into a few
discrete tokens (called semantic IDs) and autoregressively generate the next
tokens as predictions, showing advantages such as memory efficiency,
scalability, and the potential to unify retrieval and ranking. Despite these
benefits, existing tokenization methods are static and non-personalized. They
typically derive semantic IDs solely from item features, assuming a universal
item similarity that overlooks user-specific perspectives. However, under the
autoregressive paradigm, semantic IDs with the same prefixes always receive
similar probabilities, so a single fixed mapping implicitly enforces a
universal item similarity standard across all users. In practice, the same item
may be interpreted differently depending on user intentions and preferences. To
address this issue, we propose a personalized context-aware tokenizer that
incorporates a user's historical interactions when generating semantic IDs.
This design allows the same item to be tokenized into different semantic IDs
under different user contexts, enabling GR models to capture multiple
interpretive standards and produce more personalized predictions. Experiments
on three public datasets demonstrate up to 11.44% improvement in NDCG@10 over
non-personalized action tokenization baselines. Our code is available at
https://github.com/YoungZ365/Pctx.

</details>


### [6] [CausalRec: A CausalBoost Attention Model for Sequential Recommendation](https://arxiv.org/abs/2510.21333)
*Yunbo Hou,Tianle Yang,Ruijie Li,Li He,Liang Wang,Weiping Li,Bo Zheng,Guojie Song*

Main category: cs.IR

TL;DR: 提出了CausalRec框架，通过因果注意力机制改进序列推荐系统，结合因果发现模块和因果增强器，在真实数据集上显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于相关性的序列推荐系统只关注物品共现，忽略了用户行为背后的因果动机，导致虚假相关性和不准确的推荐。

Method: CausalRec包含因果发现块和CausalBooster。因果发现块学习用户行为序列中的因果图，CausalBooster利用发现的因果图来优化注意力机制，优先考虑具有因果重要性的行为。

Result: 在真实数据集上的实验表明，CausalRec优于多个最先进方法，在命中率和NDCG上平均分别提升7.21%和8.65%。

Conclusion: 这是第一个通过注意力机制在序列推荐中引入因果关系的模型，证明了因果关系在生成更准确可靠推荐方面的价值。

Abstract: Recent advances in correlation-based sequential recommendation systems have
demonstrated substantial success. Specifically, the attention-based model
outperforms other RNN-based and Markov chains-based models by capturing both
short- and long-term dependencies more effectively. However, solely focusing on
item co-occurrences overlooks the underlying motivations behind user behaviors,
leading to spurious correlations and potentially inaccurate recommendations. To
address this limitation, we present a novel framework that integrates causal
attention for sequential recommendation, CausalRec. It incorporates a causal
discovery block and a CausalBooster. The causal discovery block learns the
causal graph in user behavior sequences, and we provide a theory to guarantee
the identifiability of the learned causal graph. The CausalBooster utilizes the
discovered causal graph to refine the attention mechanism, prioritizing
behaviors with causal significance. Experimental evaluations on real-world
datasets indicate that CausalRec outperforms several state-of-the-art methods,
with average improvements of 7.21% in Hit Rate (HR) and 8.65% in Normalized
Discounted Cumulative Gain (NDCG). To the best of our knowledge, this is the
first model to incorporate causality through the attention mechanism in
sequential recommendation, demonstrating the value of causality in generating
more accurate and reliable recommendations.

</details>


### [7] [SciNUP: Natural Language User Interest Profiles for Scientific Literature Recommendation](https://arxiv.org/abs/2510.21352)
*Mariam Arustashvili,Krisztian Balog*

Main category: cs.IR

TL;DR: 提出了SciNUP数据集，用于评估基于自然语言用户画像的推荐系统，通过作者发表历史生成自然语言画像和对应推荐项目，比较了多种基线方法并发现它们具有互补性。


<details>
  <summary>Details</summary>
Motivation: 解决基于自然语言用户画像的推荐系统缺乏大规模公开测试数据集的问题，促进该领域的研究发展。

Method: 创建SciNUP合成数据集，利用作者发表历史生成自然语言画像；比较稀疏检索、稠密检索和基于LLM的重排序等基线方法。

Result: 基线方法性能相当但推荐项目不同，显示互补行为；同时存在较大改进空间，需要更有效的自然语言推荐方法。

Conclusion: SciNUP数据集为基于自然语言用户画像的推荐系统研究提供了有价值的资源，推动了该领域的发展。

Abstract: The use of natural language (NL) user profiles in recommender systems offers
greater transparency and user control compared to traditional representations.
However, there is scarcity of large-scale, publicly available test collections
for evaluating NL profile-based recommendation. To address this gap, we
introduce SciNUP, a novel synthetic dataset for scholarly recommendation that
leverages authors' publication histories to generate NL profiles and
corresponding ground truth items. We use this dataset to conduct a comparison
of baseline methods, ranging from sparse and dense retrieval approaches to
state-of-the-art LLM-based rerankers. Our results show that while baseline
methods achieve comparable performance, they often retrieve different items,
indicating complementary behaviors. At the same time, considerable headroom for
improvement remains, highlighting the need for effective NL-based
recommendation approaches. The SciNUP dataset thus serves as a valuable
resource for fostering future research and development in this area.

</details>


### [8] [Doc-Researcher: A Unified System for Multimodal Document Parsing and Deep Research](https://arxiv.org/abs/2510.21603)
*Kuicai Dong,Shurui Huang,Fangda Ye,Wei Han,Zhi Zhang,Dexun Li,Wenjun Li,Qu Yang,Gang Wang,Yichao Wang,Chen Zhang,Yong Liu*

Main category: cs.IR

TL;DR: Doc-Researcher是一个统一的多模态文档深度研究系统，通过多模态解析、系统化检索架构和迭代多智能体工作流，解决了现有系统局限于文本数据的问题，在M4DocBench基准上达到50.6%准确率，比现有最佳方法提升3.4倍。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究系统主要局限于文本网络数据，忽略了多模态文档中嵌入的丰富知识（图表、方程等），需要能够保留视觉语义、维护结构连贯性并支持跨模态检索的新系统。

Method: 系统包含三个核心组件：(1)深度多模态解析，保留布局结构和视觉语义，创建从块级到文档级的多粒度表示；(2)系统化检索架构，支持纯文本、纯视觉和混合检索范式；(3)迭代多智能体工作流，分解复杂查询、逐步积累证据并跨文档和模态合成答案。

Result: 在M4DocBench基准测试中，Doc-Researcher达到50.6%的准确率，比现有最佳基线方法提升3.4倍，验证了多模态完整性和迭代研究的重要性。

Conclusion: 有效文档研究不仅需要更好的检索，更需要能够保留多模态完整性和支持迭代研究的深度解析，Doc-Researcher为多模态文档集合的深度研究建立了新范式。

Abstract: Deep Research systems have revolutionized how LLMs solve complex questions
through iterative reasoning and evidence gathering. However, current systems
remain fundamentally constrained to textual web data, overlooking the vast
knowledge embedded in multimodal documents Processing such documents demands
sophisticated parsing to preserve visual semantics (figures, tables, charts,
and equations), intelligent chunking to maintain structural coherence, and
adaptive retrieval across modalities, which are capabilities absent in existing
systems. In response, we present Doc-Researcher, a unified system that bridges
this gap through three integrated components: (i) deep multimodal parsing that
preserves layout structure and visual semantics while creating multi-granular
representations from chunk to document level, (ii) systematic retrieval
architecture supporting text-only, vision-only, and hybrid paradigms with
dynamic granularity selection, and (iii) iterative multi-agent workflows that
decompose complex queries, progressively accumulate evidence, and synthesize
comprehensive answers across documents and modalities. To enable rigorous
evaluation, we introduce M4DocBench, the first benchmark for Multi-modal,
Multi-hop, Multi-document, and Multi-turn deep research. Featuring 158
expert-annotated questions with complete evidence chains across 304 documents,
M4DocBench tests capabilities that existing benchmarks cannot assess.
Experiments demonstrate that Doc-Researcher achieves 50.6% accuracy, 3.4xbetter
than state-of-the-art baselines, validating that effective document research
requires not just better retrieval, but fundamentally deep parsing that
preserve multimodal integrity and support iterative research. Our work
establishes a new paradigm for conducting deep research on multimodal document
collections.

</details>


### [9] [A Data-Centric Approach to Multilingual E-Commerce Product Search: Case Study on Query-Category and Query-Item Relevance](https://arxiv.org/abs/2510.21671)
*Yabo Yin,Yang Xi,Jialong Wang,Shanqi Wang,Jiateng Hu*

Main category: cs.IR

TL;DR: 提出了一种数据中心的框架，通过翻译增强、语义负采样和自验证过滤三种策略改进多语言电商搜索中的查询-类别和查询-商品相关性任务，在不改变模型的情况下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 多语言电商搜索面临数据不平衡、标签噪声和低资源语言监督有限的问题，阻碍了相关性模型的跨语言泛化能力。

Method: 采用三种数据工程策略：翻译增强为训练中缺失的语言合成样本；语义负采样生成困难负例缓解类别不平衡；自验证过滤检测并移除可能错误标注的实例。

Result: 在CIKM AnalytiCup 2025数据集上，相比强LLM基线获得了显著的F1分数提升，在官方竞赛中取得了有竞争力的结果。

Conclusion: 系统的数据工程可以与复杂模型修改一样有效，且通常更易于部署，为构建鲁棒的多语言电商搜索系统提供了实用指导。

Abstract: Multilingual e-commerce search suffers from severe data imbalance across
languages, label noise, and limited supervision for low-resource
languages--challenges that impede the cross-lingual generalization of relevance
models despite the strong capabilities of large language models (LLMs). In this
work, we present a practical, architecture-agnostic, data-centric framework to
enhance performance on two core tasks: Query-Category (QC) relevance (matching
queries to product categories) and Query-Item (QI) relevance (matching queries
to product titles). Rather than altering the model, we redesign the training
data through three complementary strategies: (1) translation-based augmentation
to synthesize examples for languages absent in training, (2) semantic negative
sampling to generate hard negatives and mitigate class imbalance, and (3)
self-validation filtering to detect and remove likely mislabeled instances.
Evaluated on the CIKM AnalytiCup 2025 dataset, our approach consistently yields
substantial F1 score improvements over strong LLM baselines, achieving
competitive results in the official competition. Our findings demonstrate that
systematic data engineering can be as impactful as--and often more deployable
than--complex model modifications, offering actionable guidance for building
robust multilingual search systems in the real-world e-commerce settings.

</details>
