<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Location Matters: Leveraging Multi-Resolution Geo-Embeddings for Housing Search](https://arxiv.org/abs/2510.01196)
*Ivo Silva,Pedro Nogueira,Guilherme Bonaldo*

Main category: cs.IR

TL;DR: 提出了一种地理感知嵌入框架，通过多层级H3网格和双塔神经网络架构解决住房推荐中的稀疏性和空间细微差别问题。


<details>
  <summary>Details</summary>
Motivation: QuintoAndar作为拉丁美洲最大的住房平台，用户在海量房源中难以找到理想住房。地理位置对房产价值、便利设施和生活质量有重要影响，因此将位置信息融入推荐系统至关重要。

Method: 使用分层H3网格在多个级别上集成到双塔神经网络架构中，与传统矩阵分解基线和单分辨率变体进行比较。

Result: 嵌入特定评估显示更丰富和平衡的嵌入表示，离线排名模拟显示推荐质量显著提升。

Conclusion: 地理感知嵌入框架能有效解决住房推荐中的空间挑战，提升推荐系统的性能。

Abstract: QuintoAndar Group is Latin America's largest housing platform,
revolutionizing property rentals and sales. Headquartered in Brazil, it
simplifies the housing process by eliminating paperwork and enhancing
accessibility for tenants, buyers, and landlords. With thousands of houses
available for each city, users struggle to find the ideal home. In this
context, location plays a pivotal role, as it significantly influences property
value, access to amenities, and life quality. A great location can make even a
modest home highly desirable. Therefore, incorporating location into
recommendations is essential for their effectiveness. We propose a geo-aware
embedding framework to address sparsity and spatial nuances in housing
recommendations on digital rental platforms. Our approach integrates an
hierarchical H3 grid at multiple levels into a two-tower neural architecture.
We compare our method with a traditional matrix factorization baseline and a
single-resolution variant using interaction data from our platform. Embedding
specific evaluation reveals richer and more balanced embedding representations,
while offline ranking simulations demonstrate a substantial uplift in
recommendation quality.

</details>


### [2] [Are LLMs ready to help non-expert users to make charts of official statistics data?](https://arxiv.org/abs/2510.01197)
*Gadir Suleymanli,Alexander Rogiers,Lucas Lageweg,Jefrey Lijffijt*

Main category: cs.IR

TL;DR: 评估大型语言模型从复杂数据自动生成图表的能力，发现数据检索和处理是主要挑战，但通过适当指导和迭代自评估可以显著提升性能


<details>
  <summary>Details</summary>
Motivation: 在虚假信息和偏见信息泛滥的时代，可靠数据源的可访问性至关重要。国家统计机构提供了大量数据，但这些数据通常分散在多个表格中，难以处理，使得开放数据实际上难以访问

Method: 使用荷兰统计局的不同公共数据，评估多个LLM在识别相关数据表、执行必要操作和自动生成适当可视化方面的能力。提出了一个跨越三个维度的新评估框架：数据检索与预处理、代码质量和视觉表示

Result: 定位和处理正确数据是最重要的挑战。LLM很少在没有明确指导的情况下实施可视化最佳实践。当提供有效图表设计信息时，模型在表示分数上显示出显著改进。采用迭代自评估的代理方法在所有评估维度上都表现出色

Conclusion: 通过适当的支架和反馈机制可以增强LLM在自动图表生成方面的有效性，系统已经能够在三个评估维度上达到必要的准确性

Abstract: In this time when biased information, deep fakes, and propaganda proliferate,
the accessibility of reliable data sources is more important than ever.
National statistical institutes provide curated data that contain quantitative
information on a wide range of topics. However, that information is typically
spread across many tables and the plain numbers may be arduous to process.
Hence, this open data may be practically inaccessible. We ask the question "Are
current Generative AI models capable of facilitating the identification of the
right data and the fully-automatic creation of charts to provide information in
visual form, corresponding to user queries?". We present a structured
evaluation of recent large language models' (LLMs) capabilities to generate
charts from complex data in response to user queries. Working with diverse
public data from Statistics Netherlands, we assessed multiple LLMs on their
ability to identify relevant data tables, perform necessary manipulations, and
generate appropriate visualizations autonomously. We propose a new evaluation
framework spanning three dimensions: data retrieval & pre-processing, code
quality, and visual representation. Results indicate that locating and
processing the correct data represents the most significant challenge.
Additionally, LLMs rarely implement visualization best practices without
explicit guidance. When supplemented with information about effective chart
design, models showed marked improvement in representation scores. Furthermore,
an agentic approach with iterative self-evaluation led to excellent performance
across all evaluation dimensions. These findings suggest that LLMs'
effectiveness for automated chart generation can be enhanced through
appropriate scaffolding and feedback mechanisms, and that systems can already
reach the necessary accuracy across the three evaluation dimensions.

</details>


### [3] [Optimal signals assignment for eBay View Item page](https://arxiv.org/abs/2510.01198)
*Matan Mandelbrod,Biwei Jiang,Giald Wagner,Tal Franji,Guy Feigenblat*

Main category: cs.IR

TL;DR: 本文提出了两种统计模型方法，用于在eBay商品详情页上优化显示信号（文本或视觉片段），通过A/B测试验证了这些方法能显著提升业务指标。


<details>
  <summary>Details</summary>
Motivation: 在eBay商品详情页上显示信号旨在为用户提供额外的上下文信息，促进智能购买并激励用户参与。

Method: 开发了两种统计模型方法，用于优化商品详情页上的信号展示。

Result: 两种方法都进行了A/B测试，结果显示业务指标有显著提升。

Conclusion: 提出的统计模型方法能有效优化eBay商品详情页的信号展示，提升用户参与和业务表现。

Abstract: Signals are short textual or visual snippets displayed on the eBay View-Item
(VI) page, providing additional, contextual information for users about the
viewed item. The aim in displaying the signals is to facilitate intelligent
purchase and to incentivise engagement. In this paper, we present two
approaches for developing statistical models that optimally populate the VI
page with signals. Both approaches were A/B tested, and yielded significant
increase in business metrics.

</details>


### [4] [MetaSynth: Multi-Agent Metadata Generation from Implicit Feedback in Black-Box Systems](https://arxiv.org/abs/2510.01523)
*Shreeranjani Srirangamsridharan,Ali Abavisani,Reza Yousefi Maragheh,Ramin Giahi,Kai Zhao,Jason Cho,Sushant Kumar*

Main category: cs.IR

TL;DR: MetaSynth是一个多智能体检索增强生成框架，通过从隐式搜索反馈中学习来优化元标题和描述，在电子商务数据上显著提升了点击率和排名指标。


<details>
  <summary>Details</summary>
Motivation: 搜索和推荐平台中的元标题和描述对用户参与度有重要影响，但现有方法存在多样性不足、产生幻觉属性或忽略历史成功案例等问题，且缺乏直接利用可观察结果隐式信号的能力。

Method: 构建一个从排名靠前结果中提取的范例库，基于产品内容和范例生成候选片段，通过评估器-生成器循环迭代优化输出，确保相关性、促销强度和合规性。

Result: 在专有电子商务数据和Amazon评论语料库上，MetaSynth在NDCG、MRR和排名指标上均优于强基线方法，大规模A/B测试显示点击率提升10.26%，点击量提升7.51%。

Conclusion: MetaSynth不仅优化了元数据，还为在黑盒系统中使用隐式信号优化内容提供了一种通用范式。

Abstract: Meta titles and descriptions strongly shape engagement in search and
recommendation platforms, yet optimizing them remains challenging. Search
engine ranking models are black box environments, explicit labels are
unavailable, and feedback such as click-through rate (CTR) arrives only
post-deployment. Existing template, LLM, and retrieval-augmented approaches
either lack diversity, hallucinate attributes, or ignore whether candidate
phrasing has historically succeeded in ranking. This leaves a gap in directly
leveraging implicit signals from observable outcomes. We introduce MetaSynth, a
multi-agent retrieval-augmented generation framework that learns from implicit
search feedback. MetaSynth builds an exemplar library from top-ranked results,
generates candidate snippets conditioned on both product content and exemplars,
and iteratively refines outputs via evaluator-generator loops that enforce
relevance, promotional strength, and compliance. On both proprietary e-commerce
data and the Amazon Reviews corpus, MetaSynth outperforms strong baselines
across NDCG, MRR, and rank metrics. Large-scale A/B tests further demonstrate
10.26% CTR and 7.51% clicks. Beyond metadata, this work contributes a general
paradigm for optimizing content in black-box systems using implicit signals.

</details>


### [5] [IoDResearch: Deep Research on Private Heterogeneous Data via the Internet of Data](https://arxiv.org/abs/2510.01553)
*Zhuofan Shi,Zijie Guo,Xinjian Ma,Gang Huang,Yun Ma,Xiang Jing*

Main category: cs.IR

TL;DR: IoDResearch是一个面向私有数据的深度研究框架，通过将异构资源封装为FAIR合规的数字对象，构建知识图谱索引，支持多粒度检索和多代理系统的可靠问答与科学报告生成。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究框架主要关注网络搜索，忽视本地私有数据，导致私有数据检索效率低且不符合FAIR原则，造成效率低下和可重用性有限的问题。

Method: 将异构资源封装为FAIR合规数字对象，细化为原子知识单元和知识图谱，形成异构图索引支持多粒度检索，并构建多代理系统支持问答和报告生成。

Result: 在检索、问答和报告写作任务上的实验结果表明，IoDResearch持续超越代表性的RAG和深度研究基线方法。

Conclusion: IoDResearch证明了在IoD范式下私有数据为中心的深度研究的可行性，为更可信、可重用和自动化的科学发现铺平了道路。

Abstract: The rapid growth of multi-source, heterogeneous, and multimodal scientific
data has increasingly exposed the limitations of traditional data management.
Most existing DeepResearch (DR) efforts focus primarily on web search while
overlooking local private data. Consequently, these frameworks exhibit low
retrieval efficiency for private data and fail to comply with the FAIR
principles, ultimately resulting in inefficiency and limited reusability. To
this end, we propose IoDResearch (Internet of Data Research), a private
data-centric Deep Research framework that operationalizes the Internet of Data
paradigm. IoDResearch encapsulates heterogeneous resources as FAIR-compliant
digital objects, and further refines them into atomic knowledge units and
knowledge graphs, forming a heterogeneous graph index for multi-granularity
retrieval. On top of this representation, a multi-agent system supports both
reliable question answering and structured scientific report generation.
Furthermore, we establish the IoD DeepResearch Benchmark to systematically
evaluate both data representation and Deep Research capabilities in IoD
scenarios. Experimental results on retrieval, QA, and report-writing tasks show
that IoDResearch consistently surpasses representative RAG and Deep Research
baselines. Overall, IoDResearch demonstrates the feasibility of
private-data-centric Deep Research under the IoD paradigm, paving the way
toward more trustworthy, reusable, and automated scientific discovery.

</details>


### [6] [Synthetic Prefixes to Mitigate Bias in Real-Time Neural Query Autocomplete](https://arxiv.org/abs/2510.01574)
*Adithya Rajan,Xiaoyu Liu,Prateek Verma,Vibhu Arora*

Main category: cs.IR

TL;DR: 提出一种通过合成前缀来缓解实时神经查询自动补全系统中呈现偏差的数据中心方法，利用非自动补全会话中的完整查询生成前缀，丰富训练数据多样性。


<details>
  <summary>Details</summary>
Motivation: 解决实时查询自动补全系统中由于模型建议影响用户行为而产生的固有参与信号偏差问题。

Method: 从非自动补全会话中收集完整用户查询生成合成前缀，构建包含查询流行度、季节性、模糊匹配分数等丰富特征的神经排序器，并引入计算复杂度从O(n²)降至O(n)的列表损失简化方法。

Result: 在大规模电商环境中部署，通过平均倒数排名等指标显示用户参与度有统计显著提升。

Conclusion: 合成前缀不仅提高了泛化能力，还为其他低延迟排序任务中的偏差缓解提供了可扩展路径。

Abstract: We introduce a data-centric approach for mitigating presentation bias in
real-time neural query autocomplete systems through the use of synthetic
prefixes. These prefixes are generated from complete user queries collected
during regular search sessions where autocomplete was not active. This allows
us to enrich the training data for learning to rank models with more diverse
and less biased examples. This method addresses the inherent bias in engagement
signals collected from live query autocomplete interactions, where model
suggestions influence user behavior. Our neural ranker is optimized for
real-time deployment under strict latency constraints and incorporates a rich
set of features, including query popularity, seasonality, fuzzy match scores,
and contextual signals such as department affinity, device type, and vertical
alignment with previous user queries. To support efficient training, we
introduce a task-specific simplification of the listwise loss, reducing
computational complexity from $O(n^2)$ to $O(n)$ by leveraging the query
autocomplete structure of having only one ground-truth selection per prefix.
Deployed in a large-scale e-commerce setting, our system demonstrates
statistically significant improvements in user engagement, as measured by mean
reciprocal rank and related metrics. Our findings show that synthetic prefixes
not only improve generalization but also provide a scalable path toward bias
mitigation in other low-latency ranking tasks, including related searches and
query recommendations.

</details>


### [7] [Bridging Collaborative Filtering and Large Language Models with Dynamic Alignment, Multimodal Fusion and Evidence-grounded Explanations](https://arxiv.org/abs/2510.01606)
*Bo Ma,LuYao Liu,Simon Lau,Chandler Yuan,and XueY Cui,Rosie Zhang*

Main category: cs.IR

TL;DR: 提出一个名为model的推荐系统框架，通过在线适应机制、多模态统一表示和基于证据的解释系统来解决现有LLM推荐方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐系统存在三个主要问题：使用静态快照无法捕捉快速变化的用户偏好；缺乏对视觉和音频等多模态内容的处理；无法提供可信的基于证据的解释。

Method: 1. 在线适应机制：通过轻量级模块持续整合新用户交互，避免重新训练大模型
2. 统一表示：将协同过滤信号与视觉、音频特征无缝结合，处理模态缺失情况
3. 解释系统：基于具体协同模式和物品属性生成可验证的自然语言理由

Result: 该方法在保持冻结基础模型效率的同时，仅增加最小计算开销，适合实际部署。

Conclusion: 该框架成功解决了LLM推荐系统中的关键挑战，实现了高效、多模态且可解释的推荐。

Abstract: Recent research has explored using Large Language Models for recommendation
tasks by transforming user interaction histories and item metadata into text
prompts, then having the LLM produce rankings or recommendations. A promising
approach involves connecting collaborative filtering knowledge to LLM
representations through compact adapter networks, which avoids expensive
fine-tuning while preserving the strengths of both components. Yet several
challenges persist in practice: collaborative filtering models often use static
snapshots that miss rapidly changing user preferences; many real-world items
contain rich visual and audio content beyond textual descriptions; and current
systems struggle to provide trustworthy explanations backed by concrete
evidence. Our work introduces \model{}, a framework that tackles these
limitations through three key innovations. We develop an online adaptation
mechanism that continuously incorporates new user interactions through
lightweight modules, avoiding the need to retrain large models. We create a
unified representation that seamlessly combines collaborative signals with
visual and audio features, handling cases where some modalities may be
unavailable. Finally, we design an explanation system that grounds
recommendations in specific collaborative patterns and item attributes,
producing natural language rationales users can verify. Our approach maintains
the efficiency of frozen base models while adding minimal computational
overhead, making it practical for real-world deployment.

</details>


### [8] [LLM4Rec: Large Language Models for Multimodal Generative Recommendation with Causal Debiasing](https://arxiv.org/abs/2510.01622)
*Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau*

Main category: cs.IR

TL;DR: 提出增强型生成推荐框架，通过多模态融合、检索增强生成、因果推断去偏、可解释推荐和实时自适应学习五大创新，在准确率、公平性和多样性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决当前生成推荐系统在处理多模态数据、消除算法偏见和提供透明决策过程中的挑战。

Method: 使用大型语言模型作为骨干，结合多模态融合架构、检索增强生成机制、因果推断去偏、可解释推荐生成和实时自适应学习能力。

Result: 在三个基准数据集上实验显示，NDCG@10提升2.3%，多样性指标提升1.4%，同时保持计算效率。

Conclusion: 该框架在推荐准确性、公平性和多样性方面取得显著改进，为生成推荐系统提供了全面解决方案。

Abstract: Contemporary generative recommendation systems face significant challenges in
handling multimodal data, eliminating algorithmic biases, and providing
transparent decision-making processes. This paper introduces an enhanced
generative recommendation framework that addresses these limitations through
five key innovations: multimodal fusion architecture, retrieval-augmented
generation mechanisms, causal inference-based debiasing, explainable
recommendation generation, and real-time adaptive learning capabilities. Our
framework leverages advanced large language models as the backbone while
incorporating specialized modules for cross-modal understanding, contextual
knowledge integration, bias mitigation, explanation synthesis, and continuous
model adaptation. Extensive experiments on three benchmark datasets
(MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistent
improvements in recommendation accuracy, fairness, and diversity compared to
existing approaches. The proposed framework achieves up to 2.3% improvement in
NDCG@10 and 1.4% enhancement in diversity metrics while maintaining
computational efficiency through optimized inference strategies.

</details>


### [9] [TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling](https://arxiv.org/abs/2510.01698)
*Seungheon Doh,Keunwoo Choi,Juhan Nam*

Main category: cs.IR

TL;DR: 提出基于LLM的音乐推荐系统，通过工具调用统一检索-重排序流程，支持多种检索方法组合使用


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐系统功能有限，未能充分利用元数据过滤等关键组件，需要更统一的推荐框架

Method: 使用LLM作为端到端推荐系统，通过工具规划调用布尔过滤、稀疏检索、稠密检索和生成检索等专用组件

Result: 该统一工具调用框架在多样化推荐场景中取得有竞争力的性能，能根据用户查询选择合适检索方法

Conclusion: 为对话式音乐推荐系统开创了新范式，通过灵活组合多种检索方法实现更好的推荐效果

Abstract: While the recent developments in large language models (LLMs) have
successfully enabled generative recommenders with natural language
interactions, their recommendation behavior is limited, leaving other simpler
yet crucial components such as metadata or attribute filtering underutilized in
the system. We propose an LLM-based music recommendation system with tool
calling to serve as a unified retrieval-reranking pipeline. Our system
positions an LLM as an end-to-end recommendation system that interprets user
intent, plans tool invocations, and orchestrates specialized components:
boolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding
similarity), and generative retrieval (semantic IDs). Through tool planning,
the system predicts which types of tools to use, their execution order, and the
arguments needed to find music matching user preferences, supporting diverse
modalities while seamlessly integrating multiple database filtering methods. We
demonstrate that this unified tool-calling framework achieves competitive
performance across diverse recommendation scenarios by selectively employing
appropriate retrieval methods based on user queries, envisioning a new paradigm
for conversational music recommendation systems.

</details>


### [10] [Ranking Items from Discrete Ratings: The Cost of Unknown User Thresholds](https://arxiv.org/abs/2510.01871)
*Oscar Villemaud,Suryanarayana Sankagiri,Matthias Grossglauser*

Main category: cs.IR

TL;DR: 该论文研究了从粗粒度用户评分中恢复细粒度物品排序的问题，证明了实现近乎完美排序需要Θ(n²)用户，远高于基于比较排序的O(n log n)复杂度，揭示了评分阈值多样性带来的排序成本。


<details>
  <summary>Details</summary>
Motivation: 在信息检索和推荐系统中，用户输入通常采用粗粒度离散评分，但系统需要恢复细粒度的物品排序。本文旨在探索从粗粒度评分中恢复细粒度排序的可能性及其复杂性。

Method: 将物品建模为具有分数，用户建模为具有阈值；当物品分数超过用户阈值时获得正面评分。用户按顺序到达，每个新用户可用于细化当前排序，通过分析Spearman距离来衡量排序质量。

Result: 证明实现近乎完美排序需要Θ(n²)用户和Ω(n²)查询，显著高于比较排序的O(n log n)复杂度。这种差距反映了识别适当阈值用户所需的额外查询成本。

Conclusion: 在线排序中存在一个张力：阈值多样性对于将多个用户的粗粒度评分合并为细粒度排序是必要的，但如果阈值事先未知，这种多样性会带来显著的成本。

Abstract: Ranking items is a central task in many information retrieval and recommender
systems. User input for the ranking task often comes in the form of ratings on
a coarse discrete scale. We ask whether it is possible to recover a
fine-grained item ranking from such coarse-grained ratings. We model items as
having scores and users as having thresholds; a user rates an item positively
if the item's score exceeds the user's threshold. Although all users agree on
the total item order, estimating that order is challenging when both the scores
and the thresholds are latent. Under our model, any ranking method naturally
partitions the $n$ items into bins; the bins are ordered, but the items inside
each bin are still unordered. Users arrive sequentially, and every new user can
be queried to refine the current ranking. We prove that achieving a
near-perfect ranking, measured by Spearman distance, requires $\Theta(n^2)$
users (and therefore $\Omega(n^2)$ queries). This is significantly worse than
the $O(n\log n)$ queries needed to rank from comparisons; the gap reflects the
additional queries needed to identify the users who have the appropriate
thresholds. Our bound also quantifies the impact of a mismatch between score
and threshold distributions via a quadratic divergence factor. To show the
tightness of our results, we provide a ranking algorithm whose query complexity
matches our bound up to a logarithmic factor. Our work reveals a tension in
online ranking: diversity in thresholds is necessary to merge coarse ratings
from many users into a fine-grained ranking, but this diversity has a cost if
the thresholds are a priori unknown.

</details>


### [11] [Contrastive Retrieval Heads Improve Attention-Based Re-Ranking](https://arxiv.org/abs/2510.02219)
*Linh Tran,Yulong Li,Radu Florian,Wei Sun*

Main category: cs.IR

TL;DR: 提出CoRe heads方法，通过对比评分指标识别出少量关键注意力头，显著提升LLM重排序性能，同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力的重排序方法中，许多注意力头产生噪声和冗余，限制了性能提升。

Method: 使用对比评分指标识别CoRe heads，奖励与相关文档相关的注意力头，抑制与不相关文档相关的注意力头。

Result: CoRe heads仅占所有头的不到1%，但显著提升重排序准确率，且集中于中间层，可修剪后50%层而不损失精度。

Conclusion: CoRe heads方法实现了最先进的重排序性能，同时大幅降低推理时间和内存使用。

Abstract: The strong zero-shot and long-context capabilities of recent Large Language
Models (LLMs) have paved the way for highly effective re-ranking systems.
Attention-based re-rankers leverage attention weights from transformer heads to
produce relevance scores, but not all heads are created equally: many
contribute noise and redundancy, thus limiting performance. To address this, we
introduce CoRe heads, a small set of retrieval heads identified via a
contrastive scoring metric that explicitly rewards high attention heads that
correlate with relevant documents, while downplaying nodes with higher
attention that correlate with irrelevant documents. This relative ranking
criterion isolates the most discriminative heads for re-ranking and yields a
state-of-the-art list-wise re-ranker. Extensive experiments with three LLMs
show that aggregated signals from CoRe heads, constituting less than 1% of all
heads, substantially improve re-ranking accuracy over strong baselines. We
further find that CoRe heads are concentrated in middle layers, and pruning the
computation of final 50% of model layers preserves accuracy while significantly
reducing inference time and memory usage.

</details>


### [12] [Study on LLMs for Promptagator-Style Dense Retriever Training](https://arxiv.org/abs/2510.02241)
*Daniel Gwon,Nour Jedidi,Jimmy Lin*

Main category: cs.IR

TL;DR: 研究表明，参数规模小至3B的开源LLM可以作为有效的Promptagator式查询生成器，为领域专用密集检索模型的微调提供可行的替代方案。


<details>
  <summary>Details</summary>
Motivation: 原始Promptagator方法依赖专有的大规模LLM，但用户可能无法访问或无法用于敏感数据。本研究旨在探索参数规模≤14B的开源LLM作为替代方案的可行性。

Method: 使用参数规模从3B到14B的开源LLM作为Promptagator式查询生成器，生成用于微调领域专用密集检索模型的合成数据。

Result: 实验结果显示，参数小至3B的开源LLM能够有效生成查询，为领域特定应用的微调提供可靠的数据生成方案。

Conclusion: 开源LLM为合成数据生成提供了可行的替代方案，为领域专用密集检索模型的微调实践提供了实用指导。

Abstract: Promptagator demonstrated that Large Language Models (LLMs) with few-shot
prompts can be used as task-specific query generators for fine-tuning
domain-specialized dense retrieval models. However, the original Promptagator
approach relied on proprietary and large-scale LLMs which users may not have
access to or may be prohibited from using with sensitive data. In this work, we
study the impact of open-source LLMs at accessible scales ($\leq$14B
parameters) as an alternative. Our results demonstrate that open-source LLMs as
small as 3B parameters can serve as effective Promptagator-style query
generators. We hope our work will inform practitioners with reliable
alternatives for synthetic data generation and give insights to maximize
fine-tuning results for domain-specific applications.

</details>
