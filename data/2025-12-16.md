<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [FloodSQL-Bench: A Retrieval-Augmented Benchmark for Geospatially-Grounded Text-to-SQL](https://arxiv.org/abs/2512.12084)
*Hanzhou Liu,Kai Yin,Zhitong Chen,Chenyue Liu,Ali Mostafavi*

Main category: cs.IR

TL;DR: FLOODSQL-BENCH是一个针对洪水管理领域的空间地理基准测试，整合异构数据集，通过键值、空间和混合连接，评估LLM在复杂领域特定Text-to-SQL任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL基准主要关注单表查询或通用领域的有限连接，无法反映领域特定、多表和空间推理的复杂性，特别是在洪水管理等高风险应用领域。

Method: 引入FLOODSQL-BENCH基准，整合社会、基础设施和灾害数据层，通过键值、空间和混合连接异构数据集，系统评估大型语言模型在检索增强生成设置下的性能。

Result: 建立了一个基于真实世界灾害管理数据的统一开放基准，为高风险应用领域的Text-to-SQL研究提供了实用的测试平台。

Conclusion: FLOODSQL-BENCH填补了现有基准在领域特定、多表和空间推理方面的空白，为推进高风险应用领域的Text-to-SQL研究提供了重要工具。

Abstract: Existing Text-to-SQL benchmarks primarily focus on single-table queries or limited joins in general-purpose domains, and thus fail to reflect the complexity of domain-specific, multi-table and geospatial reasoning, To address this limitation, we introduce FLOODSQL-BENCH, a geospatially grounded benchmark for the flood management domain that integrates heterogeneous datasets through key-based, spatial, and hybrid joins. The benchmark captures realistic flood-related information needs by combining social, infrastructural, and hazard data layers. We systematically evaluate recent large language models with the same retrieval-augmented generation settings and measure their performance across difficulty tiers. By providing a unified, open benchmark grounded in real-world disaster management data, FLOODSQL-BENCH establishes a practical testbed for advancing Text-to-SQL research in high-stakes application domains.

</details>


### [2] [Breaking the Curse of Dimensionality: On the Stability of Modern Vector Retrieval](https://arxiv.org/abs/2512.12458)
*Vihan Lakshman,Blaise Munyampirwa,Julian Shun,Benjamin Coleman*

Main category: cs.IR

TL;DR: 论文重新审视高维向量检索中的维度诅咒问题，通过稳定性理论分析三种实际检索场景，为模型和系统设计提供理论指导。


<details>
  <summary>Details</summary>
Motivation: 现代向量数据库支持高维神经嵌入的高效检索，但经典理论预测此类任务会遭受维度诅咒，导致点间距离难以区分，从而影响最近邻搜索效率。本文旨在重新审视这一悖论。

Method: 通过稳定性理论视角，将稳定性分析扩展到三种关键检索场景：多向量搜索（分析Chamfer距离和平均池化）、过滤向量搜索（研究惩罚机制的影响）、稀疏向量搜索（形式化稳定性条件）。

Result: 理论分析表明：1) 多向量搜索中，Chamfer距离保持单向量稳定性，而平均池化可能破坏稳定性；2) 过滤向量搜索中，足够大的不匹配惩罚可以诱导稳定性；3) 稀疏向量搜索中，提出了新的充分稳定性条件。实验验证了理论预测。

Conclusion: 通过稳定性理论分析，为实际向量检索系统设计提供了具体指导，帮助避免维度诅咒问题，确保检索性能的鲁棒性。

Abstract: Modern vector databases enable efficient retrieval over high-dimensional neural embeddings, powering applications from web search to retrieval-augmented generation. However, classical theory predicts such tasks should suffer from the curse of dimensionality, where distances between points become nearly indistinguishable, thereby crippling efficient nearest-neighbor search. We revisit this paradox through the lens of stability, the property that small perturbations to a query do not radically alter its nearest neighbors. Building on foundational results, we extend stability theory to three key retrieval settings widely used in practice: (i) multi-vector search, where we prove that the popular Chamfer distance metric preserves single-vector stability, while average pooling aggregation may destroy it; (ii) filtered vector search, where we show that sufficiently large penalties for mismatched filters can induce stability even when the underlying search is unstable; and (iii) sparse vector search, where we formalize and prove novel sufficient stability conditions. Across synthetic and real datasets, our experimental results match our theoretical predictions, offering concrete guidance for model and system design to avoid the curse of dimensionality.

</details>


### [3] [FuXi-$γ$: Efficient Sequential Recommendation with Exponential-Power Temporal Encoder and Diagonal-Sparse Positional Mechanism](https://arxiv.org/abs/2512.12740)
*Dezhi Yi,Wei Guo,Wenyang Cui,Wenxuan He,Huifeng Guo,Yong Liu,Zhenhua Dong,Ye Lu*

Main category: cs.IR

TL;DR: FuXi-γ是一个高效的序列推荐框架，采用解码器Transformer结构，通过指数幂时间编码器和对角稀疏位置机制，在提升推荐质量的同时显著加速训练和推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的序列推荐方法存在计算开销高的问题，主要原因是时间编码中的不连续内存访问和长序列上的密集注意力机制。

Method: 采用解码器Transformer结构，引入两个关键创新：1) 基于艾宾浩斯遗忘曲线的指数幂时间编码器，使用可调指数衰减函数编码相对时间间隔；2) 对角稀疏位置机制，利用Toeplitz矩阵的对称性通过对角滑动策略修剪低贡献注意力块。

Result: 在四个真实世界数据集上的实验表明，FuXi-γ在推荐质量上达到最先进水平，同时训练加速高达4.74倍，推理加速高达6.18倍。

Conclusion: FuXi-γ通过原则性的架构设计，在提升推荐效果的同时显著提高效率，为长序列推荐提供了一个实用且可扩展的解决方案。

Abstract: Sequential recommendation aims to model users' evolving preferences based on their historical interactions. Recent advances leverage Transformer-based architectures to capture global dependencies, but existing methods often suffer from high computational overhead, primarily due to discontinuous memory access in temporal encoding and dense attention over long sequences. To address these limitations, we propose FuXi-$γ$, a novel sequential recommendation framework that improves both effectiveness and efficiency through principled architectural design. FuXi-$γ$ adopts a decoder-only Transformer structure and introduces two key innovations: (1) An exponential-power temporal encoder that encodes relative temporal intervals using a tunable exponential decay function inspired by the Ebbinghaus forgetting curve. This encoder enables flexible modeling of both short-term and long-term preferences while maintaining high efficiency through continuous memory access and pure matrix operations. (2) A diagonal-sparse positional mechanism that prunes low-contribution attention blocks using a diagonal-sliding strategy guided by the persymmetry of Toeplitz matrix. Extensive experiments on four real-world datasets demonstrate that FuXi-$γ$ achieves state-of-the-art performance in recommendation quality, while accelerating training by up to 4.74$\times$ and inference by up to 6.18$\times$, making it a practical and scalable solution for long-sequence recommendation. Our code is available at https://github.com/Yeedzhi/FuXi-gamma.

</details>


### [4] [Intelligent Scientific Literature Explorer using Machine Learning (ISLE)](https://arxiv.org/abs/2512.12760)
*Sina Jani,Arman Heidari,Amirmohammad Anvari,Zahra Rahimi*

Main category: cs.IR

TL;DR: 提出一个整合检索、主题建模和知识图谱的AI驱动科学文献探索系统，融合arXiv全文和OpenAlex元数据，提升文献发现与理解能力。


<details>
  <summary>Details</summary>
Motivation: 科学出版加速导致研究者难以发现、定位和解释相关文献。传统关键词搜索语义理解有限，现有AI工具仅关注检索、聚类或可视化等孤立任务，缺乏整合方案。

Method: 1) 整合arXiv全文和OpenAlex元数据构建综合语料库；2) 融合BM25词法搜索和嵌入语义搜索的混合检索架构；3) 使用BERTopic或非负矩阵分解进行主题建模；4) 构建统一论文、作者、机构、国家和主题的异质知识图谱。

Result: 系统在多个查询评估中显示出检索相关性、主题连贯性和可解释性的改进，提供多层探索环境，揭示查询相关的概念和关系图谱。

Conclusion: 该框架为AI辅助科学发现提供了可扩展的基础，通过整合多种AI技术，实现了更全面、语义丰富的科学文献探索。

Abstract: The rapid acceleration of scientific publishing has created substantial challenges for researchers attempting to discover, contextualize, and interpret relevant literature. Traditional keyword-based search systems provide limited semantic understanding, while existing AI-driven tools typically focus on isolated tasks such as retrieval, clustering, or bibliometric visualization. This paper presents an integrated system for scientific literature exploration that combines large-scale data acquisition, hybrid retrieval, semantic topic modeling, and heterogeneous knowledge graph construction. The system builds a comprehensive corpus by merging full-text data from arXiv with structured metadata from OpenAlex. A hybrid retrieval architecture fuses BM25 lexical search with embedding-based semantic search using Reciprocal Rank Fusion. Topic modeling is performed on retrieved results using BERTopic or non-negative matrix factorization depending on computational resources. A knowledge graph unifies papers, authors, institutions, countries, and extracted topics into an interpretable structure. The system provides a multi-layered exploration environment that reveals not only relevant publications but also the conceptual and relational landscape surrounding a query. Evaluation across multiple queries demonstrates improvements in retrieval relevance, topic coherence, and interpretability. The proposed framework contributes an extensible foundation for AI-assisted scientific discovery.

</details>


### [5] [SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems](https://arxiv.org/abs/2512.12938)
*Duy A. Nguyen,Hai H. Do,Minh Doan,Minh N. Do*

Main category: cs.IR

TL;DR: SPAR是一个用于企业遗留文件系统的会话式自适应检索框架，采用轻量级两阶段方法替代传统RAG的完整向量数据库，降低计算开销并提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 企业历史数据大多存储在缺乏结构化组织和语义索引的大型遗留文件系统中，导致检索和分析效率低下且容易出错，需要更高效的解决方案。

Method: SPAR框架将LLM集成到RAG架构中，采用轻量级两阶段流程：首先创建语义元数据索引，然后按需动态生成会话特定的向量数据库，替代传统RAG的完整向量数据库构建。

Result: 理论复杂度分析显示SPAR相比标准LLM-based RAG具有计算优势；在合成企业级生物医学文献文件系统上的验证表明，SPAR在检索效果和下游模型准确性方面均有提升。

Conclusion: SPAR为企业遗留环境提供了一种高效、可控的检索解决方案，但部署到不同企业环境仍面临设计权衡和开放挑战。

Abstract: The ability to extract value from historical data is essential for enterprise decision-making. However, much of this information remains inaccessible within large legacy file systems that lack structured organization and semantic indexing, making retrieval and analysis inefficient and error-prone. We introduce SPAR (Session-based Pipeline for Adaptive Retrieval), a conceptual framework that integrates Large Language Models (LLMs) into a Retrieval-Augmented Generation (RAG) architecture specifically designed for legacy enterprise environments. Unlike conventional RAG pipelines, which require costly construction and maintenance of full-scale vector databases that mirror the entire file system, SPAR employs a lightweight two-stage process: a semantic Metadata Index is first created, after which session-specific vector databases are dynamically generated on demand. This design reduces computational overhead while improving transparency, controllability, and relevance in retrieval. We provide a theoretical complexity analysis comparing SPAR with standard LLM-based RAG pipelines, demonstrating its computational advantages. To validate the framework, we apply SPAR to a synthesized enterprise-scale file system containing a large corpus of biomedical literature, showing improvements in both retrieval effectiveness and downstream model accuracy. Finally, we discuss design trade-offs and outline open challenges for deploying SPAR across diverse enterprise settings.

</details>


### [6] [BLADE: A Behavior-Level Data Augmentation Framework with Dual Fusion Modeling for Multi-Behavior Sequential Recommendation](https://arxiv.org/abs/2512.12964)
*Yupeng Li,Mingyue Cheng,Yucong Luo,Yitong Zhou,Qingyang Mao,Shijin Wang*

Main category: cs.IR

TL;DR: BLADE框架通过双项目-行为融合架构处理行为异质性，并通过行为级数据增强缓解数据稀疏问题，提升多行为序列推荐性能


<details>
  <summary>Details</summary>
Motivation: 多行为序列推荐面临两个基本挑战：用户行为的异质性和数据稀疏性，导致推荐性能不理想

Method: 提出BLADE框架：1) 双项目-行为融合架构，在输入层和中间层融入行为信息；2) 三种行为级数据增强方法，直接在行为序列上操作；3) 通过对比学习增强表示学习和泛化能力

Result: 在三个真实世界数据集上的实验证明了该方法的有效性

Conclusion: BLADE框架能够有效处理多行为序列推荐中的行为异质性和数据稀疏问题，提升推荐性能

Abstract: Multi-behavior sequential recommendation aims to capture users' dynamic interests by modeling diverse types of user interactions over time. Although several studies have explored this setting, the recommendation performance remains suboptimal, mainly due to two fundamental challenges: the heterogeneity of user behaviors and data sparsity. To address these challenges, we propose BLADE, a framework that enhances multi-behavior modeling while mitigating data sparsity. Specifically, to handle behavior heterogeneity, we introduce a dual item-behavior fusion architecture that incorporates behavior information at both the input and intermediate levels, enabling preference modeling from multiple perspectives. To mitigate data sparsity, we design three behavior-level data augmentation methods that operate directly on behavior sequences rather than core item sequences. These methods generate diverse augmented views while preserving the semantic consistency of item sequences. These augmented views further enhance representation learning and generalization via contrastive learning. Experiments on three real-world datasets demonstrate the effectiveness of our approach.

</details>


### [7] [Do Reviews Matter for Recommendations in the Era of Large Language Models?](https://arxiv.org/abs/2512.12978)
*Chee Heng Tan,Huiying Zheng,Jing Wang,Zhuoyi Lin,Shaodi Feng,Huijing Zhan,Xiaoli Li,J. Senthilnath*

Main category: cs.IR

TL;DR: LLMs在推荐系统中能有效替代传统用户评论，尤其在数据稀疏和冷启动场景表现更优，部分或全部移除文本评论不一定降低推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的出现，推荐系统面临变革。传统上用户评论是提升推荐质量的重要上下文信息源，但LLMs具有强大的文本理解和生成能力，这引发了一个问题：在LLM时代，显式的用户评论是否仍然必要？

Method: 在8个公开数据集上对LLMs进行广泛实验，评估其在零样本、少样本和微调场景下的性能。引入RAREval基准评估框架，全面评估文本评论对推荐系统性能的贡献，包括：移除部分或全部文本评论、随机扭曲、数据稀疏和冷启动用户设置等场景。

Result: LLMs能够作为有效的评论感知推荐引擎，通常优于传统深度学习方法，特别是在数据稀疏和冷启动条件下。此外，移除部分或全部文本评论以及随机扭曲不一定导致推荐准确性下降。

Conclusion: 研究发现促使重新思考如何更有效地利用文本评论中的用户偏好。LLMs在推荐系统中展现出替代传统用户评论的潜力，特别是在资源受限场景下。

Abstract: With the advent of large language models (LLMs), the landscape of recommender systems is undergoing a significant transformation. Traditionally, user reviews have served as a critical source of rich, contextual information for enhancing recommendation quality. However, as LLMs demonstrate an unprecedented ability to understand and generate human-like text, this raises the question of whether explicit user reviews remain essential in the era of LLMs. In this paper, we provide a systematic investigation of the evolving role of text reviews in recommendation by comparing deep learning methods and LLM approaches. Particularly, we conduct extensive experiments on eight public datasets with LLMs and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We further introduce a benchmarking evaluation framework for review-aware recommender systems, RAREval, to comprehensively assess the contribution of textual reviews to the recommendation performance of review-aware recommender systems. Our framework examines various scenarios, including the removal of some or all textual reviews, random distortion, as well as recommendation performance in data sparsity and cold-start user settings. Our findings demonstrate that LLMs are capable of functioning as effective review-aware recommendation engines, generally outperforming traditional deep learning approaches, particularly in scenarios characterized by data sparsity and cold-start conditions. In addition, the removal of some or all textual reviews and random distortion does not necessarily lead to declines in recommendation accuracy. These findings motivate a rethinking of how user preference from text reviews can be more effectively leveraged. All code and supplementary materials are available at: https://github.com/zhytk/RAREval-data-processing.

</details>


### [8] [Reveal Hidden Pitfalls and Navigate Next Generation of Vector Similarity Search from Task-Centric Views](https://arxiv.org/abs/2512.12980)
*Tingyang Chen,Cong Fu,Jiahua Wu,Haotian Wu,Hua Fan,Xiangyu Ke,Yunjun Gao,Yabo Ni,Anxiang Zeng*

Main category: cs.IR

TL;DR: Iceberg是一个用于高维向量相似性搜索的端到端基准测试套件，关注实际应用效果而非仅召回率-延迟权衡，揭示了传统评估与下游任务性能的显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有向量相似性搜索基准主要评估召回率-延迟权衡，仅基于距离度量定义真实值，忽视了检索质量对下游任务的实际影响，这可能导致学术研究和工业实践的误导。

Method: 提出Iceberg基准套件，从任务中心视角识别信息损失漏斗的三个主要来源：嵌入损失、度量误用和数据分布敏感性。涵盖8个多样化数据集（1M-100M向量），包含丰富的任务特定标签和评估指标，对13种最先进的VSS方法进行基准测试。

Result: 基于应用级指标的重新排名与传统基于召回率-延迟的排名存在显著偏差。定义了任务中心元特征并推导出可解释的决策树，为从业者根据特定工作负载选择和调优VSS方法提供指导。

Conclusion: Iceberg提供了向量相似性搜索的端到端评估框架，揭示了传统评估与实际应用性能之间的差距，并为实际应用中的方法选择和调优提供了实用指导。

Abstract: Vector Similarity Search (VSS) in high-dimensional spaces is rapidly emerging as core functionality in next-generation database systems for numerous data-intensive services -- from embedding lookups in large language models (LLMs), to semantic information retrieval and recommendation engines. Current benchmarks, however, evaluate VSS primarily on the recall-latency trade-off against a ground truth defined solely by distance metrics, neglecting how retrieval quality ultimately impacts downstream tasks. This disconnect can mislead both academic research and industrial practice.
  We present Iceberg, a holistic benchmark suite for end-to-end evaluation of VSS methods in realistic application contexts. From a task-centric view, Iceberg uncovers the Information Loss Funnel, which identifies three principal sources of end-to-end performance degradation: (1) Embedding Loss during feature extraction; (2) Metric Misuse, where distances poorly reflect task relevance; (3) Data Distribution Sensitivity, highlighting index robustness across skews and modalities. For a more comprehensive assessment, Iceberg spans eight diverse datasets across key domains such as image classification, face recognition, text retrieval, and recommendation systems. Each dataset, ranging from 1M to 100M vectors, includes rich, task-specific labels and evaluation metrics, enabling assessment of retrieval algorithms within the full application pipeline rather than in isolation. Iceberg benchmarks 13 state-of-the-art VSS methods and re-ranks them based on application-level metrics, revealing substantial deviations from traditional rankings derived purely from recall-latency evaluations. Building on these insights, we define a set of task-centric meta-features and derive an interpretable decision tree to guide practitioners in selecting and tuning VSS methods for their specific workloads.

</details>


### [9] [Are Large Language Models Really Effective for Training-Free Cold-Start Recommendation?](https://arxiv.org/abs/2512.13001)
*Genki Kusano,Kenya Abe,Kunihiro Takeoka*

Main category: cs.IR

TL;DR: 该研究首次在相同条件下系统比较了LLM和TEM在训练免费推荐中的表现，发现TEM方法在冷启动和热启动场景下均优于LLM重排序器，挑战了LLM直接排序是唯一可行方案的普遍认知。


<details>
  <summary>Details</summary>
Motivation: 现实推荐系统常面临无训练数据的冷启动问题（如新服务上线或全新用户），传统方法无法应用。虽然LLM被探索为有前景的解决方案，但文本嵌入模型（TEM）能力提升后也适用于训练免费推荐，但此前没有研究在相同条件下直接比较这两种方法。

Method: 首次在相同设置下进行受控实验，系统评估LLM和TEM两种方法在训练免费推荐中的表现，特别关注训练免费冷启动推荐（TFCSR）这一更具挑战性的场景。

Result: 实验结果显示TEM方法优于LLM重排序器，这一趋势不仅在冷启动设置中成立，在具有丰富交互的热启动设置中也同样成立。

Conclusion: 直接LLM排序并非唯一可行选项，TEM方法为训练免费推荐提供了更强且更具扩展性的基础，挑战了当前普遍认知。

Abstract: Recommender systems usually rely on large-scale interaction data to learn from users' past behaviors and make accurate predictions. However, real-world applications often face situations where no training data is available, such as when launching new services or handling entirely new users. In such cases, conventional approaches cannot be applied. This study focuses on training-free recommendation, where no task-specific training is performed, and particularly on \textit{training-free cold-start recommendation} (TFCSR), the more challenging case where the target user has no interactions. Large language models (LLMs) have recently been explored as a promising solution, and numerous studies have been proposed. As the ability of text embedding models (TEMs) increases, they are increasingly recognized as applicable to training-free recommendation, but no prior work has directly compared LLMs and TEMs under identical conditions. We present the first controlled experiments that systematically evaluate these two approaches in the same setting. The results show that TEMs outperform LLM rerankers, and this trend holds not only in cold-start settings but also in warm-start settings with rich interactions. These findings indicate that direct LLM ranking is not the only viable option, contrary to the commonly shared belief, and TEM-based approaches provide a stronger and more scalable basis for training-free recommendation.

</details>


### [10] [Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer](https://arxiv.org/abs/2512.13037)
*Taoran Sheng,Sathappan Muthiah,Atiq Islam,Jinming Feng*

Main category: cs.IR

TL;DR: 该研究提出了一种基于上下文的自适应电商搜索框架，通过从简单启发式特征到先进序列模型的渐进式改进，显著提升了搜索结果与买家当前意图的匹配度。


<details>
  <summary>Details</summary>
Motivation: 电商搜索面临的主要挑战是如何在买家购物旅程中（从浏览到购买决策，或意图转换时）动态调整搜索结果以匹配其即时需求和偏好。

Method: 采用系统性渐进方法：从基础方法开始，逐步融入更多上下文信息和最先进技术，构建演化上下文框架，应用于搜索结果页面的商品排序。

Result: 从简单启发式自回归特征到先进序列模型的渐进增强显著提升了排序器性能，上下文技术的集成改善了生产排序器效果，在离线和在线A/B测试中均提高了平均倒数排名(MRR)。

Conclusion: 研究展示了迭代方法在电商平台搜索结果上下文化方面的重要贡献，证明了渐进式上下文框架能有效提升搜索结果与买家兴趣和当前搜索意图的匹配度。

Abstract: In e-commerce shopping, aligning search results with a buyer's immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer's shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer's interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.

</details>


### [11] [A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval](https://arxiv.org/abs/2512.13074)
*Huimu Wang,Yiming Qiu,Xingzhi Yao,Zhiguo Chen,Guoyu Tang,Songlin Wang,Sulong Xu,Mingming Li*

Main category: cs.IR

TL;DR: 本文提出SCI框架解决稠密检索中双塔架构带来的表示空间不对齐和检索索引不一致问题，通过对称表示对齐和双塔协同一致索引两个模块，提升匹配精度和检索稳定性。


<details>
  <summary>Details</summary>
Motivation: 稠密检索已成为大规模信息检索系统的行业标准，但其广泛采用的双塔编码架构存在表示空间不对齐和检索索引不一致的固有挑战，这会降低匹配精度、检索稳定性以及对长尾查询的性能，这些问题在语义ID生成中进一步放大，限制了下游生成模型的性能上限。

Method: 提出SCI框架，包含两个协同模块：1) 对称表示对齐模块：采用创新的输入交换机制统一双塔表示空间，无需增加参数；2) 双塔协同一致索引模块：通过双视图索引策略重新设计检索路径，保持从训练到推理的一致性。该框架系统、轻量、工程友好，支持十亿级部署。

Result: 提供了理论保证，并在公共数据集和真实世界电商数据集上验证了有效性。

Conclusion: SCI框架通过解决双塔架构的固有挑战，提升了稠密检索的性能，特别是在语义ID生成和下游生成模型应用中具有重要价值。

Abstract: Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.
  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.

</details>


### [12] [Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation](https://arxiv.org/abs/2512.13120)
*Mabiao Long,Jiaxi Liu,Yufeng Li,Hao Xiong,Junchi Yan,Kefan Wang,Yi Cao,Jiandong Ding*

Main category: cs.IR

TL;DR: 提出两阶段动态异构图嵌入框架：HetSGFormer用于静态学习，ILLE用于实时增量更新，解决生产环境中的可扩展性、数据新鲜度和冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 在生产环境中部署动态异构图嵌入面临三大挑战：可扩展性（处理十亿级图）、数据新鲜度（实时更新）和冷启动问题（稀疏数据）。需要平衡深度图表示和低延迟增量更新。

Method: 采用两阶段框架：1) HetSGFormer - 可扩展的图变换器，用于静态学习，具有线性可扩展性；2) ILLE - 轻量级CPU增量局部线性嵌入算法，用于实时更新。两者结合避免昂贵的全量重训练。

Result: 在十亿级图上，HetSGFormer相比先前方法提升广告主价值6.11%，ILLE模块额外提升3.22%，嵌入刷新及时性改善83.2%。框架具有冷启动弹性，能从稀疏数据生成有意义的嵌入。

Conclusion: 该工作提供了一个经过验证的生产环境动态图学习框架，成功平衡了深度表示学习和实时更新需求，解决了实际部署中的关键挑战。

Abstract: Deploying dynamic heterogeneous graph embeddings in production faces key challenges of scalability, data freshness, and cold-start. This paper introduces a practical, two-stage solution that balances deep graph representation with low-latency incremental updates. Our framework combines HetSGFormer, a scalable graph transformer for static learning, with Incremental Locally Linear Embedding (ILLE), a lightweight, CPU-based algorithm for real-time updates. HetSGFormer captures global structure with linear scalability, while ILLE provides rapid, targeted updates to incorporate new data, thus avoiding costly full retraining. This dual approach is cold-start resilient, leveraging the graph to create meaningful embeddings from sparse data. On billion-scale graphs, A/B tests show HetSGFormer achieved up to a 6.11% lift in Advertiser Value over previous methods, while the ILLE module added another 3.22% lift and improved embedding refresh timeliness by 83.2%. Our work provides a validated framework for deploying dynamic graph learning in production environments.

</details>


### [13] [Know Your Users! Estimating User Domain Knowledge in Conversational Recommenders](https://arxiv.org/abs/2512.13173)
*Ivica Kostric,Ujwal Gadiraju,Krisztian Balog*

Main category: cs.IR

TL;DR: 提出新任务：从对话中估计用户领域知识，以构建自适应对话推荐系统，并发布首个包含不同知识水平用户对话行为的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前对话推荐系统将所有用户视为专家，导致不熟悉领域的用户交互体验差。需要能根据用户知识水平自适应调整对话策略的系统，但缺乏合适的数据集来研究不同知识水平用户的对话行为。

Method: 设计基于游戏的数据收集协议，激发用户表达不同层次的知识，并发布由此产生的数据集。提出从对话中估计用户领域知识的新任务。

Result: 创建了首个捕捉不同知识水平用户对话行为的数据集，提供了初步分析，展示了该数据集在未来用户知识感知对话推荐系统研究中的潜力。

Conclusion: 通过引入用户领域知识估计任务和发布相应数据集，为构建自适应对话推荐系统迈出了重要一步，解决了现有系统缺乏个性化交互能力的问题。

Abstract: The ideal conversational recommender system (CRS) acts like a savvy salesperson, adapting its language and suggestions to each user's level of expertise. However, most current systems treat all users as experts, leading to frustrating and inefficient interactions when users are unfamiliar with a domain. Systems that can adapt their conversational strategies to a user's knowledge level stand to offer a much more natural and effective experience. To make a step toward such adaptive systems, we introduce a new task: estimating user domain knowledge from conversations, enabling a CRS to better understand user needs and personalize interactions. A key obstacle to developing such adaptive systems is the lack of suitable data; to our knowledge, no existing dataset captures the conversational behaviors of users with varying levels of domain knowledge. Furthermore, in most dialogue collection protocols, users are free to express their own preferences, which tends to concentrate on popular items and well-known features, offering little insight into how novices explore or learn about unfamiliar features. To address this, we design a game-based data collection protocol that elicits varied expressions of knowledge, release the resulting dataset, and provide an initial analysis to highlight its potential for future work on user-knowledge-aware CRS.

</details>


### [14] [BlossomRec: Block-level Fused Sparse Attention Mechanism for Sequential Recommendations](https://arxiv.org/abs/2512.13368)
*Mengyang Ma,Xiaopeng Li,Wanyu Wang,Zhaocheng Du,Jingtong Gao,Pengyue Jia,Yuyang Ye,Yiqi Wang,Yunpeng Weng,Weihong Luo,Xiao Han,Xiangyu Zhao*

Main category: cs.IR

TL;DR: BlossomRec是一种用于序列推荐系统的稀疏注意力机制，通过分离建模长短期用户兴趣来降低计算复杂度，在保持性能的同时显著减少内存使用。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在序列推荐系统中随着用户交互历史增长，计算时间和内存需求急剧增加。现有高效注意力方法和SSM模型在长序列建模效果不佳，在短序列上表现不稳定。

Method: 设计稀疏注意力机制BlossomRec，将用户兴趣分为长期和短期兴趣，分别用两种不同的稀疏注意力模式计算，通过可学习的门控输出结合结果，显著减少参与注意力计算的交互数量。

Result: 在四个公开数据集上的实验表明，BlossomRec与最先进的Transformer模型结合时，在保持相当甚至更好性能的同时，显著减少了内存使用。

Conclusion: BlossomRec通过稀疏注意力机制有效建模不同长度的序列，在效率和效果上都表现出色，为序列推荐系统提供了高效的解决方案。

Abstract: Transformer structures have been widely used in sequential recommender systems (SRS). However, as user interaction histories increase, computational time and memory requirements also grow. This is mainly caused by the standard attention mechanism. Although there exist many methods employing efficient attention and SSM-based models, these approaches struggle to effectively model long sequences and may exhibit unstable performance on short sequences. To address these challenges, we design a sparse attention mechanism, BlossomRec, which models both long-term and short-term user interests through attention computation to achieve stable performance across sequences of varying lengths. Specifically, we categorize user interests in recommendation systems into long-term and short-term interests, and compute them using two distinct sparse attention patterns, with the results combined through a learnable gated output. Theoretically, it significantly reduces the number of interactions participating in attention computation. Extensive experiments on four public datasets demonstrate that BlossomRec, when integrated with state-of-the-art Transformer-based models, achieves comparable or even superior performance while significantly reducing memory usage, providing strong evidence of BlossomRec's efficiency and effectiveness.The code is available at https://github.com/ronineume/BlossomRec.

</details>


### [15] [Automated Information Flow Selection for Multi-scenario Multi-task Recommendation](https://arxiv.org/abs/2512.13396)
*Chaohua Yang,Dugang Liu,Shiwei Li,Yuwen Fu,Xing Tang,Weihong Luo,Xiangyu Zhao,Xiuqiang He,Zhong Ming*

Main category: cs.IR

TL;DR: 提出AutoIFS框架，通过LoRA解耦信息单元和自动信息流选择，解决多场景多任务推荐中架构复杂和信息噪声问题


<details>
  <summary>Details</summary>
Motivation: 现有MSMTR模型存在两个主要问题：1) 依赖复杂架构（如MoE），增加信息融合复杂度、模型大小和训练成本；2) 提取所有信息流而不过滤无关或有害内容，引入噪声

Method: 提出轻量级AutoIFS框架：1) 使用低秩适应（LoRA）解耦四个信息单元，实现灵活高效的信息融合；2) 引入信息流选择网络，基于模型性能反馈自动过滤无效场景-任务信息流，使用剪枝函数消除无用信息流

Result: 在两个公共基准数据集和在线A/B测试中验证了AutoIFS的有效性

Conclusion: AutoIFS通过LoRA解耦和自动信息流选择，解决了MSMTR中的架构复杂性和信息噪声问题，提高了模型性能

Abstract: Multi-scenario multi-task recommendation (MSMTR) systems must address recommendation demands across diverse scenarios while simultaneously optimizing multiple objectives, such as click-through rate and conversion rate. Existing MSMTR models typically consist of four information units: scenario-shared, scenario-specific, task-shared, and task-specific networks. These units interact to generate four types of relationship information flows, directed from scenario-shared or scenario-specific networks to task-shared or task-specific networks. However, these models face two main limitations: 1) They often rely on complex architectures, such as mixture-of-experts (MoE) networks, which increase the complexity of information fusion, model size, and training cost. 2) They extract all available information flows without filtering out irrelevant or even harmful content, introducing potential noise. Regarding these challenges, we propose a lightweight Automated Information Flow Selection (AutoIFS) framework for MSMTR. To tackle the first issue, AutoIFS incorporates low-rank adaptation (LoRA) to decouple the four information units, enabling more flexible and efficient information fusion with minimal parameter overhead. To address the second issue, AutoIFS introduces an information flow selection network that automatically filters out invalid scenario-task information flows based on model performance feedback. It employs a simple yet effective pruning function to eliminate useless information flows, thereby enhancing the impact of key relationships and improving model performance. Finally, we evaluate AutoIFS and confirm its effectiveness through extensive experiments on two public benchmark datasets and an online A/B test.

</details>
