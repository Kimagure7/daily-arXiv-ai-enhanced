{"id": "2512.07846", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07846", "abs": "https://arxiv.org/abs/2512.07846", "authors": ["Guoyao Li", "Ran He", "Shusen Jing", "Kayhan Behdin", "Yubo Wang", "Sundara Raman Ramachandran", "Chanh Nguyen", "Jian Sheng", "Xiaojing Ma", "Chuanrui Zhu", "Sriram Vasudevan", "Muchen Wu", "Sayan Ghosh", "Lin Su", "Qingquan Song", "Xiaoqing Wang", "Zhipeng Wang", "Qing Lan", "Yanning Chen", "Jingwei Wu", "Luke Simon", "Wenjing Zhang", "Qi Guo", "Fedor Borisyuk"], "title": "MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction", "comment": null, "summary": "Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under industrial latency and throughput requirements. In particular, cross-encoder ranking systems often create long context prefill-heavy workloads, as the model has to be presented with the user, query and item information. To this end, we propose MixLM, a novel LLM-based ranking framework, which significantly improves the system throughput via reducing the input context length, while preserving the semantic strength of cross-encoder rankers. In contrast to a standard ranking system where the context is presented to the model as pure text, we propose to use mix-interaction, a mixture of text and embedding tokens to represent the input. Specifically, MixLM encodes all items in the catalog into a few embedding tokens and stores in a nearline cache. The encoded item descriptions are used during online inference, effectively reducing the item length from a few thousand text tokens to a few embedding tokens. We share insights from deploying our MixLM framework to a real-world search application at LinkedIn, including a detailed discussion of our training pipelines, as well as a thorough analysis of our online serving infrastructure optimization. Comparing with strong baselines, MixLM increased throughput by 10.0x under the same latency budget, while maintaining relevance metrics. The efficiency gains delivered by MixLM enabled full-traffic deployment of LLM-powered search, which resulted in a significant 0.47% increase in Daily Active Users (DAU) in online A/B tests.", "AI": {"tldr": "MixLM\u662f\u4e00\u79cd\u65b0\u578bLLM\u6392\u5e8f\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u6587\u672c\u548c\u5d4c\u5165\u4ee4\u724c\u8868\u793a\u8f93\u5165\uff0c\u5c06\u9879\u76ee\u63cf\u8ff0\u4ece\u6570\u5343\u6587\u672c\u4ee4\u724c\u538b\u7f29\u4e3a\u51e0\u4e2a\u5d4c\u5165\u4ee4\u724c\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf10\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5173\u6027\u6307\u6807\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5de5\u4e1a\u7ea7\u5ef6\u8fdf\u548c\u541e\u5410\u8981\u6c42\u4e0b\u8ba1\u7b97\u5f00\u9500\u8fc7\u9ad8\u3002\u7279\u522b\u662f\u4ea4\u53c9\u7f16\u7801\u5668\u6392\u5e8f\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u9884\u586b\u5145\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u56e0\u4e3a\u6a21\u578b\u9700\u8981\u540c\u65f6\u5904\u7406\u7528\u6237\u3001\u67e5\u8be2\u548c\u9879\u76ee\u4fe1\u606f\u3002", "method": "\u63d0\u51faMixLM\u6846\u67b6\uff0c\u4f7f\u7528\u6df7\u5408\u4ea4\u4e92\uff08\u6587\u672c\u548c\u5d4c\u5165\u4ee4\u724c\u7684\u6df7\u5408\uff09\u8868\u793a\u8f93\u5165\u3002\u5c06\u6240\u6709\u76ee\u5f55\u9879\u76ee\u7f16\u7801\u4e3a\u5c11\u91cf\u5d4c\u5165\u4ee4\u724c\u5e76\u5b58\u50a8\u5728\u8fd1\u7ebf\u7f13\u5b58\u4e2d\uff0c\u5728\u7ebf\u63a8\u7406\u65f6\u4f7f\u7528\u7f16\u7801\u540e\u7684\u9879\u76ee\u63cf\u8ff0\uff0c\u4ece\u800c\u5c06\u9879\u76ee\u957f\u5ea6\u4ece\u6570\u5343\u6587\u672c\u4ee4\u724c\u51cf\u5c11\u5230\u51e0\u4e2a\u5d4c\u5165\u4ee4\u724c\u3002", "result": "\u5728\u76f8\u540c\u5ef6\u8fdf\u9884\u7b97\u4e0b\uff0cMixLM\u5c06\u541e\u5410\u91cf\u63d0\u9ad8\u4e8610.0\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5173\u6027\u6307\u6807\u3002\u6548\u7387\u63d0\u5347\u4f7f\u5f97LLM\u9a71\u52a8\u7684\u641c\u7d22\u80fd\u591f\u5168\u6d41\u91cf\u90e8\u7f72\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u6bcf\u65e5\u6d3b\u8dc3\u7528\u6237\u663e\u8457\u589e\u52a00.47%\u3002", "conclusion": "MixLM\u901a\u8fc7\u521b\u65b0\u7684\u6df7\u5408\u4ee4\u724c\u8868\u793a\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301LLM\u8bed\u4e49\u4f18\u52bf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u641c\u7d22\u5e94\u7528\u4e2d\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08073", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08073", "abs": "https://arxiv.org/abs/2512.08073", "authors": ["Jianping Zhang", "Han Qin", "Nathaniel Huber-Fliflet"], "title": "Detecting Privileged Documents by Ranking Connected Network Entities", "comment": null, "summary": "This paper presents a link analysis approach for identifying privileged documents by constructing a network of human entities derived from email header metadata. Entities are classified as either counsel or non-counsel based on a predefined list of known legal professionals. The core assumption is that individuals with frequent interactions with lawyers are more likely to participate in privileged communications. To quantify this likelihood, an algorithm assigns a score to each entity within the network. By utilizing both entity scores and the strength of their connections, the method enhances the identification of privileged documents. Experimental results demonstrate the algorithm's effectiveness in ranking legal entities for privileged document detection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u94fe\u63a5\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u7535\u5b50\u90ae\u4ef6\u5934\u5143\u6570\u636e\u6784\u5efa\u4eba\u9645\u5173\u7cfb\u7f51\u7edc\u6765\u8bc6\u522b\u7279\u6743\u6587\u6863\uff0c\u5229\u7528\u5b9e\u4f53\u4e0e\u5f8b\u5e08\u7684\u4e92\u52a8\u9891\u7387\u6765\u91cf\u5316\u7279\u6743\u901a\u4fe1\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5728\u7535\u5b50\u53d1\u73b0\uff08e-discovery\uff09\u548c\u6cd5\u5f8b\u5ba1\u67e5\u8fc7\u7a0b\u4e2d\uff0c\u8bc6\u522b\u7279\u6743\u6587\u6863\uff08\u5982\u5f8b\u5e08-\u5ba2\u6237\u7279\u6743\u901a\u4fe1\uff09\u662f\u4e00\u9879\u91cd\u8981\u4f46\u8017\u65f6\u7684\u4efb\u52a1\u3002\u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5173\u952e\u8bcd\u641c\u7d22\u6216\u624b\u52a8\u5ba1\u67e5\uff0c\u6548\u7387\u8f83\u4f4e\u4e14\u5bb9\u6613\u9057\u6f0f\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u8bc6\u522b\u53ef\u80fd\u5305\u542b\u7279\u6743\u901a\u4fe1\u7684\u6587\u6863\u3002", "method": "1. \u4ece\u7535\u5b50\u90ae\u4ef6\u5934\u5143\u6570\u636e\u4e2d\u63d0\u53d6\u4eba\u7c7b\u5b9e\u4f53\u5e76\u6784\u5efa\u7f51\u7edc\uff1b2. \u57fa\u4e8e\u5df2\u77e5\u6cd5\u5f8b\u4e13\u4e1a\u4eba\u58eb\u5217\u8868\u5c06\u5b9e\u4f53\u5206\u7c7b\u4e3a\u5f8b\u5e08\u6216\u975e\u5f8b\u5e08\uff1b3. \u6838\u5fc3\u5047\u8bbe\uff1a\u4e0e\u5f8b\u5e08\u9891\u7e41\u4e92\u52a8\u7684\u4e2a\u4eba\u66f4\u53ef\u80fd\u53c2\u4e0e\u7279\u6743\u901a\u4fe1\uff1b4. \u5f00\u53d1\u7b97\u6cd5\u4e3a\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e2a\u5b9e\u4f53\u5206\u914d\u5206\u6570\uff0c\u91cf\u5316\u5176\u53c2\u4e0e\u7279\u6743\u901a\u4fe1\u7684\u53ef\u80fd\u6027\uff1b5. \u7ed3\u5408\u5b9e\u4f53\u5206\u6570\u548c\u8fde\u63a5\u5f3a\u5ea6\u6765\u589e\u5f3a\u7279\u6743\u6587\u6863\u8bc6\u522b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u7279\u6743\u6587\u6863\u68c0\u6d4b\u4e2d\u80fd\u591f\u6709\u6548\u5bf9\u6cd5\u5f8b\u5b9e\u4f53\u8fdb\u884c\u6392\u540d\u3002\u901a\u8fc7\u5229\u7528\u5b9e\u4f53\u95f4\u7684\u7f51\u7edc\u5173\u7cfb\u548c\u4e92\u52a8\u6a21\u5f0f\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8bc6\u522b\u7279\u6743\u6587\u6863\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u57fa\u4e8e\u94fe\u63a5\u5206\u6790\u7684\u65b9\u6cd5\u4e3a\u7279\u6743\u6587\u6863\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5206\u6790\u4eba\u9645\u5173\u7cfb\u7f51\u7edc\u548c\u4e92\u52a8\u6a21\u5f0f\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u5b9e\u4f53\u53c2\u4e0e\u7279\u6743\u901a\u4fe1\u7684\u53ef\u80fd\u6027\uff0c\u4ece\u800c\u8f85\u52a9\u6cd5\u5f8b\u5ba1\u67e5\u8fc7\u7a0b\uff0c\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u63d0\u9ad8\u8bc6\u522b\u51c6\u786e\u6027\u3002"}}
{"id": "2512.08078", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08078", "abs": "https://arxiv.org/abs/2512.08078", "authors": ["Qiang Mao", "Han Qin", "Robert Neary", "Charles Wang", "Fusheng Wei", "Jianping Zhang", "Nathaniel Huber-Fliflet"], "title": "A Comparative Study of Retrieval Methods in Azure AI Search", "comment": null, "summary": "Increasingly, attorneys are interested in moving beyond keyword and semantic search to improve the efficiency of how they find key information during a document review task. Large language models (LLMs) are now seen as tools that attorneys can use to ask natural language questions of their data during document review to receive accurate and concise answers. This study evaluates retrieval strategies within Microsoft Azure's Retrieval-Augmented Generation (RAG) framework to identify effective approaches for Early Case Assessment (ECA) in eDiscovery. During ECA, legal teams analyze data at the outset of a matter to gain a general understanding of the data and attempt to determine key facts and risks before beginning full-scale review. In this paper, we compare the performance of Azure AI Search's keyword, semantic, vector, hybrid, and hybrid-semantic retrieval methods. We then present the accuracy, relevance, and consistency of each method's AI-generated responses. Legal practitioners can use the results of this study to enhance how they select RAG configurations in the future.", "AI": {"tldr": "\u8bc4\u4f30Azure AI Search\u4e2d\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\uff08\u5173\u952e\u8bcd\u3001\u8bed\u4e49\u3001\u5411\u91cf\u3001\u6df7\u5408\u3001\u6df7\u5408\u8bed\u4e49\uff09\u5728\u7535\u5b50\u53d6\u8bc1\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u6cd5\u5f8b\u4ece\u4e1a\u8005\u9009\u62e9RAG\u914d\u7f6e\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5f8b\u5e08\u9700\u8981\u8d85\u8d8a\u4f20\u7edf\u5173\u952e\u8bcd\u548c\u8bed\u4e49\u641c\u7d22\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4ee5\u63d0\u9ad8\u6587\u6863\u5ba1\u67e5\u6548\u7387\u3002\u7279\u522b\u662f\u5728\u7535\u5b50\u53d6\u8bc1\u7684\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u9636\u6bb5\uff0c\u9700\u8981\u5feb\u901f\u7406\u89e3\u6570\u636e\u3001\u8bc6\u522b\u5173\u952e\u4e8b\u5b9e\u548c\u98ce\u9669\u3002", "method": "\u5728\u5fae\u8f6fAzure\u7684RAG\u6846\u67b6\u4e2d\uff0c\u6bd4\u8f83Azure AI Search\u7684\u4e94\u79cd\u68c0\u7d22\u65b9\u6cd5\uff1a\u5173\u952e\u8bcd\u68c0\u7d22\u3001\u8bed\u4e49\u68c0\u7d22\u3001\u5411\u91cf\u68c0\u7d22\u3001\u6df7\u5408\u68c0\u7d22\u548c\u6df7\u5408\u8bed\u4e49\u68c0\u7d22\uff0c\u8bc4\u4f30\u6bcf\u79cd\u65b9\u6cd5\u751f\u6210AI\u56de\u7b54\u7684\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u7684\u6027\u80fd\u6bd4\u8f83\u7ed3\u679c\uff0c\u5e2e\u52a9\u6cd5\u5f8b\u4ece\u4e1a\u8005\u4e86\u89e3\u5404\u79cdRAG\u914d\u7f6e\u7684\u5b9e\u9645\u6548\u679c\u3002", "conclusion": "\u6cd5\u5f8b\u4ece\u4e1a\u8005\u53ef\u4ee5\u5229\u7528\u672c\u7814\u7a76\u7ed3\u679c\u6765\u4f18\u5316\u672a\u6765RAG\u914d\u7f6e\u7684\u9009\u62e9\uff0c\u63d0\u9ad8\u7535\u5b50\u53d6\u8bc1\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2512.08079", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08079", "abs": "https://arxiv.org/abs/2512.08079", "authors": ["Qiang Mao", "Fusheng Wei", "Robert Neary", "Charles Wang", "Han Qin", "Jianping Zhang", "Nathaniel Huber-Fliflet"], "title": "Leveraging Machine Learning and Large Language Models for Automated Image Clustering and Description in Legal Discovery", "comment": null, "summary": "The rapid increase in digital image creation and retention presents substantial challenges during legal discovery, digital archive, and content management. Corporations and legal teams must organize, analyze, and extract meaningful insights from large image collections under strict time pressures, making manual review impractical and costly. These demands have intensified interest in automated methods that can efficiently organize and describe large-scale image datasets. This paper presents a systematic investigation of automated cluster description generation through the integration of image clustering, image captioning, and large language models (LLMs). We apply K-means clustering to group images into 20 visually coherent clusters and generate base captions using the Azure AI Vision API. We then evaluate three critical dimensions of the cluster description process: (1) image sampling strategies, comparing random, centroid-based, stratified, hybrid, and density-based sampling against using all cluster images; (2) prompting techniques, contrasting standard prompting with chain-of-thought prompting; and (3) description generation methods, comparing LLM-based generation with traditional TF-IDF and template-based approaches. We assess description quality using semantic similarity and coverage metrics. Results show that strategic sampling with 20 images per cluster performs comparably to exhaustive inclusion while significantly reducing computational cost, with only stratified sampling showing modest degradation. LLM-based methods consistently outperform TF-IDF baselines, and standard prompts outperform chain-of-thought prompts for this task. These findings provide practical guidance for deploying scalable, accurate cluster description systems that support high-volume workflows in legal discovery and other domains requiring automated organization of large image collections.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u81ea\u52a8\u805a\u7c7b\u63cf\u8ff0\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u56fe\u50cf\u805a\u7c7b\u3001\u56fe\u50cf\u63cf\u8ff0\u548cLLM\uff0c\u8bc4\u4f30\u4e86\u91c7\u6837\u7b56\u7565\u3001\u63d0\u793a\u6280\u672f\u548c\u751f\u6210\u65b9\u6cd5\uff0c\u53d1\u73b020\u5f20\u56fe\u50cf\u7684\u7b56\u7565\u91c7\u6837\u6548\u679c\u63a5\u8fd1\u5168\u91cf\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\uff0cLLM\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edfTF-IDF\u57fa\u7ebf\u3002", "motivation": "\u6570\u5b57\u56fe\u50cf\u6570\u91cf\u7684\u5feb\u901f\u589e\u957f\u7ed9\u6cd5\u5f8b\u53d1\u73b0\u3001\u6570\u5b57\u6863\u6848\u548c\u5185\u5bb9\u7ba1\u7406\u5e26\u6765\u4e86\u5de8\u5927\u6311\u6218\u3002\u4f01\u4e1a\u548c\u6cd5\u5f8b\u56e2\u961f\u9700\u8981\u5728\u4e25\u683c\u65f6\u95f4\u538b\u529b\u4e0b\u7ec4\u7ec7\u548c\u5206\u6790\u5927\u89c4\u6a21\u56fe\u50cf\u96c6\u5408\uff0c\u624b\u52a8\u5ba1\u67e5\u4e0d\u5207\u5b9e\u9645\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u7ec4\u7ec7\u548c\u63cf\u8ff0\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u3002", "method": "\u91c7\u7528K-means\u805a\u7c7b\u5c06\u56fe\u50cf\u5206\u4e3a20\u4e2a\u89c6\u89c9\u8fde\u8d2f\u7684\u7c07\uff0c\u4f7f\u7528Azure AI Vision API\u751f\u6210\u57fa\u7840\u63cf\u8ff0\u3002\u8bc4\u4f30\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff1a(1)\u56fe\u50cf\u91c7\u6837\u7b56\u7565\uff1a\u968f\u673a\u3001\u57fa\u4e8e\u8d28\u5fc3\u3001\u5206\u5c42\u3001\u6df7\u5408\u548c\u57fa\u4e8e\u5bc6\u5ea6\u7684\u91c7\u6837\u4e0e\u4f7f\u7528\u5168\u90e8\u56fe\u50cf\u5bf9\u6bd4\uff1b(2)\u63d0\u793a\u6280\u672f\uff1a\u6807\u51c6\u63d0\u793a\u4e0e\u601d\u7ef4\u94fe\u63d0\u793a\u5bf9\u6bd4\uff1b(3)\u63cf\u8ff0\u751f\u6210\u65b9\u6cd5\uff1aLLM\u65b9\u6cd5\u4e0e\u4f20\u7edf\u7684TF-IDF\u548c\u57fa\u4e8e\u6a21\u677f\u7684\u65b9\u6cd5\u5bf9\u6bd4\u3002\u4f7f\u7528\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u8986\u76d6\u5ea6\u6307\u6807\u8bc4\u4f30\u63cf\u8ff0\u8d28\u91cf\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6bcf\u4e2a\u7c07\u4f7f\u752820\u5f20\u56fe\u50cf\u7684\u6218\u7565\u91c7\u6837\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4e0e\u4f7f\u7528\u5168\u90e8\u56fe\u50cf\u76f8\u5f53\uff0c\u53ea\u6709\u5206\u5c42\u91c7\u6837\u663e\u793a\u51fa\u9002\u5ea6\u7684\u6027\u80fd\u4e0b\u964d\u3002LLM\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8eTF-IDF\u57fa\u7ebf\uff0c\u6807\u51c6\u63d0\u793a\u5728\u6b64\u4efb\u52a1\u4e2d\u4f18\u4e8e\u601d\u7ef4\u94fe\u63d0\u793a\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u90e8\u7f72\u53ef\u6269\u5c55\u3001\u51c6\u786e\u7684\u805a\u7c7b\u63cf\u8ff0\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u652f\u6301\u6cd5\u5f8b\u53d1\u73b0\u548c\u5176\u4ed6\u9700\u8981\u81ea\u52a8\u7ec4\u7ec7\u5927\u89c4\u6a21\u56fe\u50cf\u96c6\u5408\u7684\u9ad8\u5bb9\u91cf\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2512.08083", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08083", "abs": "https://arxiv.org/abs/2512.08083", "authors": ["Keith Huffman", "Jianping Zhang", "Nathaniel Huber-Fliflet", "Fusheng Wei", "Peter Gronvall"], "title": "Exploiting the Randomness of Large Language Models (LLM) in Text Classification Tasks: Locating Privileged Documents in Legal Matters", "comment": null, "summary": "In legal matters, text classification models are most often used to filter through large datasets in search of documents that meet certain pre-selected criteria like relevance to a certain subject matter, such as legally privileged communications and attorney-directed documents. In this context, large language models have demonstrated strong performance. This paper presents an empirical study investigating the role of randomness in LLM-based classification for attorney-client privileged document detection, focusing on four key dimensions: (1) the effectiveness of LLMs in identifying legally privileged documents, (2) the influence of randomness control parameters on classification outputs, (3) their impact on overall classification performance, and (4) a methodology for leveraging randomness to enhance accuracy. Experimental results showed that LLMs can identify privileged documents effectively, randomness control parameters have minimal impact on classification performance, and importantly, our developed methodology for leveraging randomness can have a significant impact on improving accuracy. Notably, this methodology that leverages randomness could also enhance a corporation's confidence in an LLM's output when incorporated into its sanctions-compliance processes. As organizations increasingly rely on LLMs to augment compliance workflows, reducing output variability helps build internal and regulatory confidence in LLM-derived sanctions-screening decisions.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u7814\u7a76LLM\u5728\u6cd5\u5f8b\u7279\u6743\u6587\u4ef6\u68c0\u6d4b\u4e2d\u7684\u968f\u673a\u6027\u4f5c\u7528\uff0c\u53d1\u73b0LLM\u80fd\u6709\u6548\u8bc6\u522b\u7279\u6743\u6587\u4ef6\uff0c\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u6027\u80fd\u5f71\u54cd\u6709\u9650\uff0c\u4f46\u5229\u7528\u968f\u673a\u6027\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u5e76\u589e\u5f3a\u5408\u89c4\u4fe1\u5fc3\u3002", "motivation": "\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u4e2d\uff0cLLM\u5df2\u8868\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\uff0c\u4f46\u968f\u673a\u6027\u5bf9\u5206\u7c7b\u7ed3\u679c\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u7279\u522b\u662f\u5728\u7279\u6743\u6587\u4ef6\u68c0\u6d4b\u7b49\u5173\u952e\u6cd5\u5f8b\u5e94\u7528\u4e2d\uff0c\u7406\u89e3\u5e76\u63a7\u5236\u968f\u673a\u6027\u5bf9\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\u548c\u5408\u89c4\u4fe1\u5fc3\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u4ece\u56db\u4e2a\u7ef4\u5ea6\u5206\u6790LLM\u5728\u7279\u6743\u6587\u4ef6\u68c0\u6d4b\u4e2d\u7684\u968f\u673a\u6027\u4f5c\u7528\uff1a(1) LLM\u8bc6\u522b\u7279\u6743\u6587\u4ef6\u7684\u6709\u6548\u6027\uff1b(2) \u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u8f93\u51fa\u7684\u5f71\u54cd\uff1b(3) \u968f\u673a\u6027\u5bf9\u6574\u4f53\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\uff1b(4) \u5f00\u53d1\u5229\u7528\u968f\u673a\u6027\u63d0\u5347\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1aLLM\u80fd\u6709\u6548\u8bc6\u522b\u7279\u6743\u6587\u4ef6\uff1b\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u6027\u80fd\u5f71\u54cd\u6709\u9650\uff1b\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5f00\u53d1\u7684\u5229\u7528\u968f\u673a\u6027\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\uff1b\u8be5\u65b9\u6cd5\u8fd8\u80fd\u589e\u5f3a\u4f01\u4e1a\u5728\u5236\u88c1\u5408\u89c4\u6d41\u7a0b\u4e2d\u5bf9LLM\u8f93\u51fa\u7684\u4fe1\u5fc3\u3002", "conclusion": "LLM\u5728\u6cd5\u5f8b\u7279\u6743\u6587\u4ef6\u68c0\u6d4b\u4e2d\u8868\u73b0\u6709\u6548\uff0c\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5f71\u54cd\u4e0d\u5927\uff0c\u4f46\u901a\u8fc7\u7279\u5b9a\u65b9\u6cd5\u5229\u7528\u968f\u673a\u6027\u80fd\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u3002\u968f\u7740\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56LLM\u589e\u5f3a\u5408\u89c4\u5de5\u4f5c\u6d41\u7a0b\uff0c\u51cf\u5c11\u8f93\u51fa\u53d8\u5f02\u6027\u6709\u52a9\u4e8e\u5efa\u7acb\u5bf9LLM\u884d\u751f\u5236\u88c1\u7b5b\u67e5\u51b3\u7b56\u7684\u5185\u90e8\u548c\u76d1\u7ba1\u4fe1\u5fc3\u3002"}}
{"id": "2512.08398", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08398", "abs": "https://arxiv.org/abs/2512.08398", "authors": ["Jiin Park", "Hyuna Jeon", "Yoonseo Lee", "Jisu Hong", "Misuk Kim"], "title": "Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring", "comment": null, "summary": "Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5de5\u4e1a\u6807\u51c6\u6587\u6863\uff0c\u901a\u8fc7\u5206\u5c42\u8bed\u4e49\u7ed3\u6784\u5206\u6790\u548cLLM\u4e09\u5143\u7ec4\u62bd\u53d6\uff0c\u6709\u6548\u5904\u7406\u8868\u683c\u3001\u6761\u4ef6\u89c4\u5219\u548c\u6570\u503c\u8ba1\u7b97\u7b49\u590d\u6742\u5185\u5bb9\u3002", "motivation": "\u5de5\u4e1a\u6807\u51c6\u6587\u6863\u5305\u542b\u5927\u91cf\u6280\u672f\u4fe1\u606f\u548c\u590d\u6742\u89c4\u5219\uff0c\u91c7\u7528\u8868\u683c\u3001\u5e94\u7528\u8303\u56f4\u3001\u7ea6\u675f\u6761\u4ef6\u3001\u4f8b\u5916\u60c5\u51b5\u548c\u6570\u503c\u8ba1\u7b97\u7b49\u591a\u79cd\u7ed3\u6784\u5316\u683c\u5f0f\uff0c\u4f7f\u5f97\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7279\u522b\u5177\u6709\u6311\u6218\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8868\u793a\u8fd9\u4e9b\u9886\u57df\u7279\u5b9a\u7684\u8bed\u4e49\u3002", "method": "\u5c06\u6587\u6863\u7ec4\u7ec7\u4e3a\u5206\u5c42\u8bed\u4e49\u7ed3\u6784\uff0c\u5c06\u53e5\u5b50\u548c\u8868\u683c\u5206\u89e3\u4e3a\u57fa\u4e8e\u6761\u4ef6\u548c\u6570\u503c\u89c4\u5219\u7684\u539f\u5b50\u547d\u9898\uff0c\u901a\u8fc7LLM\u8fdb\u884c\u4e09\u5143\u7ec4\u62bd\u53d6\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u672c\u4f53\u77e5\u8bc6\u56fe\u8c31\u4e2d\u3002\u8be5\u65b9\u6cd5\u540c\u65f6\u6355\u83b7\u6587\u6863\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u903b\u8f91\u7ed3\u6784\u3002", "result": "\u6784\u5efa\u4e86\u89c4\u5219\u3001\u8868\u683c\u548c\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u4ee5\u53ca\u6709\u6bd2\u6761\u6b3e\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u672c\u4f53\u611f\u77e5\u7684KG-RAG\u6846\u67b6\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u95ee\u7b54\u7c7b\u578b\u4e0a\u90fd\u6bd4\u73b0\u6709KG-RAG\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5bf9\u4e8e\u6761\u4ef6\u3001\u7ea6\u675f\u548c\u8303\u56f4\u4ea4\u7ec7\u7684\u5de5\u4e1a\u6587\u6863\uff0c\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u8868\u793a\u4e5f\u662f\u53ef\u884c\u7684\uff0c\u8fd9\u6709\u52a9\u4e8e\u672a\u6765\u9886\u57df\u7279\u5b9a\u7684RAG\u5f00\u53d1\u548c\u667a\u80fd\u6587\u6863\u7ba1\u7406\u3002"}}
{"id": "2512.08702", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08702", "abs": "https://arxiv.org/abs/2512.08702", "authors": ["Jinfeng Xu", "Zheyu Chen", "Shuo Yang", "Jinze Li", "Zitong Wan", "Hewei Wang", "Weijie Liu", "Yijie Li", "Edith C. H. Ngai"], "title": "VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions for Multimodal Recommendation", "comment": "Accepted by KDD 2026", "summary": "Although existing multimodal recommendation models have shown promising performance, their effectiveness continues to be limited by the pervasive data sparsity problem. This problem arises because users typically interact with only a small subset of available items, leading existing models to arbitrarily treat unobserved items as negative samples. To this end, we propose VI-MMRec, a model-agnostic and training cost-free framework that enriches sparse user-item interactions via similarity-aware virtual user-item interactions. These virtual interactions are constructed based on modality-specific feature similarities of user-interacted items. Specifically, VI-MMRec introduces two different strategies: (1) Overlay, which independently aggregates modality-specific similarities to preserve modality-specific user preferences, and (2) Synergistic, which holistically fuses cross-modal similarities to capture complementary user preferences. To ensure high-quality augmentation, we design a statistically informed weight allocation mechanism that adaptively assigns weights to virtual user-item interactions based on dataset-specific modality relevance. As a plug-and-play framework, VI-MMRec seamlessly integrates with existing models to enhance their performance without modifying their core architecture. Its flexibility allows it to be easily incorporated into various existing models, maximizing performance with minimal implementation effort. Moreover, VI-MMRec introduces no additional overhead during training, making it significantly advantageous for practical deployment. Comprehensive experiments conducted on six real-world datasets using seven state-of-the-art multimodal recommendation models validate the effectiveness of our VI-MMRec.", "AI": {"tldr": "VI-MMRec\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u3001\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6210\u672c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u6001\u7279\u5f81\u76f8\u4f3c\u6027\u7684\u865a\u62df\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u6765\u7f13\u89e3\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u7528\u6237\u901a\u5e38\u53ea\u4e0e\u5c11\u91cf\u7269\u54c1\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6a21\u578b\u5c06\u672a\u89c2\u5bdf\u5230\u7684\u7269\u54c1\u4efb\u610f\u89c6\u4e3a\u8d1f\u6837\u672c\uff0c\u9650\u5236\u4e86\u63a8\u8350\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff1aOverlay\uff08\u72ec\u7acb\u805a\u5408\u6a21\u6001\u7279\u5b9a\u76f8\u4f3c\u6027\uff09\u548cSynergistic\uff08\u878d\u5408\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\uff09\uff0c\u901a\u8fc7\u7edf\u8ba1\u611f\u77e5\u7684\u6743\u91cd\u5206\u914d\u673a\u5236\u81ea\u9002\u5e94\u5206\u914d\u865a\u62df\u4ea4\u4e92\u6743\u91cd\uff0c\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6846\u67b6\u4e0e\u73b0\u6709\u6a21\u578b\u96c6\u6210\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u4e03\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86VI-MMRec\u7684\u6709\u6548\u6027\u3002", "conclusion": "VI-MMRec\u662f\u4e00\u4e2a\u7075\u6d3b\u3001\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6210\u672c\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u589e\u5f3a\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4f18\u52bf\u3002"}}
