<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Tail-Aware Data Augmentation for Long-Tail Sequential Recommendation](https://arxiv.org/abs/2601.10933)
*Yizhou Dang,Zhifu Wei,Minhan Huang,Lianbo Ma,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.IR

TL;DR: 提出TADA方法，通过尾部感知的数据增强解决序列推荐中的长尾问题，在保持头部性能的同时提升尾部用户/物品的推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现实场景中大多数用户只能与少量物品交互，而大多数物品很少被消费，这种普遍的长尾问题限制了模型学习用户偏好的能力。现有方法要么难以改善尾部用户/物品交互稀缺的问题，要么在提升尾部准确性时会损害整体或头部性能。

Method: 提出尾部感知数据增强(TADA)：1) 使用线性模型捕捉低流行度物品的共现和相关性；2) 设计两种增强操作符：T-Substitute（用相关物品替换头部物品）和T-Insert（利用共现关系扩展原始序列）；3) 在表示层混合增强和原始序列以保留偏好知识；4) 跨不同尾部用户序列和增强序列扩展混合操作以生成更丰富的增强样本。

Result: 综合实验证明了该方法的优越性，代码已开源。

Conclusion: TADA方法能有效增强尾部物品/用户的交互频率，同时保持头部性能，从而提升模型对尾部部分的学习能力，解决了长尾序列推荐中的关键问题。

Abstract: Sequential recommendation (SR) learns user preferences based on their historical interaction sequences and provides personalized suggestions. In real-world scenarios, most users can only interact with a handful of items, while the majority of items are seldom consumed. This pervasive long-tail challenge limits the model's ability to learn user preferences. Despite previous efforts to enrich tail items/users with knowledge from head parts or improve tail learning through additional contextual information, they still face the following issues: 1) They struggle to improve the situation where interactions of tail users/items are scarce, leading to incomplete preferences learning for the tail parts. 2) Existing methods often degrade overall or head parts performance when improving accuracy for tail users/items, thereby harming the user experience. We propose Tail-Aware Data Augmentation (TADA) for long-tail sequential recommendation, which enhances the interaction frequency for tail items/users while maintaining head performance, thereby promoting the model's learning capabilities for the tail. Specifically, we first capture the co-occurrence and correlation among low-popularity items by a linear model. Building upon this, we design two tail-aware augmentation operators, T-Substitute and T-Insert. The former replaces the head item with a relevant item, while the latter utilizes co-occurrence relationships to extend the original sequence by incorporating both head and tail items. The augmented and original sequences are mixed at the representation level to preserve preference knowledge. We further extend the mix operation across different tail-user sequences and augmented sequences to generate richer augmented samples, thereby improving tail performance. Comprehensive experiments demonstrate the superiority of our method. The codes are provided at https://github.com/KingGugu/TADA.

</details>


### [2] [Can Instructed Retrieval Models Really Support Exploration?](https://arxiv.org/abs/2601.10936)
*Piyush Maheshwari,Sheshera Mysore,Hamed Zamani*

Main category: cs.IR

TL;DR: 评估指令跟随检索模型在探索性搜索中的表现，发现其在相关性排序上优于无指令模型，但在指令跟随能力上存在不足，不适合需要高度指令敏感性的长期探索会话。


<details>
  <summary>Details</summary>
Motivation: 探索性搜索具有目标不明确和查询意图不断演化的特点，需要能够捕捉用户查询意图细微差别并相应调整结果的检索模型。指令跟随检索模型承诺具备这种能力，但尚未在方面条件种子引导探索这一普遍应用中充分评估。

Method: 使用专家标注的测试集合评估指令检索器，包括专门为指令检索微调的LLM和使用Pairwise Ranking Prompting进行排名的通用LLM。评估重点是方面条件种子引导探索场景。

Result: 最佳指令检索器在排名相关性方面优于无指令方法，但指令跟随性能（对用户体验至关重要）并未反映相关性改进，且对指令表现出不敏感或反直觉的行为。

Conclusion: 虽然当前指令检索器相比无指令模型能给用户带来好处，但对于需要更高指令敏感性的长期探索性会话，用户可能无法从中受益。指令跟随性能与排名相关性改进不匹配表明需要进一步研究。

Abstract: Exploratory searches are characterized by under-specified goals and evolving query intents. In such scenarios, retrieval models that can capture user-specified nuances in query intent and adapt results accordingly are desirable -- instruction-following retrieval models promise such a capability. In this work, we evaluate instructed retrievers for the prevalent yet under-explored application of aspect-conditional seed-guided exploration using an expert-annotated test collection. We evaluate both recent LLMs fine-tuned for instructed retrieval and general-purpose LLMs prompted for ranking with the highly performant Pairwise Ranking Prompting. We find that the best instructed retrievers improve on ranking relevance compared to instruction-agnostic approaches. However, we also find that instruction following performance, crucial to the user experience of interacting with models, does not mirror ranking relevance improvements and displays insensitivity or counter-intuitive behavior to instructions. Our results indicate that while users may benefit from using current instructed retrievers over instruction-agnostic models, they may not benefit from using them for long-running exploratory sessions requiring greater sensitivity to instructions.

</details>


### [3] [PRISM: Personalized Recommendation via Information Synergy Module](https://arxiv.org/abs/2601.10944)
*Xinyi Zhang,Yutong Li,Peijie Sun,Letian Sha,Zhongxuan Han*

Main category: cs.IR

TL;DR: PRISM是一个用于多模态序列推荐的即插即用框架，通过信息协同模块将多模态信息分解为独特、冗余和协同组件，并根据用户偏好动态加权融合。


<details>
  <summary>Details</summary>
Motivation: 现有MSR模型往往忽视仅通过模态组合才出现的协同信息，且通常假设不同模态交互对所有用户具有固定重要性，这限制了推荐效果。

Method: 提出PRISM框架，通过交互专家层将多模态信息分解为独特、冗余和协同组件，并通过自适应融合层根据用户偏好动态加权这些组件。

Result: 在四个数据集和三个序列推荐骨干模型上的实验证明了PRISM的有效性和通用性。

Conclusion: PRISM通过信息理论设计实现了多模态信号的细粒度解耦和个性化融合，提高了多模态序列推荐的性能。

Abstract: Multimodal sequential recommendation (MSR) leverages diverse item modalities to improve recommendation accuracy, while achieving effective and adaptive fusion remains challenging. Existing MSR models often overlook synergistic information that emerges only through modality combinations. Moreover, they typically assume a fixed importance for different modality interactions across users. To address these limitations, we propose \textbf{P}ersonalized \textbf{R}ecommend-ation via \textbf{I}nformation \textbf{S}ynergy \textbf{M}odule (PRISM), a plug-and-play framework for sequential recommendation (SR). PRISM explicitly decomposes multimodal information into unique, redundant, and synergistic components through an Interaction Expert Layer and dynamically weights them via an Adaptive Fusion Layer guided by user preferences. This information-theoretic design enables fine-grained disentanglement and personalized fusion of multimodal signals. Extensive experiments on four datasets and three SR backbones demonstrate its effectiveness and versatility. The code is available at https://github.com/YutongLi2024/PRISM.

</details>


### [4] [PruneRAG: Confidence-Guided Query Decomposition Trees for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11024)
*Shuguang Jiao,Xinyu Xiao,Yunfan Wei,Shuhan Qi,Chengkai Huang,Quan Z. Michael Sheng,Lina Yao*

Main category: cs.IR

TL;DR: PruneRAG：一种基于置信度引导的查询分解框架，通过构建结构化查询分解树来解决RAG系统中的证据遗忘和效率低下问题，在保持多跳推理中关键证据的同时显著减少检索开销。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统在推理链加深或搜索树扩展时面临两个持续性问题：证据遗忘（检索到的知识未被有效利用）和效率低下（由不受控制的查询扩展和冗余检索引起）。这些问题揭示了当前RAG架构中检索与证据利用之间的关键差距。

Method: PruneRAG提出三个关键机制：1）自适应节点扩展，调节树的宽度和深度；2）置信度引导决策，接受可靠答案并剪枝不确定分支；3）细粒度检索，提取实体级锚点以提高检索精度。这些组件共同构建结构化查询分解树，实现稳定高效的推理。

Result: 在多个多跳QA基准测试上的广泛实验表明，PruneRAG在准确性和效率方面均优于最先进的基线方法。作者还定义了证据遗忘率作为量化指标，用于分析检索到的黄金证据未被正确使用的情况。

Conclusion: PruneRAG通过置信度引导的查询分解框架有效解决了RAG系统中的证据遗忘和效率问题，在多跳推理任务中实现了更好的证据保留和检索效率，为知识密集型推理任务提供了更可靠的解决方案。

Abstract: Retrieval-augmented generation (RAG) has become a powerful framework for enhancing large language models in knowledge-intensive and reasoning tasks. However, as reasoning chains deepen or search trees expand, RAG systems often face two persistent failures: evidence forgetting, where retrieved knowledge is not effectively used, and inefficiency, caused by uncontrolled query expansions and redundant retrieval. These issues reveal a critical gap between retrieval and evidence utilization in current RAG architectures. We propose PruneRAG, a confidence-guided query decomposition framework that builds a structured query decomposition tree to perform stable and efficient reasoning. PruneRAG introduces three key mechanisms: adaptive node expansion that regulates tree width and depth, confidence-guided decisions that accept reliable answers and prune uncertain branches, and fine-grained retrieval that extracts entity-level anchors to improve retrieval precision. Together, these components preserve salient evidence throughout multi-hop reasoning while significantly reducing retrieval overhead. To better analyze evidence misuse, we define the Evidence Forgetting Rate as a metric to quantify cases where golden evidence is retrieved but not correctly used. Extensive experiments across various multi-hop QA benchmarks show that PruneRAG achieves superior accuracy and efficiency over state-of-the-art baselines.

</details>


### [5] [Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings](https://arxiv.org/abs/2601.11124)
*Xiaoyu Liang,Yuchen Peng,Jiale Luo,Wenhao Wang,Haoji Hu,Xincheng Zhou*

Main category: cs.IR

TL;DR: LBR框架通过两阶段方法解决LLM在垂直领域知识不足问题：先通过信息瓶颈约束生成学习注入领域知识，再进行生成精炼对比学习对齐表示


<details>
  <summary>Details</summary>
Motivation: 现有基于对比学习的LLM在化学、法律等垂直领域表现不佳，主要原因是缺乏领域特定知识，当前"LLM+CL"范式只关注语义对齐而无法进行知识获取

Method: 提出Learn Before Represent (LBR)两阶段框架：1) 信息瓶颈约束生成学习阶段注入领域知识，保持LLM的因果注意力以最大化知识获取同时压缩语义；2) 在压缩表示上进行生成精炼对比学习以实现对齐

Result: 在医学、化学和代码检索任务上的大量实验表明，LBR显著优于强基线方法

Conclusion: LBR建立了在垂直领域构建准确鲁棒表示的新范式，解决了生成学习和对比学习之间的目标冲突

Abstract: Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law, primarily due to a lack of domain-specific knowledge. This work identifies a core bottleneck: the prevailing ``LLM+CL'' paradigm focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, we propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines. Our work establishes a new paradigm for building accurate and robust representations in vertical domains.

</details>


### [6] [Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration](https://arxiv.org/abs/2601.11144)
*Yuejie Li,Ke Yang,Tao Wang,Bolin Chen,Bowen Li,Chengjun Mao*

Main category: cs.IR

TL;DR: Deep GraphRAG提出分层全局-局部检索策略，通过三阶段检索和动态重排序平衡搜索全面性与效率，并使用DW-GRPO强化学习训练紧凑LLM实现知识整合。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG框架面临全局搜索全面性与局部搜索效率之间的权衡，难以处理大规模分层图、优化检索路径、平衡探索-利用动态，且缺乏强大的多阶段重排序机制。

Method: 1. 分层全局-局部检索策略：宏观社区间和微观社区内上下文关系结合；2. 三阶段检索：社区间过滤、社区级精炼、实体级细粒度搜索；3. 波束搜索优化的动态重排序模块；4. 知识整合模块使用DW-GRPO强化学习训练紧凑LLM。

Result: 在Natural Questions和HotpotQA数据集上评估，Deep GraphRAG在准确性和效率方面显著优于基线图检索方法，紧凑模型(1.5B)在整合任务上接近大模型(70B)性能。

Conclusion: Deep GraphRAG通过分层检索策略和自适应整合机制，有效解决了GraphRAG框架中全面性与效率的权衡问题，为大规模知识图检索提供了平衡的解决方案。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.

</details>


### [7] [Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation](https://arxiv.org/abs/2601.11151)
*Ji Dai,Quan Fang,Jun Hu,Desheng Cai,Yang Yang,Can Zhao*

Main category: cs.IR

TL;DR: CRANE：一种通过递归跨模态注意力和双图嵌入解决多媒体推荐中模态融合浅层和特征处理不对称问题的新方法


<details>
  <summary>Details</summary>
Motivation: 现有多媒体推荐系统存在两个关键局限：1）浅层模态融合通常依赖简单拼接，无法充分利用模态内和模态间的协同关系；2）不对称特征处理（用户仅用交互ID表征，而物品受益于丰富的多模态内容）阻碍了共享语义空间的学习。

Method: 提出CRANE框架：1）核心递归跨模态注意力机制，在联合潜在空间中迭代细化模态特征，捕捉高阶模态内和模态间依赖；2）通过聚合用户交互物品的特征显式构建用户多模态画像；3）对称双图框架（异构用户-物品交互图和同构物品-物品语义图），通过自监督对比学习目标统一融合行为和语义信号。

Result: 在四个公开真实数据集上的综合实验验证了CRANE在关键指标上平均提升5%优于现有最佳基线，同时保持高计算效率，在小数据集上实现更快收敛，在大规模数据集上达到更优性能上限。

Conclusion: CRANE通过递归跨模态注意力和对称双图嵌入有效解决了多媒体推荐中的模态融合和特征处理问题，在保持高效计算的同时显著提升了推荐性能。

Abstract: Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment-where users are only characterized by interaction IDs while items benefit from rich multimodal content-hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users' multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework-comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph-unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines.

</details>


### [8] [From Knots to Knobs: Towards Steerable Collaborative Filtering Using Sparse Autoencoders](https://arxiv.org/abs/2601.11182)
*Martin Spišák,Ladislav Peška,Petr Škoda,Vojtěch Vančura,Rodrigo Alves*

Main category: cs.IR

TL;DR: 将稀疏自编码器应用于协同过滤，首次在纯交互信号中提取可解释特征，实现推荐系统的可控引导


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在大型语言模型中已证明能提取高质量可解释特征并实现生成过程的可控引导，但尚未应用于协同过滤领域。本文旨在将这一方法扩展到基于交互信号的推荐系统中，提取类似的可解释特征。

Method: 在广泛采用的协同自编码器基础上，在其编码器和解码器网络之间插入稀疏自编码器。分析该表示的单义性特征，并提出语义概念与单个神经元之间的合适映射函数。

Result: 证明该表示在很大程度上是单义的，能够提取可解释特征。同时评估了一种简单而有效的方法，利用这种表示来向期望方向引导推荐结果。

Conclusion: 首次成功将稀疏自编码器方法应用于协同过滤，实现了从纯交互信号中提取可解释特征，并为推荐系统的可控引导提供了有效工具。

Abstract: Sparse autoencoders (SAEs) have recently emerged as pivotal tools for introspection into large language models. SAEs can uncover high-quality, interpretable features at different levels of granularity and enable targeted steering of the generation process by selectively activating specific neurons in their latent activations. Our paper is the first to apply this approach to collaborative filtering, aiming to extract similarly interpretable features from representations learned purely from interaction signals. In particular, we focus on a widely adopted class of collaborative autoencoders (CFAEs) and augment them by inserting an SAE between their encoder and decoder networks. We demonstrate that such representation is largely monosemantic and propose suitable mapping functions between semantic concepts and individual neurons. We also evaluate a simple yet effective method that utilizes this representation to steer the recommendations in a desired direction.

</details>


### [9] [LLM-Assisted Pseudo-Relevance Feedback](https://arxiv.org/abs/2601.11238)
*David Otero,Javier Parapar*

Main category: cs.IR

TL;DR: 提出一种混合查询扩展方法，结合传统伪相关反馈和LLM语义判断，通过LLM过滤初始检索文档后再进行RM3扩展，提升检索效果


<details>
  <summary>Details</summary>
Motivation: 传统伪相关反馈方法（如RM3）容易受到主题漂移影响，当初始检索结果包含噪声或不相关内容时效果下降。而基于LLM的查询扩展方法虽然有效，但存在幻觉和与特定领域术语不匹配的风险。需要一种既保持传统方法鲁棒性又利用LLM语义判断能力的混合方案。

Method: 在RM3伪相关反馈之前插入LLM过滤阶段：首先获取初始检索的前k个文档，然后使用LLM判断这些文档的相关性，只将LLM判定为相关的文档用于RM3查询扩展模型的估计。

Result: 该方法在多个数据集和评估指标上超越了盲目的伪相关反馈和强基线方法，证明了混合方法的有效性。

Conclusion: 提出的混合方法既保持了传统伪相关反馈的鲁棒性和可解释性，又利用了LLM的语义判断能力，通过简单的干预显著提升了查询扩展的效果。

Abstract: Query expansion is a long-standing technique to mitigate vocabulary mismatch in ad hoc Information Retrieval. Pseudo-relevance feedback methods, such as RM3, estimate an expanded query model from the top-ranked documents, but remain vulnerable to topic drift when early results include noisy or tangential content. Recent approaches instead prompt Large Language Models to generate synthetic expansions or query variants. While effective, these methods risk hallucinations and misalignment with collection-specific terminology. We propose a hybrid alternative that preserves the robustness and interpretability of classical PRF while leveraging LLM semantic judgement. Our method inserts an LLM-based filtering stage prior to RM3 estimation: the LLM judges the documents in the initial top-$k$ ranking, and RM3 is computed only over those accepted as relevant. This simple intervention improves over blind PRF and a strong baseline across several datasets and metrics.

</details>


### [10] [Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking](https://arxiv.org/abs/2601.11273)
*Yongqi Fan,Yuxiang Chu,Zhentao Xia,Xiaoyang Chen,Jie Liu,Haijin Liang,Jin Ma,Ben He,Yingfei Sun,Dezhi Ye,Tong Ruan*

Main category: cs.IR

TL;DR: Rank4Gen是一个为RAG系统设计的生成器感知排序器，通过优化下游响应质量和考虑不同生成器的偏好差异来改进证据检索和引用。


<details>
  <summary>Details</summary>
Motivation: 现有RAG中的排序模型主要优化查询-文档相关性，这与生成器在证据选择和引用方面的偏好不一致，限制了响应质量。同时，大多数方法没有考虑不同生成器之间的偏好差异，导致跨生成器性能不稳定。

Method: 提出Rank4Gen，包含两个关键偏好建模策略：1）从排序相关性转向响应质量：优化排序以提升下游响应质量而非查询-文档相关性；2）生成器特定偏好建模：使单个排序器适应不同生成器以捕捉其独特的排序偏好。构建PRISM数据集支持模型训练。

Result: 在五个具有挑战性的RAG基准测试中，Rank4Gen在复杂证据组合方面表现出强大且具有竞争力的性能。

Conclusion: Rank4Gen通过考虑生成器偏好和优化下游响应质量，显著改进了RAG系统中的证据检索和排序，提升了跨生成器的稳定性和整体性能。

Abstract: In the RAG paradigm, the information retrieval module provides context for generators by retrieving and ranking multiple documents to support the aggregation of evidence. However, existing ranking models are primarily optimized for query--document relevance, which often misaligns with generators' preferences for evidence selection and citation, limiting their impact on response quality. Moreover, most approaches do not account for preference differences across generators, resulting in unstable cross-generator performance. We propose \textbf{Rank4Gen}, a generator-aware ranker for RAG that targets the goal of \emph{Ranking for Generators}. Rank4Gen introduces two key preference modeling strategies: (1) \textbf{From Ranking Relevance to Response Quality}, which optimizes ranking with respect to downstream response quality rather than query--document relevance; and (2) \textbf{Generator-Specific Preference Modeling}, which conditions a single ranker on different generators to capture their distinct ranking preferences. To enable such modeling, we construct \textbf{PRISM}, a dataset built from multiple open-source corpora and diverse downstream generators. Experiments on five challenging and recent RAG benchmarks demonstrate that RRank4Gen achieves strong and competitive performance for complex evidence composition in RAG.

</details>


### [11] [From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics](https://arxiv.org/abs/2601.11282)
*Junjie Wang,Gaole He,Alisa Rieger,Ujwal Gadiraju*

Main category: cs.IR

TL;DR: 研究比较搜索引擎结果页(SERPs)与AI生成播客对用户态度的影响，发现信息呈现顺序和媒介类型会影响用户观点改变，特别是涉及争议性话题时。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成播客成为新兴的被动信息消费方式，并与传统搜索引擎结果页(SERPs)在信息寻求行为中日益融合，需要了解这两种媒介如何交互影响用户态度，特别是在涉及争议性、价值导向性话题时。

Method: 通过控制性用户研究(N=483)，调查用户通过SERPs和AI生成播客消费信息时的态度效应，重点关注信息暴露的顺序和媒介类型如何塑造用户观点。

Result: 多数用户表现出态度改变，信息呈现顺序对态度改变有显著影响。观点偏见和话题争议程度在塑造态度改变中起重要作用，但未发现个体调节变量的显著影响。

Conclusion: 信息媒介类型和呈现顺序共同影响用户态度形成，特别是在争议性话题上，这对设计信息呈现系统和理解媒介效应具有重要意义。

Abstract: Compared to search engine result pages (SERPs), AI-generated podcasts represent a relatively new and relatively more passive modality of information consumption, delivering narratives in a naturally engaging format. As these two media increasingly converge in everyday information-seeking behavior, it is essential to explore how their interaction influences user attitudes, particularly in contexts involving controversial, value-laden, and often debated topics. Addressing this need, we aim to understand how information mediums of present-day SERPs and AI-generated podcasts interact to shape the opinions of users. To this end, through a controlled user study (N=483), we investigated user attitudinal effects of consuming information via SERPs and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions. A majority of users in our study corresponded to attitude change outcomes, and we found an effect of sequence on attitude change. Our results further revealed a role of viewpoint bias and the degree of topic controversiality in shaping attitude change, although we found no effect of individual moderators.

</details>


### [12] [Validating Search Query Simulations: A Taxonomy of Measures](https://arxiv.org/abs/2601.11412)
*Andreas Konstantin Kruff,Nolwenn Bernard,Philipp Schaer*

Main category: cs.IR

TL;DR: 本文通过文献综述开发了用户模拟查询验证方法的分类法，实证分析了不同度量之间的关系，并为不同场景提供了验证建议和开源工具库。


<details>
  <summary>Details</summary>
Motivation: 用户模拟器在信息检索系统评估中的有效性验证仍是一个开放问题，这限制了模拟器的有效使用和基于模拟结果的可靠性。需要系统研究用户模拟查询的验证方法。

Method: 1) 进行全面的文献综述，重点关注模拟用户查询与真实查询的验证方法；2) 基于综述开发当前可用度量的分类法；3) 使用四个不同搜索场景的数据集实证分析不同度量之间的关系；4) 提供具体的验证建议并发布开源工具库。

Result: 开发了用户模拟查询验证方法的分类法，实证分析了不同度量之间的关系，为不同上下文提供了具体的验证度量选择建议，并发布了包含常用度量的专用库。

Conclusion: 本文通过系统化的方法解决了用户模拟器验证的开放问题，提供了实用的分类框架、实证依据和工具支持，有助于提高模拟评估的可靠性和促进未来研究。

Abstract: Assessing the validity of user simulators when used for the evaluation of information retrieval systems remains an open question, constraining their effective use and the reliability of simulation-based results. To address this issue, we conduct a comprehensive literature review with a particular focus on methods for the validation of simulated user queries with regard to real queries. Based on the review, we develop a taxonomy that structures the current landscape of available measures. We empirically corroborate the taxonomy by analyzing the relationships between the different measures applied to four different datasets representing diverse search scenarios. Finally, we provide concrete recommendations on which measures or combinations of measures should be considered when validating user simulation in different contexts. Furthermore, we release a dedicated library with the most commonly used measures to facilitate future research.

</details>


### [13] [Isotropy-Optimized Contrastive Learning for Semantic Course Recommendation](https://arxiv.org/abs/2601.11427)
*Ali Khreis,Anthony Nasr,Yusuf Hilal*

Main category: cs.IR

TL;DR: 基于自监督对比学习的语义课程推荐系统，通过数据增强和各向同性正则化改进BERT嵌入，为工程专业学生提供更准确的课程推荐


<details>
  <summary>Details</summary>
Motivation: 传统BERT嵌入存在各向异性问题，课程描述之间的余弦相似度很高，无论语义相关性如何，这影响了课程推荐的准确性

Method: 提出基于BERT的自监督对比学习框架，结合数据增强和各向同性正则化，生成更具区分度的嵌入表示，处理学生文本查询并推荐Top-N相关课程

Result: 实验结果表明，微调后的模型相比原始BERT基线，实现了更好的嵌入分离和更准确的课程推荐，使用了超过500门工程课程的精选数据集

Conclusion: 提出的对比学习框架有效解决了BERT嵌入的各向异性问题，显著提升了课程推荐系统的性能，为工程专业学生提供了更精准的课程推荐

Abstract: This paper presents a semantic course recommendation system for students using a self-supervised contrastive learning approach built upon BERT (Bidirectional Encoder Representations from Transformers). Traditional BERT embeddings suffer from anisotropic representation spaces, where course descriptions exhibit high cosine similarities regardless of semantic relevance. To address this limitation, we propose a contrastive learning framework with data augmentation and isotropy regularization that produces more discriminative embeddings. Our system processes student text queries and recommends Top-N relevant courses from a curated dataset of over 500 engineering courses across multiple faculties. Experimental results demonstrate that our fine-tuned model achieves improved embedding separation and more accurate course recommendations compared to vanilla BERT baselines.

</details>
