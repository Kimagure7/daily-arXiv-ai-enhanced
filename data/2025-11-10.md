<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Association via Entropy Reduction](https://arxiv.org/abs/2511.04901)
*Anthony Gamst,Lawrence Wilson*

Main category: cs.IR

TL;DR: 提出了一种名为aver的新评分方法，在关联文档发现任务中表现优于传统的tf-idf方法，特别是在大规模图数据中寻找关联顶点方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 在神经网络广泛应用之前，tf-idf被认为是识别查询相关文档的最佳选择，但作者发现tf-idf在某些场景下存在局限性，需要一种更自然且具有更好性能的替代方法。

Method: 基于简单统计模型下的熵推导出aver评分方法，该方法具有自然阈值、能区分tf-idf得分为1.0的文档对、可应用于更大文档集合等特性。

Result: 在具有真实关联标注的数据集上，aver在寻找关联文档对方面表现优于tf-idf，特别是在大规模图关联顶点发现任务中。

Conclusion: aver作为一种基于熵的统计模型方法，在某些场景下比tf-idf更自然有效，尽管计算复杂度较高且得分解释较复杂，但在特定应用领域具有明显优势。

Abstract: Prior to recent successes using neural networks, term frequency-inverse
document frequency (tf-idf) was clearly regarded as the best choice for
identifying documents related to a query. We provide a different score, aver,
and observe, on a dataset with ground truth marking for association, that aver
does do better at finding assciated pairs than tf-idf. This example involves
finding associated vertices in a large graph and that may be an area where
neural networks are not currently an obvious best choice. Beyond this one
anecdote, we observe that (1) aver has a natural threshold for declaring pairs
as unassociated while tf-idf does not, (2) aver can distinguish between pairs
of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to
larger collections of documents than pairs while tf-idf cannot, and (4) that
aver is derived from entropy under a simple statistical model while tf-idf is a
construction designed to achieve a certain goal and hence aver may be more
"natural." To be fair, we also observe that (1) writing down and computing the
aver score for a pair is more complex than for tf-idf and (2) that the fact
that the aver score is naturally scale-free makes it more complicated to
interpret aver scores.

</details>


### [2] [Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG](https://arxiv.org/abs/2511.04939)
*Harshit Nainwani,Hediyeh Baban*

Main category: cs.IR

TL;DR: 提出了Search-Is-Not-Retrieve (SINR)框架，将检索系统的搜索和检索过程分离为细粒度搜索表示和粗粒度检索上下文两个层次，提高系统的可组合性、可扩展性和上下文保真度。


<details>
  <summary>Details</summary>
Motivation: 当前大多数检索系统混淆了两个独立过程：寻找相关信息与提供足够推理上下文。需要区分精细搜索和上下文检索，使系统架构更符合人类信息处理方式。

Method: SINR双层次架构，将小的语义准确搜索块直接连接到大的上下文完整检索块，无需额外处理成本。将检索从被动步骤转变为主动过程。

Result: 该框架增强了检索系统的可组合性、可扩展性和上下文保真度，为下一代使用检索的AI系统提供了实用基础。

Conclusion: SINR框架通过区分搜索和检索过程，改变了检索系统架构，使其更符合人类信息处理方式，为下一代AI检索系统奠定了基础。

Abstract: Retrieval systems are essential to contemporary AI pipelines, although most
confuse two separate processes: finding relevant information and giving enough
context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)
framework, a dual-layer architecture that distinguishes between fine-grained
search representations and coarse-grained retrieval contexts. SINR enhances the
composability, scalability, and context fidelity of retrieval systems by
directly connecting small, semantically accurate search chunks to larger,
contextually complete retrieve chunks, all without incurring extra processing
costs. This design changes retrieval from a passive step to an active one,
making the system architecture more like how people process information. We
discuss the SINR framework's conceptual foundation, formal structure,
implementation issues, and qualitative outcomes. This provides a practical
foundation for the next generation of AI systems that use retrieval.

</details>


### [3] [Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval](https://arxiv.org/abs/2511.05000)
*Hyunkyu Kim,Yeeun Yoo,Youngjun Kwak*

Main category: cs.IR

TL;DR: 提出了一个基于LLM的领域特定信息检索基准构建方法，并在银行业创建了KoBankIR基准，包含815个查询和204份银行文档，显示现有检索模型在处理复杂多文档查询时存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法捕捉真实银行场景中复杂且领域特定的信息需求，而构建领域特定IR基准成本高且受限于客户数据的法律限制。

Method: 提出系统化方法，通过LLM生成查询，结合单文档和多文档查询生成，以及增强的推理增强可回答性评估方法。

Result: 构建了KoBankIR基准，实验显示现有检索模型在处理该基准中的复杂多文档查询时表现不佳。

Conclusion: 该方法为领域特定基准构建提供了系统化途径，并强调了金融领域需要改进检索技术。

Abstract: As financial applications of large language models (LLMs) gain attention,
accurate Information Retrieval (IR) remains crucial for reliable AI services.
However, existing benchmarks fail to capture the complex and domain-specific
information needs of real-world banking scenarios. Building domain-specific IR
benchmarks is costly and constrained by legal restrictions on using real
customer data. To address these challenges, we propose a systematic methodology
for constructing domain-specific IR benchmarks through LLM-based query
generation. As a concrete implementation of this methodology, our pipeline
combines single and multi-document query generation with an enhanced and
reasoning-augmented answerability assessment method, achieving stronger
alignment with human judgments than prior approaches. Using this methodology,
we construct KoBankIR, comprising 815 queries derived from 204 official banking
documents. Our experiments show that existing retrieval models struggle with
the complex multi-document queries in KoBankIR, demonstrating the value of our
systematic approach for domain-specific benchmark construction and underscoring
the need for improved retrieval techniques in financial domains.

</details>


### [4] [Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR](https://arxiv.org/abs/2511.05079)
*Grigory Kovalev,Natalia Loukachevitch,Mikhail Tikhomirov,Olga Babina,Pavel Mamaev*

Main category: cs.IR

TL;DR: 本文构建了基于俄语维基百科'你知道吗'栏目的新型信息检索数据集，支持事实核查、检索增强生成和全文检索等任务，并通过实验比较了词法检索模型与神经模型在俄语检索中的表现。


<details>
  <summary>Details</summary>
Motivation: 扩展俄语信息检索资源，为事实核查、检索增强生成和全文检索等任务提供标注数据集，弥补现有俄语IR资源的不足。

Method: 从俄语维基百科'你知道吗'栏目构建数据集，包含有趣事实及其引用的维基百科文章，并进行句子级别的分级相关性标注。通过实验比较BM25等词法检索模型与针对俄语优化的先进神经架构及多语言模型。

Result: 实验结果显示，词法方法在全文检索中表现优于神经模型，而神经方法在事实核查或细粒度检索等较短文本中能更好地捕捉词汇语义。结合检索与神经重排序能持续提升性能。

Conclusion: 新数据集扩展了俄语信息检索研究资源，强调了准确评估检索模型对实现最佳性能的重要性。所有数据集和实现代码均已公开，促进可复现性和未来研究。

Abstract: In this paper, we present a novel series of Russian information retrieval
datasets constructed from the "Did you know..." section of Russian Wikipedia.
Our datasets support a range of retrieval tasks, including fact-checking,
retrieval-augmented generation, and full-document retrieval, by leveraging
interesting facts and their referenced Wikipedia articles annotated at the
sentence level with graded relevance. We describe the methodology for dataset
creation that enables the expansion of existing Russian Information Retrieval
(IR) resources. Through extensive experiments, we extend the RusBEIR research
by comparing lexical retrieval models, such as BM25, with state-of-the-art
neural architectures fine-tuned for Russian, as well as multilingual models.
Results of our experiments show that lexical methods tend to outperform neural
models on full-document retrieval, while neural approaches better capture
lexical semantics in shorter texts, such as in fact-checking or fine-grained
retrieval. Using our newly created datasets, we also analyze the impact of
document length on retrieval performance and demonstrate that combining
retrieval with neural reranking consistently improves results. Our contribution
expands the resources available for Russian information retrieval research and
highlights the importance of accurate evaluation of retrieval models to achieve
optimal performance. All datasets are publicly available at HuggingFace. To
facilitate reproducibility and future research, we also release the full
implementation on GitHub.

</details>


### [5] [QUESTER: Query Specification for Generative Retrieval](https://arxiv.org/abs/2511.05301)
*Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: QUESTER将生成式检索重构为查询规范生成，使用小型LLM生成关键词查询，通过强化学习训练，在效率和效果上都表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统生成式检索存在泛化能力差和扩展成本高的问题，需要一种更有效且可扩展的检索方法。

Method: 使用小型LLM将生成式检索重构为查询规范生成（生成BM25可处理的关键词查询），采用GRPO强化学习技术训练策略。

Result: 在领域内和领域外评估中，QUESTER比BM25更有效，与神经IR模型竞争力相当，同时保持良好的效率。

Conclusion: QUESTER通过查询规范生成方法，在保持高效率的同时实现了与先进神经检索模型相当的检索效果。

Abstract: Generative Retrieval (GR) differs from the traditional index-then-retrieve
pipeline by storing relevance in model parameters and directly generating
document identifiers. However, GR often struggles to generalize and is costly
to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),
which reframes GR as query specification generation - in this work, a simple
keyword query handled by BM25 - using a (small) LLM. The policy is trained
using reinforcement learning techniques (GRPO). Across in- and out-of-domain
evaluations, we show that our model is more effective than BM25, and
competitive with neural IR models, while maintaining a good efficiency

</details>


### [6] [TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2511.05385)
*Chao Zhang,Yuhao Wang,Derong Xu,Haoxin Zhang,Yuanjie Lyu,Yuhao Chen,Shuochen Liu,Tong Xu,Xiangyu Zhao,Yan Gao,Yao Hu,Enhong Chen*

Main category: cs.IR

TL;DR: TeaRAG是一个token高效的代理式RAG框架，通过压缩检索内容和推理步骤来提高效率，在保持准确性的同时显著减少token使用量。


<details>
  <summary>Details</summary>
Motivation: 现有的代理式RAG系统虽然通过强化学习提高了准确性，但搜索和推理过程会产生大量token开销，这种权衡优先考虑准确性而非效率。

Method: 1) 通过图检索和知识关联图压缩检索内容，使用个性化PageRank突出关键知识；2) 提出迭代过程感知直接偏好优化(IP-DPO)，通过知识匹配机制评估知识充分性并惩罚过度推理步骤。

Result: 在六个数据集上，TeaRAG在Llama3-8B-Instruct和Qwen2.5-14B-Instruct上分别将平均精确匹配提高了4%和2%，同时将输出token减少了61%和59%。

Conclusion: TeaRAG成功解决了代理式RAG系统的效率问题，在保持甚至提高准确性的同时显著减少了token使用量，为实际应用提供了更实用的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment
Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs
autonomous, multi-round retrieval and reasoning to resolve queries. Although
recent agentic RAG has improved via reinforcement learning, they often incur
substantial token overhead from search and reasoning processes. This trade-off
prioritizes accuracy over efficiency. To address this issue, this work proposes
TeaRAG, a token-efficient agentic RAG framework capable of compressing both
retrieval content and reasoning steps. 1) First, the retrieved content is
compressed by augmenting chunk-based semantic retrieval with a graph retrieval
using concise triplets. A knowledge association graph is then built from
semantic similarity and co-occurrence. Finally, Personalized PageRank is
leveraged to highlight key knowledge within this graph, reducing the number of
tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative
Process-aware Direct Preference Optimization (IP-DPO) is proposed.
Specifically, our reward function evaluates the knowledge sufficiency by a
knowledge matching mechanism, while penalizing excessive reasoning steps. This
design can produce high-quality preference-pair datasets, supporting iterative
DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the
average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on
Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at
https://github.com/Applied-Machine-Learning-Lab/TeaRAG.

</details>
