<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 11]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Reasoning by Exploration: A Unified Approach to Retrieval and Generation over Graphs](https://arxiv.org/abs/2510.07484)
*Haoyu Han,Kai Guo,Harry Shomer,Yu Wang,Yucheng Chu,Hang Li,Li Ma,Jiliang Tang*

Main category: cs.IR

TL;DR: 提出Reasoning by Exploration (RoE)方法，将图结构推理统一为探索过程，通过两阶段训练实现更好的推理效果和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成的方法在处理大规模图结构时存在局限性，检索质量直接影响生成效果，且现有检索器对未见图泛化能力差

Method: 将图推理建模为探索过程，LLM逐步选择节点和边构建推理路径；采用两阶段训练：监督微调学习黄金路径，强化学习提升探索效果

Result: 在基准数据集上相比基线方法取得显著提升，对未见图具有良好的泛化能力

Conclusion: RoE通过统一检索和生成过程，有效解决了图结构推理中的挑战，为LLM处理复杂图结构提供了新思路

Abstract: Reasoning over structured graphs remains a fundamental challenge for Large
Language Models (LLMs), particularly when scaling to large graphs. Existing
approaches typically follow the retrieval-augmented generation (RAG) paradigm:
first retrieving subgraphs relevant to the query and then generating answers
conditioned on the retrieved subgraphs. However, such two-phase pipelines often
struggle to faithfully incorporate graph structure, since the generation
process is ultimately constrained by the quality and completeness of the
retrieved subgraph. Although many advanced retrievers have been proposed
recently to mitigate this issue, they are usually tailored to the training
graphs and generalize poorly to unseen graphs, which limits their practical
applicability. In this work, we propose Reasoning by Exploration (RoE), a novel
approach that unifies retrieval and generation by framing reasoning over graphs
as a process of graph exploration. At each step, the LLM selects candidate
nodes and edges to explore, gradually constructing reasoning paths and
generating answers along the way. To enable effective exploration, RoE is
trained in two stages: supervised fine-tuning (SFT) on gold reasoning paths,
followed by reinforcement learning (RL) to enhance exploration effectiveness
and generalization. Experiments on benchmark datasets demonstrate that RoE
achieves substantial overall improvements over baselines, while also
generalizing effectively to unseen graphs.

</details>


### [2] [Retentive Relevance: Capturing Long-Term User Value in Recommendation Systems](https://arxiv.org/abs/2510.07621)
*Saeideh Bakhshi,Phuong Mai Nguyen,Robert Schiller,Tiantian Xu,Pawan Kodandapani,Andrew Levine,Cayman Simpson,Qifan Wang*

Main category: cs.IR

TL;DR: 提出了Retentive Relevance这一基于调查的内容级反馈指标，通过预测用户返回平台的意图来改进推荐系统，显著提升了用户留存率预测效果。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖点击和点赞等短期参与信号存在噪声大、稀疏性强的问题，无法有效捕捉长期用户满意度和留存率。

Method: 开发了基于调查的Retentive Relevance指标，通过心理测量方法验证其有效性，构建生产就绪的代理模型并集成到多阶段排名系统中。

Result: Retentive Relevance在预测次日留存率方面显著优于参与信号和其他调查指标，特别是对历史参与度有限的用户。大规模A/B实验显示能显著提升参与度和留存率，同时减少低质量内容的曝光。

Conclusion: 提供了首个经验验证的框架，将内容级用户感知与生产系统中的留存结果联系起来，为负责任AI发展提供了可扩展的用户中心解决方案。

Abstract: Recommendation systems have traditionally relied on short-term engagement
signals, such as clicks and likes, to personalize content. However, these
signals are often noisy, sparse, and insufficient for capturing long-term user
satisfaction and retention. We introduce Retentive Relevance, a novel
content-level survey-based feedback measure that directly assesses users'
intent to return to the platform for similar content. Unlike other survey
measures that focus on immediate satisfaction, Retentive Relevance targets
forward-looking behavioral intentions, capturing longer term user intentions
and providing a stronger predictor of retention. We validate Retentive
Relevance using psychometric methods, establishing its convergent,
discriminant, and behavioral validity. Through large-scale offline modeling, we
show that Retentive Relevance significantly outperforms both engagement signals
and other survey measures in predicting next-day retention, especially for
users with limited historical engagement. We develop a production-ready proxy
model that integrates Retentive Relevance into the final stage of a multi-stage
ranking system on a social media platform. Calibrated score adjustments based
on this model yield substantial improvements in engagement, and retention,
while reducing exposure to low-quality content, as demonstrated by large-scale
A/B experiments. This work provides the first empirically validated framework
linking content-level user perceptions to retention outcomes in production
systems. We offer a scalable, user-centered solution that advances both
platform growth and user experience. Our work has broad implications for
responsible AI development.

</details>


### [3] [ISMIE: A Framework to Characterize Information Seeking in Modern Information Environments](https://arxiv.org/abs/2510.07644)
*Shuoqi Sun,Danula Hettiachchi,Damiano Spina*

Main category: cs.IR

TL;DR: 提出了ISMIE框架来建模现代信息环境中的信息寻求过程，包含组件、干预变量和活动三个核心概念，并通过案例研究展示了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代信息环境日益复杂，现有信息寻求模型难以全面捕捉其特性，需要一个新的框架来更好地理解用户-系统交互。

Method: 提出ISMIE框架，包含三个核心概念：组件（如信息寻求者）、干预变量（如交互变量）和活动（如获取）。通过误信息传播案例研究分析六个现有IS和IR模型。

Result: ISMIE框架能够有效揭示现有模型的局限性，并可作为可操作框架用于特征描述和实验设计。提出了两个研究蓝图：用户中心的真实性信任危机实验和系统导向的多巴胺驱动内容消费研究。

Conclusion: ISMIE为开发IS和IR模型提供了基础，有助于推进对现代信息环境中人类交互和系统设计的理解。

Abstract: The modern information environment (MIE) is increasingly complex, shaped by a
wide range of techniques designed to satisfy users' information needs.
Information seeking (IS) models are effective mechanisms for characterizing
user-system interactions. However, conceptualizing a model that fully captures
the MIE landscape poses a challenge. We argue: Does such a model exist? To
address this, we propose the Information Seeking in Modern Information
Environments (ISMIE) framework as a fundamental step. ISMIE conceptualizes the
information seeking process (ISP) via three key concepts: Components (e.g.,
Information Seeker), Intervening Variables (e.g., Interactive Variables), and
Activities (e.g., Acquiring). Using ISMIE's concepts and employing a case study
based on a common scenario - misinformation dissemination - we analyze six
existing IS and information retrieval (IR) models to illustrate their
limitations and the necessity of ISMIE. We then show how ISMIE serves as an
actionable framework for both characterization and experimental design. We
characterize three pressing issues and then outline two research blueprints: a
user-centric, industry-driven experimental design for the authenticity and
trust crisis to AI-generated content and a system-oriented, academic-driven
design for tackling dopamine-driven content consumption. Our framework offers a
foundation for developing IS and IR models to advance knowledge on
understanding human interactions and system design in MIEs.

</details>


### [4] [Queries Are Not Alone: Clustering Text Embeddings for Video Search](https://arxiv.org/abs/2510.07720)
*Peyang Liu,Xi Wang,Ziqiang Cui,Wei Ye*

Main category: cs.IR

TL;DR: 提出Video-Text Cluster (VTC)框架，通过文本查询聚类来增强视频检索，解决文本描述与视频内容之间的语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 传统视频检索方法依赖文本查询与视频元数据的直接匹配，难以弥合文本描述与视频多面性内容之间的语义差距。

Method: 采用文本查询聚类机制，结合Sweeper模块消除聚类噪声，并引入Video-Text Cluster-Attention (VTC-Att)机制动态调整注意力焦点。

Result: 在五个公共数据集上的实验表明，该模型超越了现有的最先进模型。

Conclusion: VTC框架通过语义聚类和动态注意力机制有效提升了视频检索性能。

Abstract: The rapid proliferation of video content across various platforms has
highlighted the urgent need for advanced video retrieval systems. Traditional
methods, which primarily depend on directly matching textual queries with video
metadata, often fail to bridge the semantic gap between text descriptions and
the multifaceted nature of video content. This paper introduces a novel
framework, the Video-Text Cluster (VTC), which enhances video retrieval by
clustering text queries to capture a broader semantic scope. We propose a
unique clustering mechanism that groups related queries, enabling our system to
consider multiple interpretations and nuances of each query. This clustering is
further refined by our innovative Sweeper module, which identifies and
mitigates noise within these clusters. Additionally, we introduce the
Video-Text Cluster-Attention (VTC-Att) mechanism, which dynamically adjusts
focus within the clusters based on the video content, ensuring that the
retrieval process emphasizes the most relevant textual features. Further
experiments have demonstrated that our proposed model surpasses existing
state-of-the-art models on five public datasets.

</details>


### [5] [Who Stole Your Data? A Method for Detecting Unauthorized RAG Theft](https://arxiv.org/abs/2510.07728)
*Peiyang Liu,Ziqiang Cui,Di Liang,Wei Ye*

Main category: cs.IR

TL;DR: 该论文提出了针对检索增强生成(RAG)系统的抄袭检测方法，包括创建专门的数据集RPD和开发双层水印系统，以保护知识产权。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统在增强大语言模型能力的同时，可能被用于大规模未经授权数据盗用的问题，保护知识产权。

Method: 1) 创建RPD数据集，涵盖不同专业领域和写作风格；2) 开发语义和词汇层面的双层水印系统；3) 采用审讯者-侦探框架，通过统计假设检验积累证据。

Result: 实验证明该方法在不同查询量、防御提示和检索参数下都有效，且能抵抗对抗性规避技术。

Conclusion: 为检索增强AI系统的知识产权保护建立了基础框架。

Abstract: Retrieval-augmented generation (RAG) enhances Large Language Models (LLMs) by
mitigating hallucinations and outdated information issues, yet simultaneously
facilitates unauthorized data appropriation at scale. This paper addresses this
challenge through two key contributions. First, we introduce RPD, a novel
dataset specifically designed for RAG plagiarism detection that encompasses
diverse professional domains and writing styles, overcoming limitations in
existing resources. Second, we develop a dual-layered watermarking system that
embeds protection at both semantic and lexical levels, complemented by an
interrogator-detective framework that employs statistical hypothesis testing on
accumulated evidence. Extensive experimentation demonstrates our approach's
effectiveness across varying query volumes, defense prompts, and retrieval
parameters, while maintaining resilience against adversarial evasion
techniques. This work establishes a foundational framework for intellectual
property protection in retrieval-augmented AI systems.

</details>


### [6] [PLUM: Adapting Pre-trained Language Models for Industrial-scale Generative Recommendations](https://arxiv.org/abs/2510.07784)
*Ruining He,Lukasz Heldt,Lichan Hong,Raghunandan Keshavan,Shifan Mao,Nikhil Mehta,Zhengyang Su,Alicia Tsai,Yueqi Wang,Shao-Chuan Wang,Xinyang Yi,Lexi Baugher,Baykal Cakici,Ed Chi,Cristos Goodrow,Ningren Han,He Ma,Romer Rosales,Abby Van Soest,Devansh Tandon,Su-Lin Wu,Weilong Yang,Yilin Zheng*

Main category: cs.IR

TL;DR: PLUM框架通过语义ID、领域持续预训练和任务特定微调，将预训练大语言模型适配到工业级推荐任务，在YouTube视频推荐中显著优于传统生产模型。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型的序列建模能力和世界知识来提升推荐系统的性能，特别是针对工业级大规模推荐任务。

Method: PLUM框架包含三个核心组件：使用语义ID进行项目标记化、在领域特定数据上进行持续预训练、以及针对推荐目标进行任务特定微调（特别是生成式检索）。

Result: 在大规模内部视频推荐数据集上的实验表明，PLUM相比基于大型嵌入表的生产模型在检索性能上有显著提升，并已部署到YouTube的数十亿用户。

Conclusion: PLUM框架成功地将预训练大语言模型适配到工业级推荐系统，证明了生成式检索在推荐任务中的有效性，并为大规模部署提供了可行方案。

Abstract: Large Language Models (LLMs) pose a new paradigm of modeling and computation
for information tasks. Recommendation systems are a critical application domain
poised to benefit significantly from the sequence modeling capabilities and
world knowledge inherent in these large models. In this paper, we introduce
PLUM, a framework designed to adapt pre-trained LLMs for industry-scale
recommendation tasks. PLUM consists of item tokenization using Semantic IDs,
continued pre-training (CPT) on domain-specific data, and task-specific
fine-tuning for recommendation objectives. For fine-tuning, we focus
particularly on generative retrieval, where the model is directly trained to
generate Semantic IDs of recommended items based on user context. We conduct
comprehensive experiments on large-scale internal video recommendation
datasets. Our results demonstrate that PLUM achieves substantial improvements
for retrieval compared to a heavily-optimized production model built with large
embedding tables. We also present a scaling study for the model's retrieval
performance, our learnings about CPT, a few enhancements to Semantic IDs, along
with an overview of the training and inference methods that enable launching
this framework to billions of users in YouTube.

</details>


### [7] [Generation and annotation of item usage scenarios in e-commerce using large language models](https://arxiv.org/abs/2510.07885)
*Madoka Hagiri,Kazushi Okamoto,Koki Karube,Kei Harada,Atsushi Shibata*

Main category: cs.IR

TL;DR: 使用大语言模型生成物品使用场景来构建互补推荐系统，通过想象具体使用情境来识别互补物品需求


<details>
  <summary>Details</summary>
Motivation: 互补关系具有主观性且因人而异，传统基于历史数据的方法难以准确推断，需要关注驱动物品组合的底层使用情境

Method: 利用大语言模型生成物品使用场景，通过人工标注评估生成场景的合理性

Result: 约85%的生成场景被判定为合理，表明大语言模型能有效生成现实的物品使用场景

Conclusion: 大语言模型能够生成合理的物品使用场景，为构建基于使用情境的互补推荐系统提供了可行起点

Abstract: Complementary recommendations suggest combinations of useful items that play
important roles in e-commerce. However, complementary relationships are often
subjective and vary among individuals, making them difficult to infer from
historical data. Unlike conventional history-based methods that rely on
statistical co-occurrence, we focus on the underlying usage context that
motivates item combinations. We hypothesized that people select complementary
items by imagining specific usage scenarios and identifying the needs in such
situations. Based on this idea, we explored the use of large language models
(LLMs) to generate item usage scenarios as a starting point for constructing
complementary recommendation systems. First, we evaluated the plausibility of
LLM-generated scenarios through manual annotation. The results demonstrated
that approximately 85% of the generated scenarios were determined to be
plausible, suggesting that LLMs can effectively generate realistic item usage
scenarios.

</details>


### [8] [TaoSR-AGRL: Adaptive Guided Reinforcement Learning Framework for E-commerce Search Relevance](https://arxiv.org/abs/2510.08048)
*Jianhui Yang,Yiming Jin,Pengkun Jiao,Chenhe Dong,Zerui Huang,Shaowei Yao,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: 提出TaoSR-AGRL框架，通过规则感知奖励塑造和自适应引导回放，提升LLM在电商搜索相关性预测中的推理能力和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在复杂业务规则和用户查询下缺乏对长尾和挑战性案例的稳健推理能力，强化学习方法如GRPO存在稀疏奖励问题。

Method: TaoSR-AGRL包含两个创新：规则感知奖励塑造将最终相关性判断分解为密集结构化奖励；自适应引导回放识别低准确率轨迹并注入真实指导。

Result: 在淘宝搜索大规模数据集和在线人工评估中，TaoSR-AGRL持续优于DPO和标准GRPO基线，提升相关性准确性、规则遵循性和训练稳定性。

Conclusion: TaoSR-AGRL成功部署在淘宝主搜索场景中，服务数亿用户，证明了其在电商搜索相关性预测中的有效性。

Abstract: Query-product relevance prediction is fundamental to e-commerce search and
has become even more critical in the era of AI-powered shopping, where semantic
understanding and complex reasoning directly shape the user experience and
business conversion. Large Language Models (LLMs) enable generative,
reasoning-based approaches, typically aligned via supervised fine-tuning (SFT)
or preference optimization methods like Direct Preference Optimization (DPO).
However, the increasing complexity of business rules and user queries exposes
the inability of existing methods to endow models with robust reasoning
capacity for long-tail and challenging cases. Efforts to address this via
reinforcement learning strategies like Group Relative Policy Optimization
(GRPO) often suffer from sparse terminal rewards, offering insufficient
guidance for multi-step reasoning and slowing convergence. To address these
challenges, we propose TaoSR-AGRL, an Adaptive Guided Reinforcement Learning
framework for LLM-based relevance prediction in Taobao Search Relevance.
TaoSR-AGRL introduces two key innovations: (1) Rule-aware Reward Shaping, which
decomposes the final relevance judgment into dense, structured rewards aligned
with domain-specific relevance criteria; and (2) Adaptive Guided Replay, which
identifies low-accuracy rollouts during training and injects targeted
ground-truth guidance to steer the policy away from stagnant, rule-violating
reasoning patterns toward compliant trajectories. TaoSR-AGRL was evaluated on
large-scale real-world datasets and through online side-by-side human
evaluations on Taobao Search. It consistently outperforms DPO and standard GRPO
baselines in offline experiments, improving relevance accuracy, rule adherence,
and training stability. The model trained with TaoSR-AGRL has been successfully
deployed in the main search scenario on Taobao, serving hundreds of millions of
users.

</details>


### [9] [VersionRAG: Version-Aware Retrieval-Augmented Generation for Evolving Documents](https://arxiv.org/abs/2510.08109)
*Daniel Huwiler,Kurt Stockinger,Jonathan Fürst*

Main category: cs.IR

TL;DR: VersionRAG是一个版本感知的RAG框架，通过分层图结构建模文档演化，在版本敏感问题上达到90%准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理版本化技术文档时表现不佳（58-64%准确率），缺乏时间有效性检查，无法处理文档演化问题。

Method: 使用分层图结构捕获版本序列、内容边界和文档状态变化，基于意图分类进行查询路由，实现版本感知过滤和变更追踪。

Result: 在VersionQA基准测试中达到90%准确率，比朴素RAG（58%）和GraphRAG（64%）显著提升；在隐式变更检测上达到60%准确率，而基线方法几乎失效（0-10%）；索引时比GraphRAG减少97%的token使用。

Conclusion: 将版本化文档问答确立为独立任务，为未来研究提供了解决方案和基准测试。

Abstract: Retrieval-Augmented Generation (RAG) systems fail when documents evolve
through versioning-a ubiquitous characteristic of technical documentation.
Existing approaches achieve only 58-64% accuracy on version-sensitive
questions, retrieving semantically similar content without temporal validity
checks. We present VersionRAG, a version-aware RAG framework that explicitly
models document evolution through a hierarchical graph structure capturing
version sequences, content boundaries, and changes between document states.
During retrieval, VersionRAG routes queries through specialized paths based on
intent classification, enabling precise version-aware filtering and change
tracking. On our VersionQA benchmark-100 manually curated questions across 34
versioned technical documents-VersionRAG achieves 90% accuracy, outperforming
naive RAG (58%) and GraphRAG (64%). VersionRAG reaches 60% accuracy on implicit
change detection where baselines fail (0-10%), demonstrating its ability to
track undocumented modifications. Additionally, VersionRAG requires 97% fewer
tokens during indexing than GraphRAG, making it practical for large-scale
deployment. Our work establishes versioned document QA as a distinct task and
provides both a solution and benchmark for future research.

</details>


### [10] [ReasonEmbed: Enhanced Text Embeddings for Reasoning-Intensive Document Retrieval](https://arxiv.org/abs/2510.08252)
*Jianlyu Chen,Junwei Lan,Chaofan Li,Defu Lian,Zheng Liu*

Main category: cs.IR

TL;DR: ReasonEmbed是一种专为推理密集型文档检索设计的文本嵌入模型，通过ReMixer数据合成方法和Redapter自适应学习算法，在多个骨干网络上实现了推理密集型检索任务的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 解决推理密集型文档检索中现有文本嵌入模型性能不足的问题，特别是处理复杂语义关系和推理强度高的查询-文档对。

Method: 提出ReMixer数据合成方法克服合成数据集的平凡性问题，生成82K高质量训练样本；设计Redapter自适应学习算法动态调整样本权重；在多个不同规模的骨干网络上实现ReasonEmbed。

Result: ReasonEmbed-Qwen3-8B模型在BRIGHT基准测试中达到创纪录的nDCG@10分数38.1，显著优于现有文本嵌入模型。

Conclusion: ReasonEmbed在推理密集型检索任务中表现出色，作者将开源所有相关资源以推动该领域研究进展。

Abstract: In this paper, we introduce ReasonEmbed, a novel text embedding model
developed for reasoning-intensive document retrieval. Our work includes three
key technical contributions. First, we propose ReMixer, a new data synthesis
method that overcomes the triviality problem prevalent in previous synthetic
datasets, enabling large-scale production of 82K high-quality training samples.
Second, we design Redapter, a self-adaptive learning algorithm that dynamically
adjusts training each sample's weight based on its reasoning intensity. This
allows the model to effectively capture the complex semantic relationships
between queries and documents. Third, we implement ReasonEmbed across multiple
backbones of varying sizes, all of which achieve superior performance on
reasoning-intensive retrieval tasks. Notably, our ReasonEmbed-Qwen3-8B model
offers a record-high nDCG@10 score of 38.1 on the BRIGHT benchmark, which
significantly outperforms existing text embedding models. We will fully
open-source our created resources in ReasonEmbed to push forward the research
advancement in this field.

</details>


### [11] [Mobile Gamer Lifetime Value Prediction via Objective Decomposition and Reconstruction](https://arxiv.org/abs/2510.08281)
*Tianwei Li,Yu Zhao,Yunze Li,Sheng Li*

Main category: cs.IR

TL;DR: 提出了一种新的用户终身价值预测方法，通过目标分解和重构框架解决分布挑战，在移动游戏广告系统中优于现有方法


<details>
  <summary>Details</summary>
Motivation: RTB广告服务需要准确预测用户终身价值来优化广告分配效率和投资回报率，但现有方法对异常值敏感且效果有限

Method: 基于移动游戏内购买特性，先预测特定价格下的交易次数，然后从这些中间预测计算总支付金额

Result: 在真实工业数据集上评估，并在TapTap RTB广告系统中进行在线A/B测试，与最先进的ZILN模型对比

Conclusion: 提出的目标分解和重构框架能有效解决LTV分布复杂性问题，提高预测准确性

Abstract: For Internet platforms operating real-time bidding (RTB) advertising service,
a comprehensive understanding of user lifetime value (LTV) plays a pivotal role
in optimizing advertisement allocation efficiency and maximizing the return on
investment (ROI) for advertisement sponsors, thereby facilitating growth of
commercialization revenue for the platform. However, the inherent complexity of
user LTV distributions induces significant challenges in accurate LTV
prediction. Existing state-of-the-art works, which primarily focus on directly
learning the LTV distributions through well-designed loss functions, achieve
limited success due to their vulnerability to outliers. In this paper, we
proposed a novel LTV prediction method to address distribution challenges
through an objective decomposition and reconstruction framework. Briefly
speaking, based on the in-app purchase characteristics of mobile gamers, our
model was designed to first predict the number of transactions at specific
prices and then calculate the total payment amount from these intermediate
predictions. Our proposed model was evaluated through experiments on real-world
industrial dataset, and deployed on the TapTap RTB advertising system for
online A/B testing along with the state-of-the-art ZILN model.

</details>
